{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/angularjs.jpg","path":"images/angularjs.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/bg.jpg","path":"images/bg.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/bg3.jpg","path":"images/bg3.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/bgimg.png","path":"images/bgimg.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/bitbucket.png","path":"images/bitbucket.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/bgpic.png","path":"images/bgpic.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/bgpic0.png","path":"images/bgpic0.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/coding.png","path":"images/coding.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/django.jpg","path":"images/django.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/express.png","path":"images/express.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/fesa.svg","path":"images/fesa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/flask.png","path":"images/flask.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/github.png","path":"images/github.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/her.jpg","path":"images/her.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/me.jpg","path":"images/me.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/nodejs.jpg","path":"images/nodejs.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/noperson.png","path":"images/noperson.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/pen.png","path":"images/pen.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/python.jpg","path":"images/python.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/rss.png","path":"images/rss.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/scrapy.png","path":"images/scrapy.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/green.svg","path":"images/green.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/ipplog.png","path":"images/ipplog.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/sina.png","path":"images/sina.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/Dijkstra/Dijkstra_Animation.gif","path":"images/Dijkstra/Dijkstra_Animation.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/Dijkstra/path.jpg","path":"images/Dijkstra/path.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mycat高可用方案.png","path":"images/Mycat/mycat高可用方案.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/TiDB/整体架构.png","path":"images/TiDB/整体架构.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Redis设计与实现.png","path":"images/books/Redis设计与实现.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/effectivejava.jpg","path":"images/books/effectivejava.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/从Paxos到Zookeeper.jpg","path":"images/books/从Paxos到Zookeeper.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/分布式Java应用.jpg","path":"images/books/分布式Java应用.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/分布式系统原理介绍.png","path":"images/books/分布式系统原理介绍.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/大型网站技术架构.png","path":"images/books/大型网站技术架构.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/大型网站系统与Java中间件实战.png","path":"images/books/大型网站系统与Java中间件实战.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/机器学习.png","path":"images/books/机器学习.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/深入分析javaWEB.jpg","path":"images/books/深入分析javaWEB.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/ghost.png","path":"images/ghost.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/最佳实践.jpg","path":"images/Mycat/最佳实践.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/hexo.png","path":"images/hexo.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/3.png","path":"images/rocketmq/3.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/从库变主库.png","path":"images/分库分表/从库变主库.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/从库变主库2.png","path":"images/分库分表/从库变主库2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/代理层特点.png","path":"images/分库分表/代理层特点.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/从库变主库1.png","path":"images/分库分表/从库变主库1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/双写迁移.png","path":"images/分库分表/双写迁移.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/双写迁移1.png","path":"images/分库分表/双写迁移1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/双写迁移2.png","path":"images/分库分表/双写迁移2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/驱动层方案.png","path":"images/分库分表/驱动层方案.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/密码学/图解密码技术.jpg","path":"images/密码学/图解密码技术.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/驱动层特点.png","path":"images/分库分表/驱动层特点.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/引擎流程.png","path":"images/推荐/引擎流程.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/数据挖掘/挖掘任务.png","path":"images/数据挖掘/挖掘任务.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/数据挖掘/知识发现.png","path":"images/数据挖掘/知识发现.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/数据挖掘/领域知识.png","path":"images/数据挖掘/领域知识.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/heritrix.jpg","path":"images/架构/heritrix.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/listener.png","path":"images/架构/listener.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/nutch.png","path":"images/架构/nutch.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/scrapy.png","path":"images/架构/scrapy.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/Java代码-roc.png","path":"images/算法/Java代码-roc.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/roc_output.png","path":"images/算法/roc_output.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/Java代码.png","path":"images/算法/Java代码.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/mahout代码.png","path":"images/算法/mahout代码.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/编程语言/动态类型语言.png","path":"images/编程语言/动态类型语言.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/编程语言/动态语言.png","path":"images/编程语言/动态语言.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/编程语言/混合语言.png","path":"images/编程语言/混合语言.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/编程语言/编译语言.png","path":"images/编程语言/编译语言.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/编程语言/解释语言.png","path":"images/编程语言/解释语言.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/项目管理/能力一般.png","path":"images/项目管理/能力一般.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/项目管理/能力较差.png","path":"images/项目管理/能力较差.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/项目管理/能力较强.png","path":"images/项目管理/能力较强.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/项目管理/需求分析.png","path":"images/项目管理/需求分析.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/文章背景.jpg","path":"images/文章背景.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/images/项目管理/搜集需求.png","path":"images/项目管理/搜集需求.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/Dijkstra/Dijkstra_detail.jpg","path":"images/Dijkstra/Dijkstra_detail.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/Dijkstra/Dijkstras_progress_animation.gif","path":"images/Dijkstra/Dijkstras_progress_animation.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/JVM/工具集合与命令.png","path":"images/JVM/工具集合与命令.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/TiDB/存储层.png","path":"images/TiDB/存储层.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/TiDB/计算层.png","path":"images/TiDB/计算层.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/bg1.jpg","path":"images/bg1.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/TiDB/运算层.png","path":"images/TiDB/运算层.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Netty权威指南.PNG","path":"images/books/Netty权威指南.PNG","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/ZooKeeper分布式过程协同技术详解.jpg","path":"images/books/ZooKeeper分布式过程协同技术详解.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/compiler.jpg","path":"images/books/compiler.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/java多线程编程核心技术.jpg","path":"images/books/java多线程编程核心技术.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/recommender-handbook.png","path":"images/books/recommender-handbook.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/分布式服务框架原理与实践.jpg","path":"images/books/分布式服务框架原理与实践.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/大数据日知录.jpg","path":"images/books/大数据日知录.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/推荐系统实战.png","path":"images/books/推荐系统实战.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/深入理解Java虚拟机.png","path":"images/books/深入理解Java虚拟机.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mahout/neighbDiagram.jpg","path":"images/mahout/neighbDiagram.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/shared-key.png","path":"images/mongodb/shared-key.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/复本-写.png","path":"images/mongodb/复本-写.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/复本-读.png","path":"images/mongodb/复本-读.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/1.png","path":"images/rocketmq/1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/rmq-basic-arc.png","path":"images/rocketmq/rmq-basic-arc.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/代理层典型实现.png","path":"images/分库分表/代理层典型实现.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/代理层方案.png","path":"images/分库分表/代理层方案.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/receng.png","path":"images/推荐/receng.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/中文单词词性表.png","path":"images/推荐/中文单词词性表.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/分库分表/驱动层典型实现.png","path":"images/分库分表/驱动层典型实现.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/推荐系统.png","path":"images/推荐/推荐系统.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/英文单词词性表.jpg","path":"images/推荐/英文单词词性表.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/数据挖掘/聚类分析.png","path":"images/数据挖掘/聚类分析.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/ActiveMQ使用场景总结.png","path":"images/架构/ActiveMQ使用场景总结.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/cas认证流程.png","path":"images/架构/cas认证流程.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/arc.png","path":"images/Mycat/arc.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案3.png","path":"images/Mycat/mysql高可用方案3.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案4.png","path":"images/Mycat/mysql高可用方案4.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/主从复制方式.png","path":"images/Mycat/主从复制方式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案5.png","path":"images/Mycat/mysql高可用方案5.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/HTTP权威指南.png","path":"images/books/HTTP权威指南.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Hadoop权威指南.png","path":"images/books/Hadoop权威指南.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/七周七并发模型.png","path":"images/books/七周七并发模型.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/BIO-字符流.png","path":"images/java源码/BIO-字符流.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/跟我学Shiro.png","path":"images/books/跟我学Shiro.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/2.png","path":"images/rocketmq/2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/config-server.png","path":"images/mongodb/config-server.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/存储机制.png","path":"images/rocketmq/存储机制.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/事务消息实现.png","path":"images/rocketmq/事务消息实现.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/rocketmq/交互流程.png","path":"images/rocketmq/交互流程.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/密码学/加密.png","path":"images/密码学/加密.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/webxml.png","path":"images/架构/webxml.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/redis验证.png","path":"images/架构/配置/redis验证.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/tomcat-session1.png","path":"images/架构/配置/tomcat-session1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/消息队列-分布式.png","path":"images/架构/消息队列-分布式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/系统架构图-双高.png","path":"images/架构/系统架构图-双高.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/tomcat-session2.png","path":"images/架构/配置/tomcat-session2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/tomcat-session3.png","path":"images/架构/配置/tomcat-session3.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/tomcat-session4.png","path":"images/架构/配置/tomcat-session4.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/advice.png","path":"images/算法/K-means/advice.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/costfunction.png","path":"images/算法/K-means/costfunction.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/dimensionality.png","path":"images/算法/K-means/dimensionality.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/init.png","path":"images/算法/K-means/init.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/pca-num.png","path":"images/算法/K-means/pca-num.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/pca.png","path":"images/算法/K-means/pca.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/unzip.png","path":"images/算法/K-means/unzip.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/costfunction.png","path":"images/算法/SVM/costfunction.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/kernel.png","path":"images/算法/SVM/kernel.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/largemargin.png","path":"images/算法/SVM/largemargin.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/other.png","path":"images/算法/SVM/other.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/vs.png","path":"images/算法/SVM/vs.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/K-means/principal.png","path":"images/算法/K-means/principal.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/kernel-simila.png","path":"images/算法/SVM/kernel-simila.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/二项分布.png","path":"images/算法/最大似然/二项分布.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/二项分布解析.png","path":"images/算法/最大似然/二项分布解析.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/似然函数.png","path":"images/算法/最大似然/似然函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/偏导数.png","path":"images/算法/最大似然/偏导数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/偏导数为0.png","path":"images/算法/最大似然/偏导数为0.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/对数似然.png","path":"images/算法/最大似然/对数似然.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/对数似然函数.png","path":"images/算法/最大似然/对数似然函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/抛硬币似然函数.png","path":"images/算法/最大似然/抛硬币似然函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/概率密度函数.png","path":"images/算法/最大似然/概率密度函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最大似然/线性回归模型.png","path":"images/算法/最大似然/线性回归模型.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/c偏导数.png","path":"images/算法/最小二乘法/c偏导数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/c偏导数为0.png","path":"images/算法/最小二乘法/c偏导数为0.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/m偏导数.png","path":"images/算法/最小二乘法/m偏导数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/代价函数.png","path":"images/算法/最小二乘法/代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/偏导数.png","path":"images/算法/最小二乘法/偏导数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/回归模型.png","path":"images/算法/最小二乘法/回归模型.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/平方差.png","path":"images/算法/最小二乘法/平方差.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/平方损失函数.png","path":"images/算法/最小二乘法/平方损失函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/模型变换.png","path":"images/算法/最小二乘法/模型变换.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/转置-代价函数.png","path":"images/算法/最小二乘法/转置-代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/杰卡德相似系数/octave.png","path":"images/算法/杰卡德相似系数/octave.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/杰卡德相似系数/octave_result.png","path":"images/算法/杰卡德相似系数/octave_result.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/杰卡德相似系数/公式.png","path":"images/算法/杰卡德相似系数/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/汉明距离/octave.png","path":"images/算法/汉明距离/octave.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/汉明距离/octave_result.png","path":"images/算法/汉明距离/octave_result.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/汉明距离/公式.png","path":"images/算法/汉明距离/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔斯曼/代码.png","path":"images/算法/皮尔斯曼/代码.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/mahout.png","path":"images/算法/皮尔森相关/mahout.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/协方差.png","path":"images/算法/皮尔森相关/协方差.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/数学公式.png","path":"images/算法/皮尔森相关/数学公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/方差.png","path":"images/算法/皮尔森相关/方差.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/标准差.png","path":"images/算法/皮尔森相关/标准差.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/backpropagation-impl.png","path":"images/算法/神经网络/backpropagation-impl.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/backpropagation.png","path":"images/算法/神经网络/backpropagation.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/costfunction.png","path":"images/算法/神经网络/costfunction.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/multi-class.png","path":"images/算法/神经网络/multi-class.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/other.png","path":"images/算法/神经网络/other.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/vector.png","path":"images/算法/神经网络/vector.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/谷本系数/公式.png","path":"images/算法/谷本系数/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/S函数.png","path":"images/算法/逻辑回归/S函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/函数范围.png","path":"images/算法/逻辑回归/函数范围.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-代价函数.png","path":"images/算法/逻辑回归/单参数-线性-代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-假设函数.png","path":"images/算法/逻辑回归/单参数-线性-假设函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-梯度下降.png","path":"images/算法/逻辑回归/单参数-线性-梯度下降.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-线性梯度下降.png","path":"images/算法/逻辑回归/单参数-线性-线性梯度下降.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png","path":"images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-代价函数.png","path":"images/算法/逻辑回归/多参数-线性-代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png","path":"images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png","path":"images/算法/逻辑回归/多参数-线性-假设函数-向量化.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数.png","path":"images/算法/逻辑回归/多参数-线性-假设函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-梯度下降.png","path":"images/算法/逻辑回归/多参数-线性-梯度下降.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-正规方程.png","path":"images/算法/逻辑回归/多参数-线性-正规方程.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/对数函数.png","path":"images/算法/逻辑回归/对数函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数.png","path":"images/算法/逻辑回归/逻辑回归-代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数1.png","path":"images/算法/逻辑回归/逻辑回归-代价函数1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数2.png","path":"images/算法/逻辑回归/逻辑回归-代价函数2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数3.png","path":"images/算法/逻辑回归/逻辑回归-代价函数3.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数向量化.png","path":"images/算法/逻辑回归/逻辑回归-代价函数向量化.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-多分类.png","path":"images/算法/逻辑回归/逻辑回归-多分类.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-梯度下降.png","path":"images/算法/逻辑回归/逻辑回归-梯度下降.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数.png","path":"images/算法/逻辑回归/逻辑回归-正则化代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png","path":"images/算法/逻辑回归/逻辑回归-正则化代价函数1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png","path":"images/算法/逻辑回归/逻辑回归-正则化代价函数2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png","path":"images/算法/逻辑回归/逻辑回归-正则化梯度下降.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归代价函数.png","path":"images/算法/逻辑回归/逻辑回归代价函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/p1.png","path":"images/算法/闵可夫斯基/p1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/p2.png","path":"images/算法/闵可夫斯基/p2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/p25.png","path":"images/算法/闵可夫斯基/p25.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/p4.png","path":"images/算法/闵可夫斯基/p4.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/plong.png","path":"images/算法/闵可夫斯基/plong.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/公式.png","path":"images/算法/闵可夫斯基/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/公式推导.png","path":"images/算法/闵可夫斯基/公式推导.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/图形展示.png","path":"images/算法/闵可夫斯基/图形展示.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/缺点.png","path":"images/算法/闵可夫斯基/缺点.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/闵可夫斯基/计算公式.png","path":"images/算法/闵可夫斯基/计算公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/马氏距离/公式.png","path":"images/算法/马氏距离/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/马氏距离/公式1.png","path":"images/算法/马氏距离/公式1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/马氏距离/公式2.png","path":"images/算法/马氏距离/公式2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/马氏距离/图例.png","path":"images/算法/马氏距离/图例.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归函数.png","path":"images/算法/逻辑回归/逻辑回归函数.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/预测函数概率.png","path":"images/算法/逻辑回归/预测函数概率.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/逻辑回归/预测分类.png","path":"images/算法/逻辑回归/预测分类.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/余弦相似度/公式.png","path":"images/算法/余弦相似度/公式.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/余弦相似度/图例.png","path":"images/算法/余弦相似度/图例.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/TiDB/整体架构1.png","path":"images/TiDB/整体架构1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Java并发编程实践.png","path":"images/books/Java并发编程实践.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Java并发编程的艺术.png","path":"images/books/Java并发编程的艺术.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/SolrInAction.png","path":"images/books/SolrInAction.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Java并发编程实战.png","path":"images/books/Java并发编程实战.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/hotspot.jpg","path":"images/books/hotspot.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/spring技术内幕.png","path":"images/books/spring技术内幕.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/分布式系统.jpg","path":"images/books/分布式系统.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/NIO-Channel类图.png","path":"images/java源码/NIO-Channel类图.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/集合-类图.jpg","path":"images/java源码/集合-类图.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/mahout/similarDiagram.jpg","path":"images/mahout/similarDiagram.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/cas-ticket.png","path":"images/架构/配置/cas-ticket.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/配置/keepalived验证.png","path":"images/架构/配置/keepalived验证.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/svm.png","path":"images/算法/SVM/svm.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/系统架构图-备案.png","path":"images/架构/系统架构图-备案.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/SVM/逻辑回归.png","path":"images/算法/SVM/逻辑回归.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/最小二乘法/m偏导数为0.png","path":"images/算法/最小二乘法/m偏导数为0.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔斯曼/例子.png","path":"images/算法/皮尔斯曼/例子.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/皮尔森相关/例子.png","path":"images/算法/皮尔森相关/例子.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/hfunction.png","path":"images/算法/神经网络/hfunction.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案2.png","path":"images/Mycat/mysql高可用方案2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案6.png","path":"images/Mycat/mysql高可用方案6.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/spring源码深度解析.png","path":"images/books/spring源码深度解析.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/unix网络编程-卷1.png","path":"images/books/unix网络编程-卷1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/统计学习方法.png","path":"images/books/统计学习方法.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/高性能MySQL.png","path":"images/books/高性能MySQL.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/BIO-字节流.png","path":"images/java源码/BIO-字节流.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/BIO-类图.jpg","path":"images/java源码/BIO-类图.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/java源码/concurrent-self类图.jpg","path":"images/java源码/concurrent-self类图.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/混合集群-写数据.png","path":"images/mongodb/混合集群-写数据.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/混合集群-读数据.png","path":"images/mongodb/混合集群-读数据.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/mongodb/混合集群.png","path":"images/mongodb/混合集群.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/amazon.png","path":"images/推荐/amazon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/postgres方案.png","path":"images/架构/postgres方案.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/架构/架构演进.png","path":"images/架构/架构演进.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/images/Mycat/mysql高可用方案1.png","path":"images/Mycat/mysql高可用方案1.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/bg2.jpg","path":"images/bg2.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/InnoDB存储引擎.png","path":"images/books/InnoDB存储引擎.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Lucene实战.png","path":"images/books/Lucene实战.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/Spring实战3.png","path":"images/books/Spring实战3.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/tcpip-卷三.png","path":"images/books/tcpip-卷三.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/unix网络编程-卷2.png","path":"images/books/unix网络编程-卷2.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/神经网络/backpropagation-pic.png","path":"images/算法/神经网络/backpropagation-pic.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/tcpip-卷一.png","path":"images/books/tcpip-卷一.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/tcpip-卷二.png","path":"images/books/tcpip-卷二.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/深入剖析tomcat.png","path":"images/books/深入剖析tomcat.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/images/mahout/recommendDiagram.jpg","path":"images/mahout/recommendDiagram.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/images/推荐/推荐场景.png","path":"images/推荐/推荐场景.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/books/数据挖掘导论.png","path":"images/books/数据挖掘导论.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/JVM/2_内存区域与异常.png","path":"images/JVM/2_内存区域与异常.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/roc-example.png","path":"images/算法/roc-example.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/score-ranking.png","path":"images/算法/score-ranking.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/fpr-and-tpr.png","path":"images/算法/fpr-and-tpr.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/算法/均值推导过程.JPG","path":"images/算法/均值推导过程.JPG","modified":1,"renderable":1}],"Cache":[{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1543495885691},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1543495885694},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1543495885698},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1543495885729},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1543495885732},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1543495885738},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1543495885746},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1543495885741},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1543495885759},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1543495885751},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1543495885775},{"_id":"themes/next/_config.yml","hash":"5449026857fd0c432bb03a6a2b87c38eeac3b085","modified":1543495885766},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1543495885779},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1543495886183},{"_id":"source/_posts/2015-08-16-用一天时间来学习angularjs.md","hash":"1c85e63eab752484ca4f1274c59ba7af342b20ac","modified":1543495884467},{"_id":"source/_posts/2015-08-31-四个例子入门NodeJS.md","hash":"6414cc097573949b0651bda41db4979604d5cd79","modified":1543495884554},{"_id":"source/_posts/2015-09-25-基于NodeJS的开发框架和优秀项目.md","hash":"6e553e2dac349d59cd56e4de376a8ad90a89551b","modified":1543495884558},{"_id":"source/_posts/2015-09-25-开始使用Python吧.md","hash":"b7439f2c9f2ac663ba795d4a5e0f372b61cd98f3","modified":1543495884562},{"_id":"source/_posts/2015-10-27-Web技术架构演进.md","hash":"024e39613fa49524a3b7932b111da7c5af79b95c","modified":1543495884571},{"_id":"source/_posts/2016-02-22-深入理解Java虚拟机-内存区域与内存溢出异常.md","hash":"f451e1f6f8e83198ffe1150985fcb2615a6a1496","modified":1543495884597},{"_id":"source/_posts/2015-09-28-求最短路径算法-Dijkstra.md","hash":"099f05110f713baa4680baafac3044c5ad95cebf","modified":1543495884567},{"_id":"source/_posts/2015-11-01-项目管理之如何提高工作效率.md","hash":"5101d9b910277a917a0b26ecb151ff6e63e13ef9","modified":1543495884579},{"_id":"source/_posts/2016-01-17-如何做好一个项目型的需求分析.md","hash":"396bf3edaea14b7aef8f9e24e88762e0ab0c8540","modified":1543495884591},{"_id":"source/_posts/2015-12-27-消息中间件ActiveMQ双高架构演进.md","hash":"8457abc3595c492735f54339c55cb198c0f80724","modified":1543495884585},{"_id":"source/_posts/2016-03-10-系统架构总结之高可用高负载.md","hash":"444596eb5cf6985faa3e7a8f83a593595f0f8af7","modified":1543495884603},{"_id":"source/_posts/2016-04-08-JDK源码分析之BIO类汇总.md","hash":"9c51e51dfc06b0f5f812b64d5d2c4b34eadaa2aa","modified":1551102836689},{"_id":"source/_posts/2016-04-08-JDK源码分析之NIO类汇总.md","hash":"ee4408850276942c400ad466a8e8cc90738a13ff","modified":1551103870003},{"_id":"source/_posts/2016-04-08-JDK源码分析之并发类汇总.md","hash":"35bac1b821d745315d38dc1c138196a0f0ff951e","modified":1543495884655},{"_id":"source/_posts/2016-03-14-SSO解决方案汇总.md","hash":"2851394f2d8f5e86c85603e4c603e78e93bca497","modified":1543495884641},{"_id":"source/_posts/2016-04-10-互联网团队技术架构-新浪微博.md","hash":"63a1bacf1bd9fc519b1e13ea5563aaf577ec3345","modified":1543495884659},{"_id":"source/_posts/2016-06-28-数字签名过程图解.md","hash":"e490cfe072fc6df8976a739000248a5a0a97ce74","modified":1551104208058},{"_id":"source/_posts/2016-06-13-Mahout构建推荐系统-相似度算法.md","hash":"be887644455df41da923944856896a1ef9550f43","modified":1543495884668},{"_id":"source/_posts/2016-07-20-推荐系统建设流程.md","hash":"06cd4973c93d7565100f0ba73a8d8ba229091aa3","modified":1543495884675},{"_id":"source/_posts/2016-04-04-JDK源码分析之集合类汇总.md","hash":"a839aa85b624714d58645a71c181367a671a8898","modified":1543495884645},{"_id":"source/_posts/2016-09-15-中英文词性表.md","hash":"a53016e9285f8aba764894a9352948bf2081f028","modified":1543495884696},{"_id":"source/_posts/2016-04-15-Java内存模型与线程同步问题整理.md","hash":"365c98995a974f3a6c398cbcd02d9a659c277c0b","modified":1543495884664},{"_id":"source/_posts/2016-07-22-推荐场景1-推荐用户已购买的内容.md","hash":"01ce55e6d48926dd3691289bf0bd2d880a0b2e21","modified":1543495884682},{"_id":"source/_posts/2016-07-22-Docker常用指令备忘录.md","hash":"55acc5077ca676af505087907a74a67b12ca35a4","modified":1543495884679},{"_id":"source/_posts/2016-08-20-Servlet配置总结.md","hash":"810de14ff0e4e072a0931521378b841b7755d348","modified":1543495884689},{"_id":"source/_posts/2016-09-21-均值公式推导.md","hash":"bb7ded26aac708420d84bd422cab924cacce0fa5","modified":1543495884702},{"_id":"source/_posts/2016-09-22-ROC曲线生成器.md","hash":"17e96a614ed0ed239012912e0b31529920a92dca","modified":1543495884940},{"_id":"source/_posts/2016-11-22-机器学习算法总览表.md","hash":"8596ced7513863829f96d6c67d31a17cd97d86f9","modified":1543495884944},{"_id":"source/_posts/2016-11-23-机器学习算法-回归-梯度下降(GradientDescent).md","hash":"5d5f90ebfaae8dad565b29e4e6a4c3b15acfcfee","modified":1543495884953},{"_id":"source/_posts/2016-11-23-机器学习算法-分类-LogisticRegression(逻辑回归).md","hash":"b5a5b54e0cd30cbb936c4f2ba77c709edf8ae20d","modified":1543495884949},{"_id":"source/_posts/2016-11-24-机器学习算法-分类-NeuralNetwork(神经网络).md","hash":"27f0848281d9b5dab8adf32ff442593786ad8ddb","modified":1543495884959},{"_id":"source/_posts/2016-11-25-机器学习算法-分类-SVM(支持向量机).md","hash":"098007ae4b8ccb1c17e5df004093ac11dc414686","modified":1543495884963},{"_id":"source/_posts/2016-11-27-机器学习算法-聚类-K-Means(K均值).md","hash":"1a995f6e2cbe5b20c67a1bee2eb78ad9661964ca","modified":1543495884968},{"_id":"source/_posts/2016-11-28-机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离).md","hash":"ae8c8a84d00fd81d3617214780e97b714d3830ac","modified":1543495884976},{"_id":"source/_posts/2016-11-29-机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度).md","hash":"a17306b5fadf999fd224aeb583a7c6299b33f9ea","modified":1543495884983},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-CosineSimilarity(余弦相似度).md","hash":"bfb02c6a57d9f2943c98ff36ed1b5dde7102bb94","modified":1543495884990},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-HammingDistance(汉明距离).md","hash":"bfb50b6f6c27c3d251ea41a587c3bc54b978c816","modified":1543495884997},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数).md","hash":"8f9429b166689d6d2680d545f327147351830e01","modified":1543495885008},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-MahalanobisDistance(马氏距离).md","hash":"90d6bf75098ec7548973b10d906f3b8ed0c0d593","modified":1543495885019},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度).md","hash":"b7f08721965ae9b0a519a093fcf21819024766d5","modified":1543495885036},{"_id":"source/_posts/2016-12-17-Web架构基础-四部件.md","hash":"dd98b19c6699da71cabb145515e69839df3bae79","modified":1543495885048},{"_id":"source/_posts/2016-12-20-Duke-快速的相似数据过滤引擎.md","hash":"d137887bbe071db6972331f0bbd4149821577395","modified":1543495885062},{"_id":"source/_posts/2016-12-23-推荐系统比较-阿里RecEng、Amazon和开源EasyRrec.md","hash":"048703871e27ded047baf53ae7521e653aed1a7d","modified":1543495885143},{"_id":"source/_posts/2016-12-25-推荐系统比较重要的期刊和学术会议.md","hash":"6f636c2956427b6d3cfccfdb903337bf89e97088","modified":1543495885154},{"_id":"source/_posts/2016-12-28-数据挖掘导论-读书笔记.md","hash":"b6f6d9b37219e8f7359cb02cbb6a957184de7d04","modified":1543495885182},{"_id":"source/_posts/2016-12-29-决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法.md","hash":"3348e589cdd51691b91ac7d8176906b3116a817f","modified":1543495885187},{"_id":"source/_posts/2016-12-31-机器学习算法-回归-最小二乘法.md","hash":"29032c31227a976f3d43ce83dc56663d4c6e8e42","modified":1543495885190},{"_id":"source/_posts/2017-01-03-机器学习算法-回归-最大似然函数.md","hash":"c57308076628f98e0196fa4c3a95a0752bd7e319","modified":1543495885194},{"_id":"source/_posts/2017-07-27-Maven-配置-插件.md","hash":"4e35d01d3394cda1c075f25c704e523502c00976","modified":1543495885290},{"_id":"source/_posts/2017-09-22-C&C++开源框架大全.md","hash":"7fd82b7065853490265186af88cce68768ac8cee","modified":1543495885292},{"_id":"source/_posts/2017-11-29-爬虫框架一二三.md","hash":"84f93885ac8d97ac4bb073138e633a1974ce84ce","modified":1543495885295},{"_id":"source/_posts/2016-11-30-机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度).md","hash":"24a9ee9f979b266ea3f56818cc5eaafedc70703c","modified":1543495885029},{"_id":"source/_posts/2018-11-29-mongoDB文档模式设计.md","hash":"26a22f332637608e49059acf1d9d6161dd665b42","modified":1543652648240},{"_id":"source/_posts/2018-11-26-RocketMQ-docker搭建.md","hash":"111c815732182c580372b3f26bab898e1599dcfe","modified":1543495885297},{"_id":"source/_posts/2017-04-09-CSS布局(layout)三大器-display-position-float.md","hash":"b8c6d4b3af053f4a1fb2847962a7443a9a6adfd4","modified":1543652648230},{"_id":"source/_posts/2017-02-20-JWT-基于Token的身份验证.md","hash":"ce8ac5db6b8f4392d838a8d8a236042fecb07929","modified":1543652648223},{"_id":"source/_posts/2018-12-02-MySQL读写分离方案选型.md","hash":"7b4854007b2ab0b5ae21c11c77dfb345f5956da1","modified":1543930054969},{"_id":"source/_posts/2018-11-30-NoSQL方案选型.md","hash":"04ecd78714f496e89e8322c83e5f86dfa0bf2e2a","modified":1543652648246},{"_id":"source/_posts/2018-12-04-Mycat中间件指南.md","hash":"cf1e021e89c9654cbbebd7a96b7db65bbe042b86","modified":1543930054977},{"_id":"source/_posts/2018-11-30-mongoDB架构与集群.md","hash":"d0e41b986b739d14e1d57dec8682ab687330b7a0","modified":1543841760646},{"_id":"source/_posts/2018-12-25-编译解释语言-静态动态语言-静态类型动态类型语言.md","hash":"2c50137b2306501a92d0a4bc3e64ea266f54217c","modified":1551104208058},{"_id":"source/_posts/2019-01-22-密码学入门.md","hash":"79fd938f69a029ae688cb87e7b1ae2850d0ce3a8","modified":1551104208058},{"_id":"source/_posts/2019-01-21-Java优秀框架源码学习.md","hash":"8b80b227920713896d446e2e4578ddaa2ba2f595","modified":1551104208058},{"_id":"source/_posts/2018-12-03-TiDB数据库指南.md","hash":"e9b6e26d9acaa198572004ab4cc191ab753aa988","modified":1545547848828},{"_id":"source/categories/index.md","hash":"31d1951e7ddfc9b4dce8e9e864aabf9fe85d8038","modified":1543495885310},{"_id":"source/tags/index.md","hash":"f8ff9ee84a6aa61636019bda82d4bbe999510c4a","modified":1543495885312},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1543495885711},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"a0a82dbfabdef9a9d7c17a08ceebfb4052d98d81","modified":1543495885716},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1543495885721},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1543495885726},{"_id":"source/_posts/2018-12-01-MySQL分库分表方案选型.md","hash":"44e469c7ff18c938331922ce92c416899590cb5f","modified":1543930054925},{"_id":"source/_posts/2018-12-05-分布式事务实现方案.md","hash":"3b12b456cc20770d3b0c4ef84c3c008cae9993bc","modified":1551104208058},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1543495885784},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1543495885791},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1543495885794},{"_id":"source/about/index.md","hash":"8d8acb34adfb1a3178179eef16274d2f970a0edd","modified":1543652648297},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1543495885798},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1543495885808},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1543495885829},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1543495885832},{"_id":"source/_posts/2018-12-05-RocketMQ中间件指南.md","hash":"798d4f8ca6437eb8555f48e419240ce061817046","modified":1544016268737},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1543495885837},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1543495885854},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1543495885868},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1543495885842},{"_id":"source/_posts/2016-03-13-双高配置之Nginx+Keepalived整理.md","hash":"e00eb7ed0db32cfe7a9160bb23a605cc78c497f8","modified":1543495884633},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1543495885872},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1543495885876},{"_id":"themes/next/layout/_layout.swig","hash":"2164570bb05db11ee4bcfbbb5d183a759afe9d07","modified":1543495885894},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1543495886164},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1543495886167},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1543495886170},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1543495886173},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1543495886187},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1543495886193},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1543495886175},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1543495886180},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1543495886178},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1543495888540},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1543495888542},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1543495888545},{"_id":"source/_posts/2015-07-29-大数据处理工具汇总.md","hash":"1cf4d996be234ad11a4e9457ebd048dbee09adc3","modified":1543495884462},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1543495885788},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1543495885812},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1543495885816},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886697},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1543495885885},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1543495885891},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1543495885900},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1543495885907},{"_id":"themes/next/layout/_macro/post.swig","hash":"4ba938822d56c597490f0731893eaa2443942e0f","modified":1543495885911},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1543495885934},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1543495885915},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1543495885940},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1543495885963},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1543495885967},{"_id":"themes/next/layout/_partials/footer.swig","hash":"26e93336dc57a39590ba8dc80564a1d2ad5ff93b","modified":1543495885943},{"_id":"themes/next/layout/_partials/head.swig","hash":"f14a39dad1ddd98e6d3ceb25dda092ba80d391b5","modified":1543495885948},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1543495885975},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1543495886015},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1543495886020},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1543495885960},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1543495886118},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1543495886121},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1543495886038},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1543495886125},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1543495886127},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1543495886138},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1543495886130},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1543495886133},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1543495886201},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1543495886206},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1543495886208},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1543495886211},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1543495886215},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1543495886221},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1543495886224},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1543495886229},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1543495886234},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"9c7343fd470e0943ebd75f227a083a980816290b","modified":1543495885922},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1543495886694},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1543495886752},{"_id":"themes/next/source/images/angularjs.jpg","hash":"d0b1234c59daf81c16033fcfc74d75e9793a60af","modified":1543495886756},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1543495886759},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1543495886762},{"_id":"themes/next/source/images/bg.jpg","hash":"071c900b3057fdd9655df95d7c90d2c0cb88af55","modified":1543495886765},{"_id":"themes/next/source/images/bg3.jpg","hash":"410782fdc71eb7c8792ee247d1fc433adaeb1b57","modified":1543495886785},{"_id":"themes/next/source/images/bgimg.png","hash":"fc395a4edcaf6b9313fad316520e758397cb528d","modified":1543495886788},{"_id":"themes/next/source/images/bitbucket.png","hash":"febf3b232f2a49a516dc28d2c7fa3dd61e62da53","modified":1543495886797},{"_id":"themes/next/source/images/bgpic.png","hash":"2a849338d18f9aaf908a2d2b06621ebbffd2ecbd","modified":1543495886792},{"_id":"themes/next/source/images/bgpic0.png","hash":"6e73ee58cd171366351ca552e1ef3578c8638480","modified":1543495886795},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1543495887033},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1543495887038},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1543495887041},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1543495887043},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1543495887046},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1543495887048},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1543495887063},{"_id":"themes/next/source/images/coding.png","hash":"43c2eb1d32f195390a687dbaa8c0fbc87008d191","modified":1543495887053},{"_id":"themes/next/source/images/django.jpg","hash":"a65e192962ba768837839100bc8e332b40cd2b21","modified":1543495887056},{"_id":"themes/next/source/images/express.png","hash":"a6bac67c3afbe46ccc856ba321a20fb738bc1a0d","modified":1543495887061},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1543495887068},{"_id":"themes/next/source/images/fesa.svg","hash":"6e032f3ae27d2ff3b4a09995ac2e94f94e5f6d08","modified":1543495887078},{"_id":"themes/next/source/images/flask.png","hash":"366722fdfbbcfdbdc2bae828ee5d7f67a52732a3","modified":1543495887081},{"_id":"themes/next/source/images/github.png","hash":"bafd339840dd76379b78f237647e4c53b951d2e0","modified":1543495887090},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1543495887128},{"_id":"themes/next/source/images/her.jpg","hash":"25a462d13264fd3c573e1b67e5af1b3bd89e689e","modified":1543495887096},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1543495887131},{"_id":"themes/next/source/images/me.jpg","hash":"5c35557e653107656e126d3a473206146ee878e7","modified":1543495887160},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1543495887171},{"_id":"themes/next/source/images/nodejs.jpg","hash":"e026e84aa25f94c791c4bc78cfddd69439fe0962","modified":1543495887163},{"_id":"themes/next/source/images/noperson.png","hash":"84584792072dc538b323816ed87100915da29cfb","modified":1543495887166},{"_id":"themes/next/source/images/pen.png","hash":"09a6cb07329f1d2b878072746bf58705fc9c78e5","modified":1543495887169},{"_id":"themes/next/source/images/python.jpg","hash":"b694df795d82fb21c7cf8b21588d5cbf4a524230","modified":1543495887174},{"_id":"themes/next/source/images/rss.png","hash":"96fdc18e76c1b5466273080f7e2dd3d711b5e781","modified":1543495887198},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1543495887179},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1543495887203},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1543495887176},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886029},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886030},{"_id":"themes/next/source/images/scrapy.png","hash":"38c20f758a3102b030f44d8e3d385adc8fee2103","modified":1543495887201},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886548},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886549},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886560},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886672},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1543495886690},{"_id":"themes/next/source/images/green.svg","hash":"7f25513aff6152b1d94b82afcb1f8d80fb0ec1ea","modified":1543495887093},{"_id":"themes/next/source/images/ipplog.png","hash":"9467bcc20a6f74bbb58d06a99c4f856b2d70bf79","modified":1543495887104},{"_id":"themes/next/source/images/sina.png","hash":"6f0e64139a7cc9102c5eafdf283632049e3f822e","modified":1543495887206},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1543495887036},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1543495885953},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1543495885981},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1543495885998},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1543495885956},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1543495886024},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1543495886028},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1543495886035},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1543495886001},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1543495886051},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1543495886005},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1543495886057},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1543495886059},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1543495886054},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1543495886064},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1543495886068},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1543495886062},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1543495886075},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1543495886077},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1543495886071},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1543495886080},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1543495886084},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1543495886088},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1543495886091},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1543495886095},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1543495886102},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1543495886099},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1543495886107},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1543495886114},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1543495886151},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1543495886110},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1543495886154},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1543495886161},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1543495886534},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1543495886543},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1543495886553},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1543495886157},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1543495886559},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1543495886671},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1543495886668},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1543495886682},{"_id":"themes/next/source/css/_variables/base.styl","hash":"b1f6ea881a4938a54603d68282b0f8efb4d7915d","modified":1543495886687},{"_id":"themes/next/source/images/Dijkstra/Dijkstra_Animation.gif","hash":"f50ae8c51775e589530b202184f15ee8bb04b3d1","modified":1543495886707},{"_id":"themes/next/source/images/Dijkstra/path.jpg","hash":"94519128d07617303b8144690f4a66a7d3bcd97f","modified":1543495886722},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1543495886011},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1543495886047},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1543495886044},{"_id":"themes/next/source/images/Mycat/mycat高可用方案.png","hash":"9d56df5415d570c25c559bf2bab970f3081459d3","modified":1543930055078},{"_id":"themes/next/source/images/TiDB/整体架构.png","hash":"830e238375ebef4b83fb50213e17745ff8f6717f","modified":1543841760693},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1543495885994},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1543495885985},{"_id":"themes/next/source/images/books/Redis设计与实现.png","hash":"045cc29c4d5ebae10df0dad4cb7533cdd9fc2b05","modified":1543495886854},{"_id":"themes/next/source/images/books/effectivejava.jpg","hash":"9acdcf1d5004cddbcdac1259190fa0b4ab580888","modified":1543495886880},{"_id":"themes/next/source/images/books/从Paxos到Zookeeper.jpg","hash":"67997e6d8a81cbf45b3fd696ff4f78e23dde364e","modified":1543495886951},{"_id":"themes/next/source/images/books/分布式Java应用.jpg","hash":"02f30d71411c5225b5ae419ae1f81d797c55e8c7","modified":1543495886956},{"_id":"themes/next/source/images/books/分布式系统原理介绍.png","hash":"8050be2a5bec6336c8b8390533febe704d351c8d","modified":1543495886971},{"_id":"themes/next/source/images/books/大型网站技术架构.png","hash":"bb6c818e8a1939d8da0895129698474256e718ec","modified":1543495886973},{"_id":"themes/next/source/images/books/大型网站系统与Java中间件实战.png","hash":"3aae3ae3902e2b26dc11c33a62e01d38a67e10c5","modified":1543495886976},{"_id":"themes/next/source/images/books/机器学习.png","hash":"51d5c1560fc10111f0f278a82f74489086794505","modified":1543495886996},{"_id":"themes/next/source/images/books/深入分析javaWEB.jpg","hash":"c3fb608b89cf0dddbef6dcaea7ef7ec91466dfaa","modified":1543495887001},{"_id":"themes/next/source/images/ghost.png","hash":"637a1de20532b3fc435af1c96b68f9a0e93fe758","modified":1543495887088},{"_id":"themes/next/source/images/Mycat/最佳实践.jpg","hash":"f9abe2e39f0cd5d8580bd6f2552fdc805e29861b","modified":1543930055339},{"_id":"themes/next/source/images/hexo.png","hash":"0cdd06b944222da6248d3a5ec2b0efc2b79332c3","modified":1543495887100},{"_id":"themes/next/source/images/rocketmq/3.png","hash":"0c08690fdb336c258361e956f7b198198c462d83","modified":1543495887195},{"_id":"themes/next/source/images/分库分表/从库变主库.png","hash":"41b6c37db08f1f9f376731c55deda8b34ef91b04","modified":1543841760724},{"_id":"themes/next/source/images/分库分表/从库变主库2.png","hash":"65d86727de27408ab4d1010f7a057b2e2cdf25fe","modified":1543841760724},{"_id":"themes/next/source/images/分库分表/代理层特点.png","hash":"b121e7a3e83bee45c276e1ca79f18d2a12cb16d4","modified":1543658331659},{"_id":"themes/next/source/images/分库分表/从库变主库1.png","hash":"be47e286ac03b5ed58408214d101304153a1b609","modified":1543841760724},{"_id":"themes/next/source/images/分库分表/双写迁移.png","hash":"889c8c950060bbe81e4c1cdfffd100981c564c39","modified":1543841760739},{"_id":"themes/next/source/images/分库分表/双写迁移1.png","hash":"cf50d10874a47bad7d1b8ef6f53c03c79d98d027","modified":1543841760739},{"_id":"themes/next/source/images/分库分表/双写迁移2.png","hash":"46aae5765abef9cdcd847b44656856bd3eee5912","modified":1543841760739},{"_id":"themes/next/source/images/分库分表/驱动层方案.png","hash":"731add785dc6d6265eb9b3eec58ac137a21560fe","modified":1543657212777},{"_id":"themes/next/source/images/密码学/图解密码技术.jpg","hash":"cdaeaca07791fcba232d10bff2da8fbd092e39a9","modified":1551104208058},{"_id":"themes/next/source/images/分库分表/驱动层特点.png","hash":"34531c01ba963ab2289ed8c61ffb0aa626a74b54","modified":1543658046459},{"_id":"themes/next/source/images/推荐/引擎流程.png","hash":"ffe0066c6462bedc22837f66d6a4c2dfcc26abeb","modified":1543495887237},{"_id":"themes/next/source/images/数据挖掘/挖掘任务.png","hash":"03f92cfc0352bc5b39f1d0eba17cc830205bfa58","modified":1543495887266},{"_id":"themes/next/source/images/数据挖掘/知识发现.png","hash":"902ecce47354272c7ea50d4048897294417bde01","modified":1543495887270},{"_id":"themes/next/source/images/数据挖掘/领域知识.png","hash":"13dc6a2b88ac1c6434f386d7d36f8141fdd896d8","modified":1543495887278},{"_id":"themes/next/source/images/架构/heritrix.jpg","hash":"94ab6fbfb9152e2c2634c10555dd0520a5f91cfb","modified":1543495887298},{"_id":"themes/next/source/images/架构/listener.png","hash":"f5568b0ddae929695539eb05c0431ef925a37631","modified":1543495887302},{"_id":"themes/next/source/images/架构/nutch.png","hash":"426a682b2f872491d096a9d83ed4e5fff916b77b","modified":1543495887350},{"_id":"themes/next/source/images/架构/scrapy.png","hash":"080e78838881c3125a398e527f72f883fe73ebcd","modified":1543495887366},{"_id":"themes/next/source/images/算法/Java代码-roc.png","hash":"b400d939d3b4226686bb2bd6ff65f19d384ba874","modified":1543495887435},{"_id":"themes/next/source/images/算法/roc_output.png","hash":"bef227b1061df4fb84fb3ae82d9644866a5c8c2c","modified":1543495887559},{"_id":"themes/next/source/images/算法/Java代码.png","hash":"2f86b85c118e1bc01de36d873dd60b79beedad16","modified":1543495887438},{"_id":"themes/next/source/images/算法/mahout代码.png","hash":"b7d1ff999ee2f61d7df1b3004c0f12ea362b6dfa","modified":1543495887536},{"_id":"themes/next/source/images/编程语言/动态类型语言.png","hash":"51c1322f7dc78499edf19ae8e4e8e2232393cbe9","modified":1551104208058},{"_id":"themes/next/source/images/编程语言/动态语言.png","hash":"b3eceb43df2f4a91c076f1fef778899ef770bae5","modified":1551104208058},{"_id":"themes/next/source/images/编程语言/混合语言.png","hash":"3f21cd5d2f95924892dc24da3a12665ef6dd9644","modified":1551104208058},{"_id":"themes/next/source/images/编程语言/编译语言.png","hash":"56c3352803fe05edc13582257d19fcca755c71bb","modified":1551104208073},{"_id":"themes/next/source/images/编程语言/解释语言.png","hash":"90a3d9c907640ce67384dd6c3cc96cff1d7a59b2","modified":1551104208073},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1543495888166},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1543495888170},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1543495888162},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1543495888179},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1543495888173},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1543495888182},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1543495888189},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1543495888186},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1543495888200},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1543495888204},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1543495888197},{"_id":"themes/next/source/images/项目管理/能力一般.png","hash":"721c85c7e37470d2b6a5133a89def045e7286bd9","modified":1543495888147},{"_id":"themes/next/source/images/项目管理/能力较差.png","hash":"b42ed04408f60641160baef311afdd19566f4bfb","modified":1543495888150},{"_id":"themes/next/source/images/项目管理/能力较强.png","hash":"59bb50164548de62641948b63de2b6f76dd88a8f","modified":1543495888153},{"_id":"themes/next/source/images/项目管理/需求分析.png","hash":"365444c535e320217f9ab22a9165d71d584ccae0","modified":1543495888157},{"_id":"themes/next/source/images/文章背景.jpg","hash":"a56d64aea500b11c01b1c13bc92db2b2c7b16645","modified":1543495887284},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1543495888338},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1543495888249},{"_id":"themes/next/source/images/项目管理/搜集需求.png","hash":"8fa30ff316aac5e79d4bbb88344dcb41b97172be","modified":1543495888143},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1543495888348},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1543495888268},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1543495888363},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1543495888367},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1543495888369},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1543495888371},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1543495888418},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1543495888341},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1543495888344},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1543495888359},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1543495888437},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1543495888426},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1543495888429},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1543495888431},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1543495888439},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1543495888441},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"e33aa8fa48b6639d8d8b937d13261597dd473b3a","modified":1543495888448},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"14264a210bf94232d58d7599ea2ba93bfa4fb458","modified":1543495888445},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1543495888455},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"2ce5f3bf15c523b9bfc97720d8884bb22602a454","modified":1543495888451},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1543495888457},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1543495888459},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1543495888462},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1543495888464},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1543495888474},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1543495888467},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1543495888469},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1543495888471},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1543495888483},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1543495888476},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1543495888479},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1543495888481},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1543495888486},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1543495888490},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1543495888494},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1543495888496},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1543495888518},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1543495888521},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1543495888531},{"_id":"themes/next/source/images/Dijkstra/Dijkstra_detail.jpg","hash":"9f019f9a4e7ff3243f85ce579bde3632aee1eefe","modified":1543495886712},{"_id":"themes/next/source/images/Dijkstra/Dijkstras_progress_animation.gif","hash":"403d67d0be4cfaf2355e60d5914a54547de1a901","modified":1543495886718},{"_id":"themes/next/source/images/JVM/工具集合与命令.png","hash":"769e8d3bfb2c481636ac72522a0e3607828ca424","modified":1543495886750},{"_id":"themes/next/source/images/TiDB/存储层.png","hash":"32a27ba9a9a010f458a49542fe7ae5044738c48b","modified":1543841760677},{"_id":"themes/next/source/images/TiDB/计算层.png","hash":"4f8ce4987c5e44ad0ee3d2bcdcf0b8e8ad9f6e3f","modified":1543841760708},{"_id":"themes/next/source/images/bg1.jpg","hash":"8867a2dc0919ab8b6d1b13dfb37336584e94d687","modified":1543495886771},{"_id":"themes/next/source/images/TiDB/运算层.png","hash":"4f8ce4987c5e44ad0ee3d2bcdcf0b8e8ad9f6e3f","modified":1543841760708},{"_id":"themes/next/source/images/books/Netty权威指南.PNG","hash":"3e9063389d20aaa41a0324b88ce702471ceac30f","modified":1543495886851},{"_id":"themes/next/source/images/books/ZooKeeper分布式过程协同技术详解.jpg","hash":"342f4db5f48ad4faa29b94ef8522bb2cc55c3c79","modified":1543495886870},{"_id":"themes/next/source/images/books/compiler.jpg","hash":"adf9940ad48c92b997538384e9aa6808247f0372","modified":1543495886875},{"_id":"themes/next/source/images/books/java多线程编程核心技术.jpg","hash":"95f36432e3160ced28544ba3088553dd2f2437af","modified":1543495886892},{"_id":"themes/next/source/images/books/recommender-handbook.png","hash":"e8d88fb6494cb6d439a7b1fd7af007f1132d0f3f","modified":1543495886897},{"_id":"themes/next/source/images/books/分布式服务框架原理与实践.jpg","hash":"af6a90a71c837e7a511a3377c5bacaf55e6e3f3e","modified":1543495886961},{"_id":"themes/next/source/images/books/大数据日知录.jpg","hash":"759e11b62277e6be21a280660db7f9832e7adf35","modified":1543495886981},{"_id":"themes/next/source/images/books/推荐系统实战.png","hash":"33ac0155260ea0dc0993487286039c2f1b657a78","modified":1543495886986},{"_id":"themes/next/source/images/books/深入理解Java虚拟机.png","hash":"ab753a052885f95b13e31d7c76e3e3a8ec6fd8b8","modified":1543495887011},{"_id":"themes/next/source/images/mahout/neighbDiagram.jpg","hash":"4015acbc6e2fc036a0c82cc4377826f24596127f","modified":1543495887136},{"_id":"themes/next/source/images/mongodb/shared-key.png","hash":"f61763191fbc88bba37af13f7f5c1df22f7fdb2d","modified":1543652648386},{"_id":"themes/next/source/images/mongodb/复本-写.png","hash":"ba682b289bb525d4fb70386406bf7d287984fa43","modified":1543652648407},{"_id":"themes/next/source/images/mongodb/复本-读.png","hash":"4e73c0016edffc10643f08d81d4adc7f2d743454","modified":1543652648413},{"_id":"themes/next/source/images/rocketmq/1.png","hash":"7b7ebb138d89051bac96864e0c265ff429fc69c2","modified":1543495887185},{"_id":"themes/next/source/images/rocketmq/rmq-basic-arc.png","hash":"e6711d899d53c06c9738627961998ab45aff146e","modified":1544016268747},{"_id":"themes/next/source/images/分库分表/代理层典型实现.png","hash":"ffb00ec836562878de6ab236a1468d581d3e7d86","modified":1543658408491},{"_id":"themes/next/source/images/分库分表/代理层方案.png","hash":"4d17a1289f8389d3fe6ff13b3cc4b864c40cc039","modified":1543657297477},{"_id":"themes/next/source/images/推荐/receng.png","hash":"4dab74d35db280c19d61eaa974824b39a2801cf2","modified":1543495887227},{"_id":"themes/next/source/images/推荐/中文单词词性表.png","hash":"3706cbce9b96ef8f82c203608c4725e671562137","modified":1543495887233},{"_id":"themes/next/source/images/分库分表/驱动层典型实现.png","hash":"1976a826817afdfd47c136996a7eb79a7107fe9a","modified":1543658182995},{"_id":"themes/next/source/images/推荐/推荐系统.png","hash":"9f86f2068e10661fcdd8496f96d5d985a868c489","modified":1543495887255},{"_id":"themes/next/source/images/推荐/英文单词词性表.jpg","hash":"b56b4e33694e6dab35a658deb3bea6ad443b9c57","modified":1543495887261},{"_id":"themes/next/source/images/数据挖掘/聚类分析.png","hash":"e69911b846e3880268730a9dd52c5a2451cbb709","modified":1543495887275},{"_id":"themes/next/source/images/架构/ActiveMQ使用场景总结.png","hash":"f6740f6c87c541f59c9ef2b7f2fa08f505f691b5","modified":1543495887290},{"_id":"themes/next/source/images/架构/cas认证流程.png","hash":"801157193bc779cd8b110a2603e8d8a46c953d0f","modified":1543495887295},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1543495888423},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1543495888533},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1543495888536},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1543495888274},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1543495886147},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1543495886143},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1543495886252},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1543495886255},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1543495886243},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1543495886246},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1543495886408},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1543495886315},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1543495886249},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1543495886489},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1543495886494},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1543495886499},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1543495886519},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1543495886505},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1543495886576},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1543495886516},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1543495886583},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1543495886526},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1543495886567},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1543495886601},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1543495886580},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1543495886593},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1543495886621},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1543495886629},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1543495886626},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1543495886632},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1543495886634},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1543495886644},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1543495886597},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1543495886606},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1543495886654},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1543495886663},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1543495886650},{"_id":"themes/next/source/images/Mycat/arc.png","hash":"94626b941615c3efa3f1e4e31cb299d958a697aa","modified":1543930055051},{"_id":"themes/next/source/images/Mycat/mysql高可用方案3.png","hash":"ec82c8f9d429c7ac13d565fdddcd4748ba5151fc","modified":1543930055150},{"_id":"themes/next/source/images/Mycat/mysql高可用方案4.png","hash":"0def29cb08040631c77cfc5dbe1296e1350f8e26","modified":1543930055162},{"_id":"themes/next/source/images/Mycat/主从复制方式.png","hash":"5286ee616961b5fab2874ca237fcb13a38136469","modified":1543930055321},{"_id":"themes/next/source/images/Mycat/mysql高可用方案5.png","hash":"b797da0b56b626b92ce1a76f050611a5f65af0a6","modified":1543930055242},{"_id":"themes/next/source/images/books/HTTP权威指南.png","hash":"8fa14b7edeaaa891dc9fb2d73fe074fb103206d9","modified":1543495886803},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1543495886647},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"ad2dcedf393ed1f3f5afd2508d24969c916d02fc","modified":1543495886660},{"_id":"themes/next/source/images/books/Hadoop权威指南.png","hash":"175e6781cddbc89392c4b3f808a38ca03d4f68f5","modified":1543495886809},{"_id":"themes/next/source/images/books/七周七并发模型.png","hash":"fc935a00327e607af698ca4d8c3365450bf48a84","modified":1543495886948},{"_id":"themes/next/source/images/java源码/BIO-字符流.png","hash":"95dbdb156035a40065cc07641be08e3640866219","modified":1551101014972},{"_id":"themes/next/source/images/books/跟我学Shiro.png","hash":"f0d89fadcc1f1f17840429dac88a15c05399e240","modified":1543495887023},{"_id":"themes/next/source/images/rocketmq/2.png","hash":"b336739d1f15e1a10baf43e1df5d65acad9010d4","modified":1543495887191},{"_id":"themes/next/source/images/mongodb/config-server.png","hash":"9ed1561624afa8f08ef7a697c604ce1745a9ee61","modified":1543652648380},{"_id":"themes/next/source/images/rocketmq/存储机制.png","hash":"7d7491e41c47e82eac2593c2ef891fa8b435a6f3","modified":1544016268795},{"_id":"themes/next/source/images/rocketmq/事务消息实现.png","hash":"59c25ee6f427aa958315a9b4933ab80add6b1091","modified":1544016268760},{"_id":"themes/next/source/images/rocketmq/交互流程.png","hash":"e23df798645e665937bb8be65fa85af248eaed8a","modified":1544016268787},{"_id":"themes/next/source/images/密码学/加密.png","hash":"044cec4acb1c48c9a9b1d9b58b4059abe07ff247","modified":1543495887214},{"_id":"themes/next/source/images/架构/webxml.png","hash":"64aa31203251bbfca116c09c799adb01b6ef498e","modified":1543495887372},{"_id":"themes/next/source/images/架构/配置/redis验证.png","hash":"8b01d38368d61d539d30de68bce8aa6b52c613e7","modified":1543495887416},{"_id":"themes/next/source/images/架构/配置/tomcat-session1.png","hash":"40d75af0558a262f9a708fb794cee933ebfa9e76","modified":1543495887420},{"_id":"themes/next/source/images/架构/消息队列-分布式.png","hash":"f9de4792c142286eb009fad3cc57f0c4b28bff1c","modified":1543495887389},{"_id":"themes/next/source/images/架构/系统架构图-双高.png","hash":"915e87dd256c6268c53ae780d055aeebf86da408","modified":1543495887396},{"_id":"themes/next/source/images/架构/配置/tomcat-session2.png","hash":"6dbd37af0f5415c3a0b3a16e6f43aa8eb98d85aa","modified":1543495887423},{"_id":"themes/next/source/images/架构/配置/tomcat-session3.png","hash":"f2ea0578c8791cbca50e53074d8fcdff5351c107","modified":1543495887427},{"_id":"themes/next/source/images/架构/配置/tomcat-session4.png","hash":"cdbb96861c74a572cd0343f15878d4d014321a46","modified":1543495887430},{"_id":"themes/next/source/images/算法/K-means/advice.png","hash":"9e354398f39e64fc36307925fa88391a455726e5","modified":1543495887443},{"_id":"themes/next/source/images/算法/K-means/costfunction.png","hash":"8d96055460ece6a78930c1fea6791a9d251163c5","modified":1543495887446},{"_id":"themes/next/source/images/算法/K-means/dimensionality.png","hash":"b1076c594c57c884efc5944e06d9fa889d240749","modified":1543495887449},{"_id":"themes/next/source/images/算法/K-means/init.png","hash":"943ae4408fc8bec9d9c8a6c9bc82a6c682383adb","modified":1543495887452},{"_id":"themes/next/source/images/算法/K-means/pca-num.png","hash":"a93ee877009a5f7401f03271c5b966dfa776e935","modified":1543495887457},{"_id":"themes/next/source/images/算法/K-means/pca.png","hash":"2f5d7e72c3b156b541c575a99ccea357fa229671","modified":1543495887461},{"_id":"themes/next/source/images/算法/K-means/unzip.png","hash":"e96a6873b823fbbf3fed48fa0585b98bb859bbe6","modified":1543495887468},{"_id":"themes/next/source/images/算法/SVM/costfunction.png","hash":"46b8955cd3eee09dfceb0cadbc35cb4ec33ad09d","modified":1543495887473},{"_id":"themes/next/source/images/算法/SVM/kernel.png","hash":"06de6fb8cea6cea1a3b6e17eac4153a4ee68be00","modified":1543495887482},{"_id":"themes/next/source/images/算法/SVM/largemargin.png","hash":"740aeb1c95118f66f53cff2815987a73d65bc8e7","modified":1543495887486},{"_id":"themes/next/source/images/算法/SVM/other.png","hash":"3ded320bb7299b518154e74337f82d32e60bf1f5","modified":1543495887492},{"_id":"themes/next/source/images/算法/SVM/vs.png","hash":"a1921fe3398632fb596c6965a9478c8129fe76e2","modified":1543495887500},{"_id":"themes/next/source/images/算法/K-means/principal.png","hash":"757236f0fd33f2bd7358491add0bd56f3c5b5226","modified":1543495887464},{"_id":"themes/next/source/images/算法/SVM/kernel-simila.png","hash":"74e613dceb98ba15c6bfc30304541bb3b897eea9","modified":1543495887477},{"_id":"themes/next/source/images/算法/最大似然/二项分布.png","hash":"627ebdb66e04c0730b4f3533619f00979a7265be","modified":1543495887636},{"_id":"themes/next/source/images/算法/最大似然/二项分布解析.png","hash":"779a553d97648cc2d5161aa30846cd739d218dcd","modified":1543495887639},{"_id":"themes/next/source/images/算法/最大似然/似然函数.png","hash":"93a6a6692019920186d0cfff6abd5e55dd288c33","modified":1543495887642},{"_id":"themes/next/source/images/算法/最大似然/偏导数.png","hash":"c20e26d662543cb52bd39ee7511a09189413cc06","modified":1543495887646},{"_id":"themes/next/source/images/算法/最大似然/偏导数为0.png","hash":"9c6c9873554e9f3d12dc31f06cbdc3ff3e74a515","modified":1543495887660},{"_id":"themes/next/source/images/算法/最大似然/对数似然.png","hash":"8d8f1c3311707c21104f2854fe8b836a3eca36ba","modified":1543495887664},{"_id":"themes/next/source/images/算法/最大似然/对数似然函数.png","hash":"9f3de48a619e1cf40b3909ac39e83685180830bb","modified":1543495887667},{"_id":"themes/next/source/images/算法/最大似然/抛硬币似然函数.png","hash":"7a0661619d7b3de77562bf47df8245726f1c4560","modified":1543495887671},{"_id":"themes/next/source/images/算法/最大似然/概率密度函数.png","hash":"9b42cc232cde0e9bcec9c48587bfcea81d565dcd","modified":1543495887678},{"_id":"themes/next/source/images/算法/最大似然/线性回归模型.png","hash":"cdb4538a8ec0dd42d209680b5f540c7309f9be35","modified":1543495887686},{"_id":"themes/next/source/images/算法/最小二乘法/c偏导数.png","hash":"54ecf120c3c40faa6c59f3f06866928dbb14c145","modified":1543495887691},{"_id":"themes/next/source/images/算法/最小二乘法/c偏导数为0.png","hash":"c12a8b2b1b397c46f547bdd94df80ac3ff010dd3","modified":1543495887696},{"_id":"themes/next/source/images/算法/最小二乘法/m偏导数.png","hash":"1c5ce59ee9307963fd76af399b249856548d6174","modified":1543495887699},{"_id":"themes/next/source/images/算法/最小二乘法/代价函数.png","hash":"7ceb12f4a655e6ab802e50be3f95847bef8a36e5","modified":1543495887714},{"_id":"themes/next/source/images/算法/最小二乘法/偏导数.png","hash":"b26a4e328bbd5f1c595ecd62df27e0f9229fc66a","modified":1543495887718},{"_id":"themes/next/source/images/算法/最小二乘法/回归模型.png","hash":"7b63e4111d825dc9db9ea7a6dfd46115403a8062","modified":1543495887722},{"_id":"themes/next/source/images/算法/最小二乘法/平方差.png","hash":"a1dd23e4086fdcac029701a413aef4b703442d20","modified":1543495887725},{"_id":"themes/next/source/images/算法/最小二乘法/平方损失函数.png","hash":"6e9cfe83392c4cbe44289e142881a45805a3867b","modified":1543495887729},{"_id":"themes/next/source/images/算法/最小二乘法/模型变换.png","hash":"ad7234cb28f2d9cc6fd2ceba33f08ac6be9d2701","modified":1543495887733},{"_id":"themes/next/source/images/算法/最小二乘法/转置-代价函数.png","hash":"db4f59c417b089802c4b57189ec2b3cbad4d162f","modified":1543495887736},{"_id":"themes/next/source/images/算法/杰卡德相似系数/octave.png","hash":"b33074d0b4fb852d340c3e9d22807311e7364254","modified":1543495887745},{"_id":"themes/next/source/images/算法/杰卡德相似系数/octave_result.png","hash":"bf21bf9f5da232967ad0008dd3ed5df4b967fef0","modified":1543495887749},{"_id":"themes/next/source/images/算法/杰卡德相似系数/公式.png","hash":"7cf280c2c631dc94013ed89fa1de657d415b1aed","modified":1543495887752},{"_id":"themes/next/source/images/算法/汉明距离/octave.png","hash":"b0a468604f60b05e6722ab8595d0bd06e0cce0a9","modified":1543495887757},{"_id":"themes/next/source/images/算法/汉明距离/octave_result.png","hash":"3dc0cc782455bff2b136e4c463bdc88a1ff735ed","modified":1543495887760},{"_id":"themes/next/source/images/算法/汉明距离/公式.png","hash":"de8d60ea7ade78d221694f8393b6eb968b551969","modified":1543495887766},{"_id":"themes/next/source/images/算法/皮尔斯曼/代码.png","hash":"7b3bef1398f98423fed83cd3ffbb36d13854bc52","modified":1543495887786},{"_id":"themes/next/source/images/算法/皮尔森相关/mahout.png","hash":"760154e3804f27dde2590fed58b188574d5e6110","modified":1543495887803},{"_id":"themes/next/source/images/算法/皮尔森相关/协方差.png","hash":"ac48802121c45a3c36063e0a7385aba4ad4f1631","modified":1543495887820},{"_id":"themes/next/source/images/算法/皮尔森相关/数学公式.png","hash":"726c06ea969fdc0f2ba156b1733ff69e731d7de8","modified":1543495887828},{"_id":"themes/next/source/images/算法/皮尔森相关/方差.png","hash":"dae65192fdf05a73dba03b569d3472871b8f7fd7","modified":1543495887843},{"_id":"themes/next/source/images/算法/皮尔森相关/标准差.png","hash":"1e474695919aff32301525c0331875a2d6f12381","modified":1543495887846},{"_id":"themes/next/source/images/算法/神经网络/backpropagation-impl.png","hash":"14646231c156774509fffa09dafb318feb333636","modified":1543495887851},{"_id":"themes/next/source/images/算法/神经网络/backpropagation.png","hash":"be89b92675a0d88fa138425098ceebaafa70b6ae","modified":1543495887866},{"_id":"themes/next/source/images/算法/神经网络/costfunction.png","hash":"73b06ee00c8ba98ecc4bad54f838cd6a21304076","modified":1543495887868},{"_id":"themes/next/source/images/算法/神经网络/multi-class.png","hash":"a4b05fde7e5704008373370d313e02282f7ad39a","modified":1543495887878},{"_id":"themes/next/source/images/算法/神经网络/other.png","hash":"a4e8a16ea026ca03647a1cf6b1711fc91ff7de23","modified":1543495887883},{"_id":"themes/next/source/images/算法/神经网络/vector.png","hash":"36f961ba8c4a2ad7c4e1ca8104f3f98d979b29dd","modified":1543495887889},{"_id":"themes/next/source/images/算法/谷本系数/公式.png","hash":"c3ac7c836711fdfac48fe8f53d8e84d006d38a0a","modified":1543495887897},{"_id":"themes/next/source/images/算法/逻辑回归/S函数.png","hash":"62f5d75bb0e6de8c476592b5f695035777a1ad83","modified":1543495887907},{"_id":"themes/next/source/images/算法/逻辑回归/函数范围.png","hash":"4f038fd0a84a73fe9f8456688b3ea506052777ef","modified":1543495887910},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-代价函数.png","hash":"f3803c927a2d369540eaf60f7975ac88c89bdbca","modified":1543495887914},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-假设函数.png","hash":"83adbc65a9da380e87de7cb227fe42b04bd51e8a","modified":1543495887918},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-梯度下降.png","hash":"5d27822fd8da77eb6a640ba76be50564877c6754","modified":1543495887926},{"_id":"themes/next/source/images/算法/逻辑回归/单参数-线性-线性梯度下降.png","hash":"22bda24e22361f93afc60c23a5ea9b0725a7e818","modified":1543495887934},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png","hash":"52afec76c687bd4441e201c49194234842c7355d","modified":1543495887943},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-代价函数.png","hash":"49d9322a26e1e28d272990df852a736d6dbb92a1","modified":1543495887938},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png","hash":"63e90e3e65d81ef7bef86bcceaac31969b5edd2f","modified":1543495887963},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png","hash":"c2fb201b091b7b0e548d7fe6331dea9a10fa3217","modified":1543495887970},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-假设函数.png","hash":"fa2449196ad107c4c7123eda07da9c5c9f02d617","modified":1543495887982},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-梯度下降.png","hash":"44976a102c3702b18ed432d0fdf021865772f6a9","modified":1543495887992},{"_id":"themes/next/source/images/算法/逻辑回归/多参数-线性-正规方程.png","hash":"b95279b732f18a53208a37214a03d3fd9e69171d","modified":1543495887999},{"_id":"themes/next/source/images/算法/逻辑回归/对数函数.png","hash":"98ca8c9fc6145305d59e1544ab4e3b7d98a3bb1a","modified":1543495888007},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数.png","hash":"696892f8d53e7c277eaf84ff2d609673c9b32b2b","modified":1543495888012},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数1.png","hash":"9bb92321f8be25d750853c74cc71aa48157cbade","modified":1543495888017},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数2.png","hash":"d91efdf8cbad9ec68433f8231d38168ad342e375","modified":1543495888021},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数3.png","hash":"f435ce02d003507a4d18187bea11c686cff7a8de","modified":1543495888024},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-代价函数向量化.png","hash":"1152fb0964de10eb8704071ca106695c6c24d8b6","modified":1543495888027},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-多分类.png","hash":"2b604445c51674355cc85c709b323db443be0917","modified":1543495888040},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-梯度下降.png","hash":"063396d4aeed96d646dd51b618d98eda1075bcab","modified":1543495888044},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数.png","hash":"709d11f5515689bf9065cbd82f9c5ad6c5e21c3f","modified":1543495888047},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png","hash":"186a0f5c79b4825e03c0a5cb096772734470a5d2","modified":1543495888050},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png","hash":"290b0e925a8ce9e8a5fa080440eb5ae99434c992","modified":1543495888053},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png","hash":"d9eb1786547d240be9f890de918b931a5f489c91","modified":1543495888057},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归代价函数.png","hash":"f20bf895c431591a39970304470ef4a7dbf8a208","modified":1543495888060},{"_id":"themes/next/source/images/算法/闵可夫斯基/p1.png","hash":"1b17bdf6222fad1c66c00eca4628ff777635c29f","modified":1543495888081},{"_id":"themes/next/source/images/算法/闵可夫斯基/p2.png","hash":"567368044ff5c5f932e5f93817a2f2545f8e1be9","modified":1543495888085},{"_id":"themes/next/source/images/算法/闵可夫斯基/p25.png","hash":"8eff26fc2b3b6936adadbfe3efcb1b058dc57a5a","modified":1543495888089},{"_id":"themes/next/source/images/算法/闵可夫斯基/p4.png","hash":"c42c028dd4b160528c40111c710560c037f0fb68","modified":1543495888093},{"_id":"themes/next/source/images/算法/闵可夫斯基/plong.png","hash":"c4b06435e87291a9d128fade1de2bb0beb68a1ea","modified":1543495888096},{"_id":"themes/next/source/images/算法/闵可夫斯基/公式.png","hash":"d4973e2b34aa944d2d0a80270bc6a2e32d96df75","modified":1543495888107},{"_id":"themes/next/source/images/算法/闵可夫斯基/公式推导.png","hash":"84f7e23b3ab9ffdd16b824bfbd72e5e7654d43ce","modified":1543495888113},{"_id":"themes/next/source/images/算法/闵可夫斯基/图形展示.png","hash":"146b204697c8ca8ce908cead4dfb3cb65a33119c","modified":1543495888116},{"_id":"themes/next/source/images/算法/闵可夫斯基/缺点.png","hash":"0047ea03a8cfc841ac6549d81eb7a0fe56aa323e","modified":1543495888120},{"_id":"themes/next/source/images/算法/闵可夫斯基/计算公式.png","hash":"b094c99f054c4fdf70b2236587ea6330caf14d64","modified":1543495888123},{"_id":"themes/next/source/images/算法/马氏距离/公式.png","hash":"5561bbeb2ac64b0f582abd36439c8564cca219b5","modified":1543495888127},{"_id":"themes/next/source/images/算法/马氏距离/公式1.png","hash":"5e0ec2b6abf29c378107e059ebe007bc60f0522b","modified":1543495888130},{"_id":"themes/next/source/images/算法/马氏距离/公式2.png","hash":"b91b7199d9e738ea959c82eb4cd22b36a09d7490","modified":1543495888135},{"_id":"themes/next/source/images/算法/马氏距离/图例.png","hash":"746f34fbbc95415856bad88510e17465c699ceca","modified":1543495888139},{"_id":"themes/next/source/images/算法/逻辑回归/逻辑回归函数.png","hash":"290be0d123d0cd77e82587ee5b1d30fb1366458a","modified":1543495888064},{"_id":"themes/next/source/images/算法/逻辑回归/预测函数概率.png","hash":"81d51fed100503b95b125f17e8aeb0689d42ec17","modified":1543495888068},{"_id":"themes/next/source/images/算法/逻辑回归/预测分类.png","hash":"ed9b0ccc59c7ade5d3cfe6230c9bccb7aa807fd1","modified":1543495888071},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1543495888194},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1543495888232},{"_id":"themes/next/source/images/算法/余弦相似度/公式.png","hash":"7986d4d6a951e03b38f3cfb53cb9cac9cbd49927","modified":1543495887588},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1543495888281},{"_id":"themes/next/source/images/算法/余弦相似度/图例.png","hash":"efcbfce6b8c50f26715c3be001586103e2f6b0f7","modified":1543495887594},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1543495888241},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1543495888245},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1543495888291},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1543495888294},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1543495888297},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1543495888326},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1543495888331},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1543495888334},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1543495888284},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1543495888352},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1543495888287},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1543495888355},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1543495888375},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1543495888379},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1543495888383},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1543495888515},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1543495888512},{"_id":"themes/next/source/images/TiDB/整体架构1.png","hash":"91184454979b4c034dc2837dbb6399fd12b60e62","modified":1543841760708},{"_id":"themes/next/source/images/books/Java并发编程实践.png","hash":"23057092749f3935cd7682378ca21742a8ba640c","modified":1543495886829},{"_id":"themes/next/source/images/books/Java并发编程的艺术.png","hash":"29f5a59b08a175f59c8de0786deb504b17975ea0","modified":1543495886836},{"_id":"themes/next/source/images/books/SolrInAction.png","hash":"47a73500dd75f1404547e5a6c9182177179ec4b8","modified":1543495886860},{"_id":"themes/next/source/images/books/Java并发编程实战.png","hash":"a95a0d1037d67a03ca2acda9bb69f81956a12e12","modified":1543495886823},{"_id":"themes/next/source/images/books/hotspot.jpg","hash":"ddb36e8401448068e89150bd445fcfd64a55d855","modified":1543495886887},{"_id":"themes/next/source/images/books/spring技术内幕.png","hash":"d70ebcd74cc6b6a498322957a67949c00ee8bbb8","modified":1543495886902},{"_id":"themes/next/source/images/books/分布式系统.jpg","hash":"95295345ddb122fb4ce89bdfe9767e8e2da51628","modified":1543495886968},{"_id":"themes/next/source/images/java源码/NIO-Channel类图.png","hash":"5824e77d6e2f28f394518c3d0783aa384ad87479","modified":1551102072815},{"_id":"themes/next/source/images/java源码/集合-类图.jpg","hash":"fb6fbd44c9604d6dded71292ef1e43a06e10c7ff","modified":1543495887128},{"_id":"themes/next/source/images/mahout/similarDiagram.jpg","hash":"b715acb042014a8a619c632694faaffce9c5697e","modified":1543495887157},{"_id":"themes/next/source/images/架构/配置/cas-ticket.png","hash":"2f3eb9fdbcde394e0cadc6d9786c2f43bf180f64","modified":1543495887408},{"_id":"themes/next/source/images/架构/配置/keepalived验证.png","hash":"0e368e8dea5f03a3db73920b9b4db78b6a0c8eb0","modified":1543495887412},{"_id":"themes/next/source/images/算法/SVM/svm.png","hash":"866681522b39db1bdb1d773a004a43c066453230","modified":1543495887496},{"_id":"themes/next/source/images/架构/系统架构图-备案.png","hash":"3f35441f0b6b89ded62a0142add1590589201e72","modified":1543495887402},{"_id":"themes/next/source/images/算法/SVM/逻辑回归.png","hash":"e4999a210556d589e54f569e3aaf02f84549f026","modified":1543495887505},{"_id":"themes/next/source/images/算法/最小二乘法/m偏导数为0.png","hash":"2101049b6e6fc61313cc2817bbdd7aa4596d8f18","modified":1543495887707},{"_id":"themes/next/source/images/算法/皮尔斯曼/例子.png","hash":"ff649455bd9a4b939bd2cd80ed99e9b3115b2373","modified":1543495887791},{"_id":"themes/next/source/images/算法/皮尔森相关/例子.png","hash":"46e3a8316148f8cb85f74ca2d1ce2d2f13fa6f7d","modified":1543495887813},{"_id":"themes/next/source/images/算法/神经网络/hfunction.png","hash":"c33e6c628f041a9b7463247682cf5d203585557b","modified":1543495887874},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1543495888237},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1543495888527},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1543495888412},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1543495888415},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1543495886260},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1543495886263},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1543495886267},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1543495886276},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1543495886280},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1543495886270},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1543495886293},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1543495886301},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1543495886305},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1543495886309},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1543495886274},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1543495886312},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1543495886320},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1543495886330},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1543495886324},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1543495886327},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1543495886337},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1543495886333},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1543495886340},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1543495886348},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1543495886342},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1543495886351},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1543495886359},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1543495886345},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1543495886356},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1543495886369},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"89d6c3b697efc63de42afd2e89194b1be14152af","modified":1543495886365},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1543495886361},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1543495886379},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1543495886389},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1543495886384},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1543495886372},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1543495886392},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1543495886284},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1543495886288},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1543495886396},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1543495886398},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1543495886418},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1543495886401},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1543495886415},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1543495886425},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1543495886405},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1543495886412},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1543495886422},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1543495886431},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1543495886439},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1543495886447},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1543495886452},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1543495886428},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1543495886466},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1543495886461},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1543495886435},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1543495886472},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1543495886483},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1543495886480},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1543495886444},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1543495886611},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1543495886616},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1543495886640},{"_id":"themes/next/source/images/Mycat/mysql高可用方案2.png","hash":"150172ea244d5bfdf50df66838c79fea4454aa66","modified":1543930055138},{"_id":"themes/next/source/images/Mycat/mysql高可用方案6.png","hash":"d109b2815fa8b2f4695b2afd4737f172c5213b6a","modified":1543930055259},{"_id":"themes/next/source/images/books/spring源码深度解析.png","hash":"f27b2ef361e7774609547c06fa0aa393564865dc","modified":1543495886907},{"_id":"themes/next/source/images/books/unix网络编程-卷1.png","hash":"e2effd5a73a155911c17a0a774d69470a9b24038","modified":1543495886936},{"_id":"themes/next/source/images/books/统计学习方法.png","hash":"c5da06321c3798ad4879fc91d5644f10d0fedf2c","modified":1543495887018},{"_id":"themes/next/source/images/books/高性能MySQL.png","hash":"95dd4d34a536904549c06c4c7f39e59e48f9a77b","modified":1543495887031},{"_id":"themes/next/source/images/java源码/BIO-字节流.png","hash":"f2515c14929d477e06d98cdae034617b85bce0e0","modified":1551100969565},{"_id":"themes/next/source/images/java源码/BIO-类图.jpg","hash":"5bcd0cfe8321a26479cd12135d466688d1a6ed52","modified":1543495887114},{"_id":"themes/next/source/images/java源码/concurrent-self类图.jpg","hash":"8a16f45aa9d4791434627f7f32481ad91450272c","modified":1543495887122},{"_id":"themes/next/source/images/mongodb/混合集群-写数据.png","hash":"1c7b02fb94a86a574f301587984a92eedbe68bed","modified":1543652648437},{"_id":"themes/next/source/images/mongodb/混合集群-读数据.png","hash":"be848661f339d8c4553ae83053a71e8154c728ff","modified":1543652648449},{"_id":"themes/next/source/images/mongodb/混合集群.png","hash":"af5c36fd7fc6559022d2540620ea86babebf875d","modified":1543652648461},{"_id":"themes/next/source/images/推荐/amazon.png","hash":"c78f34a71832a71f9b0edd1a705bf81fcc629227","modified":1543495887221},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1543495886457},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1543495886476},{"_id":"themes/next/source/images/架构/postgres方案.png","hash":"e04e2f1c0a5ebda59e51cd76d77fc6ec752330ad","modified":1543495887363},{"_id":"themes/next/source/images/架构/架构演进.png","hash":"ba98dab6d0155f17bb3747d5a41bb85d5c485cc9","modified":1543495887382},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1543495888212},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1543495888215},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1543495888218},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1543495888223},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1543495888226},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1543495888301},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1543495888304},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1543495888311},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1543495888314},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1543495888317},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1543495888323},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1543495888388},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1543495888396},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1543495888408},{"_id":"themes/next/source/images/Mycat/mysql高可用方案1.png","hash":"bb727e7e9fef8cf88c98f258c98ab97db1363879","modified":1543930055124},{"_id":"themes/next/source/images/bg2.jpg","hash":"bfee6b59dd329064da41234714ca412fdb033475","modified":1543495886781},{"_id":"themes/next/source/images/books/InnoDB存储引擎.png","hash":"7b899beabf58ea897d511f2a3e61b6c5b155c57c","modified":1543495886816},{"_id":"themes/next/source/images/books/Lucene实战.png","hash":"137ff0052fbe7ac9c4cf4443e409fe489759ba78","modified":1543495886846},{"_id":"themes/next/source/images/books/Spring实战3.png","hash":"8f26f0f2de8878020b7ca93e293cdc1e8d2ca1c8","modified":1543495886867},{"_id":"themes/next/source/images/books/tcpip-卷三.png","hash":"e4ad5aa1e060629cd9215b017b409e5dace64cae","modified":1543495886922},{"_id":"themes/next/source/images/books/unix网络编程-卷2.png","hash":"9824727e9b1115682e55c302fda3514d2e0616cb","modified":1543495886941},{"_id":"themes/next/source/images/算法/神经网络/backpropagation-pic.png","hash":"630958735ea584753eb38fa30e6010140a4ab811","modified":1543495887862},{"_id":"themes/next/source/images/books/tcpip-卷一.png","hash":"23d7ebe171797240a4ab391b87f42a86e13c28d2","modified":1543495886915},{"_id":"themes/next/source/images/books/tcpip-卷二.png","hash":"dd5b5ec3db9496b4b05c447f2392fed312e69982","modified":1543495886931},{"_id":"themes/next/source/images/books/深入剖析tomcat.png","hash":"5eb085293a983920de7a8d2ee56ee642fc66f935","modified":1543495887006},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1543495888264},{"_id":"themes/next/source/images/mahout/recommendDiagram.jpg","hash":"87af1f0aaf085686af5a452306d9fbed91283e55","modified":1543495887148},{"_id":"themes/next/source/images/推荐/推荐场景.png","hash":"b29c3f2af8f9c64ad9e429cb7941c4be6e2781c4","modified":1543495887248},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1543495888507},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1543495888403},{"_id":"themes/next/source/images/books/数据挖掘导论.png","hash":"e0a37e31c64a4920d913ce6060a2f0fb175cb93c","modified":1543495886993},{"_id":"themes/next/source/images/JVM/2_内存区域与异常.png","hash":"aab38134cef77e8c2cdfda6d07aa74badd47f70f","modified":1543495886745},{"_id":"themes/next/source/images/算法/roc-example.png","hash":"56a98007d73a76726919462d1c5bef4940cde02d","modified":1543495887556},{"_id":"themes/next/source/images/算法/score-ranking.png","hash":"ad00a22fabd5b7eb054f578d263dc6111ef4ae47","modified":1543495887583},{"_id":"themes/next/source/images/算法/fpr-and-tpr.png","hash":"62b527c785cbf9ce093d8621e859423b5393be33","modified":1543495887532},{"_id":"themes/next/source/images/算法/均值推导过程.JPG","hash":"c7d89a09869b118bd20d5379bc4f8321df79b913","modified":1543495887630},{"_id":"public/search.xml","hash":"92205071b8b9c5affe05973fd23200b8aaa697ed","modified":1551104302525},{"_id":"public/tags/index.html","hash":"6054f574729106ace62c4b4c4aac9cf039dd0316","modified":1551104302806},{"_id":"public/categories/index.html","hash":"8766b11ad358a67bd7659c1e3971214af49c68af","modified":1551104302806},{"_id":"public/about/index.html","hash":"2f8628d6384d02bad831055b246555c7c3745e48","modified":1551104302806},{"_id":"public/2019/01/22/2019-01-22-密码学入门/index.html","hash":"89cb091c4e13cd1e06881e4c9b9b50bd144b5f28","modified":1551104302806},{"_id":"public/2019/01/21/2019-01-21-Java优秀框架源码学习/index.html","hash":"de740d7eb882f48a4e067e31b8eaf36a22b40916","modified":1551104302806},{"_id":"public/2018/12/25/2018-12-25-编译解释语言-静态动态语言-静态类型动态类型语言/index.html","hash":"c7cc377ae4078f11f1d02ddd5be187fcca5e0e6d","modified":1551104302806},{"_id":"public/2018/12/05/2018-12-05-RocketMQ中间件指南/index.html","hash":"fbde97e79434af240481a70301f22c100bd26fda","modified":1551104302806},{"_id":"public/2018/12/05/2018-12-05-分布式事务实现方案/index.html","hash":"f7fce3c398587081b2b760c4cf41420c8c4dce2d","modified":1551104302806},{"_id":"public/2018/12/04/2018-12-04-Mycat中间件指南/index.html","hash":"ef5f3eb33a3478cb82e925d90bc1a029cb868a97","modified":1551104302806},{"_id":"public/2018/12/03/2018-12-03-TiDB数据库指南/index.html","hash":"bd872107f4a6ee0068d99b9b2d99918dfeef186b","modified":1551104302806},{"_id":"public/2018/12/02/2018-12-02-MySQL读写分离方案选型/index.html","hash":"d3018f9f40c9c4fabd249040b0338923d979335d","modified":1551104302806},{"_id":"public/2018/12/01/2018-12-01-MySQL分库分表方案选型/index.html","hash":"18307a65b8e49a4149406cc70af33e84727d4abc","modified":1551104302806},{"_id":"public/2018/11/30/2018-11-30-mongoDB架构与集群/index.html","hash":"9143ebf4d29b4ffffd7313f11238f4d3b2327b4a","modified":1551104302806},{"_id":"public/2018/11/30/2018-11-30-NoSQL方案选型/index.html","hash":"d2afd5694ff43b460d1545f208fc13d71efa130c","modified":1551104302806},{"_id":"public/2018/11/29/2018-11-29-mongoDB文档模式设计/index.html","hash":"98c60fb07a7599b547874dd3509d9f7ead616c44","modified":1551104302806},{"_id":"public/2018/11/26/2018-11-26-RocketMQ-docker搭建/index.html","hash":"9f5b4e5791a6268cc32e2a6cdeaa9426ad2791ab","modified":1551104302806},{"_id":"public/2017/11/29/2017-11-29-爬虫框架一二三/index.html","hash":"40ea3812fe4f09449d4c17876a1d10caa014d071","modified":1551104302806},{"_id":"public/2017/07/27/2017-07-27-Maven-配置-插件/index.html","hash":"7fa5e387b17fa8d579507b24c8841d206e1d2041","modified":1551104302806},{"_id":"public/2017/07/27/2017-09-22-C&C++开源框架大全/index.html","hash":"7696ca28e008b55f0283bb582a8f50ca3bfb50d4","modified":1551104302806},{"_id":"public/2017/04/09/2017-04-09-CSS布局(layout)三大器-display-position-float/index.html","hash":"7db2c6c13d017a829c17dffcd893a2716fc99a02","modified":1551104302806},{"_id":"public/2017/02/20/2017-02-20-JWT-基于Token的身份验证/index.html","hash":"ee8ef2ae165466bfbd697534c861818918979980","modified":1551104302806},{"_id":"public/2017/01/03/2017-01-03-机器学习算法-回归-最大似然函数/index.html","hash":"8935d2007183150ebcf029e0c732fb1acd699a1f","modified":1551104302806},{"_id":"public/2016/12/31/2016-12-31-机器学习算法-回归-最小二乘法/index.html","hash":"50a9ad5b81949931a99bfc23b0a72c78e5c0f967","modified":1551104302806},{"_id":"public/2016/12/29/2016-12-29-决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法/index.html","hash":"f62c54b8f2484db0526ac78bfd3580e142350f40","modified":1551104302806},{"_id":"public/2016/12/28/2016-12-28-数据挖掘导论-读书笔记/index.html","hash":"3762e5a97f819cdf64a40ff9bdeca771ecd92aab","modified":1551104302806},{"_id":"public/2016/12/25/2016-12-25-推荐系统比较重要的期刊和学术会议/index.html","hash":"0430ff085bfd846d9212b9dde81f10cf50fbfe94","modified":1551104302806},{"_id":"public/2016/12/23/2016-12-23-推荐系统比较-阿里RecEng、Amazon和开源EasyRrec/index.html","hash":"223c59062c651b5d239b705bdf55b61b994f3a5e","modified":1551104302806},{"_id":"public/2016/12/20/2016-12-20-Duke-快速的相似数据过滤引擎/index.html","hash":"561afaa1c32303e8b15f21b6de703abe0780126d","modified":1551104302806},{"_id":"public/2016/12/17/2016-12-17-Web架构基础-四部件/index.html","hash":"610bb7165f713f13b3f690ec0331cc4c7425131c","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)/index.html","hash":"f54679f09187f6af512d3cfb6b075615439c43e4","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-MahalanobisDistance(马氏距离)/index.html","hash":"b7fc0732d35fbd916c93f7bfa0e8c927bad04f97","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度)/index.html","hash":"c9d82e3a0a11a6fb0f832bdaff5e7dcd114a67d7","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数)/index.html","hash":"82b619e6d58745ac4344425c9dee85282c97765b","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-HammingDistance(汉明距离)/index.html","hash":"0653063e7f2b08e419df0624adaa6e967c243292","modified":1551104302806},{"_id":"public/2016/11/30/2016-11-30-机器学习算法-相似度-CosineSimilarity(余弦相似度)/index.html","hash":"5aedca486dac1eb82e8fd0c40953d412e9923848","modified":1551104302806},{"_id":"public/2016/11/29/2016-11-29-机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度)/index.html","hash":"bf53963dc7ba03b4f789610e3c1a12a2568b145f","modified":1551104302806},{"_id":"public/2016/11/28/2016-11-28-机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离)/index.html","hash":"63ad2cb11b286d147bb6d65cd4aebd309fd70dcb","modified":1551104302806},{"_id":"public/2016/11/27/2016-11-27-机器学习算法-聚类-K-Means(K均值)/index.html","hash":"34bc22b0b66c96d7fcd747a5a6598c007d76e99e","modified":1551104302806},{"_id":"public/2016/11/25/2016-11-25-机器学习算法-分类-SVM(支持向量机)/index.html","hash":"659ec217d772eb178e82d41c3660a2d699700626","modified":1551104302806},{"_id":"public/2016/11/24/2016-11-24-机器学习算法-分类-NeuralNetwork(神经网络)/index.html","hash":"805ea650d393aafaa6da4e690dab19c21071fb62","modified":1551104302806},{"_id":"public/2016/11/23/2016-11-23-机器学习算法-分类-LogisticRegression(逻辑回归)/index.html","hash":"76ad464e4eeeb7b2e44ff5e4eca1c29d1df33a2f","modified":1551104302806},{"_id":"public/2016/11/23/2016-11-23-机器学习算法-回归-梯度下降(GradientDescent)/index.html","hash":"b20283fb6da63bae53fc78ae7845583cb8a13fd5","modified":1551104302806},{"_id":"public/2016/11/22/2016-11-22-机器学习算法总览表/index.html","hash":"c6bf241b0fd8edc14e5cdceb09478e62f1f90656","modified":1551104302806},{"_id":"public/2016/09/22/2016-09-22-ROC曲线生成器/index.html","hash":"0c1d2de569d66423b15276fc7c0e9160441e0346","modified":1551104302806},{"_id":"public/2016/09/21/2016-09-21-均值公式推导/index.html","hash":"f3521080c742192200dfb98ce99c8e26e0d0e02a","modified":1551104302806},{"_id":"public/2016/09/15/2016-09-15-中英文词性表/index.html","hash":"e59ae7af6730c114216298aa57c4face43256337","modified":1551104302806},{"_id":"public/2016/08/20/2016-08-20-Servlet配置总结/index.html","hash":"5ed7e58c376767ee33b98b70d807002385bce28c","modified":1551104302806},{"_id":"public/2016/07/22/2016-07-22-Docker常用指令备忘录/index.html","hash":"b0338b81b9e3b365ed78d1236c05694bb193d5ee","modified":1551104302806},{"_id":"public/2016/07/22/2016-07-22-推荐场景1-推荐用户已购买的内容/index.html","hash":"3ef8b0b63ab063174d73f46877614e99347a3b25","modified":1551104302806},{"_id":"public/2016/07/20/2016-07-20-推荐系统建设流程/index.html","hash":"8a72bc3a9ea68096a208ff9ca385e01f0f1beb2e","modified":1551104302806},{"_id":"public/2016/06/28/2016-06-28-数字签名过程图解/index.html","hash":"d138d2524048fdafd35745276f06f512c61a53bf","modified":1551104302806},{"_id":"public/2016/06/13/2016-06-13-Mahout构建推荐系统-相似度算法/index.html","hash":"3a71c6ea51375b9a8ec16e22afe5633c4bd6b6bc","modified":1551104302806},{"_id":"public/2016/04/15/2016-04-15-Java内存模型与线程同步问题整理/index.html","hash":"06f464e50a4b18de7cf00a1da1fe1289d147c7a9","modified":1551104302806},{"_id":"public/2016/04/10/2016-04-10-互联网团队技术架构-新浪微博/index.html","hash":"c3ffbf96d918ae24d9e6cfd12f34410b4370f03b","modified":1551104302806},{"_id":"public/2016/04/08/2016-04-08-JDK源码分析之并发类汇总/index.html","hash":"9e56c6969d4dc56d25bd3c5bbedd2ec174336799","modified":1551104302806},{"_id":"public/2016/04/08/2016-04-08-JDK源码分析之NIO类汇总/index.html","hash":"e3f4675d1a525d77f237b57827c4abfff2fe77a9","modified":1551104302806},{"_id":"public/2016/04/08/2016-04-08-JDK源码分析之BIO类汇总/index.html","hash":"8a878df68189ad15ec452a42a60dc9b67221f681","modified":1551104302806},{"_id":"public/2016/04/04/2016-04-04-JDK源码分析之集合类汇总/index.html","hash":"4c3fb82a017c0ee693d4d9416e3951053971c743","modified":1551104302806},{"_id":"public/2016/03/14/2016-03-14-SSO解决方案汇总/index.html","hash":"d697c58822045687f7a0d3eb5eaf67cc560b7701","modified":1551104302806},{"_id":"public/2016/03/13/2016-03-13-双高配置之Nginx+Keepalived整理/index.html","hash":"97da8c6a0ce2e1f1071d28b5da639bb744f51cd0","modified":1551104302806},{"_id":"public/2016/03/10/2016-03-10-系统架构总结之高可用高负载/index.html","hash":"975db0c8597b354c5e1e0e0266a39c44bfff4045","modified":1551104302806},{"_id":"public/2016/02/22/2016-02-22-深入理解Java虚拟机-内存区域与内存溢出异常/index.html","hash":"3099221adc9a366a12cfa669b46a2fdf13ba597b","modified":1551104302806},{"_id":"public/2016/01/17/2016-01-17-如何做好一个项目型的需求分析/index.html","hash":"f04ddde2982ba7846f7efba3f22eec892462cfdf","modified":1551104302806},{"_id":"public/2015/12/27/2015-12-27-消息中间件ActiveMQ双高架构演进/index.html","hash":"2b15137c6ade6c0f7aa0aa49a185d73aaa5df2d1","modified":1551104302806},{"_id":"public/2015/11/01/2015-11-01-项目管理之如何提高工作效率/index.html","hash":"bf353ca451fe8c8a96f46b77d180960b47a02dc2","modified":1551104302806},{"_id":"public/2015/10/27/2015-10-27-Web技术架构演进/index.html","hash":"c31693ca056027e54bb61a4433e6a9185c0924e2","modified":1551104302806},{"_id":"public/2015/09/28/2015-09-28-求最短路径算法-Dijkstra/index.html","hash":"d83aaa117cfc1779ff34910c8b93ea1463b6a620","modified":1551104302806},{"_id":"public/2015/09/25/2015-09-25-基于NodeJS的开发框架和优秀项目/index.html","hash":"b6e06cc99244ab4b230fb040ddda22ca816a2b12","modified":1551104302806},{"_id":"public/2015/09/25/2015-09-25-开始使用Python吧/index.html","hash":"c8b2e0a17a9c855b98bc77593642ecd620befc69","modified":1551104302806},{"_id":"public/2015/08/31/2015-08-31-四个例子入门NodeJS/index.html","hash":"fab49d3cdaa3fd37138e28219faef8ddb82610a8","modified":1551104302806},{"_id":"public/2015/08/16/2015-08-16-用一天时间来学习angularjs/index.html","hash":"f3962dc2dc156355dbaf605901825df1b896ba30","modified":1551104302806},{"_id":"public/2015/07/29/2015-07-29-大数据处理工具汇总/index.html","hash":"e9e353ecf8908690a219398357f32b823c8ec9da","modified":1551104302806},{"_id":"public/archives/index.html","hash":"446ffdbc243aec6844eac041a4b4098cd2fc2f57","modified":1551104302806},{"_id":"public/archives/page/2/index.html","hash":"38bce97b8d9db65e6588df62bc11a861c173c743","modified":1551104302806},{"_id":"public/archives/page/3/index.html","hash":"5a21d829acfc73807780ac4b45fa8ad3a8f4f94d","modified":1551104302806},{"_id":"public/archives/page/4/index.html","hash":"64083037413bf4bbbf6b0c98701d0eb3a3342de1","modified":1551104302806},{"_id":"public/archives/page/5/index.html","hash":"1035119ab0574c4a64ea4c7e434387aadb85bb81","modified":1551104302806},{"_id":"public/archives/page/6/index.html","hash":"11295751f3972567b68189cb8e155190b1af7683","modified":1551104302806},{"_id":"public/archives/page/7/index.html","hash":"7f80a948503d3a465f07fca9b8069579b0a3c7dd","modified":1551104302806},{"_id":"public/archives/2015/index.html","hash":"e316dcf5ff499d32b7e6a157f6c90d4f095fc9d5","modified":1551104302806},{"_id":"public/archives/2015/07/index.html","hash":"f952d17512d0a6e0d75d50a511695be736e35d2a","modified":1551104302821},{"_id":"public/archives/2015/08/index.html","hash":"13324b891ed439bcdf67c598b2c7bc3db7046390","modified":1551104302821},{"_id":"public/archives/2015/09/index.html","hash":"f49bb8159f270e85fed33f91d03ec8a740e78cc0","modified":1551104302821},{"_id":"public/archives/2015/10/index.html","hash":"10e6aeeb05a41ca073173e46b45bff9959db2fac","modified":1551104302821},{"_id":"public/archives/2015/11/index.html","hash":"216a5202bcb59699c97859d490ff0da7c57f0e16","modified":1551104302821},{"_id":"public/archives/2015/12/index.html","hash":"3dda64d563cdee8c2108ae521e02e7730e42b62c","modified":1551104302821},{"_id":"public/archives/2016/index.html","hash":"56f028019484fd6cee9762c4d9f771d07bb8154a","modified":1551104302821},{"_id":"public/archives/2016/page/2/index.html","hash":"dd1786b50526978218255117961b04efc86aa231","modified":1551104302821},{"_id":"public/archives/2016/page/3/index.html","hash":"ffc5e1aea2ee59a00301c601bad383345bcd5c6e","modified":1551104302821},{"_id":"public/archives/2016/page/4/index.html","hash":"c77d325c8ee2215847393363927b2215858d4ff7","modified":1551104302821},{"_id":"public/archives/2016/page/5/index.html","hash":"a9673802c108104e964ae3d48cf054844c51ac7c","modified":1551104302821},{"_id":"public/archives/2016/01/index.html","hash":"7465819f27186ff47a76e82d15df153816b7021b","modified":1551104302821},{"_id":"public/archives/2016/02/index.html","hash":"b7de126b8aa59ca87d29f7bd7f07c443901e7da3","modified":1551104302821},{"_id":"public/archives/2016/03/index.html","hash":"b95b4d6ca7bd21746e15f7c53592eba68c3a9193","modified":1551104302821},{"_id":"public/archives/2016/04/index.html","hash":"48625c658e13f24e1f0544c51e4fb967b73c1900","modified":1551104302821},{"_id":"public/archives/2016/06/index.html","hash":"ef15af84a3e63e68d41014cb072e7cdb095fd2ba","modified":1551104302821},{"_id":"public/archives/2016/07/index.html","hash":"86f80e46bb04a52737d1ef2de66513fe9ac02792","modified":1551104302821},{"_id":"public/archives/2016/08/index.html","hash":"ced600aa1033ccf7172882217a0f353523f22045","modified":1551104302821},{"_id":"public/archives/2016/09/index.html","hash":"5e3c5062e32362b71f269178a3aec7b71b08930e","modified":1551104302821},{"_id":"public/archives/2016/11/index.html","hash":"a70192fdfaf0aa9ad86aa0044138a08c4934e0a1","modified":1551104302821},{"_id":"public/archives/2016/11/page/2/index.html","hash":"81849bb67cf0f8ebb78fda01ea2aa5b17455422b","modified":1551104302821},{"_id":"public/archives/2016/12/index.html","hash":"e37a1e30fcd5285151168c7edcbc8d8ba965037a","modified":1551104302821},{"_id":"public/archives/2017/index.html","hash":"6f9481506dbc8c9080e19970c7ea203555b391cf","modified":1551104302821},{"_id":"public/archives/2017/01/index.html","hash":"979209fca9744796997ccd36d80826da0873588b","modified":1551104302821},{"_id":"public/archives/2017/02/index.html","hash":"6cb65b51b0f008b132925c8dfc58391b14dd1551","modified":1551104302821},{"_id":"public/archives/2017/04/index.html","hash":"a783266ed96ed7b206c8ef668ea504868f230e24","modified":1551104302821},{"_id":"public/archives/2017/07/index.html","hash":"3234bb03a0933a202568677d8679b1a9e0ab7180","modified":1551104302821},{"_id":"public/archives/2017/11/index.html","hash":"3a5ed40524d59cca79c9af519e93d2d6f0d42145","modified":1551104302821},{"_id":"public/archives/2018/index.html","hash":"e76a46c78d094c10a2063a1aab55e9d4e4d434b7","modified":1551104302821},{"_id":"public/archives/2018/11/index.html","hash":"596b312396c3ceb25d59443488af4eb308a61fd9","modified":1551104302821},{"_id":"public/archives/2018/page/2/index.html","hash":"5302897c6591f947b41e25a748b3b14166602f49","modified":1551104302821},{"_id":"public/archives/2018/12/index.html","hash":"33e086c6a03ae2ea148c7667a2c7221116528006","modified":1551104302821},{"_id":"public/archives/2019/index.html","hash":"006bca148e52578282726518a7e6a2a461022fa6","modified":1551104302821},{"_id":"public/archives/2019/01/index.html","hash":"0f8cdd034b2449c15e2ae962476452413849220a","modified":1551104302821},{"_id":"public/categories/前端/index.html","hash":"0d4e4c950a881c441e838335f6a7dbd885a8ff06","modified":1551104302821},{"_id":"public/categories/后端脚本/index.html","hash":"bd1c18dee656eca07fb5c1997dcdf8ebaf85c5c5","modified":1551104302821},{"_id":"public/categories/架构/index.html","hash":"06be502f6926403a37a19ad5a03c7ad23bc84470","modified":1551104302821},{"_id":"public/categories/JVM高级特性/index.html","hash":"895d172427f98b7120484ba35af03b43caba15c4","modified":1551104302821},{"_id":"public/categories/算法/index.html","hash":"2904e74288dbcf9f9b7eac665ca9e33721724ecc","modified":1551104302821},{"_id":"public/categories/项目管理/index.html","hash":"13a7057b63b5d090b5c37ff6017020d672a5b95c","modified":1551104302821},{"_id":"public/categories/JAVA源码/index.html","hash":"7be054419f364fc75da21b0e5292945462d495b8","modified":1551104302821},{"_id":"public/categories/互联网团队技术/index.html","hash":"606b0e5267a9c65a832bae8f0e33f589838c9cbd","modified":1551104302821},{"_id":"public/categories/密码学/index.html","hash":"15d963bacbcd0b7e9dff361533016ad16c67c60f","modified":1551104302821},{"_id":"public/categories/相似度算法/index.html","hash":"9b40d14177851f99f9fd37cfd8d1933dd4035159","modified":1551104302821},{"_id":"public/categories/系统架构/index.html","hash":"592825de935da516fe69457e2b7612c4813e82fe","modified":1551104302821},{"_id":"public/categories/推荐/index.html","hash":"4c2bd9ab33c5677b22f91f78b38cc863dd36c08f","modified":1551104302821},{"_id":"public/categories/用户场景/index.html","hash":"c773f5be75c8cddf8e43955b1eeab4ed2459811d","modified":1551104302821},{"_id":"public/categories/Docker指令/index.html","hash":"20a022f6e31bfba6afb78162b3ff4e2e0ceca2ee","modified":1551104302821},{"_id":"public/categories/文本挖掘/index.html","hash":"81a7b41fe06cb728e5eb01a68b36942369cd1f4a","modified":1551104302821},{"_id":"public/categories/回归算法/index.html","hash":"481d3fe2b011c1de908d16aa8c2a41d98e008775","modified":1551104302821},{"_id":"public/categories/分类算法/index.html","hash":"4c48379f4473b6bf6a921504fa4418c0b64312cc","modified":1551104302821},{"_id":"public/categories/聚类算法/index.html","hash":"da5c58ee0d9d95701a40f68b0ca0533c8a50a05a","modified":1551104302821},{"_id":"public/categories/Duke/index.html","hash":"d79cb00750de8260fb18fb9439856075016f8cbf","modified":1551104302821},{"_id":"public/categories/学术会议/index.html","hash":"ea37f8681b9d9657bf37dbcdda7c30fb7fe14483","modified":1551104302821},{"_id":"public/categories/读书笔记/index.html","hash":"599a578dc513856d7973c3a93909c459927aa0b1","modified":1551104302821},{"_id":"public/categories/项目构建/index.html","hash":"5476806ead57d513269f67acb34c198ec6204bad","modified":1551104302821},{"_id":"public/categories/开源框架/index.html","hash":"e53ffb6297b86cb7deeab0f0d161b7234d7b48c8","modified":1551104302821},{"_id":"public/categories/中间件/index.html","hash":"60a256d8c90aff0ad9b2b4ea7a9562d29f37e9fc","modified":1551104302821},{"_id":"public/categories/CSS布局/index.html","hash":"1c3f433ddd478f198d7a3ad287c3fa355a3aa397","modified":1551104302821},{"_id":"public/categories/Token详解/index.html","hash":"9af2d8055e5131864fd75ec8268a901f2e46f7f0","modified":1551104302821},{"_id":"public/categories/其它/index.html","hash":"c31bc9dc30814af2eb7922aa7840debbd2c5322c","modified":1551104302821},{"_id":"public/categories/源码研究/index.html","hash":"43d67acaa84b0a21b23120ad28638685b47f68e8","modified":1551104302821},{"_id":"public/categories/分布式/index.html","hash":"5ac812efa90dabd2ee7f19fe09b985ade9e58256","modified":1551104302821},{"_id":"public/categories/大数据/index.html","hash":"fe2ebe43c703b2f8193bcd3c339a5e4c24d2270e","modified":1551104302821},{"_id":"public/index.html","hash":"62cd6dc8c2deafdb81fce9b65872eff455f06d45","modified":1551104302821},{"_id":"public/page/2/index.html","hash":"f27e83d248966256789c40229c2fb8fb5d0d64e9","modified":1551104302821},{"_id":"public/page/3/index.html","hash":"12de5e8efdaee1b87cca0936889dcb4fd5df2f73","modified":1551104302821},{"_id":"public/page/4/index.html","hash":"cb655cf7240e2f868e5fb156d561def756520213","modified":1551104302821},{"_id":"public/page/5/index.html","hash":"b1cebed31520a81c3f45ddcc441556407131dfbe","modified":1551104302821},{"_id":"public/page/6/index.html","hash":"7425521acdbf415031d852fd8505265f2de4d7eb","modified":1551104302821},{"_id":"public/page/7/index.html","hash":"87603d08ff53b0540c63a4d90418ba5eeec62b17","modified":1551104302821},{"_id":"public/tags/AngularJS/index.html","hash":"bc6bc17215c198281a1c649433404e7d294c63f6","modified":1551104302821},{"_id":"public/tags/NodeJS/index.html","hash":"7de7c2cc5b2e3ae29f4b5a602d34400aa9e33b85","modified":1551104302821},{"_id":"public/tags/Python/index.html","hash":"fbb602251162f50b60a1544c442e82b13dc012c6","modified":1551104302821},{"_id":"public/tags/网站架构/index.html","hash":"95296d51323e0befc424012643f4211b64c1e6df","modified":1551104302821},{"_id":"public/tags/内存区域/index.html","hash":"f245682aaf068f66a1fcf477a08c072145dc32bb","modified":1551104302821},{"_id":"public/tags/Search-algorithm/index.html","hash":"aa156a6047bb58d8f9f34006d5486ec20c44503a","modified":1551104302821},{"_id":"public/tags/工作效率/index.html","hash":"558fc57ec7739580f167c226f55e8276d49628a4","modified":1551104302821},{"_id":"public/tags/需求分析/index.html","hash":"fd8c6fb6af79edd3663051fe0ba7ab34eacf2884","modified":1551104302821},{"_id":"public/tags/消息中间件/index.html","hash":"edb7e87c0ba098297d0e180b7413e3c0f1bfddfa","modified":1551104302821},{"_id":"public/tags/双高架构/index.html","hash":"0dabd2e477bd024897961d2e715280fc6d3cf120","modified":1551104302821},{"_id":"public/tags/IO类/index.html","hash":"cbad6ac7a37dbdc9b67e935f4af19384d60091c5","modified":1551104302821},{"_id":"public/tags/并发类/index.html","hash":"760710c5861360d29e63e57da74f7f8c0cf5b0da","modified":1551104302821},{"_id":"public/tags/单点登录/index.html","hash":"4e0b0c770df47cc19be2a13d2c5f34d5ae2ef896","modified":1551104302821},{"_id":"public/tags/新浪微博/index.html","hash":"ab1ec03d095478d834bb8c281b2471f26e8684db","modified":1551104302821},{"_id":"public/tags/加密解密/index.html","hash":"93d35c594c0a088170fa0f40bcd0e1a5b2ebe119","modified":1551104302821},{"_id":"public/tags/推荐系统/index.html","hash":"28567186c63eefbc7ded039c27a2eb28cbf0b9b2","modified":1551104302821},{"_id":"public/tags/Collection集合类/index.html","hash":"c0f28eb952224a892df1850b7ed85ac43d52a02c","modified":1551104302821},{"_id":"public/tags/文本挖掘/index.html","hash":"24fc1dfaf746274bea51728c5740c341c63a1aee","modified":1551104302821},{"_id":"public/tags/内存模型/index.html","hash":"1a13b886f3154d1fd9b2b56d1fe1041cf99a920d","modified":1551104302821},{"_id":"public/tags/备忘录/index.html","hash":"b935f45e993f17ef6d165a4fd16399eb881675c1","modified":1551104302821},{"_id":"public/tags/Servlet3-0/index.html","hash":"2e004b78722f4a1236a5daa67c84b14ad6a0d571","modified":1551104302821},{"_id":"public/tags/均值算法/index.html","hash":"31891d8331a532bd3acdfa7c6068a05c54a78e4e","modified":1551104302821},{"_id":"public/tags/ROC曲线/index.html","hash":"0e72c35aa7a03713c5cfcf35388a520e496cd52e","modified":1551104302821},{"_id":"public/tags/机器学习/index.html","hash":"57b378c7775cd386feb49dec08dcbf74178ef4d0","modified":1551104302821},{"_id":"public/tags/机器学习/page/2/index.html","hash":"6089251eb6ca850bdd65189384212d11472499f0","modified":1551104302821},{"_id":"public/tags/其他/index.html","hash":"9dd4d9dc31d2a66e5a3a01520426d5a8088fbfc3","modified":1551104302821},{"_id":"public/tags/数据挖掘/index.html","hash":"14822693ffc82bd769592a67c46f6f9cc9cef9ea","modified":1551104302821},{"_id":"public/tags/WEB技术/index.html","hash":"9f734b85645c77c2d7c499232ead22fb762b7554","modified":1551104302821},{"_id":"public/tags/C-C/index.html","hash":"2b529caa662a19867edadf063101e695f06938e8","modified":1551104302821},{"_id":"public/tags/爬虫/index.html","hash":"21ef42c90dffa1a326fd9117838b5972b83b8da7","modified":1551104302821},{"_id":"public/tags/NoSQL/index.html","hash":"c7f9a3c645f727c9cc8f4ab638cf85068cf9b321","modified":1551104302821},{"_id":"public/tags/mongoDB/index.html","hash":"b70f94cc82a3e8751ddb8b1508968d669b723bcb","modified":1551104302821},{"_id":"public/tags/MQ/index.html","hash":"99328936b09e0d5a073ca8e08cbc9252aea07e78","modified":1551104302821},{"_id":"public/tags/MySQL/index.html","hash":"732bcb69a0d3fa89ec0dfe8c0fb7031f9d3bc3bf","modified":1551104302821},{"_id":"public/tags/Mycat/index.html","hash":"99e8fd5f5841f7e251101fe0b8ebdf676a9d93e5","modified":1551104302821},{"_id":"public/tags/编程语言/index.html","hash":"6e300a7a0e50066df80280247dd855945eba155c","modified":1551104302821},{"_id":"public/tags/JAVA框架/index.html","hash":"21708b0d7f6ee47b92b5e1c5997d131de5b050ae","modified":1551104302821},{"_id":"public/tags/TiDB/index.html","hash":"fad6b9987e9c0327ef200183b5596dc973600159","modified":1551104302821},{"_id":"public/tags/分布式事务/index.html","hash":"fe92be4ef707181e5e7ff327141adcb7fd04113b","modified":1551104302821},{"_id":"public/tags/工具/index.html","hash":"d9a0a2d417965785e95e02133f8de504e3580924","modified":1551104302821},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1551104302962},{"_id":"public/images/angularjs.jpg","hash":"d0b1234c59daf81c16033fcfc74d75e9793a60af","modified":1551104302962},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1551104302962},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1551104302962},{"_id":"public/images/bg3.jpg","hash":"410782fdc71eb7c8792ee247d1fc433adaeb1b57","modified":1551104302962},{"_id":"public/images/bg.jpg","hash":"071c900b3057fdd9655df95d7c90d2c0cb88af55","modified":1551104302962},{"_id":"public/images/bitbucket.png","hash":"febf3b232f2a49a516dc28d2c7fa3dd61e62da53","modified":1551104302962},{"_id":"public/images/bgimg.png","hash":"fc395a4edcaf6b9313fad316520e758397cb528d","modified":1551104302962},{"_id":"public/images/bgpic.png","hash":"2a849338d18f9aaf908a2d2b06621ebbffd2ecbd","modified":1551104302962},{"_id":"public/images/bgpic0.png","hash":"6e73ee58cd171366351ca552e1ef3578c8638480","modified":1551104302962},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1551104302962},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1551104302962},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1551104302962},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1551104302962},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1551104302962},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1551104302962},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1551104302962},{"_id":"public/images/coding.png","hash":"43c2eb1d32f195390a687dbaa8c0fbc87008d191","modified":1551104302962},{"_id":"public/images/django.jpg","hash":"a65e192962ba768837839100bc8e332b40cd2b21","modified":1551104302962},{"_id":"public/images/express.png","hash":"a6bac67c3afbe46ccc856ba321a20fb738bc1a0d","modified":1551104302962},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1551104302962},{"_id":"public/images/fesa.svg","hash":"6e032f3ae27d2ff3b4a09995ac2e94f94e5f6d08","modified":1551104302962},{"_id":"public/images/flask.png","hash":"366722fdfbbcfdbdc2bae828ee5d7f67a52732a3","modified":1551104302962},{"_id":"public/images/github.png","hash":"bafd339840dd76379b78f237647e4c53b951d2e0","modified":1551104302962},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1551104302962},{"_id":"public/images/her.jpg","hash":"25a462d13264fd3c573e1b67e5af1b3bd89e689e","modified":1551104302962},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1551104302962},{"_id":"public/images/me.jpg","hash":"5c35557e653107656e126d3a473206146ee878e7","modified":1551104302962},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1551104302962},{"_id":"public/images/nodejs.jpg","hash":"e026e84aa25f94c791c4bc78cfddd69439fe0962","modified":1551104302962},{"_id":"public/images/noperson.png","hash":"84584792072dc538b323816ed87100915da29cfb","modified":1551104302962},{"_id":"public/images/pen.png","hash":"09a6cb07329f1d2b878072746bf58705fc9c78e5","modified":1551104302962},{"_id":"public/images/python.jpg","hash":"b694df795d82fb21c7cf8b21588d5cbf4a524230","modified":1551104302962},{"_id":"public/images/rss.png","hash":"96fdc18e76c1b5466273080f7e2dd3d711b5e781","modified":1551104302962},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1551104302962},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1551104302962},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1551104302962},{"_id":"public/images/scrapy.png","hash":"38c20f758a3102b030f44d8e3d385adc8fee2103","modified":1551104302962},{"_id":"public/images/sina.png","hash":"6f0e64139a7cc9102c5eafdf283632049e3f822e","modified":1551104302962},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1551104302962},{"_id":"public/images/Dijkstra/Dijkstra_Animation.gif","hash":"f50ae8c51775e589530b202184f15ee8bb04b3d1","modified":1551104302962},{"_id":"public/images/Dijkstra/path.jpg","hash":"94519128d07617303b8144690f4a66a7d3bcd97f","modified":1551104302962},{"_id":"public/images/Mycat/mycat高可用方案.png","hash":"9d56df5415d570c25c559bf2bab970f3081459d3","modified":1551104302962},{"_id":"public/images/TiDB/整体架构.png","hash":"830e238375ebef4b83fb50213e17745ff8f6717f","modified":1551104302962},{"_id":"public/images/books/Redis设计与实现.png","hash":"045cc29c4d5ebae10df0dad4cb7533cdd9fc2b05","modified":1551104302962},{"_id":"public/images/books/effectivejava.jpg","hash":"9acdcf1d5004cddbcdac1259190fa0b4ab580888","modified":1551104302962},{"_id":"public/images/books/从Paxos到Zookeeper.jpg","hash":"67997e6d8a81cbf45b3fd696ff4f78e23dde364e","modified":1551104302962},{"_id":"public/images/books/分布式Java应用.jpg","hash":"02f30d71411c5225b5ae419ae1f81d797c55e8c7","modified":1551104302962},{"_id":"public/images/books/分布式系统原理介绍.png","hash":"8050be2a5bec6336c8b8390533febe704d351c8d","modified":1551104302962},{"_id":"public/images/books/大型网站技术架构.png","hash":"bb6c818e8a1939d8da0895129698474256e718ec","modified":1551104302962},{"_id":"public/images/books/大型网站系统与Java中间件实战.png","hash":"3aae3ae3902e2b26dc11c33a62e01d38a67e10c5","modified":1551104302962},{"_id":"public/images/books/机器学习.png","hash":"51d5c1560fc10111f0f278a82f74489086794505","modified":1551104302962},{"_id":"public/images/books/深入分析javaWEB.jpg","hash":"c3fb608b89cf0dddbef6dcaea7ef7ec91466dfaa","modified":1551104302962},{"_id":"public/images/Mycat/最佳实践.jpg","hash":"f9abe2e39f0cd5d8580bd6f2552fdc805e29861b","modified":1551104302962},{"_id":"public/images/rocketmq/3.png","hash":"0c08690fdb336c258361e956f7b198198c462d83","modified":1551104302962},{"_id":"public/images/分库分表/从库变主库.png","hash":"41b6c37db08f1f9f376731c55deda8b34ef91b04","modified":1551104302962},{"_id":"public/images/分库分表/从库变主库2.png","hash":"65d86727de27408ab4d1010f7a057b2e2cdf25fe","modified":1551104302962},{"_id":"public/images/分库分表/代理层特点.png","hash":"b121e7a3e83bee45c276e1ca79f18d2a12cb16d4","modified":1551104302962},{"_id":"public/images/分库分表/从库变主库1.png","hash":"be47e286ac03b5ed58408214d101304153a1b609","modified":1551104302962},{"_id":"public/images/分库分表/双写迁移.png","hash":"889c8c950060bbe81e4c1cdfffd100981c564c39","modified":1551104302962},{"_id":"public/images/分库分表/双写迁移1.png","hash":"cf50d10874a47bad7d1b8ef6f53c03c79d98d027","modified":1551104302962},{"_id":"public/images/分库分表/双写迁移2.png","hash":"46aae5765abef9cdcd847b44656856bd3eee5912","modified":1551104302962},{"_id":"public/images/分库分表/驱动层方案.png","hash":"731add785dc6d6265eb9b3eec58ac137a21560fe","modified":1551104302962},{"_id":"public/images/密码学/图解密码技术.jpg","hash":"cdaeaca07791fcba232d10bff2da8fbd092e39a9","modified":1551104302962},{"_id":"public/images/分库分表/驱动层特点.png","hash":"34531c01ba963ab2289ed8c61ffb0aa626a74b54","modified":1551104302962},{"_id":"public/images/推荐/引擎流程.png","hash":"ffe0066c6462bedc22837f66d6a4c2dfcc26abeb","modified":1551104302962},{"_id":"public/images/数据挖掘/挖掘任务.png","hash":"03f92cfc0352bc5b39f1d0eba17cc830205bfa58","modified":1551104302962},{"_id":"public/images/数据挖掘/知识发现.png","hash":"902ecce47354272c7ea50d4048897294417bde01","modified":1551104302962},{"_id":"public/images/数据挖掘/领域知识.png","hash":"13dc6a2b88ac1c6434f386d7d36f8141fdd896d8","modified":1551104302962},{"_id":"public/images/架构/heritrix.jpg","hash":"94ab6fbfb9152e2c2634c10555dd0520a5f91cfb","modified":1551104302962},{"_id":"public/images/架构/listener.png","hash":"f5568b0ddae929695539eb05c0431ef925a37631","modified":1551104302962},{"_id":"public/images/架构/nutch.png","hash":"426a682b2f872491d096a9d83ed4e5fff916b77b","modified":1551104302962},{"_id":"public/images/架构/scrapy.png","hash":"080e78838881c3125a398e527f72f883fe73ebcd","modified":1551104302977},{"_id":"public/images/算法/Java代码-roc.png","hash":"b400d939d3b4226686bb2bd6ff65f19d384ba874","modified":1551104302977},{"_id":"public/images/算法/roc_output.png","hash":"bef227b1061df4fb84fb3ae82d9644866a5c8c2c","modified":1551104302977},{"_id":"public/images/算法/Java代码.png","hash":"2f86b85c118e1bc01de36d873dd60b79beedad16","modified":1551104302977},{"_id":"public/images/算法/mahout代码.png","hash":"b7d1ff999ee2f61d7df1b3004c0f12ea362b6dfa","modified":1551104302977},{"_id":"public/images/编程语言/动态类型语言.png","hash":"51c1322f7dc78499edf19ae8e4e8e2232393cbe9","modified":1551104302977},{"_id":"public/images/编程语言/动态语言.png","hash":"b3eceb43df2f4a91c076f1fef778899ef770bae5","modified":1551104302977},{"_id":"public/images/编程语言/混合语言.png","hash":"3f21cd5d2f95924892dc24da3a12665ef6dd9644","modified":1551104302977},{"_id":"public/images/编程语言/编译语言.png","hash":"56c3352803fe05edc13582257d19fcca755c71bb","modified":1551104302977},{"_id":"public/images/编程语言/解释语言.png","hash":"90a3d9c907640ce67384dd6c3cc96cff1d7a59b2","modified":1551104302977},{"_id":"public/images/项目管理/能力一般.png","hash":"721c85c7e37470d2b6a5133a89def045e7286bd9","modified":1551104302977},{"_id":"public/images/项目管理/能力较差.png","hash":"b42ed04408f60641160baef311afdd19566f4bfb","modified":1551104302977},{"_id":"public/images/项目管理/能力较强.png","hash":"59bb50164548de62641948b63de2b6f76dd88a8f","modified":1551104302977},{"_id":"public/images/项目管理/需求分析.png","hash":"365444c535e320217f9ab22a9165d71d584ccae0","modified":1551104302977},{"_id":"public/images/项目管理/搜集需求.png","hash":"8fa30ff316aac5e79d4bbb88344dcb41b97172be","modified":1551104302977},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1551104302977},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1551104302977},{"_id":"public/images/架构/配置/redis验证.png","hash":"8b01d38368d61d539d30de68bce8aa6b52c613e7","modified":1551104302977},{"_id":"public/images/架构/配置/tomcat-session1.png","hash":"40d75af0558a262f9a708fb794cee933ebfa9e76","modified":1551104302977},{"_id":"public/images/架构/配置/tomcat-session2.png","hash":"6dbd37af0f5415c3a0b3a16e6f43aa8eb98d85aa","modified":1551104302977},{"_id":"public/images/架构/配置/tomcat-session4.png","hash":"cdbb96861c74a572cd0343f15878d4d014321a46","modified":1551104302977},{"_id":"public/images/算法/K-means/advice.png","hash":"9e354398f39e64fc36307925fa88391a455726e5","modified":1551104302977},{"_id":"public/images/算法/K-means/dimensionality.png","hash":"b1076c594c57c884efc5944e06d9fa889d240749","modified":1551104302977},{"_id":"public/images/算法/K-means/costfunction.png","hash":"8d96055460ece6a78930c1fea6791a9d251163c5","modified":1551104302977},{"_id":"public/images/算法/K-means/init.png","hash":"943ae4408fc8bec9d9c8a6c9bc82a6c682383adb","modified":1551104302977},{"_id":"public/images/算法/K-means/pca-num.png","hash":"a93ee877009a5f7401f03271c5b966dfa776e935","modified":1551104302977},{"_id":"public/images/算法/K-means/pca.png","hash":"2f5d7e72c3b156b541c575a99ccea357fa229671","modified":1551104302977},{"_id":"public/images/算法/K-means/unzip.png","hash":"e96a6873b823fbbf3fed48fa0585b98bb859bbe6","modified":1551104302977},{"_id":"public/images/算法/SVM/kernel.png","hash":"06de6fb8cea6cea1a3b6e17eac4153a4ee68be00","modified":1551104302977},{"_id":"public/images/算法/SVM/costfunction.png","hash":"46b8955cd3eee09dfceb0cadbc35cb4ec33ad09d","modified":1551104302977},{"_id":"public/images/算法/SVM/largemargin.png","hash":"740aeb1c95118f66f53cff2815987a73d65bc8e7","modified":1551104302977},{"_id":"public/images/算法/SVM/other.png","hash":"3ded320bb7299b518154e74337f82d32e60bf1f5","modified":1551104302977},{"_id":"public/images/算法/SVM/vs.png","hash":"a1921fe3398632fb596c6965a9478c8129fe76e2","modified":1551104302977},{"_id":"public/images/算法/K-means/principal.png","hash":"757236f0fd33f2bd7358491add0bd56f3c5b5226","modified":1551104302977},{"_id":"public/images/算法/SVM/kernel-simila.png","hash":"74e613dceb98ba15c6bfc30304541bb3b897eea9","modified":1551104302977},{"_id":"public/images/算法/最大似然/二项分布.png","hash":"627ebdb66e04c0730b4f3533619f00979a7265be","modified":1551104302977},{"_id":"public/images/算法/最大似然/似然函数.png","hash":"93a6a6692019920186d0cfff6abd5e55dd288c33","modified":1551104302977},{"_id":"public/images/算法/最大似然/二项分布解析.png","hash":"779a553d97648cc2d5161aa30846cd739d218dcd","modified":1551104302977},{"_id":"public/images/算法/最大似然/偏导数.png","hash":"c20e26d662543cb52bd39ee7511a09189413cc06","modified":1551104302977},{"_id":"public/images/算法/最大似然/偏导数为0.png","hash":"9c6c9873554e9f3d12dc31f06cbdc3ff3e74a515","modified":1551104302977},{"_id":"public/images/算法/最大似然/对数似然.png","hash":"8d8f1c3311707c21104f2854fe8b836a3eca36ba","modified":1551104302977},{"_id":"public/images/算法/最大似然/对数似然函数.png","hash":"9f3de48a619e1cf40b3909ac39e83685180830bb","modified":1551104302977},{"_id":"public/images/算法/最大似然/抛硬币似然函数.png","hash":"7a0661619d7b3de77562bf47df8245726f1c4560","modified":1551104302977},{"_id":"public/images/算法/最大似然/概率密度函数.png","hash":"9b42cc232cde0e9bcec9c48587bfcea81d565dcd","modified":1551104302977},{"_id":"public/images/算法/最大似然/线性回归模型.png","hash":"cdb4538a8ec0dd42d209680b5f540c7309f9be35","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/c偏导数.png","hash":"54ecf120c3c40faa6c59f3f06866928dbb14c145","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/c偏导数为0.png","hash":"c12a8b2b1b397c46f547bdd94df80ac3ff010dd3","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/m偏导数.png","hash":"1c5ce59ee9307963fd76af399b249856548d6174","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/代价函数.png","hash":"7ceb12f4a655e6ab802e50be3f95847bef8a36e5","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/偏导数.png","hash":"b26a4e328bbd5f1c595ecd62df27e0f9229fc66a","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/回归模型.png","hash":"7b63e4111d825dc9db9ea7a6dfd46115403a8062","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/平方差.png","hash":"a1dd23e4086fdcac029701a413aef4b703442d20","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/平方损失函数.png","hash":"6e9cfe83392c4cbe44289e142881a45805a3867b","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/模型变换.png","hash":"ad7234cb28f2d9cc6fd2ceba33f08ac6be9d2701","modified":1551104302977},{"_id":"public/images/算法/最小二乘法/转置-代价函数.png","hash":"db4f59c417b089802c4b57189ec2b3cbad4d162f","modified":1551104302977},{"_id":"public/images/算法/杰卡德相似系数/octave.png","hash":"b33074d0b4fb852d340c3e9d22807311e7364254","modified":1551104302977},{"_id":"public/images/算法/杰卡德相似系数/octave_result.png","hash":"bf21bf9f5da232967ad0008dd3ed5df4b967fef0","modified":1551104302977},{"_id":"public/images/算法/杰卡德相似系数/公式.png","hash":"7cf280c2c631dc94013ed89fa1de657d415b1aed","modified":1551104302977},{"_id":"public/images/算法/汉明距离/octave_result.png","hash":"3dc0cc782455bff2b136e4c463bdc88a1ff735ed","modified":1551104302977},{"_id":"public/images/算法/汉明距离/octave.png","hash":"b0a468604f60b05e6722ab8595d0bd06e0cce0a9","modified":1551104302977},{"_id":"public/images/算法/汉明距离/公式.png","hash":"de8d60ea7ade78d221694f8393b6eb968b551969","modified":1551104302977},{"_id":"public/images/架构/配置/tomcat-session3.png","hash":"f2ea0578c8791cbca50e53074d8fcdff5351c107","modified":1551104302977},{"_id":"public/images/算法/皮尔斯曼/代码.png","hash":"7b3bef1398f98423fed83cd3ffbb36d13854bc52","modified":1551104302977},{"_id":"public/images/算法/皮尔森相关/mahout.png","hash":"760154e3804f27dde2590fed58b188574d5e6110","modified":1551104302977},{"_id":"public/images/算法/皮尔森相关/协方差.png","hash":"ac48802121c45a3c36063e0a7385aba4ad4f1631","modified":1551104302977},{"_id":"public/images/算法/皮尔森相关/数学公式.png","hash":"726c06ea969fdc0f2ba156b1733ff69e731d7de8","modified":1551104302977},{"_id":"public/images/算法/皮尔森相关/方差.png","hash":"dae65192fdf05a73dba03b569d3472871b8f7fd7","modified":1551104302977},{"_id":"public/images/算法/皮尔森相关/标准差.png","hash":"1e474695919aff32301525c0331875a2d6f12381","modified":1551104302977},{"_id":"public/images/算法/神经网络/backpropagation-impl.png","hash":"14646231c156774509fffa09dafb318feb333636","modified":1551104302977},{"_id":"public/images/算法/神经网络/backpropagation.png","hash":"be89b92675a0d88fa138425098ceebaafa70b6ae","modified":1551104302977},{"_id":"public/images/算法/神经网络/costfunction.png","hash":"73b06ee00c8ba98ecc4bad54f838cd6a21304076","modified":1551104302977},{"_id":"public/images/算法/神经网络/multi-class.png","hash":"a4b05fde7e5704008373370d313e02282f7ad39a","modified":1551104302977},{"_id":"public/images/算法/神经网络/other.png","hash":"a4e8a16ea026ca03647a1cf6b1711fc91ff7de23","modified":1551104302977},{"_id":"public/images/算法/神经网络/vector.png","hash":"36f961ba8c4a2ad7c4e1ca8104f3f98d979b29dd","modified":1551104302977},{"_id":"public/images/算法/谷本系数/公式.png","hash":"c3ac7c836711fdfac48fe8f53d8e84d006d38a0a","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/S函数.png","hash":"62f5d75bb0e6de8c476592b5f695035777a1ad83","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/函数范围.png","hash":"4f038fd0a84a73fe9f8456688b3ea506052777ef","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/单参数-线性-代价函数.png","hash":"f3803c927a2d369540eaf60f7975ac88c89bdbca","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/单参数-线性-假设函数.png","hash":"83adbc65a9da380e87de7cb227fe42b04bd51e8a","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/单参数-线性-梯度下降.png","hash":"5d27822fd8da77eb6a640ba76be50564877c6754","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/单参数-线性-线性梯度下降.png","hash":"22bda24e22361f93afc60c23a5ea9b0725a7e818","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png","hash":"52afec76c687bd4441e201c49194234842c7355d","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-代价函数.png","hash":"49d9322a26e1e28d272990df852a736d6dbb92a1","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png","hash":"63e90e3e65d81ef7bef86bcceaac31969b5edd2f","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png","hash":"c2fb201b091b7b0e548d7fe6331dea9a10fa3217","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-假设函数.png","hash":"fa2449196ad107c4c7123eda07da9c5c9f02d617","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-梯度下降.png","hash":"44976a102c3702b18ed432d0fdf021865772f6a9","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/多参数-线性-正规方程.png","hash":"b95279b732f18a53208a37214a03d3fd9e69171d","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/对数函数.png","hash":"98ca8c9fc6145305d59e1544ab4e3b7d98a3bb1a","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-代价函数.png","hash":"696892f8d53e7c277eaf84ff2d609673c9b32b2b","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-代价函数1.png","hash":"9bb92321f8be25d750853c74cc71aa48157cbade","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-代价函数2.png","hash":"d91efdf8cbad9ec68433f8231d38168ad342e375","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-代价函数3.png","hash":"f435ce02d003507a4d18187bea11c686cff7a8de","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-代价函数向量化.png","hash":"1152fb0964de10eb8704071ca106695c6c24d8b6","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-多分类.png","hash":"2b604445c51674355cc85c709b323db443be0917","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-梯度下降.png","hash":"063396d4aeed96d646dd51b618d98eda1075bcab","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-正则化代价函数.png","hash":"709d11f5515689bf9065cbd82f9c5ad6c5e21c3f","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png","hash":"186a0f5c79b4825e03c0a5cb096772734470a5d2","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png","hash":"290b0e925a8ce9e8a5fa080440eb5ae99434c992","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png","hash":"d9eb1786547d240be9f890de918b931a5f489c91","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归代价函数.png","hash":"f20bf895c431591a39970304470ef4a7dbf8a208","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/p1.png","hash":"1b17bdf6222fad1c66c00eca4628ff777635c29f","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/p2.png","hash":"567368044ff5c5f932e5f93817a2f2545f8e1be9","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/p25.png","hash":"8eff26fc2b3b6936adadbfe3efcb1b058dc57a5a","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/p4.png","hash":"c42c028dd4b160528c40111c710560c037f0fb68","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/plong.png","hash":"c4b06435e87291a9d128fade1de2bb0beb68a1ea","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/公式.png","hash":"d4973e2b34aa944d2d0a80270bc6a2e32d96df75","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/公式推导.png","hash":"84f7e23b3ab9ffdd16b824bfbd72e5e7654d43ce","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/图形展示.png","hash":"146b204697c8ca8ce908cead4dfb3cb65a33119c","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/缺点.png","hash":"0047ea03a8cfc841ac6549d81eb7a0fe56aa323e","modified":1551104302977},{"_id":"public/images/算法/闵可夫斯基/计算公式.png","hash":"b094c99f054c4fdf70b2236587ea6330caf14d64","modified":1551104302977},{"_id":"public/images/算法/马氏距离/公式.png","hash":"5561bbeb2ac64b0f582abd36439c8564cca219b5","modified":1551104302977},{"_id":"public/images/算法/马氏距离/公式1.png","hash":"5e0ec2b6abf29c378107e059ebe007bc60f0522b","modified":1551104302977},{"_id":"public/images/算法/马氏距离/公式2.png","hash":"b91b7199d9e738ea959c82eb4cd22b36a09d7490","modified":1551104302977},{"_id":"public/images/算法/马氏距离/图例.png","hash":"746f34fbbc95415856bad88510e17465c699ceca","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/逻辑回归函数.png","hash":"290be0d123d0cd77e82587ee5b1d30fb1366458a","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/预测函数概率.png","hash":"81d51fed100503b95b125f17e8aeb0689d42ec17","modified":1551104302977},{"_id":"public/images/算法/逻辑回归/预测分类.png","hash":"ed9b0ccc59c7ade5d3cfe6230c9bccb7aa807fd1","modified":1551104302977},{"_id":"public/images/算法/余弦相似度/公式.png","hash":"7986d4d6a951e03b38f3cfb53cb9cac9cbd49927","modified":1551104302977},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1551104302977},{"_id":"public/images/算法/余弦相似度/图例.png","hash":"efcbfce6b8c50f26715c3be001586103e2f6b0f7","modified":1551104302977},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1551104302977},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1551104302977},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1551104302977},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1551104302977},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1551104302977},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1551104302977},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1551104302977},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1551104302977},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1551104302977},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1551104302977},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1551104302993},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1551104302993},{"_id":"public/images/green.svg","hash":"7f25513aff6152b1d94b82afcb1f8d80fb0ec1ea","modified":1551104304132},{"_id":"public/images/ipplog.png","hash":"9467bcc20a6f74bbb58d06a99c4f856b2d70bf79","modified":1551104304147},{"_id":"public/images/Dijkstra/Dijkstra_detail.jpg","hash":"9f019f9a4e7ff3243f85ce579bde3632aee1eefe","modified":1551104304163},{"_id":"public/images/Dijkstra/Dijkstras_progress_animation.gif","hash":"403d67d0be4cfaf2355e60d5914a54547de1a901","modified":1551104304163},{"_id":"public/images/JVM/工具集合与命令.png","hash":"769e8d3bfb2c481636ac72522a0e3607828ca424","modified":1551104304163},{"_id":"public/images/TiDB/存储层.png","hash":"32a27ba9a9a010f458a49542fe7ae5044738c48b","modified":1551104304163},{"_id":"public/images/TiDB/计算层.png","hash":"4f8ce4987c5e44ad0ee3d2bcdcf0b8e8ad9f6e3f","modified":1551104304163},{"_id":"public/images/TiDB/运算层.png","hash":"4f8ce4987c5e44ad0ee3d2bcdcf0b8e8ad9f6e3f","modified":1551104304163},{"_id":"public/images/books/Netty权威指南.PNG","hash":"3e9063389d20aaa41a0324b88ce702471ceac30f","modified":1551104304163},{"_id":"public/images/books/ZooKeeper分布式过程协同技术详解.jpg","hash":"342f4db5f48ad4faa29b94ef8522bb2cc55c3c79","modified":1551104304163},{"_id":"public/images/books/compiler.jpg","hash":"adf9940ad48c92b997538384e9aa6808247f0372","modified":1551104304163},{"_id":"public/images/books/java多线程编程核心技术.jpg","hash":"95f36432e3160ced28544ba3088553dd2f2437af","modified":1551104304163},{"_id":"public/images/books/recommender-handbook.png","hash":"e8d88fb6494cb6d439a7b1fd7af007f1132d0f3f","modified":1551104304163},{"_id":"public/images/books/分布式服务框架原理与实践.jpg","hash":"af6a90a71c837e7a511a3377c5bacaf55e6e3f3e","modified":1551104304163},{"_id":"public/images/books/大数据日知录.jpg","hash":"759e11b62277e6be21a280660db7f9832e7adf35","modified":1551104304163},{"_id":"public/images/books/推荐系统实战.png","hash":"33ac0155260ea0dc0993487286039c2f1b657a78","modified":1551104304163},{"_id":"public/images/books/深入理解Java虚拟机.png","hash":"ab753a052885f95b13e31d7c76e3e3a8ec6fd8b8","modified":1551104304163},{"_id":"public/images/mahout/neighbDiagram.jpg","hash":"4015acbc6e2fc036a0c82cc4377826f24596127f","modified":1551104304163},{"_id":"public/images/mongodb/shared-key.png","hash":"f61763191fbc88bba37af13f7f5c1df22f7fdb2d","modified":1551104304163},{"_id":"public/images/mongodb/复本-写.png","hash":"ba682b289bb525d4fb70386406bf7d287984fa43","modified":1551104304163},{"_id":"public/images/mongodb/复本-读.png","hash":"4e73c0016edffc10643f08d81d4adc7f2d743454","modified":1551104304163},{"_id":"public/images/rocketmq/1.png","hash":"7b7ebb138d89051bac96864e0c265ff429fc69c2","modified":1551104304163},{"_id":"public/images/rocketmq/rmq-basic-arc.png","hash":"e6711d899d53c06c9738627961998ab45aff146e","modified":1551104304163},{"_id":"public/images/分库分表/代理层典型实现.png","hash":"ffb00ec836562878de6ab236a1468d581d3e7d86","modified":1551104304163},{"_id":"public/images/分库分表/代理层方案.png","hash":"4d17a1289f8389d3fe6ff13b3cc4b864c40cc039","modified":1551104304163},{"_id":"public/images/推荐/receng.png","hash":"4dab74d35db280c19d61eaa974824b39a2801cf2","modified":1551104304163},{"_id":"public/images/推荐/中文单词词性表.png","hash":"3706cbce9b96ef8f82c203608c4725e671562137","modified":1551104304163},{"_id":"public/images/分库分表/驱动层典型实现.png","hash":"1976a826817afdfd47c136996a7eb79a7107fe9a","modified":1551104304163},{"_id":"public/images/推荐/推荐系统.png","hash":"9f86f2068e10661fcdd8496f96d5d985a868c489","modified":1551104304163},{"_id":"public/images/推荐/英文单词词性表.jpg","hash":"b56b4e33694e6dab35a658deb3bea6ad443b9c57","modified":1551104304163},{"_id":"public/images/数据挖掘/聚类分析.png","hash":"e69911b846e3880268730a9dd52c5a2451cbb709","modified":1551104304163},{"_id":"public/images/架构/ActiveMQ使用场景总结.png","hash":"f6740f6c87c541f59c9ef2b7f2fa08f505f691b5","modified":1551104304163},{"_id":"public/images/架构/cas认证流程.png","hash":"801157193bc779cd8b110a2603e8d8a46c953d0f","modified":1551104304163},{"_id":"public/images/架构/配置/cas-ticket.png","hash":"2f3eb9fdbcde394e0cadc6d9786c2f43bf180f64","modified":1551104304163},{"_id":"public/images/架构/配置/keepalived验证.png","hash":"0e368e8dea5f03a3db73920b9b4db78b6a0c8eb0","modified":1551104304163},{"_id":"public/images/算法/SVM/svm.png","hash":"866681522b39db1bdb1d773a004a43c066453230","modified":1551104304163},{"_id":"public/images/算法/SVM/逻辑回归.png","hash":"e4999a210556d589e54f569e3aaf02f84549f026","modified":1551104304163},{"_id":"public/images/算法/最小二乘法/m偏导数为0.png","hash":"2101049b6e6fc61313cc2817bbdd7aa4596d8f18","modified":1551104304163},{"_id":"public/images/算法/皮尔斯曼/例子.png","hash":"ff649455bd9a4b939bd2cd80ed99e9b3115b2373","modified":1551104304163},{"_id":"public/images/算法/皮尔森相关/例子.png","hash":"46e3a8316148f8cb85f74ca2d1ce2d2f13fa6f7d","modified":1551104304163},{"_id":"public/images/算法/神经网络/hfunction.png","hash":"c33e6c628f041a9b7463247682cf5d203585557b","modified":1551104304163},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1551104304163},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1551104304163},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1551104304225},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1551104304225},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1551104304225},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1551104304225},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1551104304225},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1551104304225},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1551104304225},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1551104304225},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1551104304225},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1551104304225},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1551104304225},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1551104304225},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1551104304225},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1551104304225},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1551104304225},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1551104304225},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1551104304225},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1551104304225},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1551104304225},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1551104304225},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1551104304225},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1551104304225},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1551104304225},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1551104304225},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1551104304225},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1551104304225},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1551104304225},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1551104304225},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1551104304225},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1551104304225},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1551104304225},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1551104304225},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1551104304225},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1551104304225},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1551104304225},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1551104304225},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1551104304225},{"_id":"public/css/main.css","hash":"ce2fcf33883cf4361e181994e838685c2d221825","modified":1551104304225},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1551104304225},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1551104304225},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1551104304225},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1551104304225},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1551104304225},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1551104304225},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1551104304225},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1551104304225},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1551104304225},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1551104304225},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1551104304225},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1551104304225},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1551104304225},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1551104304225},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1551104304225},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1551104304225},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1551104304225},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1551104304225},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1551104304225},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1551104304225},{"_id":"public/images/ghost.png","hash":"637a1de20532b3fc435af1c96b68f9a0e93fe758","modified":1551104304225},{"_id":"public/images/hexo.png","hash":"0cdd06b944222da6248d3a5ec2b0efc2b79332c3","modified":1551104304225},{"_id":"public/images/文章背景.jpg","hash":"a56d64aea500b11c01b1c13bc92db2b2c7b16645","modified":1551104304225},{"_id":"public/images/Mycat/arc.png","hash":"94626b941615c3efa3f1e4e31cb299d958a697aa","modified":1551104304225},{"_id":"public/images/Mycat/mysql高可用方案3.png","hash":"ec82c8f9d429c7ac13d565fdddcd4748ba5151fc","modified":1551104304225},{"_id":"public/images/Mycat/mysql高可用方案4.png","hash":"0def29cb08040631c77cfc5dbe1296e1350f8e26","modified":1551104304225},{"_id":"public/images/Mycat/主从复制方式.png","hash":"5286ee616961b5fab2874ca237fcb13a38136469","modified":1551104304225},{"_id":"public/images/Mycat/mysql高可用方案5.png","hash":"b797da0b56b626b92ce1a76f050611a5f65af0a6","modified":1551104304225},{"_id":"public/images/books/HTTP权威指南.png","hash":"8fa14b7edeaaa891dc9fb2d73fe074fb103206d9","modified":1551104304225},{"_id":"public/images/books/Hadoop权威指南.png","hash":"175e6781cddbc89392c4b3f808a38ca03d4f68f5","modified":1551104304225},{"_id":"public/images/books/七周七并发模型.png","hash":"fc935a00327e607af698ca4d8c3365450bf48a84","modified":1551104304225},{"_id":"public/images/java源码/BIO-字符流.png","hash":"95dbdb156035a40065cc07641be08e3640866219","modified":1551104304225},{"_id":"public/images/books/跟我学Shiro.png","hash":"f0d89fadcc1f1f17840429dac88a15c05399e240","modified":1551104304225},{"_id":"public/images/rocketmq/2.png","hash":"b336739d1f15e1a10baf43e1df5d65acad9010d4","modified":1551104304225},{"_id":"public/images/mongodb/config-server.png","hash":"9ed1561624afa8f08ef7a697c604ce1745a9ee61","modified":1551104304225},{"_id":"public/images/rocketmq/存储机制.png","hash":"7d7491e41c47e82eac2593c2ef891fa8b435a6f3","modified":1551104304225},{"_id":"public/images/rocketmq/事务消息实现.png","hash":"59c25ee6f427aa958315a9b4933ab80add6b1091","modified":1551104304225},{"_id":"public/images/rocketmq/交互流程.png","hash":"e23df798645e665937bb8be65fa85af248eaed8a","modified":1551104304225},{"_id":"public/images/密码学/加密.png","hash":"044cec4acb1c48c9a9b1d9b58b4059abe07ff247","modified":1551104304225},{"_id":"public/images/架构/webxml.png","hash":"64aa31203251bbfca116c09c799adb01b6ef498e","modified":1551104304225},{"_id":"public/images/架构/消息队列-分布式.png","hash":"f9de4792c142286eb009fad3cc57f0c4b28bff1c","modified":1551104304225},{"_id":"public/images/架构/系统架构图-双高.png","hash":"915e87dd256c6268c53ae780d055aeebf86da408","modified":1551104304225},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1551104304225},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1551104304225},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1551104304225},{"_id":"public/images/bg1.jpg","hash":"8867a2dc0919ab8b6d1b13dfb37336584e94d687","modified":1551104304256},{"_id":"public/images/TiDB/整体架构1.png","hash":"91184454979b4c034dc2837dbb6399fd12b60e62","modified":1551104304256},{"_id":"public/images/books/Java并发编程实践.png","hash":"23057092749f3935cd7682378ca21742a8ba640c","modified":1551104304256},{"_id":"public/images/books/Java并发编程的艺术.png","hash":"29f5a59b08a175f59c8de0786deb504b17975ea0","modified":1551104304256},{"_id":"public/images/books/SolrInAction.png","hash":"47a73500dd75f1404547e5a6c9182177179ec4b8","modified":1551104304256},{"_id":"public/images/books/Java并发编程实战.png","hash":"a95a0d1037d67a03ca2acda9bb69f81956a12e12","modified":1551104304256},{"_id":"public/images/books/hotspot.jpg","hash":"ddb36e8401448068e89150bd445fcfd64a55d855","modified":1551104304256},{"_id":"public/images/books/spring技术内幕.png","hash":"d70ebcd74cc6b6a498322957a67949c00ee8bbb8","modified":1551104304256},{"_id":"public/images/books/分布式系统.jpg","hash":"95295345ddb122fb4ce89bdfe9767e8e2da51628","modified":1551104304256},{"_id":"public/images/java源码/NIO-Channel类图.png","hash":"5824e77d6e2f28f394518c3d0783aa384ad87479","modified":1551104304256},{"_id":"public/images/java源码/集合-类图.jpg","hash":"fb6fbd44c9604d6dded71292ef1e43a06e10c7ff","modified":1551104304256},{"_id":"public/images/mahout/similarDiagram.jpg","hash":"b715acb042014a8a619c632694faaffce9c5697e","modified":1551104304256},{"_id":"public/images/架构/系统架构图-备案.png","hash":"3f35441f0b6b89ded62a0142add1590589201e72","modified":1551104304256},{"_id":"public/images/算法/神经网络/backpropagation-pic.png","hash":"630958735ea584753eb38fa30e6010140a4ab811","modified":1551104304256},{"_id":"public/images/Mycat/mysql高可用方案2.png","hash":"150172ea244d5bfdf50df66838c79fea4454aa66","modified":1551104304288},{"_id":"public/images/Mycat/mysql高可用方案6.png","hash":"d109b2815fa8b2f4695b2afd4737f172c5213b6a","modified":1551104304288},{"_id":"public/images/books/spring源码深度解析.png","hash":"f27b2ef361e7774609547c06fa0aa393564865dc","modified":1551104304288},{"_id":"public/images/books/unix网络编程-卷1.png","hash":"e2effd5a73a155911c17a0a774d69470a9b24038","modified":1551104304288},{"_id":"public/images/books/统计学习方法.png","hash":"c5da06321c3798ad4879fc91d5644f10d0fedf2c","modified":1551104304288},{"_id":"public/images/books/高性能MySQL.png","hash":"95dd4d34a536904549c06c4c7f39e59e48f9a77b","modified":1551104304288},{"_id":"public/images/java源码/BIO-字节流.png","hash":"f2515c14929d477e06d98cdae034617b85bce0e0","modified":1551104304288},{"_id":"public/images/java源码/BIO-类图.jpg","hash":"5bcd0cfe8321a26479cd12135d466688d1a6ed52","modified":1551104304288},{"_id":"public/images/java源码/concurrent-self类图.jpg","hash":"8a16f45aa9d4791434627f7f32481ad91450272c","modified":1551104304288},{"_id":"public/images/mongodb/混合集群-写数据.png","hash":"1c7b02fb94a86a574f301587984a92eedbe68bed","modified":1551104304288},{"_id":"public/images/mongodb/混合集群-读数据.png","hash":"be848661f339d8c4553ae83053a71e8154c728ff","modified":1551104304288},{"_id":"public/images/mongodb/混合集群.png","hash":"af5c36fd7fc6559022d2540620ea86babebf875d","modified":1551104304288},{"_id":"public/images/架构/postgres方案.png","hash":"e04e2f1c0a5ebda59e51cd76d77fc6ec752330ad","modified":1551104304288},{"_id":"public/images/推荐/amazon.png","hash":"c78f34a71832a71f9b0edd1a705bf81fcc629227","modified":1551104304288},{"_id":"public/images/架构/架构演进.png","hash":"ba98dab6d0155f17bb3747d5a41bb85d5c485cc9","modified":1551104304288},{"_id":"public/images/Mycat/mysql高可用方案1.png","hash":"bb727e7e9fef8cf88c98f258c98ab97db1363879","modified":1551104304412},{"_id":"public/images/books/InnoDB存储引擎.png","hash":"7b899beabf58ea897d511f2a3e61b6c5b155c57c","modified":1551104304412},{"_id":"public/images/books/Lucene实战.png","hash":"137ff0052fbe7ac9c4cf4443e409fe489759ba78","modified":1551104304428},{"_id":"public/images/books/Spring实战3.png","hash":"8f26f0f2de8878020b7ca93e293cdc1e8d2ca1c8","modified":1551104304428},{"_id":"public/images/books/tcpip-卷三.png","hash":"e4ad5aa1e060629cd9215b017b409e5dace64cae","modified":1551104304428},{"_id":"public/images/books/unix网络编程-卷2.png","hash":"9824727e9b1115682e55c302fda3514d2e0616cb","modified":1551104304428},{"_id":"public/images/books/tcpip-卷一.png","hash":"23d7ebe171797240a4ab391b87f42a86e13c28d2","modified":1551104304646},{"_id":"public/images/books/深入剖析tomcat.png","hash":"5eb085293a983920de7a8d2ee56ee642fc66f935","modified":1551104304646},{"_id":"public/images/books/tcpip-卷二.png","hash":"dd5b5ec3db9496b4b05c447f2392fed312e69982","modified":1551104304646},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1551104304646},{"_id":"public/images/bg2.jpg","hash":"bfee6b59dd329064da41234714ca412fdb033475","modified":1551104304724},{"_id":"public/images/mahout/recommendDiagram.jpg","hash":"87af1f0aaf085686af5a452306d9fbed91283e55","modified":1551104304724},{"_id":"public/images/推荐/推荐场景.png","hash":"b29c3f2af8f9c64ad9e429cb7941c4be6e2781c4","modified":1551104304724},{"_id":"public/images/books/数据挖掘导论.png","hash":"e0a37e31c64a4920d913ce6060a2f0fb175cb93c","modified":1551104305052},{"_id":"public/images/JVM/2_内存区域与异常.png","hash":"aab38134cef77e8c2cdfda6d07aa74badd47f70f","modified":1551104305349},{"_id":"public/images/算法/roc-example.png","hash":"56a98007d73a76726919462d1c5bef4940cde02d","modified":1551104305349},{"_id":"public/images/算法/score-ranking.png","hash":"ad00a22fabd5b7eb054f578d263dc6111ef4ae47","modified":1551104305365},{"_id":"public/images/算法/fpr-and-tpr.png","hash":"62b527c785cbf9ce093d8621e859423b5393be33","modified":1551104305365},{"_id":"public/images/算法/均值推导过程.JPG","hash":"c7d89a09869b118bd20d5379bc4f8321df79b913","modified":1551104305381}],"Category":[{"name":"前端","_id":"cjskffnw000024glmvspznr50"},{"name":"后端脚本","_id":"cjskffnxq000i4glmajxydbl2"},{"name":"架构","_id":"cjskffny6000p4glmd8ksw0cr"},{"name":"JVM高级特性","_id":"cjskffny6000v4glm41hq6ttx"},{"name":"算法","_id":"cjskffnym00114glmi95ebesu"},{"name":"项目管理","_id":"cjskffnym00154glmx7inrh5l"},{"name":"JAVA源码","_id":"cjskffnz1001l4glmakxlvgyd"},{"name":"互联网团队技术","_id":"cjskffo6e00264glmhs5kk6ww"},{"name":"密码学","_id":"cjskffo6u002c4glmos81466d"},{"name":"相似度算法","_id":"cjskffo7a002i4glm5pa4x5gz"},{"name":"系统架构","_id":"cjskffo7p002p4glm35x2m0u1"},{"name":"推荐","_id":"cjskffo85002y4glm5v2icjnn"},{"name":"用户场景","_id":"cjskffo8k00364glm9sn226u8"},{"name":"Docker指令","_id":"cjskffo90003c4glmz0vb2t94"},{"name":"文本挖掘","_id":"cjskffo9g003j4glmjveuehx3"},{"name":"回归算法","_id":"cjskffo9v003u4glm7lglska5"},{"name":"分类算法","_id":"cjskffoab00434glmyvocsg13"},{"name":"聚类算法","_id":"cjskffobm004q4glmfl48w6rj"},{"name":"Duke","_id":"cjskffoc1004y4glmulnmikfi"},{"name":"学术会议","_id":"cjskffoch00584glmpo1vn9py"},{"name":"读书笔记","_id":"cjskffodc005i4glmn3dqjyfx"},{"name":"项目构建","_id":"cjskffoen005q4glmw16nhnpx"},{"name":"开源框架","_id":"cjskffof2005y4glmoed1izr9"},{"name":"中间件","_id":"cjskffofi006b4glmulr9s618"},{"name":"CSS布局","_id":"cjskffogd006q4glmh5svmfke"},{"name":"Token详解","_id":"cjskffogt006y4glmxy956yo9"},{"name":"其它","_id":"cjskffoho007l4glmuj2kygu5"},{"name":"源码研究","_id":"cjskffoho007q4glmtkug9g0c"},{"name":"分布式","_id":"cjskffoho007t4glmt4snvjjc"},{"name":"大数据","_id":"cjskffp4n008r4glm2jwokcuw"}],"Data":[],"Page":[{"title":"tags","date":"2018-11-29T05:30:15.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-11-29 13:30:15\ntype: \"tags\"\ncomments: false\n---\n","updated":"2018-11-29T12:51:25.312Z","path":"tags/index.html","layout":"page","_id":"cjskffo5z00234glm1h3pogt4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2018-11-29T05:29:11.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-11-29 13:29:11\ntype: \"categories\"\ncomments: false\n---\n","updated":"2018-11-29T12:51:25.310Z","path":"categories/index.html","layout":"page","_id":"cjskffo6e00254glmlvlhi7mn","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2018-11-29T05:30:23.000Z","_content":"\n万千程序员中的一个coder。\n\n喜欢用后端技术来实现逻辑。\n\n喜欢用前端技术把产品展示给用户。\n\n喜欢用原型工具来记下天马行空的想法，然后放在站酷上记录一下。\n\n用c#做了3年的 winform开发，\n\n后来转java了，一直靠这个语言工作着。。。\n\n接触的行业有社保，医疗，金融。。。\n\n接触了原型设计，工作中离不开axure，上班每天可以不打开IDE，但是一定要打开axure。。。\n\n想当一个产品经理，其实人人都是产品经理。\n\n想做一名合格的运营，掌握如何把一个产品推广到最好。\n\n最大的梦想是做一个营销人，营销自己，营销自己的想法，营销自己做的产品，改变一点点事情。。。\n\n博客园:\n\nhttps://www.cnblogs.com/lvfeilong/\n\n站酷:\n\nhttps://www.zcool.com.cn/u/2631545/\n\n新浪微博：\n\nhttps://weibo.com/u/1627099732\n\nQQ：\n\n244328187","source":"about/index.md","raw":"---\ntitle: about\ndate: 2018-11-29 13:30:23\n---\n\n万千程序员中的一个coder。\n\n喜欢用后端技术来实现逻辑。\n\n喜欢用前端技术把产品展示给用户。\n\n喜欢用原型工具来记下天马行空的想法，然后放在站酷上记录一下。\n\n用c#做了3年的 winform开发，\n\n后来转java了，一直靠这个语言工作着。。。\n\n接触的行业有社保，医疗，金融。。。\n\n接触了原型设计，工作中离不开axure，上班每天可以不打开IDE，但是一定要打开axure。。。\n\n想当一个产品经理，其实人人都是产品经理。\n\n想做一名合格的运营，掌握如何把一个产品推广到最好。\n\n最大的梦想是做一个营销人，营销自己，营销自己的想法，营销自己做的产品，改变一点点事情。。。\n\n博客园:\n\nhttps://www.cnblogs.com/lvfeilong/\n\n站酷:\n\nhttps://www.zcool.com.cn/u/2631545/\n\n新浪微博：\n\nhttps://weibo.com/u/1627099732\n\nQQ：\n\n244328187","updated":"2018-12-01T08:24:08.297Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjskffo6e00294glmw14ggbvr","content":"<p>万千程序员中的一个coder。</p>\n<p>喜欢用后端技术来实现逻辑。</p>\n<p>喜欢用前端技术把产品展示给用户。</p>\n<p>喜欢用原型工具来记下天马行空的想法，然后放在站酷上记录一下。</p>\n<p>用c#做了3年的 winform开发，</p>\n<p>后来转java了，一直靠这个语言工作着。。。</p>\n<p>接触的行业有社保，医疗，金融。。。</p>\n<p>接触了原型设计，工作中离不开axure，上班每天可以不打开IDE，但是一定要打开axure。。。</p>\n<p>想当一个产品经理，其实人人都是产品经理。</p>\n<p>想做一名合格的运营，掌握如何把一个产品推广到最好。</p>\n<p>最大的梦想是做一个营销人，营销自己，营销自己的想法，营销自己做的产品，改变一点点事情。。。</p>\n<p>博客园:</p>\n<p><a href=\"https://www.cnblogs.com/lvfeilong/\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lvfeilong/</a></p>\n<p>站酷:</p>\n<p><a href=\"https://www.zcool.com.cn/u/2631545/\" target=\"_blank\" rel=\"noopener\">https://www.zcool.com.cn/u/2631545/</a></p>\n<p>新浪微博：</p>\n<p><a href=\"https://weibo.com/u/1627099732\" target=\"_blank\" rel=\"noopener\">https://weibo.com/u/1627099732</a></p>\n<p>QQ：</p>\n<p>244328187</p>\n","site":{"data":{}},"excerpt":"","more":"<p>万千程序员中的一个coder。</p>\n<p>喜欢用后端技术来实现逻辑。</p>\n<p>喜欢用前端技术把产品展示给用户。</p>\n<p>喜欢用原型工具来记下天马行空的想法，然后放在站酷上记录一下。</p>\n<p>用c#做了3年的 winform开发，</p>\n<p>后来转java了，一直靠这个语言工作着。。。</p>\n<p>接触的行业有社保，医疗，金融。。。</p>\n<p>接触了原型设计，工作中离不开axure，上班每天可以不打开IDE，但是一定要打开axure。。。</p>\n<p>想当一个产品经理，其实人人都是产品经理。</p>\n<p>想做一名合格的运营，掌握如何把一个产品推广到最好。</p>\n<p>最大的梦想是做一个营销人，营销自己，营销自己的想法，营销自己做的产品，改变一点点事情。。。</p>\n<p>博客园:</p>\n<p><a href=\"https://www.cnblogs.com/lvfeilong/\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/lvfeilong/</a></p>\n<p>站酷:</p>\n<p><a href=\"https://www.zcool.com.cn/u/2631545/\" target=\"_blank\" rel=\"noopener\">https://www.zcool.com.cn/u/2631545/</a></p>\n<p>新浪微博：</p>\n<p><a href=\"https://weibo.com/u/1627099732\" target=\"_blank\" rel=\"noopener\">https://weibo.com/u/1627099732</a></p>\n<p>QQ：</p>\n<p>244328187</p>\n"}],"Post":[{"layout":"lay_post","title":"用一天时间来学习angularjs","date":"2015-08-16T04:10:12.000Z","author":"lvyafei","published":1,"summary":["/images/angularjs.jpg"],"_content":"\n* 目录\n{:toc #meuid}\n\n对于学习angulaJS来说，更多的是对整体的了解。看了Todd Motto 的一篇文章后，对这个框架有了一个比较清晰的认识。\n[查看原文](http://toddmotto.com/ultimate-guide-to-learning-angular-js-in-one-day/)\n<!-- more -->\n\n## I.什么是AngularJS?\n\n![](/images/angularjs.jpg)\n\nAngular 是一个客户端MVC/MVVM框架，内置在JavaScript中，是现在流行的单页面web应用（甚至是网站）必不可少的东西。这篇文章是我学习angularjs的全部的经验，建议和最佳的做法。通过掌握它你会学会很多东西。\n\n## II.Terminology(术语)\n\nAngular 有一个短的学习路线，掌握了基本知识后你会发现它的优点和缺点，对学习这个框架来说，掌握这些术语和学会用MVC思考是非常重要的，下面是一些Angular中包含的一些高级并且重要的api和术语。\n\n## III.MVC\n\n你可能听说过MVC，用在许多编程语言中来构建应用程序/软件/架构的一种手段。这里是每个部分的简单含义：\n\n**Model**：每一个应用中都离不开数据结构，通常放在JSON中。在开始Angular之前先要读懂JSON，因为它对了解server和view是如何通信的非常重要。例如，一组用户身份标识可以有以下模型：\n\n    {\n      \"users\" : [{\n      \"name\": \"Joe Bloggs\",\n      \"id\": \"82047392\"\n    },{\n      \"name\": \"John Doe\",\n      \"id\": \"65198013\"\n     }]\n    }\n\n然后你就可以从服务器通过XHR抓取信息（XMLHTTP请求），在Jquery中是通过$.ajax方法，在Angular中是$http,或者它会写进你的代码在页面解析（从一个数据仓库/数据库）时，然后你可以推送更新到你的模型，并把它发送回。\n\n**View**: View是非常容易理解的，它是你的HTML页面或呈现的输出。使用MVC框架，你会使用Model数据来更新View和HTML中显示的相关数据。\n\n**Controller**：Controller直接访问服务器中的View，作为中间人，你能够在Controller中更新Model中的数据来改变View。\n\n## 0.建立一个AngularJS项目（基本要点）\n\n首先，我们需要确认安装了AngularJS必备的基础环境，在我们开始前有一些事情是需要注意的，一般由ng-app声明来定义你的应用程序,一个Controller和View页面、一些DOM邦定还有Angular来交互。以下是基本要点：\n\n一些带“ng-*” 声明的HTML\n\n    <div ng-app=\"myApp\">\n      <div ng-controller=\"MainCtrl\">\n          <!-- controller logic -->\n       </div>\n    </div>\n    \nAngular的 Module 和 Controller:\n\n\tvar myApp = angular.module('myApp', []);\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n \t   // Controller magic\n\t}]);\n    \n在开始动手之前，我们需要创建一个包含所有逻辑的Angular module,有很多种方法来声明 modules,你可以将所有的逻辑像这样串联起来（我不喜欢这种做法）：\n\n\tangular.module('myApp', [])\n\t.controller('MainCtrl', ['$scope', function ($scope) {...}])\n\t.controller('NavCtrl', ['$scope', function ($scope) {...}])\n\t.controller('UserCtrl', ['$scope', function ($scope) {...}]);\n    \n在我的使用中，建立一个全局的Module被证明是一个非常好的方式。缺少分号和意外关闭的'连接'证明适得其反，会出现一些不必要的编译错误，像这样：\n\n\tvar myApp = angular.module('myApp', []);\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {...}]);\n\tmyApp.controller('NavCtrl', ['$scope', function ($scope) {...}]);\n\tmyApp.controller('UserCtrl', ['$scope', function ($scope) {...}]);\n    \n我创建的每一文件都使用简单的myApp命名空间并自动的邦定到Application上，没错，我会为每个Controller, Directive, Factory 和其它的内容创建一个文件，关联和压缩这些文件到一个脚本文件中，然后引入到DOM中（使用Grunt或Gulp类似的工具）\n\n## 1.Controllers(控制器)\n \n现在你已经掌握了MVC设计模式的概念和基本设置，让我们看看Angular中是如何运用Controllers的。\n从上面的例子中我们可以很简单的从一个Controller中拿到数据然后放入到DOM中，Angular采用一种模板风格 {{ handlebars }} 嵌在你的HTML中，你的HTML应该（最好）不包含物理文本或硬编码的值以最大限度地利用Angular，下面是一个将字符串推送到页面上的例子：\n\n    <div ng-app=\"myApp\">\n\t  <div ng-controller=\"MainCtrl\">\n          { { text } }\n  \t  </div>\n    </div>\n\n脚本：\n\n\tvar myApp = angular.module('myApp', []);\n\t\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n    \n    \t$scope.text = 'Hello, Angular fanatic.';\n    \n\t}]);\n\n\n\n演示：http://runjs.cn/code/jgevzqjd\n\n这里的核心法则是“$scope”的概念，你会在一个特定的Controller里面邦定所有的功能。$scope代表的是DOM中当前的元素，封装一个非常好的观察能力，保持元素范围内的数据和逻辑完完美邦定。它提供了JavaScript的公共/私有范围的DOM，这很神奇。\n\n$scope的范围概念似乎有点可怕，但这是你从服务器到DOM的交互方式（静态数据，如果你有过）！这个例子教你了一个如何把数据“推”到DOM的办法。\n\n让我们看一个比较有代表性的数据结构，我们假设从服务器检索显示用户的登录信息。现在我将使用静态数据；我后边会告诉你如何获取动态JSON数据。\n\n首先我们要编写JavaScript：\n\n    var myApp = angular.module('myApp', []);\n\n    myApp.controller('UserCtrl', ['$scope', function ($scope) {\n    \n        // Let's namespace the user details\n        // Also great for DOM visual aids too\n        $scope.user = {};\n        $scope.user.details = {\n            \"username\": \"Todd Motto\",\n            \"id\": \"89101112\"\n        };\n    \n    }]);\n    \n然后交给DOM来显示这些数据：\n\n    <div ng-app=\"myApp\">\n        <div ng-controller=\"UserCtrl\">\n            <p class=\"username\">Welcome, { { user.details.username } }</p>\n            <p class=\"id\">User ID: { { user.details.id } }</p>\n        </div>\n    </div>\n    \n演示：http://runjs.cn/code/4xrlzycm\n\n重要的一点要记住，控制器只为数据，并创建函数（也包括事件函数）！它跟服务器交互并且推/拉JSON数据。这里没有DOM操作，所以不需要jQery工具。指令(Directives )是DOM操作，这是下一个要介绍的。\n\n小提示：在Angular的官方文档中（我在写这篇文章时）他们的例子中使用这种方式创建Controllers：\n\n    var myApp = angular.module('myApp', []);\n\n    function MainCtrl ($scope) {\n    //...\n    };\n    \n…不要这样做。这将所有的功能都暴露在全局范围内，并不会让它们与应用程序很好地联系在一起。这也意味着你不能很容易的缩小你的代码或运行测试。不要滥用全局名称空间，要保证Controller只在您的应用程序内。\n\n\n## 2.Directives(指令)\n\n指令最简化形式是一段HTML模板，在应用程序需要的地方最好能多次使用。这是毫不费力的注入DOM到应用中最简单的方式，或执行自定义DOM交互。指令并不简单，想完全征服他们需要一个非常令人难以置信的学习路线，但通过这一小节的学习会让你基本掌握它。\n\n那指令有什么用处？很多事情，包括DOM组件，例如制表符或导航元素会依赖你的应用程序中使用的UI。让我这样说吧，如果你有过ng-show或者ng-hide，这就是指令（虽然他们不注入DOM）。\n\n对于这个练习，我想把它弄的很简单，创建一个自定义按钮（称为CustomButton）注入一些标记，我讨厌写很多字。有各种不同的方式定义DOM中的指令，这些可能看起来像这样：\n\n    <!-- 1: as an attribute declaration -->\n    <a custom-button>Click me</a>\n\n    <!-- 2: as a custom element -->\n    <custom-button>Click me</custom-button>\n\n    <!-- 3: as a class (used for old IE compat) -->\n    <a class=\"custom-button\">Click me</a>\n\n    <!-- 4: as a comment (not good for this demo, however) -->\n    <!-- directive: custom-button -->\n    \n我更喜欢他们作为一个属性使用，自定义元素作为HTML5未来的一个Web组件特性，但Angular指出这在一些老的浏览器上会当成是一个BUG。\n\n现在你知道在使用/注入指令的时候如何声明了吧，让我们创建这个自定义按钮。再次，我会回调我的全局命名空间MyApp的应用，这是最简形式的指令：\n\n    myApp.directive('customButton', function () {\n      return {\n        link: function (scope, element, attrs) {\n          // DOM manipulation/events here!\n        }\n      };\n    });\n    \n我使用 .directive()方法来创建指令，传入指令的名称“CustomButton“。当你在指令的名称中使用一些字母，它会通过DOM中的连字符进行分割（如上图）。\n\n一个指令简单的返回一个带有参数的对象。对我来说最重要的是：restrict, replace, transclude, template 和 templateUrl,当然还有 link 属性。让我把其它的也加入进来吧：\n\n    myApp.directive('customButton', function () {\n      return {\n        restrict: 'A',\n        replace: true,\n        transclude: true,\n        template: '<a href=\"\" class=\"myawesomebutton\" ng-transclude>' +\n                    '<i class=\"icon-ok-sign\"></i>' +\n                  '</a>',\n        link: function (scope, element, attrs) {\n          // DOM manipulation/events here!\n        }\n      };\n    });\n    \n演示： http://runjs.cn/code/xtupcxdh\n\n验证你是否插入元素，请确认你是否注入附加标记。指令的属性解释：\n\n**restrict**：[约束]看下上面的例子我们是怎么使用restrict的，如果你的项目需要支持IE的话，你可能需要声明attribute或class。使用“A”意味着你限制它作为一个Attribute，E代表Element，C代表Class，M代表Comment。默认是“EA”，对的，你可以限制多个。\n\n**replace**：[替换]替换DOM为指令中定义的内容，在这个例子中，你会注意到初始DOM已经被指令的模板替换。\n\n**transclude**：[嵌入]简单地说，使用嵌入允许现有的DOM内容被复制到指令中。你会看到单词'点击我'已被'移'到指令中，在显示的时候。\n\n**template**：[模板]模板（如上）允许你将标记为被注入。这是一个好主意，用这一小段HTML片断。注入模板都通过Angular编译，这意味着你可以定义处理的方法已更好的邦定使用。\n\n**templateUrl**：[模板Url]类似于一个模板，但保持在它自己的文件或<脚本>标签。你可以指定一个模板的URL，你会使用一个单独的文件来管理HTML模板，请指定路径和文件名，最好放在自己的模板目录中：\n\n    myApp.directive('customButton', function () {\n      return {\n        templateUrl: 'templates/customButton.html'\n        // directive stuff...\n      };\n    });\n    \n加入你的文件（文件名不敏感）：\n\n    <!-- inside customButton.html -->\n    <a href=\"\" class=\"myawesomebutton\" ng-transclude>\n      <i class=\"icon-ok-sign\"></i>\n    </a>\n    \n这样做真的很好，浏览器会缓存HTML文件，干的漂亮！设置不缓存的另一个选择是在script标签中声明一个模板：\n\n    <script type=\"text/ng-template\" id=\"customButton.html\">\n    <a href=\"\" class=\"myawesomebutton\" ng-transclude>\n      <i class=\"icon-ok-sign\"></i>\n    </a>\n    </script>\n    \n你会告诉Angular它是一个模板并且还有一个ID，Angular会查找NG模板或*.HTML文件,他们很容易管理，提高性能和保持DOM很干净，你可以建立1个或100个指令，你可以很容易的浏览它们。\n\n## 3.Services(服务)\n\n服务通常是混淆点。从经验和研究上，他们更多的是一种风格的设计模式，而不是提供更多的功能差异。在深入到Angular源码后,他们指望通过相同的编译器运行，并共享大量的功能。从我的研究来看，你应该在单例，工厂以及其它更复杂的功能上使用服务，如对象字面量和更复杂的用例。\n\n下面是一个Service例子,计算2个数字的乘积：\n\n     myApp.service('Math', function () {\n          this.multiply = function (x, y) {\n              return x * y;\n         };\n    });\n    \n然后，你应该使用这样的内部控制器：\n\n    myApp.controller('MainCtrl', ['$scope', function ($scope) {\n        var a = 12;\n        var b = 24;\n       // outputs 288\n        var result = Math.multiply(a, b);\n    }]);\n    \n是的，乘法是很容易的，不需要一个服务，但你领会到了其中的要点。\n\n当你创建一个服务（或工厂）时，你需要使用依赖注入来告诉Angular需要扑获新的服度，否则你会得到编译错误，你的控制器会中断。你可能已经注意到了这个函数($scope)的部分，现在，这是简单的依赖注入。看下你的代码,你也会注意到（$scope）之前的功能（$scope），我会到后面解释。这里是如何使用依赖注入来告诉你需要你的服务：\n\n    // Pass in Math\n    myApp.controller('MainCtrl', ['$scope', 'Math', function ($scope, Math) {\n      var a = 12;\n      var b = 24;\n      // outputs 288\n      var result = Math.multiply(a, b);\n    }]);\n    \n## 4.Factories(工厂)\n\n从服务到工厂现在应该是简单的，我们可以在工厂里创建一个对象字面量或简单地提供一些更深入的方法：\n\n\tmyApp.factory('Server', ['$http', function ($http) {\n\t  return {\n\t    get: function(url) {\n\t      return $http.get(url);\n\t    },\n\t    post: function(url) {\n\t      return $http.post(url);\n\t    },\n\t  };\n\t}]);\n\t\n下面，在依赖注入到一个控制器后，我创造了一个Angular的XHR自定义包装。这个例子很简单：\n\n\tmyApp.controller('MainCtrl', ['$scope', 'Server', function ($scope, Server) {\n\t    var jsonGet = 'http://myserver/getURL';\n\t    var jsonPost = 'http://myserver/postURL';\n\t    Server.get(jsonGet);\n\t    Server.post(jsonPost);\n\t}]);\n\t\n如果你想为了改变而轮询服务，你可以设置一个Server.poll(jsonPool),或者假如你正在使用一个Socket,你可以设置Server.socket(jsonSocket).它打开了大门，模块化代码以及创造您使用和保持代码内的控制器，作为一个最小的完整集合。\n\n## 5.Filters(过滤器)\n    \n过滤器一般和数组一块使用，用在循环外，如果你遍历数组来筛选出特定的东西，在正确的地方，你也可以使用过滤器过滤用户想要的类型在<input>标签为例，有几个方法可以使用过滤器，在控制器里面或作为一个定义的方法。这里有使用的方法，您可以在全局使用：\n\n\tmyApp.filter('reverse', function () {\n\t    return function (input, uppercase) {\n\t        var out = '';\n\t        for (var i = 0; i < input.length; i++) {\n\t            out = input.charAt(i) + out;\n\t        }\n\t        if (uppercase) {\n\t            out = out.toUpperCase();\n\t        }\n        return out;\n\t    }\n\t});\n\n\t// Controller included to supply data\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t    $scope.greeting = 'Todd Motto';\n\t}]);\n\t\nDOM内容：\n\n\t<div ng-app=\"myApp\">\n\t    <div ng-controller=\"MainCtrl\">\n\t        <p>No filter: { { greeting } }</p>\n\t        <p>Reverse: { { greeting | reverse } }</p>\n\t    </div>\n\t</div>\n\t\n例子：http://runjs.cn/code/ina2n1lb\n\n可以看到我们通过传递过滤符号“|”在greeting 数据上，对该数据进行逆向过滤。\n\n在标签ng-repeat中的用法为：\n\n\t<ul>\n\t  <li ng-repeat=\"number in myNumbers |filter:oddNumbers\">{{ number }}</li>\n\t</ul>\n\n一个在controller中使用过滤器的简明例子：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t\t$scope.numbers = [10, 25, 35, 45, 60, 80, 100];\n\t\t$scope.lowerBound = 42;\n\t\t// Does the Filters\n\t\t$scope.greaterThanNum = function (item) {\n\t\t    return item > $scope.lowerBound;\n\t\t};\n\t}]);\n\t\n在ng-repeat标签中的用法为:\n\n\t<li ng-repeat=\"number in numbers | filter:greaterThanNum\">\n\t  {{ number }}\n\t</li>\n\t\n演示:http://runjs.cn/code/xiricwi3\n\n这是AngularJS中的主体部分和API，虽然这只是冰山一角，但利用这些内容足以建立起你自己的angular应用。\n\n## 6.Two-way data-binding(双向数据绑定)\n\n当我第一次听说双向数据绑定时，我并不太明白它是什么。双向数据绑定是最好的理解为一个完全同步的数据循环：更新模型并更新视图，更新视图并更新模型。这意味着数据不需要做任何操作都是同步的。如果我将一个ng模型绑定到一个<input>标签然后开始输入，这将在同一时间创建（或更新一个现有的）模型。\n\n我创建的一个<input>标签并绑定模型称为\"myModel\"，然后我可以利用angularjs中的语法来反射这个模型并同时更新视图：\n\n\t<div ng-app=\"myApp\">\n\t    <div ng-controller=\"MainCtrl\">\n\t        <input type=\"text\" ng-model=\"myModel\" placeholder=\"Start typing...\" />\n\t        <p>My model data: {{ myModel }}</p>\n\t    </div>\n\t</div>\n\t\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t    // Capture the model data\n\t    // and/or initialise it with an existing string\n\t    $scope.myModel = '';\n\t}]);\n\t\n示例：http://runjs.cn/code/fu074xjf\n\n## 7.XHR/Ajax/$http calls and binding JSON\n\n你已经掌握了如何把一个基础数据邦定到$scope上，并大致了解了这个model是如何工作的，包括数据的双向邦定。\n现在是时候学习一些真正的XHR去调用一个服务。对于网站来说，这是没有必要的除非你有特别的Ajax要求，这主要是集中在抓取数据的Web应用程序。\n\n当你在做本地开发时，你可能使用类似Java，ASP.NET，PHP或别的东西来运行一个本地服务器。无论您是和本地数据库通信还是实际使用服务器作为接口来与其他资源进行通信，这都是相同的。\n\n输入$http,就可以愉快的开始了。$HTTP方法是从服务器访问数据的一个很好的Angular包装，你可以很方便的使用。这里是一个“GET”请求的简单例子，它从服务器获取数据。它的语法很像是jQuery，所以很好理解：\n\n\tmyApp.controller('MainCtrl', ['$scope', '$http', function ($scope, $http) {\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrl'\n\t  });\n\t}]);\n\t\nAngular然后返回内容(叫做承诺)，这是处理回调的一种更有效和可读的方式。承诺是链接function到他们从使用点.mypromise()。正如预期的那样，我们有错误和成功的处理程序：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrl'\n\t  })\n\t  .success(function (data, status, headers, config) {\n\t\t// successful data retrieval\n\t  })\n\t  .error(function (data, status, headers, config) {\n\t\t// something went wrong :(\n\t  });\n\t}]);\n\t\n非常好的可读性。这就是我们合并视图和绑定模式或更新模型数据到DOM的服务器。让我们假设一个设置和推动一个用户名的DOM，通过Ajax调用。\n\n理想情况下，我们应该首先建立和设计我们的JSON，这将影响我们如何构造我们的数据。让我们保持简单，这是一个后端开发者将开放一个API在应用程序中，您希望如下：\n\n\t{\n\t  \"user\": {\n\t\t\"name\": \"Todd Motto\",\n\t\t\"id\": \"80138731\"\n\t  }\n\t}\n\t\n这意味着我们会得到一个从服务器返回的对象（化名就叫‘数据’[你可以看到数据被传递到我们的承诺处理]），并嵌有data.user属性。在data.user属性里面，有name和id,访问这些很容易的，我们需要寻找data.user.name这个属性时，它将返回这个属性的值。现在让我们来操作下吧！\n\nJavaScript代码：\n\n\tmyApp.controller('UserCtrl', ['$scope', '$http', function ($scope, $http) {\n\t  // create a user Object\n\t  $scope.user = {};\n\t  // Initiate a model as an empty string\n\t  $scope.user.username = '';\n\t  // We want to make a call and get\n\t  // the person's username\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrlForGettingUsername'\n\t  })\n\t  .success(function (data, status, headers, config) {\n\t\t// See here, we are now assigning this username\n\t\t// to our existing model!\n\t\t$scope.user.username = data.user.name;\n\t  })\n\t  .error(function (data, status, headers, config) {\n\t\t// something went wrong :(\n\t  });\n\t}]);\n\nDOM代码：\n\n\t<div ng-controller=\"UserCtrl\">\n\t  <p>{{ user.username }}</p>\n\t</div>\n\t\n它会打印username的值。下面我们将进一步了解声明式数据绑定，这是非常令人兴奋的。\n\n## 8.Declarative data-binding(声明式数据邦定)\n\nAngular的理念是创建动态HTML.它是一个强大的功能,代替了你在客户端做的大量工作。这正是他的目的所在。\n\n让我们想象一下，我们刚刚作了一个Ajax请求得到一些电子邮件的列表包含主题，发送日期，现在想把它们展示在DOM中。这里会体现出Angular的优势。首先，我需要设置一个电子邮件的controller：\n\n\tmyApp.controller('EmailsCtrl', ['$scope', function ($scope) {\n\t  // create a emails Object\n\t  $scope.emails = {};\n\t  // pretend data we just got back from the server\n\t  // this is an ARRAY of OBJECTS\n\t  $scope.emails.messages = [{\n\t\t    \"from\": \"Steve Jobs\",\n\t\t    \"subject\": \"I think I'm holding my phone wrong :/\",\n\t\t    \"sent\": \"2013-10-01T08:05:59Z\"\n\t\t},{\n\t\t    \"from\": \"Ellie Goulding\",\n\t\t    \"subject\": \"I've got Starry Eyes, lulz\",\n\t\t    \"sent\": \"2013-09-21T19:45:00Z\"\n\t\t},{\n\t\t    \"from\": \"Michael Stipe\",\n\t\t    \"subject\": \"Everybody hurts, sometimes.\",\n\t\t    \"sent\": \"2013-09-12T11:38:30Z\"\n\t\t},{\n\t\t    \"from\": \"Jeremy Clarkson\",\n\t\t    \"subject\": \"Think I've found the best car... In the world\",\n\t\t    \"sent\": \"2013-09-03T13:15:11Z\"\n\t\t}];\n\t}]);\n\t\n现在我们需要把它插入到我们的HTML中。这时我们会使用声明式绑定宣布什么应用程序将创建我们的第一个动态HTML。我们要用到Angular的内置指令ng-repeat，它会遍历数据，完全没有回调或状态变化的渲染输出，这都是非常灵活的：\n\n\t<ul>\n\t  <li ng-repeat=\"message in emails.messages\">\n\t\t<p>From: {{ message.from }}</p>\n\t\t<p>Subject: {{ message.subject }}</p>\n\t\t<p>{{ message.sent | date:'MMM d, y h:mm:ss a' }}</p>\n\t  </li>\n\t</ul>\n\t\n示例：http://runjs.cn/code/q9beqc9s\n\n我使用了一个日期过滤器，从中你可以看到如何处理UTC日期。\n\n深入Angular的ng-*指令,你将完全释放出angular的声明式绑定的能力，这里展示了如何从服务器到模型，以及模拟和渲染数据。\n\n\n## 9.Scope functions(范围函数)\n\n作为声明性绑定的延续，范围函数是在创建应用程序时的下一个层次。这里展示了一个基本功能，删除我们的电子邮件中的一个数据：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t  $scope.deleteEmail = function (index) {\n\t\t$scope.emails.messages.splice(index, 1)\n\t  };\n\t}]);\n\t\n友情提示：重要的一点是要考虑从模型中删除数据。不删除元素或任何实际的DOM相关，angular是一个MVC框架，将为您处理这一切与它的双向绑定和回调的自由世界，你只需要设置你的代码可以让它响应你的数据！\n\n\t<a ng-click=\"deleteEmail($index)\">Delete email</a>\n\t\n这是一种不同的内联点击处理程序，因为许多原因。这将很快覆盖。你会看到我也在通过$index，angular知道你正在删除的项目（这样可以节省你多少代码和逻辑！）。\n\n示例：http://runjs.cn/code/jm84qnh3\n\n## 10.Declarative DOM methods(陈述性DOM方法)\n\n现在我们要转移到的DOM方法，这些也都是些指令和模拟功能的DOM，你通常会写出更多的逻辑脚本。这个例子是一个简单的切换导航。用一个简单的ng-show和一个简单的ng-click设置，我们可以创建一个完美无瑕的切换导航：\n\n\t<a href=\"\" ng-click=\"toggle = !toggle\">Toggle nav</a>\n\t<ul ng-show=\"toggle\">\n\t  <li>Link 1</li>\n\t  <li>Link 2</li>\n\t  <li>Link 3</li>\n\t</ul>\n\t\n我们开始进入MVVM的学习，你会发现脚本里没有controller的代码，我们会很快进入MVVM。\n\n示例：http://runjs.cn/code/r5tlnqrb\n\n## 11.Expressions(表达式)\n\n我最喜欢Angular的一部分是，你会用JavaScript写出很多重复的代码。\n\n你尝试过这个吗？\n\n\telem.onclick = function (data) {\n\t  if (data.length === 0) {\n\t\totherElem.innerHTML = 'No data';\n\t  } else {\n\t\totherElem.innerHTML = 'My data';\n\t  }\n\t};\n\t\n这可能是一个GET请求回调，你会改变基于数据的DOM。Angular给你这个自由，你就可以做到无需编写任何内置的JavaScript！\n\n\t<p>{{ data.length > 0 && 'My data' || 'No data' }}</p>\n\n这会动态更新自己而没有回调应用程序获取数据。如果没有数据，它会告诉你，如果有数据，它会显示数据。针对Angular处理自动双向绑定数据，会有很多的使用情况。\n\n示例：http://runjs.cn/code/ahl0hfcc\n\n## 12.Dynamic views and routing(动态视图和路由)\n\n单页面web应用(也包括网站)背后的理念是: 你有一个标题，页脚，侧边栏，和中间的内容,通过设置URL可以神奇地注入新的内容。\n\nAngular通过一个简单的设置来配置我们所说的动态视图。动态视图依靠URL注入每个视图，通过$routeprovider。一个简单的设置如下：\n\n\tmyApp.config(['$routeProvider', function ($routeProvider) {\n\t  /**\n\t   * $routeProvider\n\t   */\n\t  $routeProvider\n\t  .when('/', {\n\t\ttemplateUrl: 'views/main.html'\n\t  })\n\t  .otherwise({\n\t\tredirectTo: '/'\n\t  });\n\t}]);\n\n你会看到，当URL是\"/\"(即该站点的根目录),你会注入main.html。当你在一个单页面应用中已经有一个index.html页面，这是一个好的方法去调用内部的main.html视图而不是index.html。依靠URL去添加更多的视图是如此简单：\n\n\tmyApp.config(['$routeProvider', function ($routeProvider) {\n\t  /**\n\t   * $routeProvider\n\t   */\n\t  $routeProvider\n\t  .when('/', {\n\t\ttemplateUrl: 'views/main.html'\n\t  })\n\t  .when('/emails', {\n\t\ttemplateUrl: 'views/emails.html'\n\t  })\n\t  .otherwise({\n\t\tredirectTo: '/'\n\t  });\n\t}]);\n\t\n我们可以在emails.html上简单的加载HTML去生成我们的邮件列表,最终你可以毫不费力的创建一个复杂的应用程序。\n\n## 13.Global static data(全局静态数据)\n\nGmail处理很多内部初始化数据是通过将JSON加入到页面中(右键查看源代码)。如果你想立即在你的页面设置数据，它会加快渲染时间并且Angular将更快的执行。\n\n当我们开发应用程序时，页面渲染时，Java标签放置在DOM中，数据从后台发送过来。[我没有Java开发经验，你需要知道一个下面的声明，虽然在服务器上你可以使用任何语言。]这里是如何把JSON加入到网页中，然后把它传给一个控制器,为即时邦定使用：\n\n\t<!-- inside index.html (bottom of page ofc) -->\n\t<script>\n\twindow.globalData = {};\n\tglobalData.emails = <javaTagHereToGenerateMessages>;\n\t</script>\n\t\n我定义的java标签使数据能在页面中渲染，Angular会轻松的渲染你的emails数据，只要把你的数据放入到controller中即可:\n\n\tmyApp.controller('EmailsCtrl', ['$scope', function ($scope) {\n\t\t$scope.emails = {};\n\t\t// Assign the initial data!\n\t\t$scope.emails.messages = globalData.emails;\n\t}]);\n\t\n## 14.Minification(精简)\n\n这一段是关于精简你的angular代码内容。在这方面你可能已经尝试过了，有时跑一个精简过的代码，会遇到了一个错误！\n\n精简你的AngularJS代码很简单，你需要指定你的依赖注入的内容在函数数组：\n\n\tmyApp.controller('MainCtrl',\n\t['$scope', 'Dependency', 'Service', 'Factory',\n\tfunction ($scope, Dependency, Service, Factory) {\n\t  // code\n\t}]);\n\t\n精简后:\n\n\tmyApp.controller('MainCtrl',\n\t['$scope', 'Dependency', 'Service', 'Factory',\n\tfunction (a,b,c,d) {\n\t  // a = $scope\n\t  // b = Dependency\n\t  // c = Service\n\t  // d = Factory\n\t  // $scope alias usage\n\t  a.someFunction = function () {...};\n\t}]);\n\t\n请记住，以保持参数的顺序出现，否则你可能会导致你和你的团队费劲。\n\n## 15.Differences in MVC and MVVM(MVC和MVVM的差异)\n\n这里简要介绍两者的区别:\n\n**MVC**: 用一个controller交互,关系是Model-View-Controller\n**MVVM**: 封装声明数据邦定,Model-View-View-Model,Model和View交互,View也可以和Model交互,Angular的双向数据绑定允许它在不做任何事情时保持同步。它还允许你在没有控制器的情况下,编写逻辑代码！\n\n一个简单的例子，你可以创建一个ng-repeat标签去提供数据,而不需要Controller:\n\n\t<li ng-repeat=\"number in [1,2,3,4,5,6,7,8,9]\">\n\t  {{ number }}\n\t</li>\n\t\n对于快速测试这是很有帮助的，但对与复杂的情况时，我建议使用一个Controller。\n\n## 16.HTML5 Web Components(HTML5组件)\n\n在早些时候你会发现AngularJS允许你创建自定义的元素:\n\n\t<myCustomElement></myCustomElement>\n\n这实际上是符合HTML5未来的特性。HTML5 Web部件和模板元素，Angular让我们今天就能这样用。Web部件包括通过动态JavaScript注入生成的自定义元素！\n\n## 17.Scope comments(范围注释)\n\n范围注释,我觉得真的是一个不错特性,代替了HTML注释，像这样的块：\n\n\t<!-- header -->\n\t<header>\n\t  Stuff.\n\t</header>\n\t<!-- /header -->\n\t\n引入Angular后，让我们思考的是Views和Scopes，而不是DOM，除非你故意共享控制器间的数据，我发现使用范围是一个很大的帮助：\n\n\t<!-- scope: MainCtrl -->\n\t<div class=\"content\" ng-controller=\"MainCtrl\">\n\t</div>\n\t<!-- /scope: MainCtrl -->\n\t\n## 18.Debugging AngularJS(调试)\n\n对于调试AngularJS的话，可以使用Chrome的一个扩展工具-Batarang,你可以去下载下看看。\n\n## 结束\n到此本文结束,希望能够对大家学习angular有一个好的指导，更多关于angular的细节可以参看[Todd Motto](http://toddmotto.com/) 的系列文章 \n再次感谢原作者的整理，文中如有不对的地方可以指出。\n","source":"_posts/2015-08-16-用一天时间来学习angularjs.md","raw":"---\nlayout: lay_post\ntitle: 用一天时间来学习angularjs\ndate: 2015-08-16 12:10:12\ncategories: 前端\ntags: AngularJS\nauthor: lvyafei\npublished: true\nsummary: [\"/images/angularjs.jpg\"]\n---\n\n* 目录\n{:toc #meuid}\n\n对于学习angulaJS来说，更多的是对整体的了解。看了Todd Motto 的一篇文章后，对这个框架有了一个比较清晰的认识。\n[查看原文](http://toddmotto.com/ultimate-guide-to-learning-angular-js-in-one-day/)\n<!-- more -->\n\n## I.什么是AngularJS?\n\n![](/images/angularjs.jpg)\n\nAngular 是一个客户端MVC/MVVM框架，内置在JavaScript中，是现在流行的单页面web应用（甚至是网站）必不可少的东西。这篇文章是我学习angularjs的全部的经验，建议和最佳的做法。通过掌握它你会学会很多东西。\n\n## II.Terminology(术语)\n\nAngular 有一个短的学习路线，掌握了基本知识后你会发现它的优点和缺点，对学习这个框架来说，掌握这些术语和学会用MVC思考是非常重要的，下面是一些Angular中包含的一些高级并且重要的api和术语。\n\n## III.MVC\n\n你可能听说过MVC，用在许多编程语言中来构建应用程序/软件/架构的一种手段。这里是每个部分的简单含义：\n\n**Model**：每一个应用中都离不开数据结构，通常放在JSON中。在开始Angular之前先要读懂JSON，因为它对了解server和view是如何通信的非常重要。例如，一组用户身份标识可以有以下模型：\n\n    {\n      \"users\" : [{\n      \"name\": \"Joe Bloggs\",\n      \"id\": \"82047392\"\n    },{\n      \"name\": \"John Doe\",\n      \"id\": \"65198013\"\n     }]\n    }\n\n然后你就可以从服务器通过XHR抓取信息（XMLHTTP请求），在Jquery中是通过$.ajax方法，在Angular中是$http,或者它会写进你的代码在页面解析（从一个数据仓库/数据库）时，然后你可以推送更新到你的模型，并把它发送回。\n\n**View**: View是非常容易理解的，它是你的HTML页面或呈现的输出。使用MVC框架，你会使用Model数据来更新View和HTML中显示的相关数据。\n\n**Controller**：Controller直接访问服务器中的View，作为中间人，你能够在Controller中更新Model中的数据来改变View。\n\n## 0.建立一个AngularJS项目（基本要点）\n\n首先，我们需要确认安装了AngularJS必备的基础环境，在我们开始前有一些事情是需要注意的，一般由ng-app声明来定义你的应用程序,一个Controller和View页面、一些DOM邦定还有Angular来交互。以下是基本要点：\n\n一些带“ng-*” 声明的HTML\n\n    <div ng-app=\"myApp\">\n      <div ng-controller=\"MainCtrl\">\n          <!-- controller logic -->\n       </div>\n    </div>\n    \nAngular的 Module 和 Controller:\n\n\tvar myApp = angular.module('myApp', []);\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n \t   // Controller magic\n\t}]);\n    \n在开始动手之前，我们需要创建一个包含所有逻辑的Angular module,有很多种方法来声明 modules,你可以将所有的逻辑像这样串联起来（我不喜欢这种做法）：\n\n\tangular.module('myApp', [])\n\t.controller('MainCtrl', ['$scope', function ($scope) {...}])\n\t.controller('NavCtrl', ['$scope', function ($scope) {...}])\n\t.controller('UserCtrl', ['$scope', function ($scope) {...}]);\n    \n在我的使用中，建立一个全局的Module被证明是一个非常好的方式。缺少分号和意外关闭的'连接'证明适得其反，会出现一些不必要的编译错误，像这样：\n\n\tvar myApp = angular.module('myApp', []);\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {...}]);\n\tmyApp.controller('NavCtrl', ['$scope', function ($scope) {...}]);\n\tmyApp.controller('UserCtrl', ['$scope', function ($scope) {...}]);\n    \n我创建的每一文件都使用简单的myApp命名空间并自动的邦定到Application上，没错，我会为每个Controller, Directive, Factory 和其它的内容创建一个文件，关联和压缩这些文件到一个脚本文件中，然后引入到DOM中（使用Grunt或Gulp类似的工具）\n\n## 1.Controllers(控制器)\n \n现在你已经掌握了MVC设计模式的概念和基本设置，让我们看看Angular中是如何运用Controllers的。\n从上面的例子中我们可以很简单的从一个Controller中拿到数据然后放入到DOM中，Angular采用一种模板风格 {{ handlebars }} 嵌在你的HTML中，你的HTML应该（最好）不包含物理文本或硬编码的值以最大限度地利用Angular，下面是一个将字符串推送到页面上的例子：\n\n    <div ng-app=\"myApp\">\n\t  <div ng-controller=\"MainCtrl\">\n          { { text } }\n  \t  </div>\n    </div>\n\n脚本：\n\n\tvar myApp = angular.module('myApp', []);\n\t\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n    \n    \t$scope.text = 'Hello, Angular fanatic.';\n    \n\t}]);\n\n\n\n演示：http://runjs.cn/code/jgevzqjd\n\n这里的核心法则是“$scope”的概念，你会在一个特定的Controller里面邦定所有的功能。$scope代表的是DOM中当前的元素，封装一个非常好的观察能力，保持元素范围内的数据和逻辑完完美邦定。它提供了JavaScript的公共/私有范围的DOM，这很神奇。\n\n$scope的范围概念似乎有点可怕，但这是你从服务器到DOM的交互方式（静态数据，如果你有过）！这个例子教你了一个如何把数据“推”到DOM的办法。\n\n让我们看一个比较有代表性的数据结构，我们假设从服务器检索显示用户的登录信息。现在我将使用静态数据；我后边会告诉你如何获取动态JSON数据。\n\n首先我们要编写JavaScript：\n\n    var myApp = angular.module('myApp', []);\n\n    myApp.controller('UserCtrl', ['$scope', function ($scope) {\n    \n        // Let's namespace the user details\n        // Also great for DOM visual aids too\n        $scope.user = {};\n        $scope.user.details = {\n            \"username\": \"Todd Motto\",\n            \"id\": \"89101112\"\n        };\n    \n    }]);\n    \n然后交给DOM来显示这些数据：\n\n    <div ng-app=\"myApp\">\n        <div ng-controller=\"UserCtrl\">\n            <p class=\"username\">Welcome, { { user.details.username } }</p>\n            <p class=\"id\">User ID: { { user.details.id } }</p>\n        </div>\n    </div>\n    \n演示：http://runjs.cn/code/4xrlzycm\n\n重要的一点要记住，控制器只为数据，并创建函数（也包括事件函数）！它跟服务器交互并且推/拉JSON数据。这里没有DOM操作，所以不需要jQery工具。指令(Directives )是DOM操作，这是下一个要介绍的。\n\n小提示：在Angular的官方文档中（我在写这篇文章时）他们的例子中使用这种方式创建Controllers：\n\n    var myApp = angular.module('myApp', []);\n\n    function MainCtrl ($scope) {\n    //...\n    };\n    \n…不要这样做。这将所有的功能都暴露在全局范围内，并不会让它们与应用程序很好地联系在一起。这也意味着你不能很容易的缩小你的代码或运行测试。不要滥用全局名称空间，要保证Controller只在您的应用程序内。\n\n\n## 2.Directives(指令)\n\n指令最简化形式是一段HTML模板，在应用程序需要的地方最好能多次使用。这是毫不费力的注入DOM到应用中最简单的方式，或执行自定义DOM交互。指令并不简单，想完全征服他们需要一个非常令人难以置信的学习路线，但通过这一小节的学习会让你基本掌握它。\n\n那指令有什么用处？很多事情，包括DOM组件，例如制表符或导航元素会依赖你的应用程序中使用的UI。让我这样说吧，如果你有过ng-show或者ng-hide，这就是指令（虽然他们不注入DOM）。\n\n对于这个练习，我想把它弄的很简单，创建一个自定义按钮（称为CustomButton）注入一些标记，我讨厌写很多字。有各种不同的方式定义DOM中的指令，这些可能看起来像这样：\n\n    <!-- 1: as an attribute declaration -->\n    <a custom-button>Click me</a>\n\n    <!-- 2: as a custom element -->\n    <custom-button>Click me</custom-button>\n\n    <!-- 3: as a class (used for old IE compat) -->\n    <a class=\"custom-button\">Click me</a>\n\n    <!-- 4: as a comment (not good for this demo, however) -->\n    <!-- directive: custom-button -->\n    \n我更喜欢他们作为一个属性使用，自定义元素作为HTML5未来的一个Web组件特性，但Angular指出这在一些老的浏览器上会当成是一个BUG。\n\n现在你知道在使用/注入指令的时候如何声明了吧，让我们创建这个自定义按钮。再次，我会回调我的全局命名空间MyApp的应用，这是最简形式的指令：\n\n    myApp.directive('customButton', function () {\n      return {\n        link: function (scope, element, attrs) {\n          // DOM manipulation/events here!\n        }\n      };\n    });\n    \n我使用 .directive()方法来创建指令，传入指令的名称“CustomButton“。当你在指令的名称中使用一些字母，它会通过DOM中的连字符进行分割（如上图）。\n\n一个指令简单的返回一个带有参数的对象。对我来说最重要的是：restrict, replace, transclude, template 和 templateUrl,当然还有 link 属性。让我把其它的也加入进来吧：\n\n    myApp.directive('customButton', function () {\n      return {\n        restrict: 'A',\n        replace: true,\n        transclude: true,\n        template: '<a href=\"\" class=\"myawesomebutton\" ng-transclude>' +\n                    '<i class=\"icon-ok-sign\"></i>' +\n                  '</a>',\n        link: function (scope, element, attrs) {\n          // DOM manipulation/events here!\n        }\n      };\n    });\n    \n演示： http://runjs.cn/code/xtupcxdh\n\n验证你是否插入元素，请确认你是否注入附加标记。指令的属性解释：\n\n**restrict**：[约束]看下上面的例子我们是怎么使用restrict的，如果你的项目需要支持IE的话，你可能需要声明attribute或class。使用“A”意味着你限制它作为一个Attribute，E代表Element，C代表Class，M代表Comment。默认是“EA”，对的，你可以限制多个。\n\n**replace**：[替换]替换DOM为指令中定义的内容，在这个例子中，你会注意到初始DOM已经被指令的模板替换。\n\n**transclude**：[嵌入]简单地说，使用嵌入允许现有的DOM内容被复制到指令中。你会看到单词'点击我'已被'移'到指令中，在显示的时候。\n\n**template**：[模板]模板（如上）允许你将标记为被注入。这是一个好主意，用这一小段HTML片断。注入模板都通过Angular编译，这意味着你可以定义处理的方法已更好的邦定使用。\n\n**templateUrl**：[模板Url]类似于一个模板，但保持在它自己的文件或<脚本>标签。你可以指定一个模板的URL，你会使用一个单独的文件来管理HTML模板，请指定路径和文件名，最好放在自己的模板目录中：\n\n    myApp.directive('customButton', function () {\n      return {\n        templateUrl: 'templates/customButton.html'\n        // directive stuff...\n      };\n    });\n    \n加入你的文件（文件名不敏感）：\n\n    <!-- inside customButton.html -->\n    <a href=\"\" class=\"myawesomebutton\" ng-transclude>\n      <i class=\"icon-ok-sign\"></i>\n    </a>\n    \n这样做真的很好，浏览器会缓存HTML文件，干的漂亮！设置不缓存的另一个选择是在script标签中声明一个模板：\n\n    <script type=\"text/ng-template\" id=\"customButton.html\">\n    <a href=\"\" class=\"myawesomebutton\" ng-transclude>\n      <i class=\"icon-ok-sign\"></i>\n    </a>\n    </script>\n    \n你会告诉Angular它是一个模板并且还有一个ID，Angular会查找NG模板或*.HTML文件,他们很容易管理，提高性能和保持DOM很干净，你可以建立1个或100个指令，你可以很容易的浏览它们。\n\n## 3.Services(服务)\n\n服务通常是混淆点。从经验和研究上，他们更多的是一种风格的设计模式，而不是提供更多的功能差异。在深入到Angular源码后,他们指望通过相同的编译器运行，并共享大量的功能。从我的研究来看，你应该在单例，工厂以及其它更复杂的功能上使用服务，如对象字面量和更复杂的用例。\n\n下面是一个Service例子,计算2个数字的乘积：\n\n     myApp.service('Math', function () {\n          this.multiply = function (x, y) {\n              return x * y;\n         };\n    });\n    \n然后，你应该使用这样的内部控制器：\n\n    myApp.controller('MainCtrl', ['$scope', function ($scope) {\n        var a = 12;\n        var b = 24;\n       // outputs 288\n        var result = Math.multiply(a, b);\n    }]);\n    \n是的，乘法是很容易的，不需要一个服务，但你领会到了其中的要点。\n\n当你创建一个服务（或工厂）时，你需要使用依赖注入来告诉Angular需要扑获新的服度，否则你会得到编译错误，你的控制器会中断。你可能已经注意到了这个函数($scope)的部分，现在，这是简单的依赖注入。看下你的代码,你也会注意到（$scope）之前的功能（$scope），我会到后面解释。这里是如何使用依赖注入来告诉你需要你的服务：\n\n    // Pass in Math\n    myApp.controller('MainCtrl', ['$scope', 'Math', function ($scope, Math) {\n      var a = 12;\n      var b = 24;\n      // outputs 288\n      var result = Math.multiply(a, b);\n    }]);\n    \n## 4.Factories(工厂)\n\n从服务到工厂现在应该是简单的，我们可以在工厂里创建一个对象字面量或简单地提供一些更深入的方法：\n\n\tmyApp.factory('Server', ['$http', function ($http) {\n\t  return {\n\t    get: function(url) {\n\t      return $http.get(url);\n\t    },\n\t    post: function(url) {\n\t      return $http.post(url);\n\t    },\n\t  };\n\t}]);\n\t\n下面，在依赖注入到一个控制器后，我创造了一个Angular的XHR自定义包装。这个例子很简单：\n\n\tmyApp.controller('MainCtrl', ['$scope', 'Server', function ($scope, Server) {\n\t    var jsonGet = 'http://myserver/getURL';\n\t    var jsonPost = 'http://myserver/postURL';\n\t    Server.get(jsonGet);\n\t    Server.post(jsonPost);\n\t}]);\n\t\n如果你想为了改变而轮询服务，你可以设置一个Server.poll(jsonPool),或者假如你正在使用一个Socket,你可以设置Server.socket(jsonSocket).它打开了大门，模块化代码以及创造您使用和保持代码内的控制器，作为一个最小的完整集合。\n\n## 5.Filters(过滤器)\n    \n过滤器一般和数组一块使用，用在循环外，如果你遍历数组来筛选出特定的东西，在正确的地方，你也可以使用过滤器过滤用户想要的类型在<input>标签为例，有几个方法可以使用过滤器，在控制器里面或作为一个定义的方法。这里有使用的方法，您可以在全局使用：\n\n\tmyApp.filter('reverse', function () {\n\t    return function (input, uppercase) {\n\t        var out = '';\n\t        for (var i = 0; i < input.length; i++) {\n\t            out = input.charAt(i) + out;\n\t        }\n\t        if (uppercase) {\n\t            out = out.toUpperCase();\n\t        }\n        return out;\n\t    }\n\t});\n\n\t// Controller included to supply data\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t    $scope.greeting = 'Todd Motto';\n\t}]);\n\t\nDOM内容：\n\n\t<div ng-app=\"myApp\">\n\t    <div ng-controller=\"MainCtrl\">\n\t        <p>No filter: { { greeting } }</p>\n\t        <p>Reverse: { { greeting | reverse } }</p>\n\t    </div>\n\t</div>\n\t\n例子：http://runjs.cn/code/ina2n1lb\n\n可以看到我们通过传递过滤符号“|”在greeting 数据上，对该数据进行逆向过滤。\n\n在标签ng-repeat中的用法为：\n\n\t<ul>\n\t  <li ng-repeat=\"number in myNumbers |filter:oddNumbers\">{{ number }}</li>\n\t</ul>\n\n一个在controller中使用过滤器的简明例子：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t\t$scope.numbers = [10, 25, 35, 45, 60, 80, 100];\n\t\t$scope.lowerBound = 42;\n\t\t// Does the Filters\n\t\t$scope.greaterThanNum = function (item) {\n\t\t    return item > $scope.lowerBound;\n\t\t};\n\t}]);\n\t\n在ng-repeat标签中的用法为:\n\n\t<li ng-repeat=\"number in numbers | filter:greaterThanNum\">\n\t  {{ number }}\n\t</li>\n\t\n演示:http://runjs.cn/code/xiricwi3\n\n这是AngularJS中的主体部分和API，虽然这只是冰山一角，但利用这些内容足以建立起你自己的angular应用。\n\n## 6.Two-way data-binding(双向数据绑定)\n\n当我第一次听说双向数据绑定时，我并不太明白它是什么。双向数据绑定是最好的理解为一个完全同步的数据循环：更新模型并更新视图，更新视图并更新模型。这意味着数据不需要做任何操作都是同步的。如果我将一个ng模型绑定到一个<input>标签然后开始输入，这将在同一时间创建（或更新一个现有的）模型。\n\n我创建的一个<input>标签并绑定模型称为\"myModel\"，然后我可以利用angularjs中的语法来反射这个模型并同时更新视图：\n\n\t<div ng-app=\"myApp\">\n\t    <div ng-controller=\"MainCtrl\">\n\t        <input type=\"text\" ng-model=\"myModel\" placeholder=\"Start typing...\" />\n\t        <p>My model data: {{ myModel }}</p>\n\t    </div>\n\t</div>\n\t\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t    // Capture the model data\n\t    // and/or initialise it with an existing string\n\t    $scope.myModel = '';\n\t}]);\n\t\n示例：http://runjs.cn/code/fu074xjf\n\n## 7.XHR/Ajax/$http calls and binding JSON\n\n你已经掌握了如何把一个基础数据邦定到$scope上，并大致了解了这个model是如何工作的，包括数据的双向邦定。\n现在是时候学习一些真正的XHR去调用一个服务。对于网站来说，这是没有必要的除非你有特别的Ajax要求，这主要是集中在抓取数据的Web应用程序。\n\n当你在做本地开发时，你可能使用类似Java，ASP.NET，PHP或别的东西来运行一个本地服务器。无论您是和本地数据库通信还是实际使用服务器作为接口来与其他资源进行通信，这都是相同的。\n\n输入$http,就可以愉快的开始了。$HTTP方法是从服务器访问数据的一个很好的Angular包装，你可以很方便的使用。这里是一个“GET”请求的简单例子，它从服务器获取数据。它的语法很像是jQuery，所以很好理解：\n\n\tmyApp.controller('MainCtrl', ['$scope', '$http', function ($scope, $http) {\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrl'\n\t  });\n\t}]);\n\t\nAngular然后返回内容(叫做承诺)，这是处理回调的一种更有效和可读的方式。承诺是链接function到他们从使用点.mypromise()。正如预期的那样，我们有错误和成功的处理程序：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrl'\n\t  })\n\t  .success(function (data, status, headers, config) {\n\t\t// successful data retrieval\n\t  })\n\t  .error(function (data, status, headers, config) {\n\t\t// something went wrong :(\n\t  });\n\t}]);\n\t\n非常好的可读性。这就是我们合并视图和绑定模式或更新模型数据到DOM的服务器。让我们假设一个设置和推动一个用户名的DOM，通过Ajax调用。\n\n理想情况下，我们应该首先建立和设计我们的JSON，这将影响我们如何构造我们的数据。让我们保持简单，这是一个后端开发者将开放一个API在应用程序中，您希望如下：\n\n\t{\n\t  \"user\": {\n\t\t\"name\": \"Todd Motto\",\n\t\t\"id\": \"80138731\"\n\t  }\n\t}\n\t\n这意味着我们会得到一个从服务器返回的对象（化名就叫‘数据’[你可以看到数据被传递到我们的承诺处理]），并嵌有data.user属性。在data.user属性里面，有name和id,访问这些很容易的，我们需要寻找data.user.name这个属性时，它将返回这个属性的值。现在让我们来操作下吧！\n\nJavaScript代码：\n\n\tmyApp.controller('UserCtrl', ['$scope', '$http', function ($scope, $http) {\n\t  // create a user Object\n\t  $scope.user = {};\n\t  // Initiate a model as an empty string\n\t  $scope.user.username = '';\n\t  // We want to make a call and get\n\t  // the person's username\n\t  $http({\n\t\tmethod: 'GET',\n\t\turl: '//localhost:9000/someUrlForGettingUsername'\n\t  })\n\t  .success(function (data, status, headers, config) {\n\t\t// See here, we are now assigning this username\n\t\t// to our existing model!\n\t\t$scope.user.username = data.user.name;\n\t  })\n\t  .error(function (data, status, headers, config) {\n\t\t// something went wrong :(\n\t  });\n\t}]);\n\nDOM代码：\n\n\t<div ng-controller=\"UserCtrl\">\n\t  <p>{{ user.username }}</p>\n\t</div>\n\t\n它会打印username的值。下面我们将进一步了解声明式数据绑定，这是非常令人兴奋的。\n\n## 8.Declarative data-binding(声明式数据邦定)\n\nAngular的理念是创建动态HTML.它是一个强大的功能,代替了你在客户端做的大量工作。这正是他的目的所在。\n\n让我们想象一下，我们刚刚作了一个Ajax请求得到一些电子邮件的列表包含主题，发送日期，现在想把它们展示在DOM中。这里会体现出Angular的优势。首先，我需要设置一个电子邮件的controller：\n\n\tmyApp.controller('EmailsCtrl', ['$scope', function ($scope) {\n\t  // create a emails Object\n\t  $scope.emails = {};\n\t  // pretend data we just got back from the server\n\t  // this is an ARRAY of OBJECTS\n\t  $scope.emails.messages = [{\n\t\t    \"from\": \"Steve Jobs\",\n\t\t    \"subject\": \"I think I'm holding my phone wrong :/\",\n\t\t    \"sent\": \"2013-10-01T08:05:59Z\"\n\t\t},{\n\t\t    \"from\": \"Ellie Goulding\",\n\t\t    \"subject\": \"I've got Starry Eyes, lulz\",\n\t\t    \"sent\": \"2013-09-21T19:45:00Z\"\n\t\t},{\n\t\t    \"from\": \"Michael Stipe\",\n\t\t    \"subject\": \"Everybody hurts, sometimes.\",\n\t\t    \"sent\": \"2013-09-12T11:38:30Z\"\n\t\t},{\n\t\t    \"from\": \"Jeremy Clarkson\",\n\t\t    \"subject\": \"Think I've found the best car... In the world\",\n\t\t    \"sent\": \"2013-09-03T13:15:11Z\"\n\t\t}];\n\t}]);\n\t\n现在我们需要把它插入到我们的HTML中。这时我们会使用声明式绑定宣布什么应用程序将创建我们的第一个动态HTML。我们要用到Angular的内置指令ng-repeat，它会遍历数据，完全没有回调或状态变化的渲染输出，这都是非常灵活的：\n\n\t<ul>\n\t  <li ng-repeat=\"message in emails.messages\">\n\t\t<p>From: {{ message.from }}</p>\n\t\t<p>Subject: {{ message.subject }}</p>\n\t\t<p>{{ message.sent | date:'MMM d, y h:mm:ss a' }}</p>\n\t  </li>\n\t</ul>\n\t\n示例：http://runjs.cn/code/q9beqc9s\n\n我使用了一个日期过滤器，从中你可以看到如何处理UTC日期。\n\n深入Angular的ng-*指令,你将完全释放出angular的声明式绑定的能力，这里展示了如何从服务器到模型，以及模拟和渲染数据。\n\n\n## 9.Scope functions(范围函数)\n\n作为声明性绑定的延续，范围函数是在创建应用程序时的下一个层次。这里展示了一个基本功能，删除我们的电子邮件中的一个数据：\n\n\tmyApp.controller('MainCtrl', ['$scope', function ($scope) {\n\t  $scope.deleteEmail = function (index) {\n\t\t$scope.emails.messages.splice(index, 1)\n\t  };\n\t}]);\n\t\n友情提示：重要的一点是要考虑从模型中删除数据。不删除元素或任何实际的DOM相关，angular是一个MVC框架，将为您处理这一切与它的双向绑定和回调的自由世界，你只需要设置你的代码可以让它响应你的数据！\n\n\t<a ng-click=\"deleteEmail($index)\">Delete email</a>\n\t\n这是一种不同的内联点击处理程序，因为许多原因。这将很快覆盖。你会看到我也在通过$index，angular知道你正在删除的项目（这样可以节省你多少代码和逻辑！）。\n\n示例：http://runjs.cn/code/jm84qnh3\n\n## 10.Declarative DOM methods(陈述性DOM方法)\n\n现在我们要转移到的DOM方法，这些也都是些指令和模拟功能的DOM，你通常会写出更多的逻辑脚本。这个例子是一个简单的切换导航。用一个简单的ng-show和一个简单的ng-click设置，我们可以创建一个完美无瑕的切换导航：\n\n\t<a href=\"\" ng-click=\"toggle = !toggle\">Toggle nav</a>\n\t<ul ng-show=\"toggle\">\n\t  <li>Link 1</li>\n\t  <li>Link 2</li>\n\t  <li>Link 3</li>\n\t</ul>\n\t\n我们开始进入MVVM的学习，你会发现脚本里没有controller的代码，我们会很快进入MVVM。\n\n示例：http://runjs.cn/code/r5tlnqrb\n\n## 11.Expressions(表达式)\n\n我最喜欢Angular的一部分是，你会用JavaScript写出很多重复的代码。\n\n你尝试过这个吗？\n\n\telem.onclick = function (data) {\n\t  if (data.length === 0) {\n\t\totherElem.innerHTML = 'No data';\n\t  } else {\n\t\totherElem.innerHTML = 'My data';\n\t  }\n\t};\n\t\n这可能是一个GET请求回调，你会改变基于数据的DOM。Angular给你这个自由，你就可以做到无需编写任何内置的JavaScript！\n\n\t<p>{{ data.length > 0 && 'My data' || 'No data' }}</p>\n\n这会动态更新自己而没有回调应用程序获取数据。如果没有数据，它会告诉你，如果有数据，它会显示数据。针对Angular处理自动双向绑定数据，会有很多的使用情况。\n\n示例：http://runjs.cn/code/ahl0hfcc\n\n## 12.Dynamic views and routing(动态视图和路由)\n\n单页面web应用(也包括网站)背后的理念是: 你有一个标题，页脚，侧边栏，和中间的内容,通过设置URL可以神奇地注入新的内容。\n\nAngular通过一个简单的设置来配置我们所说的动态视图。动态视图依靠URL注入每个视图，通过$routeprovider。一个简单的设置如下：\n\n\tmyApp.config(['$routeProvider', function ($routeProvider) {\n\t  /**\n\t   * $routeProvider\n\t   */\n\t  $routeProvider\n\t  .when('/', {\n\t\ttemplateUrl: 'views/main.html'\n\t  })\n\t  .otherwise({\n\t\tredirectTo: '/'\n\t  });\n\t}]);\n\n你会看到，当URL是\"/\"(即该站点的根目录),你会注入main.html。当你在一个单页面应用中已经有一个index.html页面，这是一个好的方法去调用内部的main.html视图而不是index.html。依靠URL去添加更多的视图是如此简单：\n\n\tmyApp.config(['$routeProvider', function ($routeProvider) {\n\t  /**\n\t   * $routeProvider\n\t   */\n\t  $routeProvider\n\t  .when('/', {\n\t\ttemplateUrl: 'views/main.html'\n\t  })\n\t  .when('/emails', {\n\t\ttemplateUrl: 'views/emails.html'\n\t  })\n\t  .otherwise({\n\t\tredirectTo: '/'\n\t  });\n\t}]);\n\t\n我们可以在emails.html上简单的加载HTML去生成我们的邮件列表,最终你可以毫不费力的创建一个复杂的应用程序。\n\n## 13.Global static data(全局静态数据)\n\nGmail处理很多内部初始化数据是通过将JSON加入到页面中(右键查看源代码)。如果你想立即在你的页面设置数据，它会加快渲染时间并且Angular将更快的执行。\n\n当我们开发应用程序时，页面渲染时，Java标签放置在DOM中，数据从后台发送过来。[我没有Java开发经验，你需要知道一个下面的声明，虽然在服务器上你可以使用任何语言。]这里是如何把JSON加入到网页中，然后把它传给一个控制器,为即时邦定使用：\n\n\t<!-- inside index.html (bottom of page ofc) -->\n\t<script>\n\twindow.globalData = {};\n\tglobalData.emails = <javaTagHereToGenerateMessages>;\n\t</script>\n\t\n我定义的java标签使数据能在页面中渲染，Angular会轻松的渲染你的emails数据，只要把你的数据放入到controller中即可:\n\n\tmyApp.controller('EmailsCtrl', ['$scope', function ($scope) {\n\t\t$scope.emails = {};\n\t\t// Assign the initial data!\n\t\t$scope.emails.messages = globalData.emails;\n\t}]);\n\t\n## 14.Minification(精简)\n\n这一段是关于精简你的angular代码内容。在这方面你可能已经尝试过了，有时跑一个精简过的代码，会遇到了一个错误！\n\n精简你的AngularJS代码很简单，你需要指定你的依赖注入的内容在函数数组：\n\n\tmyApp.controller('MainCtrl',\n\t['$scope', 'Dependency', 'Service', 'Factory',\n\tfunction ($scope, Dependency, Service, Factory) {\n\t  // code\n\t}]);\n\t\n精简后:\n\n\tmyApp.controller('MainCtrl',\n\t['$scope', 'Dependency', 'Service', 'Factory',\n\tfunction (a,b,c,d) {\n\t  // a = $scope\n\t  // b = Dependency\n\t  // c = Service\n\t  // d = Factory\n\t  // $scope alias usage\n\t  a.someFunction = function () {...};\n\t}]);\n\t\n请记住，以保持参数的顺序出现，否则你可能会导致你和你的团队费劲。\n\n## 15.Differences in MVC and MVVM(MVC和MVVM的差异)\n\n这里简要介绍两者的区别:\n\n**MVC**: 用一个controller交互,关系是Model-View-Controller\n**MVVM**: 封装声明数据邦定,Model-View-View-Model,Model和View交互,View也可以和Model交互,Angular的双向数据绑定允许它在不做任何事情时保持同步。它还允许你在没有控制器的情况下,编写逻辑代码！\n\n一个简单的例子，你可以创建一个ng-repeat标签去提供数据,而不需要Controller:\n\n\t<li ng-repeat=\"number in [1,2,3,4,5,6,7,8,9]\">\n\t  {{ number }}\n\t</li>\n\t\n对于快速测试这是很有帮助的，但对与复杂的情况时，我建议使用一个Controller。\n\n## 16.HTML5 Web Components(HTML5组件)\n\n在早些时候你会发现AngularJS允许你创建自定义的元素:\n\n\t<myCustomElement></myCustomElement>\n\n这实际上是符合HTML5未来的特性。HTML5 Web部件和模板元素，Angular让我们今天就能这样用。Web部件包括通过动态JavaScript注入生成的自定义元素！\n\n## 17.Scope comments(范围注释)\n\n范围注释,我觉得真的是一个不错特性,代替了HTML注释，像这样的块：\n\n\t<!-- header -->\n\t<header>\n\t  Stuff.\n\t</header>\n\t<!-- /header -->\n\t\n引入Angular后，让我们思考的是Views和Scopes，而不是DOM，除非你故意共享控制器间的数据，我发现使用范围是一个很大的帮助：\n\n\t<!-- scope: MainCtrl -->\n\t<div class=\"content\" ng-controller=\"MainCtrl\">\n\t</div>\n\t<!-- /scope: MainCtrl -->\n\t\n## 18.Debugging AngularJS(调试)\n\n对于调试AngularJS的话，可以使用Chrome的一个扩展工具-Batarang,你可以去下载下看看。\n\n## 结束\n到此本文结束,希望能够对大家学习angular有一个好的指导，更多关于angular的细节可以参看[Todd Motto](http://toddmotto.com/) 的系列文章 \n再次感谢原作者的整理，文中如有不对的地方可以指出。\n","slug":"2015-08-16-用一天时间来学习angularjs","updated":"2018-11-29T12:51:24.467Z","comments":1,"photos":[],"link":"","_id":"cjskffnv500004glmttvc9pny","content":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<p>对于学习angulaJS来说，更多的是对整体的了解。看了Todd Motto 的一篇文章后，对这个框架有了一个比较清晰的认识。<br><a href=\"http://toddmotto.com/ultimate-guide-to-learning-angular-js-in-one-day/\" target=\"_blank\" rel=\"noopener\">查看原文</a><br><a id=\"more\"></a></p>\n<h2 id=\"I-什么是AngularJS\"><a href=\"#I-什么是AngularJS\" class=\"headerlink\" title=\"I.什么是AngularJS?\"></a>I.什么是AngularJS?</h2><p><img src=\"/images/angularjs.jpg\" alt=\"\"></p>\n<p>Angular 是一个客户端MVC/MVVM框架，内置在JavaScript中，是现在流行的单页面web应用（甚至是网站）必不可少的东西。这篇文章是我学习angularjs的全部的经验，建议和最佳的做法。通过掌握它你会学会很多东西。</p>\n<h2 id=\"II-Terminology-术语\"><a href=\"#II-Terminology-术语\" class=\"headerlink\" title=\"II.Terminology(术语)\"></a>II.Terminology(术语)</h2><p>Angular 有一个短的学习路线，掌握了基本知识后你会发现它的优点和缺点，对学习这个框架来说，掌握这些术语和学会用MVC思考是非常重要的，下面是一些Angular中包含的一些高级并且重要的api和术语。</p>\n<h2 id=\"III-MVC\"><a href=\"#III-MVC\" class=\"headerlink\" title=\"III.MVC\"></a>III.MVC</h2><p>你可能听说过MVC，用在许多编程语言中来构建应用程序/软件/架构的一种手段。这里是每个部分的简单含义：</p>\n<p><strong>Model</strong>：每一个应用中都离不开数据结构，通常放在JSON中。在开始Angular之前先要读懂JSON，因为它对了解server和view是如何通信的非常重要。例如，一组用户身份标识可以有以下模型：</p>\n<pre><code>{\n  &quot;users&quot; : [{\n  &quot;name&quot;: &quot;Joe Bloggs&quot;,\n  &quot;id&quot;: &quot;82047392&quot;\n},{\n  &quot;name&quot;: &quot;John Doe&quot;,\n  &quot;id&quot;: &quot;65198013&quot;\n }]\n}\n</code></pre><p>然后你就可以从服务器通过XHR抓取信息（XMLHTTP请求），在Jquery中是通过$.ajax方法，在Angular中是$http,或者它会写进你的代码在页面解析（从一个数据仓库/数据库）时，然后你可以推送更新到你的模型，并把它发送回。</p>\n<p><strong>View</strong>: View是非常容易理解的，它是你的HTML页面或呈现的输出。使用MVC框架，你会使用Model数据来更新View和HTML中显示的相关数据。</p>\n<p><strong>Controller</strong>：Controller直接访问服务器中的View，作为中间人，你能够在Controller中更新Model中的数据来改变View。</p>\n<h2 id=\"0-建立一个AngularJS项目（基本要点）\"><a href=\"#0-建立一个AngularJS项目（基本要点）\" class=\"headerlink\" title=\"0.建立一个AngularJS项目（基本要点）\"></a>0.建立一个AngularJS项目（基本要点）</h2><p>首先，我们需要确认安装了AngularJS必备的基础环境，在我们开始前有一些事情是需要注意的，一般由ng-app声明来定义你的应用程序,一个Controller和View页面、一些DOM邦定还有Angular来交互。以下是基本要点：</p>\n<p>一些带“ng-*” 声明的HTML</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n  &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n      &lt;!-- controller logic --&gt;\n   &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>Angular的 Module 和 Controller:</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    // Controller magic\n}]);\n</code></pre><p>在开始动手之前，我们需要创建一个包含所有逻辑的Angular module,有很多种方法来声明 modules,你可以将所有的逻辑像这样串联起来（我不喜欢这种做法）：</p>\n<pre><code>angular.module(&apos;myApp&apos;, [])\n.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}])\n.controller(&apos;NavCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}])\n.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\n</code></pre><p>在我的使用中，建立一个全局的Module被证明是一个非常好的方式。缺少分号和意外关闭的’连接’证明适得其反，会出现一些不必要的编译错误，像这样：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\nmyApp.controller(&apos;NavCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\nmyApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\n</code></pre><p>我创建的每一文件都使用简单的myApp命名空间并自动的邦定到Application上，没错，我会为每个Controller, Directive, Factory 和其它的内容创建一个文件，关联和压缩这些文件到一个脚本文件中，然后引入到DOM中（使用Grunt或Gulp类似的工具）</p>\n<h2 id=\"1-Controllers-控制器\"><a href=\"#1-Controllers-控制器\" class=\"headerlink\" title=\"1.Controllers(控制器)\"></a>1.Controllers(控制器)</h2><p>现在你已经掌握了MVC设计模式的概念和基本设置，让我们看看Angular中是如何运用Controllers的。<br>从上面的例子中我们可以很简单的从一个Controller中拿到数据然后放入到DOM中，Angular采用一种模板风格  嵌在你的HTML中，你的HTML应该（最好）不包含物理文本或硬编码的值以最大限度地利用Angular，下面是一个将字符串推送到页面上的例子：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n  &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n      { { text } }\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>脚本：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n\n    $scope.text = &apos;Hello, Angular fanatic.&apos;;\n\n}]);\n</code></pre><p>演示：<a href=\"http://runjs.cn/code/jgevzqjd\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/jgevzqjd</a></p>\n<p>这里的核心法则是“$scope”的概念，你会在一个特定的Controller里面邦定所有的功能。$scope代表的是DOM中当前的元素，封装一个非常好的观察能力，保持元素范围内的数据和逻辑完完美邦定。它提供了JavaScript的公共/私有范围的DOM，这很神奇。</p>\n<p>$scope的范围概念似乎有点可怕，但这是你从服务器到DOM的交互方式（静态数据，如果你有过）！这个例子教你了一个如何把数据“推”到DOM的办法。</p>\n<p>让我们看一个比较有代表性的数据结构，我们假设从服务器检索显示用户的登录信息。现在我将使用静态数据；我后边会告诉你如何获取动态JSON数据。</p>\n<p>首先我们要编写JavaScript：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n\n    // Let&apos;s namespace the user details\n    // Also great for DOM visual aids too\n    $scope.user = {};\n    $scope.user.details = {\n        &quot;username&quot;: &quot;Todd Motto&quot;,\n        &quot;id&quot;: &quot;89101112&quot;\n    };\n\n}]);\n</code></pre><p>然后交给DOM来显示这些数据：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;UserCtrl&quot;&gt;\n        &lt;p class=&quot;username&quot;&gt;Welcome, { { user.details.username } }&lt;/p&gt;\n        &lt;p class=&quot;id&quot;&gt;User ID: { { user.details.id } }&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>演示：<a href=\"http://runjs.cn/code/4xrlzycm\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/4xrlzycm</a></p>\n<p>重要的一点要记住，控制器只为数据，并创建函数（也包括事件函数）！它跟服务器交互并且推/拉JSON数据。这里没有DOM操作，所以不需要jQery工具。指令(Directives )是DOM操作，这是下一个要介绍的。</p>\n<p>小提示：在Angular的官方文档中（我在写这篇文章时）他们的例子中使用这种方式创建Controllers：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nfunction MainCtrl ($scope) {\n//...\n};\n</code></pre><p>…不要这样做。这将所有的功能都暴露在全局范围内，并不会让它们与应用程序很好地联系在一起。这也意味着你不能很容易的缩小你的代码或运行测试。不要滥用全局名称空间，要保证Controller只在您的应用程序内。</p>\n<h2 id=\"2-Directives-指令\"><a href=\"#2-Directives-指令\" class=\"headerlink\" title=\"2.Directives(指令)\"></a>2.Directives(指令)</h2><p>指令最简化形式是一段HTML模板，在应用程序需要的地方最好能多次使用。这是毫不费力的注入DOM到应用中最简单的方式，或执行自定义DOM交互。指令并不简单，想完全征服他们需要一个非常令人难以置信的学习路线，但通过这一小节的学习会让你基本掌握它。</p>\n<p>那指令有什么用处？很多事情，包括DOM组件，例如制表符或导航元素会依赖你的应用程序中使用的UI。让我这样说吧，如果你有过ng-show或者ng-hide，这就是指令（虽然他们不注入DOM）。</p>\n<p>对于这个练习，我想把它弄的很简单，创建一个自定义按钮（称为CustomButton）注入一些标记，我讨厌写很多字。有各种不同的方式定义DOM中的指令，这些可能看起来像这样：</p>\n<pre><code>&lt;!-- 1: as an attribute declaration --&gt;\n&lt;a custom-button&gt;Click me&lt;/a&gt;\n\n&lt;!-- 2: as a custom element --&gt;\n&lt;custom-button&gt;Click me&lt;/custom-button&gt;\n\n&lt;!-- 3: as a class (used for old IE compat) --&gt;\n&lt;a class=&quot;custom-button&quot;&gt;Click me&lt;/a&gt;\n\n&lt;!-- 4: as a comment (not good for this demo, however) --&gt;\n&lt;!-- directive: custom-button --&gt;\n</code></pre><p>我更喜欢他们作为一个属性使用，自定义元素作为HTML5未来的一个Web组件特性，但Angular指出这在一些老的浏览器上会当成是一个BUG。</p>\n<p>现在你知道在使用/注入指令的时候如何声明了吧，让我们创建这个自定义按钮。再次，我会回调我的全局命名空间MyApp的应用，这是最简形式的指令：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    link: function (scope, element, attrs) {\n      // DOM manipulation/events here!\n    }\n  };\n});\n</code></pre><p>我使用 .directive()方法来创建指令，传入指令的名称“CustomButton“。当你在指令的名称中使用一些字母，它会通过DOM中的连字符进行分割（如上图）。</p>\n<p>一个指令简单的返回一个带有参数的对象。对我来说最重要的是：restrict, replace, transclude, template 和 templateUrl,当然还有 link 属性。让我把其它的也加入进来吧：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    restrict: &apos;A&apos;,\n    replace: true,\n    transclude: true,\n    template: &apos;&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;&apos; +\n                &apos;&lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;&apos; +\n              &apos;&lt;/a&gt;&apos;,\n    link: function (scope, element, attrs) {\n      // DOM manipulation/events here!\n    }\n  };\n});\n</code></pre><p>演示： <a href=\"http://runjs.cn/code/xtupcxdh\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/xtupcxdh</a></p>\n<p>验证你是否插入元素，请确认你是否注入附加标记。指令的属性解释：</p>\n<p><strong>restrict</strong>：[约束]看下上面的例子我们是怎么使用restrict的，如果你的项目需要支持IE的话，你可能需要声明attribute或class。使用“A”意味着你限制它作为一个Attribute，E代表Element，C代表Class，M代表Comment。默认是“EA”，对的，你可以限制多个。</p>\n<p><strong>replace</strong>：[替换]替换DOM为指令中定义的内容，在这个例子中，你会注意到初始DOM已经被指令的模板替换。</p>\n<p><strong>transclude</strong>：[嵌入]简单地说，使用嵌入允许现有的DOM内容被复制到指令中。你会看到单词’点击我’已被’移’到指令中，在显示的时候。</p>\n<p><strong>template</strong>：[模板]模板（如上）允许你将标记为被注入。这是一个好主意，用这一小段HTML片断。注入模板都通过Angular编译，这意味着你可以定义处理的方法已更好的邦定使用。</p>\n<p><strong>templateUrl</strong>：[模板Url]类似于一个模板，但保持在它自己的文件或&lt;脚本&gt;标签。你可以指定一个模板的URL，你会使用一个单独的文件来管理HTML模板，请指定路径和文件名，最好放在自己的模板目录中：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    templateUrl: &apos;templates/customButton.html&apos;\n    // directive stuff...\n  };\n});\n</code></pre><p>加入你的文件（文件名不敏感）：</p>\n<pre><code>&lt;!-- inside customButton.html --&gt;\n&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;\n  &lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;\n&lt;/a&gt;\n</code></pre><p>这样做真的很好，浏览器会缓存HTML文件，干的漂亮！设置不缓存的另一个选择是在script标签中声明一个模板：</p>\n<pre><code>&lt;script type=&quot;text/ng-template&quot; id=&quot;customButton.html&quot;&gt;\n&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;\n  &lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;\n&lt;/a&gt;\n&lt;/script&gt;\n</code></pre><p>你会告诉Angular它是一个模板并且还有一个ID，Angular会查找NG模板或*.HTML文件,他们很容易管理，提高性能和保持DOM很干净，你可以建立1个或100个指令，你可以很容易的浏览它们。</p>\n<h2 id=\"3-Services-服务\"><a href=\"#3-Services-服务\" class=\"headerlink\" title=\"3.Services(服务)\"></a>3.Services(服务)</h2><p>服务通常是混淆点。从经验和研究上，他们更多的是一种风格的设计模式，而不是提供更多的功能差异。在深入到Angular源码后,他们指望通过相同的编译器运行，并共享大量的功能。从我的研究来看，你应该在单例，工厂以及其它更复杂的功能上使用服务，如对象字面量和更复杂的用例。</p>\n<p>下面是一个Service例子,计算2个数字的乘积：</p>\n<pre><code> myApp.service(&apos;Math&apos;, function () {\n      this.multiply = function (x, y) {\n          return x * y;\n     };\n});\n</code></pre><p>然后，你应该使用这样的内部控制器：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    var a = 12;\n    var b = 24;\n   // outputs 288\n    var result = Math.multiply(a, b);\n}]);\n</code></pre><p>是的，乘法是很容易的，不需要一个服务，但你领会到了其中的要点。</p>\n<p>当你创建一个服务（或工厂）时，你需要使用依赖注入来告诉Angular需要扑获新的服度，否则你会得到编译错误，你的控制器会中断。你可能已经注意到了这个函数($scope)的部分，现在，这是简单的依赖注入。看下你的代码,你也会注意到（$scope）之前的功能（$scope），我会到后面解释。这里是如何使用依赖注入来告诉你需要你的服务：</p>\n<pre><code>// Pass in Math\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;Math&apos;, function ($scope, Math) {\n  var a = 12;\n  var b = 24;\n  // outputs 288\n  var result = Math.multiply(a, b);\n}]);\n</code></pre><h2 id=\"4-Factories-工厂\"><a href=\"#4-Factories-工厂\" class=\"headerlink\" title=\"4.Factories(工厂)\"></a>4.Factories(工厂)</h2><p>从服务到工厂现在应该是简单的，我们可以在工厂里创建一个对象字面量或简单地提供一些更深入的方法：</p>\n<pre><code>myApp.factory(&apos;Server&apos;, [&apos;$http&apos;, function ($http) {\n  return {\n    get: function(url) {\n      return $http.get(url);\n    },\n    post: function(url) {\n      return $http.post(url);\n    },\n  };\n}]);\n</code></pre><p>下面，在依赖注入到一个控制器后，我创造了一个Angular的XHR自定义包装。这个例子很简单：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;Server&apos;, function ($scope, Server) {\n    var jsonGet = &apos;http://myserver/getURL&apos;;\n    var jsonPost = &apos;http://myserver/postURL&apos;;\n    Server.get(jsonGet);\n    Server.post(jsonPost);\n}]);\n</code></pre><p>如果你想为了改变而轮询服务，你可以设置一个Server.poll(jsonPool),或者假如你正在使用一个Socket,你可以设置Server.socket(jsonSocket).它打开了大门，模块化代码以及创造您使用和保持代码内的控制器，作为一个最小的完整集合。</p>\n<h2 id=\"5-Filters-过滤器\"><a href=\"#5-Filters-过滤器\" class=\"headerlink\" title=\"5.Filters(过滤器)\"></a>5.Filters(过滤器)</h2><p>过滤器一般和数组一块使用，用在循环外，如果你遍历数组来筛选出特定的东西，在正确的地方，你也可以使用过滤器过滤用户想要的类型在<input>标签为例，有几个方法可以使用过滤器，在控制器里面或作为一个定义的方法。这里有使用的方法，您可以在全局使用：</p>\n<pre><code>myApp.filter(&apos;reverse&apos;, function () {\n    return function (input, uppercase) {\n        var out = &apos;&apos;;\n        for (var i = 0; i &lt; input.length; i++) {\n            out = input.charAt(i) + out;\n        }\n        if (uppercase) {\n            out = out.toUpperCase();\n        }\n    return out;\n    }\n});\n\n// Controller included to supply data\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.greeting = &apos;Todd Motto&apos;;\n}]);\n</code></pre><p>DOM内容：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n        &lt;p&gt;No filter: { { greeting } }&lt;/p&gt;\n        &lt;p&gt;Reverse: { { greeting | reverse } }&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>例子：<a href=\"http://runjs.cn/code/ina2n1lb\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/ina2n1lb</a></p>\n<p>可以看到我们通过传递过滤符号“|”在greeting 数据上，对该数据进行逆向过滤。</p>\n<p>在标签ng-repeat中的用法为：</p>\n<pre><code>&lt;ul&gt;\n  &lt;li ng-repeat=&quot;number in myNumbers |filter:oddNumbers&quot;&gt;{{ number }}&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>一个在controller中使用过滤器的简明例子：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.numbers = [10, 25, 35, 45, 60, 80, 100];\n    $scope.lowerBound = 42;\n    // Does the Filters\n    $scope.greaterThanNum = function (item) {\n        return item &gt; $scope.lowerBound;\n    };\n}]);\n</code></pre><p>在ng-repeat标签中的用法为:</p>\n<pre><code>&lt;li ng-repeat=&quot;number in numbers | filter:greaterThanNum&quot;&gt;\n  {{ number }}\n&lt;/li&gt;\n</code></pre><p>演示:<a href=\"http://runjs.cn/code/xiricwi3\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/xiricwi3</a></p>\n<p>这是AngularJS中的主体部分和API，虽然这只是冰山一角，但利用这些内容足以建立起你自己的angular应用。</p>\n<h2 id=\"6-Two-way-data-binding-双向数据绑定\"><a href=\"#6-Two-way-data-binding-双向数据绑定\" class=\"headerlink\" title=\"6.Two-way data-binding(双向数据绑定)\"></a>6.Two-way data-binding(双向数据绑定)</h2><p>当我第一次听说双向数据绑定时，我并不太明白它是什么。双向数据绑定是最好的理解为一个完全同步的数据循环：更新模型并更新视图，更新视图并更新模型。这意味着数据不需要做任何操作都是同步的。如果我将一个ng模型绑定到一个<input>标签然后开始输入，这将在同一时间创建（或更新一个现有的）模型。</p>\n<p>我创建的一个<input>标签并绑定模型称为”myModel”，然后我可以利用angularjs中的语法来反射这个模型并同时更新视图：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n        &lt;input type=&quot;text&quot; ng-model=&quot;myModel&quot; placeholder=&quot;Start typing...&quot; /&gt;\n        &lt;p&gt;My model data: {{ myModel }}&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    // Capture the model data\n    // and/or initialise it with an existing string\n    $scope.myModel = &apos;&apos;;\n}]);\n</code></pre><p>示例：<a href=\"http://runjs.cn/code/fu074xjf\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/fu074xjf</a></p>\n<h2 id=\"7-XHR-Ajax-http-calls-and-binding-JSON\"><a href=\"#7-XHR-Ajax-http-calls-and-binding-JSON\" class=\"headerlink\" title=\"7.XHR/Ajax/$http calls and binding JSON\"></a>7.XHR/Ajax/$http calls and binding JSON</h2><p>你已经掌握了如何把一个基础数据邦定到$scope上，并大致了解了这个model是如何工作的，包括数据的双向邦定。<br>现在是时候学习一些真正的XHR去调用一个服务。对于网站来说，这是没有必要的除非你有特别的Ajax要求，这主要是集中在抓取数据的Web应用程序。</p>\n<p>当你在做本地开发时，你可能使用类似Java，ASP.NET，PHP或别的东西来运行一个本地服务器。无论您是和本地数据库通信还是实际使用服务器作为接口来与其他资源进行通信，这都是相同的。</p>\n<p>输入$http,就可以愉快的开始了。$HTTP方法是从服务器访问数据的一个很好的Angular包装，你可以很方便的使用。这里是一个“GET”请求的简单例子，它从服务器获取数据。它的语法很像是jQuery，所以很好理解：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;$http&apos;, function ($scope, $http) {\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrl&apos;\n  });\n}]);\n</code></pre><p>Angular然后返回内容(叫做承诺)，这是处理回调的一种更有效和可读的方式。承诺是链接function到他们从使用点.mypromise()。正如预期的那样，我们有错误和成功的处理程序：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrl&apos;\n  })\n  .success(function (data, status, headers, config) {\n    // successful data retrieval\n  })\n  .error(function (data, status, headers, config) {\n    // something went wrong :(\n  });\n}]);\n</code></pre><p>非常好的可读性。这就是我们合并视图和绑定模式或更新模型数据到DOM的服务器。让我们假设一个设置和推动一个用户名的DOM，通过Ajax调用。</p>\n<p>理想情况下，我们应该首先建立和设计我们的JSON，这将影响我们如何构造我们的数据。让我们保持简单，这是一个后端开发者将开放一个API在应用程序中，您希望如下：</p>\n<pre><code>{\n  &quot;user&quot;: {\n    &quot;name&quot;: &quot;Todd Motto&quot;,\n    &quot;id&quot;: &quot;80138731&quot;\n  }\n}\n</code></pre><p>这意味着我们会得到一个从服务器返回的对象（化名就叫‘数据’[你可以看到数据被传递到我们的承诺处理]），并嵌有data.user属性。在data.user属性里面，有name和id,访问这些很容易的，我们需要寻找data.user.name这个属性时，它将返回这个属性的值。现在让我们来操作下吧！</p>\n<p>JavaScript代码：</p>\n<pre><code>myApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, &apos;$http&apos;, function ($scope, $http) {\n  // create a user Object\n  $scope.user = {};\n  // Initiate a model as an empty string\n  $scope.user.username = &apos;&apos;;\n  // We want to make a call and get\n  // the person&apos;s username\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrlForGettingUsername&apos;\n  })\n  .success(function (data, status, headers, config) {\n    // See here, we are now assigning this username\n    // to our existing model!\n    $scope.user.username = data.user.name;\n  })\n  .error(function (data, status, headers, config) {\n    // something went wrong :(\n  });\n}]);\n</code></pre><p>DOM代码：</p>\n<pre><code>&lt;div ng-controller=&quot;UserCtrl&quot;&gt;\n  &lt;p&gt;{{ user.username }}&lt;/p&gt;\n&lt;/div&gt;\n</code></pre><p>它会打印username的值。下面我们将进一步了解声明式数据绑定，这是非常令人兴奋的。</p>\n<h2 id=\"8-Declarative-data-binding-声明式数据邦定\"><a href=\"#8-Declarative-data-binding-声明式数据邦定\" class=\"headerlink\" title=\"8.Declarative data-binding(声明式数据邦定)\"></a>8.Declarative data-binding(声明式数据邦定)</h2><p>Angular的理念是创建动态HTML.它是一个强大的功能,代替了你在客户端做的大量工作。这正是他的目的所在。</p>\n<p>让我们想象一下，我们刚刚作了一个Ajax请求得到一些电子邮件的列表包含主题，发送日期，现在想把它们展示在DOM中。这里会体现出Angular的优势。首先，我需要设置一个电子邮件的controller：</p>\n<pre><code>myApp.controller(&apos;EmailsCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  // create a emails Object\n  $scope.emails = {};\n  // pretend data we just got back from the server\n  // this is an ARRAY of OBJECTS\n  $scope.emails.messages = [{\n        &quot;from&quot;: &quot;Steve Jobs&quot;,\n        &quot;subject&quot;: &quot;I think I&apos;m holding my phone wrong :/&quot;,\n        &quot;sent&quot;: &quot;2013-10-01T08:05:59Z&quot;\n    },{\n        &quot;from&quot;: &quot;Ellie Goulding&quot;,\n        &quot;subject&quot;: &quot;I&apos;ve got Starry Eyes, lulz&quot;,\n        &quot;sent&quot;: &quot;2013-09-21T19:45:00Z&quot;\n    },{\n        &quot;from&quot;: &quot;Michael Stipe&quot;,\n        &quot;subject&quot;: &quot;Everybody hurts, sometimes.&quot;,\n        &quot;sent&quot;: &quot;2013-09-12T11:38:30Z&quot;\n    },{\n        &quot;from&quot;: &quot;Jeremy Clarkson&quot;,\n        &quot;subject&quot;: &quot;Think I&apos;ve found the best car... In the world&quot;,\n        &quot;sent&quot;: &quot;2013-09-03T13:15:11Z&quot;\n    }];\n}]);\n</code></pre><p>现在我们需要把它插入到我们的HTML中。这时我们会使用声明式绑定宣布什么应用程序将创建我们的第一个动态HTML。我们要用到Angular的内置指令ng-repeat，它会遍历数据，完全没有回调或状态变化的渲染输出，这都是非常灵活的：</p>\n<pre><code>&lt;ul&gt;\n  &lt;li ng-repeat=&quot;message in emails.messages&quot;&gt;\n    &lt;p&gt;From: {{ message.from }}&lt;/p&gt;\n    &lt;p&gt;Subject: {{ message.subject }}&lt;/p&gt;\n    &lt;p&gt;{{ message.sent | date:'MMM d, y h:mm:ss a' }}&lt;/p&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>示例：<a href=\"http://runjs.cn/code/q9beqc9s\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/q9beqc9s</a></p>\n<p>我使用了一个日期过滤器，从中你可以看到如何处理UTC日期。</p>\n<p>深入Angular的ng-*指令,你将完全释放出angular的声明式绑定的能力，这里展示了如何从服务器到模型，以及模拟和渲染数据。</p>\n<h2 id=\"9-Scope-functions-范围函数\"><a href=\"#9-Scope-functions-范围函数\" class=\"headerlink\" title=\"9.Scope functions(范围函数)\"></a>9.Scope functions(范围函数)</h2><p>作为声明性绑定的延续，范围函数是在创建应用程序时的下一个层次。这里展示了一个基本功能，删除我们的电子邮件中的一个数据：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  $scope.deleteEmail = function (index) {\n    $scope.emails.messages.splice(index, 1)\n  };\n}]);\n</code></pre><p>友情提示：重要的一点是要考虑从模型中删除数据。不删除元素或任何实际的DOM相关，angular是一个MVC框架，将为您处理这一切与它的双向绑定和回调的自由世界，你只需要设置你的代码可以让它响应你的数据！</p>\n<pre><code>&lt;a ng-click=&quot;deleteEmail($index)&quot;&gt;Delete email&lt;/a&gt;\n</code></pre><p>这是一种不同的内联点击处理程序，因为许多原因。这将很快覆盖。你会看到我也在通过$index，angular知道你正在删除的项目（这样可以节省你多少代码和逻辑！）。</p>\n<p>示例：<a href=\"http://runjs.cn/code/jm84qnh3\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/jm84qnh3</a></p>\n<h2 id=\"10-Declarative-DOM-methods-陈述性DOM方法\"><a href=\"#10-Declarative-DOM-methods-陈述性DOM方法\" class=\"headerlink\" title=\"10.Declarative DOM methods(陈述性DOM方法)\"></a>10.Declarative DOM methods(陈述性DOM方法)</h2><p>现在我们要转移到的DOM方法，这些也都是些指令和模拟功能的DOM，你通常会写出更多的逻辑脚本。这个例子是一个简单的切换导航。用一个简单的ng-show和一个简单的ng-click设置，我们可以创建一个完美无瑕的切换导航：</p>\n<pre><code>&lt;a href=&quot;&quot; ng-click=&quot;toggle = !toggle&quot;&gt;Toggle nav&lt;/a&gt;\n&lt;ul ng-show=&quot;toggle&quot;&gt;\n  &lt;li&gt;Link 1&lt;/li&gt;\n  &lt;li&gt;Link 2&lt;/li&gt;\n  &lt;li&gt;Link 3&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>我们开始进入MVVM的学习，你会发现脚本里没有controller的代码，我们会很快进入MVVM。</p>\n<p>示例：<a href=\"http://runjs.cn/code/r5tlnqrb\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/r5tlnqrb</a></p>\n<h2 id=\"11-Expressions-表达式\"><a href=\"#11-Expressions-表达式\" class=\"headerlink\" title=\"11.Expressions(表达式)\"></a>11.Expressions(表达式)</h2><p>我最喜欢Angular的一部分是，你会用JavaScript写出很多重复的代码。</p>\n<p>你尝试过这个吗？</p>\n<pre><code>elem.onclick = function (data) {\n  if (data.length === 0) {\n    otherElem.innerHTML = &apos;No data&apos;;\n  } else {\n    otherElem.innerHTML = &apos;My data&apos;;\n  }\n};\n</code></pre><p>这可能是一个GET请求回调，你会改变基于数据的DOM。Angular给你这个自由，你就可以做到无需编写任何内置的JavaScript！</p>\n<pre><code>&lt;p&gt;{{ data.length > 0 && 'My data' || 'No data' }}&lt;/p&gt;\n</code></pre><p>这会动态更新自己而没有回调应用程序获取数据。如果没有数据，它会告诉你，如果有数据，它会显示数据。针对Angular处理自动双向绑定数据，会有很多的使用情况。</p>\n<p>示例：<a href=\"http://runjs.cn/code/ahl0hfcc\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/ahl0hfcc</a></p>\n<h2 id=\"12-Dynamic-views-and-routing-动态视图和路由\"><a href=\"#12-Dynamic-views-and-routing-动态视图和路由\" class=\"headerlink\" title=\"12.Dynamic views and routing(动态视图和路由)\"></a>12.Dynamic views and routing(动态视图和路由)</h2><p>单页面web应用(也包括网站)背后的理念是: 你有一个标题，页脚，侧边栏，和中间的内容,通过设置URL可以神奇地注入新的内容。</p>\n<p>Angular通过一个简单的设置来配置我们所说的动态视图。动态视图依靠URL注入每个视图，通过$routeprovider。一个简单的设置如下：</p>\n<pre><code>myApp.config([&apos;$routeProvider&apos;, function ($routeProvider) {\n  /**\n   * $routeProvider\n   */\n  $routeProvider\n  .when(&apos;/&apos;, {\n    templateUrl: &apos;views/main.html&apos;\n  })\n  .otherwise({\n    redirectTo: &apos;/&apos;\n  });\n}]);\n</code></pre><p>你会看到，当URL是”/“(即该站点的根目录),你会注入main.html。当你在一个单页面应用中已经有一个index.html页面，这是一个好的方法去调用内部的main.html视图而不是index.html。依靠URL去添加更多的视图是如此简单：</p>\n<pre><code>myApp.config([&apos;$routeProvider&apos;, function ($routeProvider) {\n  /**\n   * $routeProvider\n   */\n  $routeProvider\n  .when(&apos;/&apos;, {\n    templateUrl: &apos;views/main.html&apos;\n  })\n  .when(&apos;/emails&apos;, {\n    templateUrl: &apos;views/emails.html&apos;\n  })\n  .otherwise({\n    redirectTo: &apos;/&apos;\n  });\n}]);\n</code></pre><p>我们可以在emails.html上简单的加载HTML去生成我们的邮件列表,最终你可以毫不费力的创建一个复杂的应用程序。</p>\n<h2 id=\"13-Global-static-data-全局静态数据\"><a href=\"#13-Global-static-data-全局静态数据\" class=\"headerlink\" title=\"13.Global static data(全局静态数据)\"></a>13.Global static data(全局静态数据)</h2><p>Gmail处理很多内部初始化数据是通过将JSON加入到页面中(右键查看源代码)。如果你想立即在你的页面设置数据，它会加快渲染时间并且Angular将更快的执行。</p>\n<p>当我们开发应用程序时，页面渲染时，Java标签放置在DOM中，数据从后台发送过来。[我没有Java开发经验，你需要知道一个下面的声明，虽然在服务器上你可以使用任何语言。]这里是如何把JSON加入到网页中，然后把它传给一个控制器,为即时邦定使用：</p>\n<pre><code>&lt;!-- inside index.html (bottom of page ofc) --&gt;\n&lt;script&gt;\nwindow.globalData = {};\nglobalData.emails = &lt;javaTagHereToGenerateMessages&gt;;\n&lt;/script&gt;\n</code></pre><p>我定义的java标签使数据能在页面中渲染，Angular会轻松的渲染你的emails数据，只要把你的数据放入到controller中即可:</p>\n<pre><code>myApp.controller(&apos;EmailsCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.emails = {};\n    // Assign the initial data!\n    $scope.emails.messages = globalData.emails;\n}]);\n</code></pre><h2 id=\"14-Minification-精简\"><a href=\"#14-Minification-精简\" class=\"headerlink\" title=\"14.Minification(精简)\"></a>14.Minification(精简)</h2><p>这一段是关于精简你的angular代码内容。在这方面你可能已经尝试过了，有时跑一个精简过的代码，会遇到了一个错误！</p>\n<p>精简你的AngularJS代码很简单，你需要指定你的依赖注入的内容在函数数组：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;,\n[&apos;$scope&apos;, &apos;Dependency&apos;, &apos;Service&apos;, &apos;Factory&apos;,\nfunction ($scope, Dependency, Service, Factory) {\n  // code\n}]);\n</code></pre><p>精简后:</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;,\n[&apos;$scope&apos;, &apos;Dependency&apos;, &apos;Service&apos;, &apos;Factory&apos;,\nfunction (a,b,c,d) {\n  // a = $scope\n  // b = Dependency\n  // c = Service\n  // d = Factory\n  // $scope alias usage\n  a.someFunction = function () {...};\n}]);\n</code></pre><p>请记住，以保持参数的顺序出现，否则你可能会导致你和你的团队费劲。</p>\n<h2 id=\"15-Differences-in-MVC-and-MVVM-MVC和MVVM的差异\"><a href=\"#15-Differences-in-MVC-and-MVVM-MVC和MVVM的差异\" class=\"headerlink\" title=\"15.Differences in MVC and MVVM(MVC和MVVM的差异)\"></a>15.Differences in MVC and MVVM(MVC和MVVM的差异)</h2><p>这里简要介绍两者的区别:</p>\n<p><strong>MVC</strong>: 用一个controller交互,关系是Model-View-Controller<br><strong>MVVM</strong>: 封装声明数据邦定,Model-View-View-Model,Model和View交互,View也可以和Model交互,Angular的双向数据绑定允许它在不做任何事情时保持同步。它还允许你在没有控制器的情况下,编写逻辑代码！</p>\n<p>一个简单的例子，你可以创建一个ng-repeat标签去提供数据,而不需要Controller:</p>\n<pre><code>&lt;li ng-repeat=&quot;number in [1,2,3,4,5,6,7,8,9]&quot;&gt;\n  {{ number }}\n&lt;/li&gt;\n</code></pre><p>对于快速测试这是很有帮助的，但对与复杂的情况时，我建议使用一个Controller。</p>\n<h2 id=\"16-HTML5-Web-Components-HTML5组件\"><a href=\"#16-HTML5-Web-Components-HTML5组件\" class=\"headerlink\" title=\"16.HTML5 Web Components(HTML5组件)\"></a>16.HTML5 Web Components(HTML5组件)</h2><p>在早些时候你会发现AngularJS允许你创建自定义的元素:</p>\n<pre><code>&lt;myCustomElement&gt;&lt;/myCustomElement&gt;\n</code></pre><p>这实际上是符合HTML5未来的特性。HTML5 Web部件和模板元素，Angular让我们今天就能这样用。Web部件包括通过动态JavaScript注入生成的自定义元素！</p>\n<h2 id=\"17-Scope-comments-范围注释\"><a href=\"#17-Scope-comments-范围注释\" class=\"headerlink\" title=\"17.Scope comments(范围注释)\"></a>17.Scope comments(范围注释)</h2><p>范围注释,我觉得真的是一个不错特性,代替了HTML注释，像这样的块：</p>\n<pre><code>&lt;!-- header --&gt;\n&lt;header&gt;\n  Stuff.\n&lt;/header&gt;\n&lt;!-- /header --&gt;\n</code></pre><p>引入Angular后，让我们思考的是Views和Scopes，而不是DOM，除非你故意共享控制器间的数据，我发现使用范围是一个很大的帮助：</p>\n<pre><code>&lt;!-- scope: MainCtrl --&gt;\n&lt;div class=&quot;content&quot; ng-controller=&quot;MainCtrl&quot;&gt;\n&lt;/div&gt;\n&lt;!-- /scope: MainCtrl --&gt;\n</code></pre><h2 id=\"18-Debugging-AngularJS-调试\"><a href=\"#18-Debugging-AngularJS-调试\" class=\"headerlink\" title=\"18.Debugging AngularJS(调试)\"></a>18.Debugging AngularJS(调试)</h2><p>对于调试AngularJS的话，可以使用Chrome的一个扩展工具-Batarang,你可以去下载下看看。</p>\n<h2 id=\"结束\"><a href=\"#结束\" class=\"headerlink\" title=\"结束\"></a>结束</h2><p>到此本文结束,希望能够对大家学习angular有一个好的指导，更多关于angular的细节可以参看<a href=\"http://toddmotto.com/\" target=\"_blank\" rel=\"noopener\">Todd Motto</a> 的系列文章<br>再次感谢原作者的整理，文中如有不对的地方可以指出。</p>\n","site":{"data":{}},"excerpt":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<p>对于学习angulaJS来说，更多的是对整体的了解。看了Todd Motto 的一篇文章后，对这个框架有了一个比较清晰的认识。<br><a href=\"http://toddmotto.com/ultimate-guide-to-learning-angular-js-in-one-day/\" target=\"_blank\" rel=\"noopener\">查看原文</a><br>","more":"</p>\n<h2 id=\"I-什么是AngularJS\"><a href=\"#I-什么是AngularJS\" class=\"headerlink\" title=\"I.什么是AngularJS?\"></a>I.什么是AngularJS?</h2><p><img src=\"/images/angularjs.jpg\" alt=\"\"></p>\n<p>Angular 是一个客户端MVC/MVVM框架，内置在JavaScript中，是现在流行的单页面web应用（甚至是网站）必不可少的东西。这篇文章是我学习angularjs的全部的经验，建议和最佳的做法。通过掌握它你会学会很多东西。</p>\n<h2 id=\"II-Terminology-术语\"><a href=\"#II-Terminology-术语\" class=\"headerlink\" title=\"II.Terminology(术语)\"></a>II.Terminology(术语)</h2><p>Angular 有一个短的学习路线，掌握了基本知识后你会发现它的优点和缺点，对学习这个框架来说，掌握这些术语和学会用MVC思考是非常重要的，下面是一些Angular中包含的一些高级并且重要的api和术语。</p>\n<h2 id=\"III-MVC\"><a href=\"#III-MVC\" class=\"headerlink\" title=\"III.MVC\"></a>III.MVC</h2><p>你可能听说过MVC，用在许多编程语言中来构建应用程序/软件/架构的一种手段。这里是每个部分的简单含义：</p>\n<p><strong>Model</strong>：每一个应用中都离不开数据结构，通常放在JSON中。在开始Angular之前先要读懂JSON，因为它对了解server和view是如何通信的非常重要。例如，一组用户身份标识可以有以下模型：</p>\n<pre><code>{\n  &quot;users&quot; : [{\n  &quot;name&quot;: &quot;Joe Bloggs&quot;,\n  &quot;id&quot;: &quot;82047392&quot;\n},{\n  &quot;name&quot;: &quot;John Doe&quot;,\n  &quot;id&quot;: &quot;65198013&quot;\n }]\n}\n</code></pre><p>然后你就可以从服务器通过XHR抓取信息（XMLHTTP请求），在Jquery中是通过$.ajax方法，在Angular中是$http,或者它会写进你的代码在页面解析（从一个数据仓库/数据库）时，然后你可以推送更新到你的模型，并把它发送回。</p>\n<p><strong>View</strong>: View是非常容易理解的，它是你的HTML页面或呈现的输出。使用MVC框架，你会使用Model数据来更新View和HTML中显示的相关数据。</p>\n<p><strong>Controller</strong>：Controller直接访问服务器中的View，作为中间人，你能够在Controller中更新Model中的数据来改变View。</p>\n<h2 id=\"0-建立一个AngularJS项目（基本要点）\"><a href=\"#0-建立一个AngularJS项目（基本要点）\" class=\"headerlink\" title=\"0.建立一个AngularJS项目（基本要点）\"></a>0.建立一个AngularJS项目（基本要点）</h2><p>首先，我们需要确认安装了AngularJS必备的基础环境，在我们开始前有一些事情是需要注意的，一般由ng-app声明来定义你的应用程序,一个Controller和View页面、一些DOM邦定还有Angular来交互。以下是基本要点：</p>\n<p>一些带“ng-*” 声明的HTML</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n  &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n      &lt;!-- controller logic --&gt;\n   &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>Angular的 Module 和 Controller:</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    // Controller magic\n}]);\n</code></pre><p>在开始动手之前，我们需要创建一个包含所有逻辑的Angular module,有很多种方法来声明 modules,你可以将所有的逻辑像这样串联起来（我不喜欢这种做法）：</p>\n<pre><code>angular.module(&apos;myApp&apos;, [])\n.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}])\n.controller(&apos;NavCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}])\n.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\n</code></pre><p>在我的使用中，建立一个全局的Module被证明是一个非常好的方式。缺少分号和意外关闭的’连接’证明适得其反，会出现一些不必要的编译错误，像这样：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\nmyApp.controller(&apos;NavCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\nmyApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {...}]);\n</code></pre><p>我创建的每一文件都使用简单的myApp命名空间并自动的邦定到Application上，没错，我会为每个Controller, Directive, Factory 和其它的内容创建一个文件，关联和压缩这些文件到一个脚本文件中，然后引入到DOM中（使用Grunt或Gulp类似的工具）</p>\n<h2 id=\"1-Controllers-控制器\"><a href=\"#1-Controllers-控制器\" class=\"headerlink\" title=\"1.Controllers(控制器)\"></a>1.Controllers(控制器)</h2><p>现在你已经掌握了MVC设计模式的概念和基本设置，让我们看看Angular中是如何运用Controllers的。<br>从上面的例子中我们可以很简单的从一个Controller中拿到数据然后放入到DOM中，Angular采用一种模板风格  嵌在你的HTML中，你的HTML应该（最好）不包含物理文本或硬编码的值以最大限度地利用Angular，下面是一个将字符串推送到页面上的例子：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n  &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n      { { text } }\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>脚本：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n\n    $scope.text = &apos;Hello, Angular fanatic.&apos;;\n\n}]);\n</code></pre><p>演示：<a href=\"http://runjs.cn/code/jgevzqjd\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/jgevzqjd</a></p>\n<p>这里的核心法则是“$scope”的概念，你会在一个特定的Controller里面邦定所有的功能。$scope代表的是DOM中当前的元素，封装一个非常好的观察能力，保持元素范围内的数据和逻辑完完美邦定。它提供了JavaScript的公共/私有范围的DOM，这很神奇。</p>\n<p>$scope的范围概念似乎有点可怕，但这是你从服务器到DOM的交互方式（静态数据，如果你有过）！这个例子教你了一个如何把数据“推”到DOM的办法。</p>\n<p>让我们看一个比较有代表性的数据结构，我们假设从服务器检索显示用户的登录信息。现在我将使用静态数据；我后边会告诉你如何获取动态JSON数据。</p>\n<p>首先我们要编写JavaScript：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nmyApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n\n    // Let&apos;s namespace the user details\n    // Also great for DOM visual aids too\n    $scope.user = {};\n    $scope.user.details = {\n        &quot;username&quot;: &quot;Todd Motto&quot;,\n        &quot;id&quot;: &quot;89101112&quot;\n    };\n\n}]);\n</code></pre><p>然后交给DOM来显示这些数据：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;UserCtrl&quot;&gt;\n        &lt;p class=&quot;username&quot;&gt;Welcome, { { user.details.username } }&lt;/p&gt;\n        &lt;p class=&quot;id&quot;&gt;User ID: { { user.details.id } }&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>演示：<a href=\"http://runjs.cn/code/4xrlzycm\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/4xrlzycm</a></p>\n<p>重要的一点要记住，控制器只为数据，并创建函数（也包括事件函数）！它跟服务器交互并且推/拉JSON数据。这里没有DOM操作，所以不需要jQery工具。指令(Directives )是DOM操作，这是下一个要介绍的。</p>\n<p>小提示：在Angular的官方文档中（我在写这篇文章时）他们的例子中使用这种方式创建Controllers：</p>\n<pre><code>var myApp = angular.module(&apos;myApp&apos;, []);\n\nfunction MainCtrl ($scope) {\n//...\n};\n</code></pre><p>…不要这样做。这将所有的功能都暴露在全局范围内，并不会让它们与应用程序很好地联系在一起。这也意味着你不能很容易的缩小你的代码或运行测试。不要滥用全局名称空间，要保证Controller只在您的应用程序内。</p>\n<h2 id=\"2-Directives-指令\"><a href=\"#2-Directives-指令\" class=\"headerlink\" title=\"2.Directives(指令)\"></a>2.Directives(指令)</h2><p>指令最简化形式是一段HTML模板，在应用程序需要的地方最好能多次使用。这是毫不费力的注入DOM到应用中最简单的方式，或执行自定义DOM交互。指令并不简单，想完全征服他们需要一个非常令人难以置信的学习路线，但通过这一小节的学习会让你基本掌握它。</p>\n<p>那指令有什么用处？很多事情，包括DOM组件，例如制表符或导航元素会依赖你的应用程序中使用的UI。让我这样说吧，如果你有过ng-show或者ng-hide，这就是指令（虽然他们不注入DOM）。</p>\n<p>对于这个练习，我想把它弄的很简单，创建一个自定义按钮（称为CustomButton）注入一些标记，我讨厌写很多字。有各种不同的方式定义DOM中的指令，这些可能看起来像这样：</p>\n<pre><code>&lt;!-- 1: as an attribute declaration --&gt;\n&lt;a custom-button&gt;Click me&lt;/a&gt;\n\n&lt;!-- 2: as a custom element --&gt;\n&lt;custom-button&gt;Click me&lt;/custom-button&gt;\n\n&lt;!-- 3: as a class (used for old IE compat) --&gt;\n&lt;a class=&quot;custom-button&quot;&gt;Click me&lt;/a&gt;\n\n&lt;!-- 4: as a comment (not good for this demo, however) --&gt;\n&lt;!-- directive: custom-button --&gt;\n</code></pre><p>我更喜欢他们作为一个属性使用，自定义元素作为HTML5未来的一个Web组件特性，但Angular指出这在一些老的浏览器上会当成是一个BUG。</p>\n<p>现在你知道在使用/注入指令的时候如何声明了吧，让我们创建这个自定义按钮。再次，我会回调我的全局命名空间MyApp的应用，这是最简形式的指令：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    link: function (scope, element, attrs) {\n      // DOM manipulation/events here!\n    }\n  };\n});\n</code></pre><p>我使用 .directive()方法来创建指令，传入指令的名称“CustomButton“。当你在指令的名称中使用一些字母，它会通过DOM中的连字符进行分割（如上图）。</p>\n<p>一个指令简单的返回一个带有参数的对象。对我来说最重要的是：restrict, replace, transclude, template 和 templateUrl,当然还有 link 属性。让我把其它的也加入进来吧：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    restrict: &apos;A&apos;,\n    replace: true,\n    transclude: true,\n    template: &apos;&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;&apos; +\n                &apos;&lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;&apos; +\n              &apos;&lt;/a&gt;&apos;,\n    link: function (scope, element, attrs) {\n      // DOM manipulation/events here!\n    }\n  };\n});\n</code></pre><p>演示： <a href=\"http://runjs.cn/code/xtupcxdh\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/xtupcxdh</a></p>\n<p>验证你是否插入元素，请确认你是否注入附加标记。指令的属性解释：</p>\n<p><strong>restrict</strong>：[约束]看下上面的例子我们是怎么使用restrict的，如果你的项目需要支持IE的话，你可能需要声明attribute或class。使用“A”意味着你限制它作为一个Attribute，E代表Element，C代表Class，M代表Comment。默认是“EA”，对的，你可以限制多个。</p>\n<p><strong>replace</strong>：[替换]替换DOM为指令中定义的内容，在这个例子中，你会注意到初始DOM已经被指令的模板替换。</p>\n<p><strong>transclude</strong>：[嵌入]简单地说，使用嵌入允许现有的DOM内容被复制到指令中。你会看到单词’点击我’已被’移’到指令中，在显示的时候。</p>\n<p><strong>template</strong>：[模板]模板（如上）允许你将标记为被注入。这是一个好主意，用这一小段HTML片断。注入模板都通过Angular编译，这意味着你可以定义处理的方法已更好的邦定使用。</p>\n<p><strong>templateUrl</strong>：[模板Url]类似于一个模板，但保持在它自己的文件或&lt;脚本&gt;标签。你可以指定一个模板的URL，你会使用一个单独的文件来管理HTML模板，请指定路径和文件名，最好放在自己的模板目录中：</p>\n<pre><code>myApp.directive(&apos;customButton&apos;, function () {\n  return {\n    templateUrl: &apos;templates/customButton.html&apos;\n    // directive stuff...\n  };\n});\n</code></pre><p>加入你的文件（文件名不敏感）：</p>\n<pre><code>&lt;!-- inside customButton.html --&gt;\n&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;\n  &lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;\n&lt;/a&gt;\n</code></pre><p>这样做真的很好，浏览器会缓存HTML文件，干的漂亮！设置不缓存的另一个选择是在script标签中声明一个模板：</p>\n<pre><code>&lt;script type=&quot;text/ng-template&quot; id=&quot;customButton.html&quot;&gt;\n&lt;a href=&quot;&quot; class=&quot;myawesomebutton&quot; ng-transclude&gt;\n  &lt;i class=&quot;icon-ok-sign&quot;&gt;&lt;/i&gt;\n&lt;/a&gt;\n&lt;/script&gt;\n</code></pre><p>你会告诉Angular它是一个模板并且还有一个ID，Angular会查找NG模板或*.HTML文件,他们很容易管理，提高性能和保持DOM很干净，你可以建立1个或100个指令，你可以很容易的浏览它们。</p>\n<h2 id=\"3-Services-服务\"><a href=\"#3-Services-服务\" class=\"headerlink\" title=\"3.Services(服务)\"></a>3.Services(服务)</h2><p>服务通常是混淆点。从经验和研究上，他们更多的是一种风格的设计模式，而不是提供更多的功能差异。在深入到Angular源码后,他们指望通过相同的编译器运行，并共享大量的功能。从我的研究来看，你应该在单例，工厂以及其它更复杂的功能上使用服务，如对象字面量和更复杂的用例。</p>\n<p>下面是一个Service例子,计算2个数字的乘积：</p>\n<pre><code> myApp.service(&apos;Math&apos;, function () {\n      this.multiply = function (x, y) {\n          return x * y;\n     };\n});\n</code></pre><p>然后，你应该使用这样的内部控制器：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    var a = 12;\n    var b = 24;\n   // outputs 288\n    var result = Math.multiply(a, b);\n}]);\n</code></pre><p>是的，乘法是很容易的，不需要一个服务，但你领会到了其中的要点。</p>\n<p>当你创建一个服务（或工厂）时，你需要使用依赖注入来告诉Angular需要扑获新的服度，否则你会得到编译错误，你的控制器会中断。你可能已经注意到了这个函数($scope)的部分，现在，这是简单的依赖注入。看下你的代码,你也会注意到（$scope）之前的功能（$scope），我会到后面解释。这里是如何使用依赖注入来告诉你需要你的服务：</p>\n<pre><code>// Pass in Math\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;Math&apos;, function ($scope, Math) {\n  var a = 12;\n  var b = 24;\n  // outputs 288\n  var result = Math.multiply(a, b);\n}]);\n</code></pre><h2 id=\"4-Factories-工厂\"><a href=\"#4-Factories-工厂\" class=\"headerlink\" title=\"4.Factories(工厂)\"></a>4.Factories(工厂)</h2><p>从服务到工厂现在应该是简单的，我们可以在工厂里创建一个对象字面量或简单地提供一些更深入的方法：</p>\n<pre><code>myApp.factory(&apos;Server&apos;, [&apos;$http&apos;, function ($http) {\n  return {\n    get: function(url) {\n      return $http.get(url);\n    },\n    post: function(url) {\n      return $http.post(url);\n    },\n  };\n}]);\n</code></pre><p>下面，在依赖注入到一个控制器后，我创造了一个Angular的XHR自定义包装。这个例子很简单：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;Server&apos;, function ($scope, Server) {\n    var jsonGet = &apos;http://myserver/getURL&apos;;\n    var jsonPost = &apos;http://myserver/postURL&apos;;\n    Server.get(jsonGet);\n    Server.post(jsonPost);\n}]);\n</code></pre><p>如果你想为了改变而轮询服务，你可以设置一个Server.poll(jsonPool),或者假如你正在使用一个Socket,你可以设置Server.socket(jsonSocket).它打开了大门，模块化代码以及创造您使用和保持代码内的控制器，作为一个最小的完整集合。</p>\n<h2 id=\"5-Filters-过滤器\"><a href=\"#5-Filters-过滤器\" class=\"headerlink\" title=\"5.Filters(过滤器)\"></a>5.Filters(过滤器)</h2><p>过滤器一般和数组一块使用，用在循环外，如果你遍历数组来筛选出特定的东西，在正确的地方，你也可以使用过滤器过滤用户想要的类型在<input>标签为例，有几个方法可以使用过滤器，在控制器里面或作为一个定义的方法。这里有使用的方法，您可以在全局使用：</p>\n<pre><code>myApp.filter(&apos;reverse&apos;, function () {\n    return function (input, uppercase) {\n        var out = &apos;&apos;;\n        for (var i = 0; i &lt; input.length; i++) {\n            out = input.charAt(i) + out;\n        }\n        if (uppercase) {\n            out = out.toUpperCase();\n        }\n    return out;\n    }\n});\n\n// Controller included to supply data\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.greeting = &apos;Todd Motto&apos;;\n}]);\n</code></pre><p>DOM内容：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n        &lt;p&gt;No filter: { { greeting } }&lt;/p&gt;\n        &lt;p&gt;Reverse: { { greeting | reverse } }&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre><p>例子：<a href=\"http://runjs.cn/code/ina2n1lb\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/ina2n1lb</a></p>\n<p>可以看到我们通过传递过滤符号“|”在greeting 数据上，对该数据进行逆向过滤。</p>\n<p>在标签ng-repeat中的用法为：</p>\n<pre><code>&lt;ul&gt;\n  &lt;li ng-repeat=&quot;number in myNumbers |filter:oddNumbers&quot;&gt;{{ number }}&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>一个在controller中使用过滤器的简明例子：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.numbers = [10, 25, 35, 45, 60, 80, 100];\n    $scope.lowerBound = 42;\n    // Does the Filters\n    $scope.greaterThanNum = function (item) {\n        return item &gt; $scope.lowerBound;\n    };\n}]);\n</code></pre><p>在ng-repeat标签中的用法为:</p>\n<pre><code>&lt;li ng-repeat=&quot;number in numbers | filter:greaterThanNum&quot;&gt;\n  {{ number }}\n&lt;/li&gt;\n</code></pre><p>演示:<a href=\"http://runjs.cn/code/xiricwi3\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/xiricwi3</a></p>\n<p>这是AngularJS中的主体部分和API，虽然这只是冰山一角，但利用这些内容足以建立起你自己的angular应用。</p>\n<h2 id=\"6-Two-way-data-binding-双向数据绑定\"><a href=\"#6-Two-way-data-binding-双向数据绑定\" class=\"headerlink\" title=\"6.Two-way data-binding(双向数据绑定)\"></a>6.Two-way data-binding(双向数据绑定)</h2><p>当我第一次听说双向数据绑定时，我并不太明白它是什么。双向数据绑定是最好的理解为一个完全同步的数据循环：更新模型并更新视图，更新视图并更新模型。这意味着数据不需要做任何操作都是同步的。如果我将一个ng模型绑定到一个<input>标签然后开始输入，这将在同一时间创建（或更新一个现有的）模型。</p>\n<p>我创建的一个<input>标签并绑定模型称为”myModel”，然后我可以利用angularjs中的语法来反射这个模型并同时更新视图：</p>\n<pre><code>&lt;div ng-app=&quot;myApp&quot;&gt;\n    &lt;div ng-controller=&quot;MainCtrl&quot;&gt;\n        &lt;input type=&quot;text&quot; ng-model=&quot;myModel&quot; placeholder=&quot;Start typing...&quot; /&gt;\n        &lt;p&gt;My model data: {{ myModel }}&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\nmyApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    // Capture the model data\n    // and/or initialise it with an existing string\n    $scope.myModel = &apos;&apos;;\n}]);\n</code></pre><p>示例：<a href=\"http://runjs.cn/code/fu074xjf\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/fu074xjf</a></p>\n<h2 id=\"7-XHR-Ajax-http-calls-and-binding-JSON\"><a href=\"#7-XHR-Ajax-http-calls-and-binding-JSON\" class=\"headerlink\" title=\"7.XHR/Ajax/$http calls and binding JSON\"></a>7.XHR/Ajax/$http calls and binding JSON</h2><p>你已经掌握了如何把一个基础数据邦定到$scope上，并大致了解了这个model是如何工作的，包括数据的双向邦定。<br>现在是时候学习一些真正的XHR去调用一个服务。对于网站来说，这是没有必要的除非你有特别的Ajax要求，这主要是集中在抓取数据的Web应用程序。</p>\n<p>当你在做本地开发时，你可能使用类似Java，ASP.NET，PHP或别的东西来运行一个本地服务器。无论您是和本地数据库通信还是实际使用服务器作为接口来与其他资源进行通信，这都是相同的。</p>\n<p>输入$http,就可以愉快的开始了。$HTTP方法是从服务器访问数据的一个很好的Angular包装，你可以很方便的使用。这里是一个“GET”请求的简单例子，它从服务器获取数据。它的语法很像是jQuery，所以很好理解：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, &apos;$http&apos;, function ($scope, $http) {\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrl&apos;\n  });\n}]);\n</code></pre><p>Angular然后返回内容(叫做承诺)，这是处理回调的一种更有效和可读的方式。承诺是链接function到他们从使用点.mypromise()。正如预期的那样，我们有错误和成功的处理程序：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrl&apos;\n  })\n  .success(function (data, status, headers, config) {\n    // successful data retrieval\n  })\n  .error(function (data, status, headers, config) {\n    // something went wrong :(\n  });\n}]);\n</code></pre><p>非常好的可读性。这就是我们合并视图和绑定模式或更新模型数据到DOM的服务器。让我们假设一个设置和推动一个用户名的DOM，通过Ajax调用。</p>\n<p>理想情况下，我们应该首先建立和设计我们的JSON，这将影响我们如何构造我们的数据。让我们保持简单，这是一个后端开发者将开放一个API在应用程序中，您希望如下：</p>\n<pre><code>{\n  &quot;user&quot;: {\n    &quot;name&quot;: &quot;Todd Motto&quot;,\n    &quot;id&quot;: &quot;80138731&quot;\n  }\n}\n</code></pre><p>这意味着我们会得到一个从服务器返回的对象（化名就叫‘数据’[你可以看到数据被传递到我们的承诺处理]），并嵌有data.user属性。在data.user属性里面，有name和id,访问这些很容易的，我们需要寻找data.user.name这个属性时，它将返回这个属性的值。现在让我们来操作下吧！</p>\n<p>JavaScript代码：</p>\n<pre><code>myApp.controller(&apos;UserCtrl&apos;, [&apos;$scope&apos;, &apos;$http&apos;, function ($scope, $http) {\n  // create a user Object\n  $scope.user = {};\n  // Initiate a model as an empty string\n  $scope.user.username = &apos;&apos;;\n  // We want to make a call and get\n  // the person&apos;s username\n  $http({\n    method: &apos;GET&apos;,\n    url: &apos;//localhost:9000/someUrlForGettingUsername&apos;\n  })\n  .success(function (data, status, headers, config) {\n    // See here, we are now assigning this username\n    // to our existing model!\n    $scope.user.username = data.user.name;\n  })\n  .error(function (data, status, headers, config) {\n    // something went wrong :(\n  });\n}]);\n</code></pre><p>DOM代码：</p>\n<pre><code>&lt;div ng-controller=&quot;UserCtrl&quot;&gt;\n  &lt;p&gt;{{ user.username }}&lt;/p&gt;\n&lt;/div&gt;\n</code></pre><p>它会打印username的值。下面我们将进一步了解声明式数据绑定，这是非常令人兴奋的。</p>\n<h2 id=\"8-Declarative-data-binding-声明式数据邦定\"><a href=\"#8-Declarative-data-binding-声明式数据邦定\" class=\"headerlink\" title=\"8.Declarative data-binding(声明式数据邦定)\"></a>8.Declarative data-binding(声明式数据邦定)</h2><p>Angular的理念是创建动态HTML.它是一个强大的功能,代替了你在客户端做的大量工作。这正是他的目的所在。</p>\n<p>让我们想象一下，我们刚刚作了一个Ajax请求得到一些电子邮件的列表包含主题，发送日期，现在想把它们展示在DOM中。这里会体现出Angular的优势。首先，我需要设置一个电子邮件的controller：</p>\n<pre><code>myApp.controller(&apos;EmailsCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  // create a emails Object\n  $scope.emails = {};\n  // pretend data we just got back from the server\n  // this is an ARRAY of OBJECTS\n  $scope.emails.messages = [{\n        &quot;from&quot;: &quot;Steve Jobs&quot;,\n        &quot;subject&quot;: &quot;I think I&apos;m holding my phone wrong :/&quot;,\n        &quot;sent&quot;: &quot;2013-10-01T08:05:59Z&quot;\n    },{\n        &quot;from&quot;: &quot;Ellie Goulding&quot;,\n        &quot;subject&quot;: &quot;I&apos;ve got Starry Eyes, lulz&quot;,\n        &quot;sent&quot;: &quot;2013-09-21T19:45:00Z&quot;\n    },{\n        &quot;from&quot;: &quot;Michael Stipe&quot;,\n        &quot;subject&quot;: &quot;Everybody hurts, sometimes.&quot;,\n        &quot;sent&quot;: &quot;2013-09-12T11:38:30Z&quot;\n    },{\n        &quot;from&quot;: &quot;Jeremy Clarkson&quot;,\n        &quot;subject&quot;: &quot;Think I&apos;ve found the best car... In the world&quot;,\n        &quot;sent&quot;: &quot;2013-09-03T13:15:11Z&quot;\n    }];\n}]);\n</code></pre><p>现在我们需要把它插入到我们的HTML中。这时我们会使用声明式绑定宣布什么应用程序将创建我们的第一个动态HTML。我们要用到Angular的内置指令ng-repeat，它会遍历数据，完全没有回调或状态变化的渲染输出，这都是非常灵活的：</p>\n<pre><code>&lt;ul&gt;\n  &lt;li ng-repeat=&quot;message in emails.messages&quot;&gt;\n    &lt;p&gt;From: {{ message.from }}&lt;/p&gt;\n    &lt;p&gt;Subject: {{ message.subject }}&lt;/p&gt;\n    &lt;p&gt;{{ message.sent | date:'MMM d, y h:mm:ss a' }}&lt;/p&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>示例：<a href=\"http://runjs.cn/code/q9beqc9s\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/q9beqc9s</a></p>\n<p>我使用了一个日期过滤器，从中你可以看到如何处理UTC日期。</p>\n<p>深入Angular的ng-*指令,你将完全释放出angular的声明式绑定的能力，这里展示了如何从服务器到模型，以及模拟和渲染数据。</p>\n<h2 id=\"9-Scope-functions-范围函数\"><a href=\"#9-Scope-functions-范围函数\" class=\"headerlink\" title=\"9.Scope functions(范围函数)\"></a>9.Scope functions(范围函数)</h2><p>作为声明性绑定的延续，范围函数是在创建应用程序时的下一个层次。这里展示了一个基本功能，删除我们的电子邮件中的一个数据：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n  $scope.deleteEmail = function (index) {\n    $scope.emails.messages.splice(index, 1)\n  };\n}]);\n</code></pre><p>友情提示：重要的一点是要考虑从模型中删除数据。不删除元素或任何实际的DOM相关，angular是一个MVC框架，将为您处理这一切与它的双向绑定和回调的自由世界，你只需要设置你的代码可以让它响应你的数据！</p>\n<pre><code>&lt;a ng-click=&quot;deleteEmail($index)&quot;&gt;Delete email&lt;/a&gt;\n</code></pre><p>这是一种不同的内联点击处理程序，因为许多原因。这将很快覆盖。你会看到我也在通过$index，angular知道你正在删除的项目（这样可以节省你多少代码和逻辑！）。</p>\n<p>示例：<a href=\"http://runjs.cn/code/jm84qnh3\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/jm84qnh3</a></p>\n<h2 id=\"10-Declarative-DOM-methods-陈述性DOM方法\"><a href=\"#10-Declarative-DOM-methods-陈述性DOM方法\" class=\"headerlink\" title=\"10.Declarative DOM methods(陈述性DOM方法)\"></a>10.Declarative DOM methods(陈述性DOM方法)</h2><p>现在我们要转移到的DOM方法，这些也都是些指令和模拟功能的DOM，你通常会写出更多的逻辑脚本。这个例子是一个简单的切换导航。用一个简单的ng-show和一个简单的ng-click设置，我们可以创建一个完美无瑕的切换导航：</p>\n<pre><code>&lt;a href=&quot;&quot; ng-click=&quot;toggle = !toggle&quot;&gt;Toggle nav&lt;/a&gt;\n&lt;ul ng-show=&quot;toggle&quot;&gt;\n  &lt;li&gt;Link 1&lt;/li&gt;\n  &lt;li&gt;Link 2&lt;/li&gt;\n  &lt;li&gt;Link 3&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre><p>我们开始进入MVVM的学习，你会发现脚本里没有controller的代码，我们会很快进入MVVM。</p>\n<p>示例：<a href=\"http://runjs.cn/code/r5tlnqrb\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/r5tlnqrb</a></p>\n<h2 id=\"11-Expressions-表达式\"><a href=\"#11-Expressions-表达式\" class=\"headerlink\" title=\"11.Expressions(表达式)\"></a>11.Expressions(表达式)</h2><p>我最喜欢Angular的一部分是，你会用JavaScript写出很多重复的代码。</p>\n<p>你尝试过这个吗？</p>\n<pre><code>elem.onclick = function (data) {\n  if (data.length === 0) {\n    otherElem.innerHTML = &apos;No data&apos;;\n  } else {\n    otherElem.innerHTML = &apos;My data&apos;;\n  }\n};\n</code></pre><p>这可能是一个GET请求回调，你会改变基于数据的DOM。Angular给你这个自由，你就可以做到无需编写任何内置的JavaScript！</p>\n<pre><code>&lt;p&gt;{{ data.length > 0 && 'My data' || 'No data' }}&lt;/p&gt;\n</code></pre><p>这会动态更新自己而没有回调应用程序获取数据。如果没有数据，它会告诉你，如果有数据，它会显示数据。针对Angular处理自动双向绑定数据，会有很多的使用情况。</p>\n<p>示例：<a href=\"http://runjs.cn/code/ahl0hfcc\" target=\"_blank\" rel=\"noopener\">http://runjs.cn/code/ahl0hfcc</a></p>\n<h2 id=\"12-Dynamic-views-and-routing-动态视图和路由\"><a href=\"#12-Dynamic-views-and-routing-动态视图和路由\" class=\"headerlink\" title=\"12.Dynamic views and routing(动态视图和路由)\"></a>12.Dynamic views and routing(动态视图和路由)</h2><p>单页面web应用(也包括网站)背后的理念是: 你有一个标题，页脚，侧边栏，和中间的内容,通过设置URL可以神奇地注入新的内容。</p>\n<p>Angular通过一个简单的设置来配置我们所说的动态视图。动态视图依靠URL注入每个视图，通过$routeprovider。一个简单的设置如下：</p>\n<pre><code>myApp.config([&apos;$routeProvider&apos;, function ($routeProvider) {\n  /**\n   * $routeProvider\n   */\n  $routeProvider\n  .when(&apos;/&apos;, {\n    templateUrl: &apos;views/main.html&apos;\n  })\n  .otherwise({\n    redirectTo: &apos;/&apos;\n  });\n}]);\n</code></pre><p>你会看到，当URL是”/“(即该站点的根目录),你会注入main.html。当你在一个单页面应用中已经有一个index.html页面，这是一个好的方法去调用内部的main.html视图而不是index.html。依靠URL去添加更多的视图是如此简单：</p>\n<pre><code>myApp.config([&apos;$routeProvider&apos;, function ($routeProvider) {\n  /**\n   * $routeProvider\n   */\n  $routeProvider\n  .when(&apos;/&apos;, {\n    templateUrl: &apos;views/main.html&apos;\n  })\n  .when(&apos;/emails&apos;, {\n    templateUrl: &apos;views/emails.html&apos;\n  })\n  .otherwise({\n    redirectTo: &apos;/&apos;\n  });\n}]);\n</code></pre><p>我们可以在emails.html上简单的加载HTML去生成我们的邮件列表,最终你可以毫不费力的创建一个复杂的应用程序。</p>\n<h2 id=\"13-Global-static-data-全局静态数据\"><a href=\"#13-Global-static-data-全局静态数据\" class=\"headerlink\" title=\"13.Global static data(全局静态数据)\"></a>13.Global static data(全局静态数据)</h2><p>Gmail处理很多内部初始化数据是通过将JSON加入到页面中(右键查看源代码)。如果你想立即在你的页面设置数据，它会加快渲染时间并且Angular将更快的执行。</p>\n<p>当我们开发应用程序时，页面渲染时，Java标签放置在DOM中，数据从后台发送过来。[我没有Java开发经验，你需要知道一个下面的声明，虽然在服务器上你可以使用任何语言。]这里是如何把JSON加入到网页中，然后把它传给一个控制器,为即时邦定使用：</p>\n<pre><code>&lt;!-- inside index.html (bottom of page ofc) --&gt;\n&lt;script&gt;\nwindow.globalData = {};\nglobalData.emails = &lt;javaTagHereToGenerateMessages&gt;;\n&lt;/script&gt;\n</code></pre><p>我定义的java标签使数据能在页面中渲染，Angular会轻松的渲染你的emails数据，只要把你的数据放入到controller中即可:</p>\n<pre><code>myApp.controller(&apos;EmailsCtrl&apos;, [&apos;$scope&apos;, function ($scope) {\n    $scope.emails = {};\n    // Assign the initial data!\n    $scope.emails.messages = globalData.emails;\n}]);\n</code></pre><h2 id=\"14-Minification-精简\"><a href=\"#14-Minification-精简\" class=\"headerlink\" title=\"14.Minification(精简)\"></a>14.Minification(精简)</h2><p>这一段是关于精简你的angular代码内容。在这方面你可能已经尝试过了，有时跑一个精简过的代码，会遇到了一个错误！</p>\n<p>精简你的AngularJS代码很简单，你需要指定你的依赖注入的内容在函数数组：</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;,\n[&apos;$scope&apos;, &apos;Dependency&apos;, &apos;Service&apos;, &apos;Factory&apos;,\nfunction ($scope, Dependency, Service, Factory) {\n  // code\n}]);\n</code></pre><p>精简后:</p>\n<pre><code>myApp.controller(&apos;MainCtrl&apos;,\n[&apos;$scope&apos;, &apos;Dependency&apos;, &apos;Service&apos;, &apos;Factory&apos;,\nfunction (a,b,c,d) {\n  // a = $scope\n  // b = Dependency\n  // c = Service\n  // d = Factory\n  // $scope alias usage\n  a.someFunction = function () {...};\n}]);\n</code></pre><p>请记住，以保持参数的顺序出现，否则你可能会导致你和你的团队费劲。</p>\n<h2 id=\"15-Differences-in-MVC-and-MVVM-MVC和MVVM的差异\"><a href=\"#15-Differences-in-MVC-and-MVVM-MVC和MVVM的差异\" class=\"headerlink\" title=\"15.Differences in MVC and MVVM(MVC和MVVM的差异)\"></a>15.Differences in MVC and MVVM(MVC和MVVM的差异)</h2><p>这里简要介绍两者的区别:</p>\n<p><strong>MVC</strong>: 用一个controller交互,关系是Model-View-Controller<br><strong>MVVM</strong>: 封装声明数据邦定,Model-View-View-Model,Model和View交互,View也可以和Model交互,Angular的双向数据绑定允许它在不做任何事情时保持同步。它还允许你在没有控制器的情况下,编写逻辑代码！</p>\n<p>一个简单的例子，你可以创建一个ng-repeat标签去提供数据,而不需要Controller:</p>\n<pre><code>&lt;li ng-repeat=&quot;number in [1,2,3,4,5,6,7,8,9]&quot;&gt;\n  {{ number }}\n&lt;/li&gt;\n</code></pre><p>对于快速测试这是很有帮助的，但对与复杂的情况时，我建议使用一个Controller。</p>\n<h2 id=\"16-HTML5-Web-Components-HTML5组件\"><a href=\"#16-HTML5-Web-Components-HTML5组件\" class=\"headerlink\" title=\"16.HTML5 Web Components(HTML5组件)\"></a>16.HTML5 Web Components(HTML5组件)</h2><p>在早些时候你会发现AngularJS允许你创建自定义的元素:</p>\n<pre><code>&lt;myCustomElement&gt;&lt;/myCustomElement&gt;\n</code></pre><p>这实际上是符合HTML5未来的特性。HTML5 Web部件和模板元素，Angular让我们今天就能这样用。Web部件包括通过动态JavaScript注入生成的自定义元素！</p>\n<h2 id=\"17-Scope-comments-范围注释\"><a href=\"#17-Scope-comments-范围注释\" class=\"headerlink\" title=\"17.Scope comments(范围注释)\"></a>17.Scope comments(范围注释)</h2><p>范围注释,我觉得真的是一个不错特性,代替了HTML注释，像这样的块：</p>\n<pre><code>&lt;!-- header --&gt;\n&lt;header&gt;\n  Stuff.\n&lt;/header&gt;\n&lt;!-- /header --&gt;\n</code></pre><p>引入Angular后，让我们思考的是Views和Scopes，而不是DOM，除非你故意共享控制器间的数据，我发现使用范围是一个很大的帮助：</p>\n<pre><code>&lt;!-- scope: MainCtrl --&gt;\n&lt;div class=&quot;content&quot; ng-controller=&quot;MainCtrl&quot;&gt;\n&lt;/div&gt;\n&lt;!-- /scope: MainCtrl --&gt;\n</code></pre><h2 id=\"18-Debugging-AngularJS-调试\"><a href=\"#18-Debugging-AngularJS-调试\" class=\"headerlink\" title=\"18.Debugging AngularJS(调试)\"></a>18.Debugging AngularJS(调试)</h2><p>对于调试AngularJS的话，可以使用Chrome的一个扩展工具-Batarang,你可以去下载下看看。</p>\n<h2 id=\"结束\"><a href=\"#结束\" class=\"headerlink\" title=\"结束\"></a>结束</h2><p>到此本文结束,希望能够对大家学习angular有一个好的指导，更多关于angular的细节可以参看<a href=\"http://toddmotto.com/\" target=\"_blank\" rel=\"noopener\">Todd Motto</a> 的系列文章<br>再次感谢原作者的整理，文中如有不对的地方可以指出。</p>"},{"layout":"lay_post","title":"四个例子入门NodeJS","date":"2015-08-31T08:50:12.000Z","author":"lvyafei","published":1,"summary":["/images/nodejs.jpg"],"_content":"\n* 目录\n{:toc #meuid}\n\n## 0.前言\n\n### NodeJS是什么?\n\nJavaScript是一种运行在浏览器的脚本，它简单，轻巧，易于编辑，这种脚本通常用于浏览器的前端编程，但是一位开发者Ryan有一天发现这种前端式的脚本语言可以运行在服务器上的时候，一场席卷全球的风暴就开始了。\n\nNode.js是一个基于Chrome JavaScript运行时建立的平台， 用于方便地搭建响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型而得以轻量和高效，非常适合在分布式设备上运行的数据密集型的实时应用。\n<!-- more -->\n\n![](/images/nodejs.jpg)\n\nNode是一个Javascript运行环境(runtime)。实际上它是对Google V8引擎进行了封装。V8引 擎执行Javascript的速度非常快，性能非常好。Node对一些特殊用例进行了优化，提供了替代的API，使得V8在非浏览器环境下运行得更好。\n\n### 我们该如何入门学习？\n\n对于一个新的技术来说，入门学习很重要，如果有一个好的入门学习资料，将会对以后深入学习该技术产生很大的帮助，本文就是以这中思想来解说的，希望能够对学习NodeJS的人来说有一个好的开始，也欢迎大家对本文指出不足。\n\n[本文源码](https://github.com/lvyafei/NodeJS.git)\n\n关于如何安装NodeJS,对于Linux上用户直接到官网下载编译过的安装包，然后加入到环境变量中即可\n\n\tln -s /home/software/node-v0.12.7-linux-x64/bin/node /usr/local/bin/node\n\tln -s /home/software/node-v0.12.7-linux-x64/bin/npm /usr/local/bin/npm\n\n输入node回车即可进入node命令。\n\n## 1.了解结构\n\n**入口**：\n\n\tvar server=require(\"./server\");\n\tserver.start();\n\t\nNodeJS入口是指node命令后面要执行的文件，例如\"node helloworld.js\"即可之执行编写的代码，其中require是之加载模块，这里加载了本地的一个模块，也可加载内置的模块,比如require(\"http\"),是指加载node中自带的http模块，这点和函数式编程有点像。后面就可以调用具体的function了，这点就是Javascript里面的东西了，很简单吧。\n\n**server**:\n\n\tfunction start(){\n\t  function onRequest(request,response){\n\t\t router.route(pathname,request,response,null);\n\t   }\n\t  http.createServer(onRequest).listen(8888);\n\t}\n\texports.start=start;\n\nserver.js中的内容就是服务请求的入口了，包含请求的处理，路由的处理。最好是把处理放在一个单独的文件中这样管理起来也很方便。exports就是把该方法暴露出去，可以让外边的程序调用。最后在一个端口上监听就可以了.\n\n**route**:\n\n\tfunction route(pathname,request,response,data){\n\t  handler.menu(request,response,data);\n\t}\n\texports.route=route;\n\n对于路由后的内容要有一个处理的文件，就是requestHandlers,这个文件中是对每个路由到的地址进行具体的请求。\n\n**handler**:\n\n\tfunction menu(request,response,postdata){}\n\tfunction start(request,response,postdata){}\n\tfunction textpost(request,response,postdata){}\n\tfunction filepost(request,response,postdata){}\n\t\n\texports.menu=menu;\n\texports.start=start;\n\texports.textpost=textpost;\n\texports.filepost=filepost;\n\t\n每个对应一个请求，这是一种最简单的处理方式。\n\n了解以上的内容后，就可以写一个简单的有结构的程序了，下面的示例是在以上的基础上演示了几种常见的情景:非阻塞请求，post数据，查看图片,上传图片。\n\n## 2.示例一：阻塞演示\n\n对于处理一个比较费时的操作，如果要在当前线程中处理的话会阻塞，一旦产生阻塞就会影响其它请求的执行，一种处理阻塞的方法时利用回调，将好事耗时的任务利用child_process的操作来执行，也可以将response的方法在数据处理完后发送给客户端。\n\n在requestHandlers.js中start的方法演示了如何处理阻塞请求:\n\n\tfunction start(request,response,postdata){\n\t  console.log(\"request handler 'start' was called.\");\n\t  exec(\"find /\",{timeout:10000,maxBuffer:20000*1024},function(error,stdout,stderr){\n\t\tresponse.writeHead(200,{\"Content-Type\":\"text/plain\"});\n\t\tresponse.write(stdout);\n\t\tresponse.end();\n\t\t});\n\t}\n\n## 3.示例二:post请求\n\n对于一个请求，如果不带参数的化可以直接路由即可，但对于post方法中带的数据的情况，node 中有专门的方法处理，由于该过程也回产生阻塞，为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。\n\n我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。\n\n在server.js中onRequest的方法演示了如何该情况:\n\n\trequest.setEncoding(\"utf-8\");\n\trequest.addListener(\"data\",function(postDataChunk){\n\t  postData+=postDataChunk;\n\t  console.log(\"Received POST data:\"+postDataChunk+\".\");\n\t});\n\trequest.addListener(\"end\",function(){\n\t  router.route(pathname,request,response,postData);\n\t});\n\t\nrequestHandlers.js中upload方法就可以拿到数据，然后写回客户端:\n\n\tresponse.writeHead(200,{\"Content-Type\":\"text/plain\"});\n\tresponse.write(\"You've sent : \"+querystring.parse(postdata).text);\n\tresponse.end();\n\n## 4.示例三:查看图片\n\n对于查看服务器上的资源，可以用file system模块，调用方式如：require(\"fs\").\nrequestHandlers.js中show方法就是读取一个图片的示例:\n\n\tfs.readFile(\"/root/图片/new.png\",\"binary\",function(error,file){\n\t\tif(error){\n\t\t\tresponse.writeHead(500,{\"Content-Type\":\"text/plain\"});\n\t\t\tresponse.write(error+\"\\n\");\n\t\t\tresponse.end();\n\t\t}else{\n\t\t\tresponse.writeHead(200,{\"Content-Type\":\"image/png\"});\n\t\t\tresponse.write(file,\"binary\");\n\t\t\tresponse.end();\n\t\t}\n\t});\n\n在示例中不仅此处用了该方法，加载具体的html文件也用到该模块。\n\n## 5.示例四:图片上传\n\n文件上传也是一个比较常见的情形，单要用到一个模块formidable，该模块需要自己安装，node默认没有自带.\n\n安装方法: \n\t\n\tnpm install formidable\n\t\nrequestHandlers.js中uploadfile方法就是处理上传上来的文件的示例:\n\n\tvar form=new formidable.IncomingForm();\n\t\tform.parse(request,function(error,fields,files){\n\t\t\tfs.renameSync(files.upload.path,\"/root/图片/new.png\");\n\t\t\tresponse.writeHead(200,{\"Content-Type\":\"text/html\"});\n\t\t\tresponse.write(\"received image:<br/>\");\n\t\t\tresponse.write(\"<img src='/show' />\");\n\t\t\tresponse.end();\n\t});\n\n注意的是：这里不再调用addListener方法，而是要自己处理上传的资源。\n单独的处理，避免和其它处理方式混淆:\n\n\tif(pathname==\"/uploadfile\"){\n\t\trouter.route(pathname,request,response,null);\n\t}else{\n\t    //.....\n\t}\n\n## 6.总结\n\n通过这几个示例可以更加深入的了解到node的开发方式，希望能对刚入门的人有一个指导性的作用。\n","source":"_posts/2015-08-31-四个例子入门NodeJS.md","raw":"---\nlayout: lay_post\ntitle: 四个例子入门NodeJS\ndate: 2015-08-31 16:50:12\ncategories: 前端\ntags: NodeJS\nauthor: lvyafei\npublished: true\nsummary: [\"/images/nodejs.jpg\"]\n---\n\n* 目录\n{:toc #meuid}\n\n## 0.前言\n\n### NodeJS是什么?\n\nJavaScript是一种运行在浏览器的脚本，它简单，轻巧，易于编辑，这种脚本通常用于浏览器的前端编程，但是一位开发者Ryan有一天发现这种前端式的脚本语言可以运行在服务器上的时候，一场席卷全球的风暴就开始了。\n\nNode.js是一个基于Chrome JavaScript运行时建立的平台， 用于方便地搭建响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型而得以轻量和高效，非常适合在分布式设备上运行的数据密集型的实时应用。\n<!-- more -->\n\n![](/images/nodejs.jpg)\n\nNode是一个Javascript运行环境(runtime)。实际上它是对Google V8引擎进行了封装。V8引 擎执行Javascript的速度非常快，性能非常好。Node对一些特殊用例进行了优化，提供了替代的API，使得V8在非浏览器环境下运行得更好。\n\n### 我们该如何入门学习？\n\n对于一个新的技术来说，入门学习很重要，如果有一个好的入门学习资料，将会对以后深入学习该技术产生很大的帮助，本文就是以这中思想来解说的，希望能够对学习NodeJS的人来说有一个好的开始，也欢迎大家对本文指出不足。\n\n[本文源码](https://github.com/lvyafei/NodeJS.git)\n\n关于如何安装NodeJS,对于Linux上用户直接到官网下载编译过的安装包，然后加入到环境变量中即可\n\n\tln -s /home/software/node-v0.12.7-linux-x64/bin/node /usr/local/bin/node\n\tln -s /home/software/node-v0.12.7-linux-x64/bin/npm /usr/local/bin/npm\n\n输入node回车即可进入node命令。\n\n## 1.了解结构\n\n**入口**：\n\n\tvar server=require(\"./server\");\n\tserver.start();\n\t\nNodeJS入口是指node命令后面要执行的文件，例如\"node helloworld.js\"即可之执行编写的代码，其中require是之加载模块，这里加载了本地的一个模块，也可加载内置的模块,比如require(\"http\"),是指加载node中自带的http模块，这点和函数式编程有点像。后面就可以调用具体的function了，这点就是Javascript里面的东西了，很简单吧。\n\n**server**:\n\n\tfunction start(){\n\t  function onRequest(request,response){\n\t\t router.route(pathname,request,response,null);\n\t   }\n\t  http.createServer(onRequest).listen(8888);\n\t}\n\texports.start=start;\n\nserver.js中的内容就是服务请求的入口了，包含请求的处理，路由的处理。最好是把处理放在一个单独的文件中这样管理起来也很方便。exports就是把该方法暴露出去，可以让外边的程序调用。最后在一个端口上监听就可以了.\n\n**route**:\n\n\tfunction route(pathname,request,response,data){\n\t  handler.menu(request,response,data);\n\t}\n\texports.route=route;\n\n对于路由后的内容要有一个处理的文件，就是requestHandlers,这个文件中是对每个路由到的地址进行具体的请求。\n\n**handler**:\n\n\tfunction menu(request,response,postdata){}\n\tfunction start(request,response,postdata){}\n\tfunction textpost(request,response,postdata){}\n\tfunction filepost(request,response,postdata){}\n\t\n\texports.menu=menu;\n\texports.start=start;\n\texports.textpost=textpost;\n\texports.filepost=filepost;\n\t\n每个对应一个请求，这是一种最简单的处理方式。\n\n了解以上的内容后，就可以写一个简单的有结构的程序了，下面的示例是在以上的基础上演示了几种常见的情景:非阻塞请求，post数据，查看图片,上传图片。\n\n## 2.示例一：阻塞演示\n\n对于处理一个比较费时的操作，如果要在当前线程中处理的话会阻塞，一旦产生阻塞就会影响其它请求的执行，一种处理阻塞的方法时利用回调，将好事耗时的任务利用child_process的操作来执行，也可以将response的方法在数据处理完后发送给客户端。\n\n在requestHandlers.js中start的方法演示了如何处理阻塞请求:\n\n\tfunction start(request,response,postdata){\n\t  console.log(\"request handler 'start' was called.\");\n\t  exec(\"find /\",{timeout:10000,maxBuffer:20000*1024},function(error,stdout,stderr){\n\t\tresponse.writeHead(200,{\"Content-Type\":\"text/plain\"});\n\t\tresponse.write(stdout);\n\t\tresponse.end();\n\t\t});\n\t}\n\n## 3.示例二:post请求\n\n对于一个请求，如果不带参数的化可以直接路由即可，但对于post方法中带的数据的情况，node 中有专门的方法处理，由于该过程也回产生阻塞，为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。\n\n我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。\n\n在server.js中onRequest的方法演示了如何该情况:\n\n\trequest.setEncoding(\"utf-8\");\n\trequest.addListener(\"data\",function(postDataChunk){\n\t  postData+=postDataChunk;\n\t  console.log(\"Received POST data:\"+postDataChunk+\".\");\n\t});\n\trequest.addListener(\"end\",function(){\n\t  router.route(pathname,request,response,postData);\n\t});\n\t\nrequestHandlers.js中upload方法就可以拿到数据，然后写回客户端:\n\n\tresponse.writeHead(200,{\"Content-Type\":\"text/plain\"});\n\tresponse.write(\"You've sent : \"+querystring.parse(postdata).text);\n\tresponse.end();\n\n## 4.示例三:查看图片\n\n对于查看服务器上的资源，可以用file system模块，调用方式如：require(\"fs\").\nrequestHandlers.js中show方法就是读取一个图片的示例:\n\n\tfs.readFile(\"/root/图片/new.png\",\"binary\",function(error,file){\n\t\tif(error){\n\t\t\tresponse.writeHead(500,{\"Content-Type\":\"text/plain\"});\n\t\t\tresponse.write(error+\"\\n\");\n\t\t\tresponse.end();\n\t\t}else{\n\t\t\tresponse.writeHead(200,{\"Content-Type\":\"image/png\"});\n\t\t\tresponse.write(file,\"binary\");\n\t\t\tresponse.end();\n\t\t}\n\t});\n\n在示例中不仅此处用了该方法，加载具体的html文件也用到该模块。\n\n## 5.示例四:图片上传\n\n文件上传也是一个比较常见的情形，单要用到一个模块formidable，该模块需要自己安装，node默认没有自带.\n\n安装方法: \n\t\n\tnpm install formidable\n\t\nrequestHandlers.js中uploadfile方法就是处理上传上来的文件的示例:\n\n\tvar form=new formidable.IncomingForm();\n\t\tform.parse(request,function(error,fields,files){\n\t\t\tfs.renameSync(files.upload.path,\"/root/图片/new.png\");\n\t\t\tresponse.writeHead(200,{\"Content-Type\":\"text/html\"});\n\t\t\tresponse.write(\"received image:<br/>\");\n\t\t\tresponse.write(\"<img src='/show' />\");\n\t\t\tresponse.end();\n\t});\n\n注意的是：这里不再调用addListener方法，而是要自己处理上传的资源。\n单独的处理，避免和其它处理方式混淆:\n\n\tif(pathname==\"/uploadfile\"){\n\t\trouter.route(pathname,request,response,null);\n\t}else{\n\t    //.....\n\t}\n\n## 6.总结\n\n通过这几个示例可以更加深入的了解到node的开发方式，希望能对刚入门的人有一个指导性的作用。\n","slug":"2015-08-31-四个例子入门NodeJS","updated":"2018-11-29T12:51:24.554Z","comments":1,"photos":[],"link":"","_id":"cjskffnvk00014glm8ftkgsqo","content":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-前言\"><a href=\"#0-前言\" class=\"headerlink\" title=\"0.前言\"></a>0.前言</h2><h3 id=\"NodeJS是什么\"><a href=\"#NodeJS是什么\" class=\"headerlink\" title=\"NodeJS是什么?\"></a>NodeJS是什么?</h3><p>JavaScript是一种运行在浏览器的脚本，它简单，轻巧，易于编辑，这种脚本通常用于浏览器的前端编程，但是一位开发者Ryan有一天发现这种前端式的脚本语言可以运行在服务器上的时候，一场席卷全球的风暴就开始了。</p>\n<p>Node.js是一个基于Chrome JavaScript运行时建立的平台， 用于方便地搭建响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型而得以轻量和高效，非常适合在分布式设备上运行的数据密集型的实时应用。<br><a id=\"more\"></a></p>\n<p><img src=\"/images/nodejs.jpg\" alt=\"\"></p>\n<p>Node是一个Javascript运行环境(runtime)。实际上它是对Google V8引擎进行了封装。V8引 擎执行Javascript的速度非常快，性能非常好。Node对一些特殊用例进行了优化，提供了替代的API，使得V8在非浏览器环境下运行得更好。</p>\n<h3 id=\"我们该如何入门学习？\"><a href=\"#我们该如何入门学习？\" class=\"headerlink\" title=\"我们该如何入门学习？\"></a>我们该如何入门学习？</h3><p>对于一个新的技术来说，入门学习很重要，如果有一个好的入门学习资料，将会对以后深入学习该技术产生很大的帮助，本文就是以这中思想来解说的，希望能够对学习NodeJS的人来说有一个好的开始，也欢迎大家对本文指出不足。</p>\n<p><a href=\"https://github.com/lvyafei/NodeJS.git\" target=\"_blank\" rel=\"noopener\">本文源码</a></p>\n<p>关于如何安装NodeJS,对于Linux上用户直接到官网下载编译过的安装包，然后加入到环境变量中即可</p>\n<pre><code>ln -s /home/software/node-v0.12.7-linux-x64/bin/node /usr/local/bin/node\nln -s /home/software/node-v0.12.7-linux-x64/bin/npm /usr/local/bin/npm\n</code></pre><p>输入node回车即可进入node命令。</p>\n<h2 id=\"1-了解结构\"><a href=\"#1-了解结构\" class=\"headerlink\" title=\"1.了解结构\"></a>1.了解结构</h2><p><strong>入口</strong>：</p>\n<pre><code>var server=require(&quot;./server&quot;);\nserver.start();\n</code></pre><p>NodeJS入口是指node命令后面要执行的文件，例如”node helloworld.js”即可之执行编写的代码，其中require是之加载模块，这里加载了本地的一个模块，也可加载内置的模块,比如require(“http”),是指加载node中自带的http模块，这点和函数式编程有点像。后面就可以调用具体的function了，这点就是Javascript里面的东西了，很简单吧。</p>\n<p><strong>server</strong>:</p>\n<pre><code>function start(){\n  function onRequest(request,response){\n     router.route(pathname,request,response,null);\n   }\n  http.createServer(onRequest).listen(8888);\n}\nexports.start=start;\n</code></pre><p>server.js中的内容就是服务请求的入口了，包含请求的处理，路由的处理。最好是把处理放在一个单独的文件中这样管理起来也很方便。exports就是把该方法暴露出去，可以让外边的程序调用。最后在一个端口上监听就可以了.</p>\n<p><strong>route</strong>:</p>\n<pre><code>function route(pathname,request,response,data){\n  handler.menu(request,response,data);\n}\nexports.route=route;\n</code></pre><p>对于路由后的内容要有一个处理的文件，就是requestHandlers,这个文件中是对每个路由到的地址进行具体的请求。</p>\n<p><strong>handler</strong>:</p>\n<pre><code>function menu(request,response,postdata){}\nfunction start(request,response,postdata){}\nfunction textpost(request,response,postdata){}\nfunction filepost(request,response,postdata){}\n\nexports.menu=menu;\nexports.start=start;\nexports.textpost=textpost;\nexports.filepost=filepost;\n</code></pre><p>每个对应一个请求，这是一种最简单的处理方式。</p>\n<p>了解以上的内容后，就可以写一个简单的有结构的程序了，下面的示例是在以上的基础上演示了几种常见的情景:非阻塞请求，post数据，查看图片,上传图片。</p>\n<h2 id=\"2-示例一：阻塞演示\"><a href=\"#2-示例一：阻塞演示\" class=\"headerlink\" title=\"2.示例一：阻塞演示\"></a>2.示例一：阻塞演示</h2><p>对于处理一个比较费时的操作，如果要在当前线程中处理的话会阻塞，一旦产生阻塞就会影响其它请求的执行，一种处理阻塞的方法时利用回调，将好事耗时的任务利用child_process的操作来执行，也可以将response的方法在数据处理完后发送给客户端。</p>\n<p>在requestHandlers.js中start的方法演示了如何处理阻塞请求:</p>\n<pre><code>function start(request,response,postdata){\n  console.log(&quot;request handler &apos;start&apos; was called.&quot;);\n  exec(&quot;find /&quot;,{timeout:10000,maxBuffer:20000*1024},function(error,stdout,stderr){\n    response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\n    response.write(stdout);\n    response.end();\n    });\n}\n</code></pre><h2 id=\"3-示例二-post请求\"><a href=\"#3-示例二-post请求\" class=\"headerlink\" title=\"3.示例二:post请求\"></a>3.示例二:post请求</h2><p>对于一个请求，如果不带参数的化可以直接路由即可，但对于post方法中带的数据的情况，node 中有专门的方法处理，由于该过程也回产生阻塞，为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。</p>\n<p>我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。</p>\n<p>在server.js中onRequest的方法演示了如何该情况:</p>\n<pre><code>request.setEncoding(&quot;utf-8&quot;);\nrequest.addListener(&quot;data&quot;,function(postDataChunk){\n  postData+=postDataChunk;\n  console.log(&quot;Received POST data:&quot;+postDataChunk+&quot;.&quot;);\n});\nrequest.addListener(&quot;end&quot;,function(){\n  router.route(pathname,request,response,postData);\n});\n</code></pre><p>requestHandlers.js中upload方法就可以拿到数据，然后写回客户端:</p>\n<pre><code>response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\nresponse.write(&quot;You&apos;ve sent : &quot;+querystring.parse(postdata).text);\nresponse.end();\n</code></pre><h2 id=\"4-示例三-查看图片\"><a href=\"#4-示例三-查看图片\" class=\"headerlink\" title=\"4.示例三:查看图片\"></a>4.示例三:查看图片</h2><p>对于查看服务器上的资源，可以用file system模块，调用方式如：require(“fs”).<br>requestHandlers.js中show方法就是读取一个图片的示例:</p>\n<pre><code>fs.readFile(&quot;/root/图片/new.png&quot;,&quot;binary&quot;,function(error,file){\n    if(error){\n        response.writeHead(500,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\n        response.write(error+&quot;\\n&quot;);\n        response.end();\n    }else{\n        response.writeHead(200,{&quot;Content-Type&quot;:&quot;image/png&quot;});\n        response.write(file,&quot;binary&quot;);\n        response.end();\n    }\n});\n</code></pre><p>在示例中不仅此处用了该方法，加载具体的html文件也用到该模块。</p>\n<h2 id=\"5-示例四-图片上传\"><a href=\"#5-示例四-图片上传\" class=\"headerlink\" title=\"5.示例四:图片上传\"></a>5.示例四:图片上传</h2><p>文件上传也是一个比较常见的情形，单要用到一个模块formidable，该模块需要自己安装，node默认没有自带.</p>\n<p>安装方法: </p>\n<pre><code>npm install formidable\n</code></pre><p>requestHandlers.js中uploadfile方法就是处理上传上来的文件的示例:</p>\n<pre><code>var form=new formidable.IncomingForm();\n    form.parse(request,function(error,fields,files){\n        fs.renameSync(files.upload.path,&quot;/root/图片/new.png&quot;);\n        response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/html&quot;});\n        response.write(&quot;received image:&lt;br/&gt;&quot;);\n        response.write(&quot;&lt;img src=&apos;/show&apos; /&gt;&quot;);\n        response.end();\n});\n</code></pre><p>注意的是：这里不再调用addListener方法，而是要自己处理上传的资源。<br>单独的处理，避免和其它处理方式混淆:</p>\n<pre><code>if(pathname==&quot;/uploadfile&quot;){\n    router.route(pathname,request,response,null);\n}else{\n    //.....\n}\n</code></pre><h2 id=\"6-总结\"><a href=\"#6-总结\" class=\"headerlink\" title=\"6.总结\"></a>6.总结</h2><p>通过这几个示例可以更加深入的了解到node的开发方式，希望能对刚入门的人有一个指导性的作用。</p>\n","site":{"data":{}},"excerpt":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-前言\"><a href=\"#0-前言\" class=\"headerlink\" title=\"0.前言\"></a>0.前言</h2><h3 id=\"NodeJS是什么\"><a href=\"#NodeJS是什么\" class=\"headerlink\" title=\"NodeJS是什么?\"></a>NodeJS是什么?</h3><p>JavaScript是一种运行在浏览器的脚本，它简单，轻巧，易于编辑，这种脚本通常用于浏览器的前端编程，但是一位开发者Ryan有一天发现这种前端式的脚本语言可以运行在服务器上的时候，一场席卷全球的风暴就开始了。</p>\n<p>Node.js是一个基于Chrome JavaScript运行时建立的平台， 用于方便地搭建响应速度快、易于扩展的网络应用。Node.js 使用事件驱动， 非阻塞I/O 模型而得以轻量和高效，非常适合在分布式设备上运行的数据密集型的实时应用。<br>","more":"</p>\n<p><img src=\"/images/nodejs.jpg\" alt=\"\"></p>\n<p>Node是一个Javascript运行环境(runtime)。实际上它是对Google V8引擎进行了封装。V8引 擎执行Javascript的速度非常快，性能非常好。Node对一些特殊用例进行了优化，提供了替代的API，使得V8在非浏览器环境下运行得更好。</p>\n<h3 id=\"我们该如何入门学习？\"><a href=\"#我们该如何入门学习？\" class=\"headerlink\" title=\"我们该如何入门学习？\"></a>我们该如何入门学习？</h3><p>对于一个新的技术来说，入门学习很重要，如果有一个好的入门学习资料，将会对以后深入学习该技术产生很大的帮助，本文就是以这中思想来解说的，希望能够对学习NodeJS的人来说有一个好的开始，也欢迎大家对本文指出不足。</p>\n<p><a href=\"https://github.com/lvyafei/NodeJS.git\" target=\"_blank\" rel=\"noopener\">本文源码</a></p>\n<p>关于如何安装NodeJS,对于Linux上用户直接到官网下载编译过的安装包，然后加入到环境变量中即可</p>\n<pre><code>ln -s /home/software/node-v0.12.7-linux-x64/bin/node /usr/local/bin/node\nln -s /home/software/node-v0.12.7-linux-x64/bin/npm /usr/local/bin/npm\n</code></pre><p>输入node回车即可进入node命令。</p>\n<h2 id=\"1-了解结构\"><a href=\"#1-了解结构\" class=\"headerlink\" title=\"1.了解结构\"></a>1.了解结构</h2><p><strong>入口</strong>：</p>\n<pre><code>var server=require(&quot;./server&quot;);\nserver.start();\n</code></pre><p>NodeJS入口是指node命令后面要执行的文件，例如”node helloworld.js”即可之执行编写的代码，其中require是之加载模块，这里加载了本地的一个模块，也可加载内置的模块,比如require(“http”),是指加载node中自带的http模块，这点和函数式编程有点像。后面就可以调用具体的function了，这点就是Javascript里面的东西了，很简单吧。</p>\n<p><strong>server</strong>:</p>\n<pre><code>function start(){\n  function onRequest(request,response){\n     router.route(pathname,request,response,null);\n   }\n  http.createServer(onRequest).listen(8888);\n}\nexports.start=start;\n</code></pre><p>server.js中的内容就是服务请求的入口了，包含请求的处理，路由的处理。最好是把处理放在一个单独的文件中这样管理起来也很方便。exports就是把该方法暴露出去，可以让外边的程序调用。最后在一个端口上监听就可以了.</p>\n<p><strong>route</strong>:</p>\n<pre><code>function route(pathname,request,response,data){\n  handler.menu(request,response,data);\n}\nexports.route=route;\n</code></pre><p>对于路由后的内容要有一个处理的文件，就是requestHandlers,这个文件中是对每个路由到的地址进行具体的请求。</p>\n<p><strong>handler</strong>:</p>\n<pre><code>function menu(request,response,postdata){}\nfunction start(request,response,postdata){}\nfunction textpost(request,response,postdata){}\nfunction filepost(request,response,postdata){}\n\nexports.menu=menu;\nexports.start=start;\nexports.textpost=textpost;\nexports.filepost=filepost;\n</code></pre><p>每个对应一个请求，这是一种最简单的处理方式。</p>\n<p>了解以上的内容后，就可以写一个简单的有结构的程序了，下面的示例是在以上的基础上演示了几种常见的情景:非阻塞请求，post数据，查看图片,上传图片。</p>\n<h2 id=\"2-示例一：阻塞演示\"><a href=\"#2-示例一：阻塞演示\" class=\"headerlink\" title=\"2.示例一：阻塞演示\"></a>2.示例一：阻塞演示</h2><p>对于处理一个比较费时的操作，如果要在当前线程中处理的话会阻塞，一旦产生阻塞就会影响其它请求的执行，一种处理阻塞的方法时利用回调，将好事耗时的任务利用child_process的操作来执行，也可以将response的方法在数据处理完后发送给客户端。</p>\n<p>在requestHandlers.js中start的方法演示了如何处理阻塞请求:</p>\n<pre><code>function start(request,response,postdata){\n  console.log(&quot;request handler &apos;start&apos; was called.&quot;);\n  exec(&quot;find /&quot;,{timeout:10000,maxBuffer:20000*1024},function(error,stdout,stderr){\n    response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\n    response.write(stdout);\n    response.end();\n    });\n}\n</code></pre><h2 id=\"3-示例二-post请求\"><a href=\"#3-示例二-post请求\" class=\"headerlink\" title=\"3.示例二:post请求\"></a>3.示例二:post请求</h2><p>对于一个请求，如果不带参数的化可以直接路由即可，但对于post方法中带的数据的情况，node 中有专门的方法处理，由于该过程也回产生阻塞，为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。</p>\n<p>我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。</p>\n<p>在server.js中onRequest的方法演示了如何该情况:</p>\n<pre><code>request.setEncoding(&quot;utf-8&quot;);\nrequest.addListener(&quot;data&quot;,function(postDataChunk){\n  postData+=postDataChunk;\n  console.log(&quot;Received POST data:&quot;+postDataChunk+&quot;.&quot;);\n});\nrequest.addListener(&quot;end&quot;,function(){\n  router.route(pathname,request,response,postData);\n});\n</code></pre><p>requestHandlers.js中upload方法就可以拿到数据，然后写回客户端:</p>\n<pre><code>response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\nresponse.write(&quot;You&apos;ve sent : &quot;+querystring.parse(postdata).text);\nresponse.end();\n</code></pre><h2 id=\"4-示例三-查看图片\"><a href=\"#4-示例三-查看图片\" class=\"headerlink\" title=\"4.示例三:查看图片\"></a>4.示例三:查看图片</h2><p>对于查看服务器上的资源，可以用file system模块，调用方式如：require(“fs”).<br>requestHandlers.js中show方法就是读取一个图片的示例:</p>\n<pre><code>fs.readFile(&quot;/root/图片/new.png&quot;,&quot;binary&quot;,function(error,file){\n    if(error){\n        response.writeHead(500,{&quot;Content-Type&quot;:&quot;text/plain&quot;});\n        response.write(error+&quot;\\n&quot;);\n        response.end();\n    }else{\n        response.writeHead(200,{&quot;Content-Type&quot;:&quot;image/png&quot;});\n        response.write(file,&quot;binary&quot;);\n        response.end();\n    }\n});\n</code></pre><p>在示例中不仅此处用了该方法，加载具体的html文件也用到该模块。</p>\n<h2 id=\"5-示例四-图片上传\"><a href=\"#5-示例四-图片上传\" class=\"headerlink\" title=\"5.示例四:图片上传\"></a>5.示例四:图片上传</h2><p>文件上传也是一个比较常见的情形，单要用到一个模块formidable，该模块需要自己安装，node默认没有自带.</p>\n<p>安装方法: </p>\n<pre><code>npm install formidable\n</code></pre><p>requestHandlers.js中uploadfile方法就是处理上传上来的文件的示例:</p>\n<pre><code>var form=new formidable.IncomingForm();\n    form.parse(request,function(error,fields,files){\n        fs.renameSync(files.upload.path,&quot;/root/图片/new.png&quot;);\n        response.writeHead(200,{&quot;Content-Type&quot;:&quot;text/html&quot;});\n        response.write(&quot;received image:&lt;br/&gt;&quot;);\n        response.write(&quot;&lt;img src=&apos;/show&apos; /&gt;&quot;);\n        response.end();\n});\n</code></pre><p>注意的是：这里不再调用addListener方法，而是要自己处理上传的资源。<br>单独的处理，避免和其它处理方式混淆:</p>\n<pre><code>if(pathname==&quot;/uploadfile&quot;){\n    router.route(pathname,request,response,null);\n}else{\n    //.....\n}\n</code></pre><h2 id=\"6-总结\"><a href=\"#6-总结\" class=\"headerlink\" title=\"6.总结\"></a>6.总结</h2><p>通过这几个示例可以更加深入的了解到node的开发方式，希望能对刚入门的人有一个指导性的作用。</p>"},{"layout":"lay_post","title":"基于NodeJS的开发框架和优秀项目","date":"2015-09-25T07:00:00.000Z","author":"lvyafei","published":1,"summary":["/images/express.png","/images/hexo.png","/images/ghost.png"],"_content":"\n* 目录\n{:toc #meuid}\n\n## 0.如何进阶NodeJS?\n\n通过前面\"四个例子入门NodeJS\"后，我们可以写出一个简单的Web应用，但似乎和真实的大型项目好像有一点不同，原因在哪里？其实我们前面掌握的那些都是NodeJS比较基础但很重要的内容，想要进阶学习,必须要掌握和熟悉至少一个优秀的应用框架和项目。\n<!-- more -->\n\n## 1.Express -NodeJS的Web应用框架\n\n![](/images/express.png)\n\n**Web 应用**\nExpress 是一个基于 Node.js 平台的极简、灵活的 web 应用开发框架，它提供一系列强大的特性，帮助你创建各种 Web 和移动设备应用。\n\n**API**\n丰富的 HTTP 快捷方法和任意排列组合的 Connect 中间件，让你创建健壮、友好的 API 变得既快速又简单。\n\n**性能**\nExpress 不对 Node.js 已有的特性进行二次抽象，我们只是在它之上扩展了 Web 应用所需的基本功能。\n\n**LoopBack 提供赞助**\nDevelop model-driven apps with an Express-based framework.\nFind out more at loopback.io.\n\n[Express官网](http://www.expressjs.com.cn/)\n\n## 2.Hexo -静态博客框架\n\n![](/images/hexo.png)\n\n如果你想在github上部署个人blog的话，有两种方式：一种是使用Jekyll，一种是使用Hexo。这两种是目前github支持的方式。\nHexo比Jekyll有更多的主题，若你是一个Geek，对一切包装过的东西很讨厌的话，选择Jekyll也很不错!\n\n**特性**\n\n**风一般的速度**\nHexo基于Node.js，支持多进程，几百篇文章也可以秒生成。\n\n**流畅的撰写**\n支持GitHub Flavored Markdown和所有Octopress的插件。\n\n**扩展性**\nHexo支持EJS、Swig和Stylus。通过插件支持Haml、Jade和Less.\n\n## 3.Ghost -NodeJS平台最强博客平台\n\n![](/images/ghost.png)\n\nGhost是Node.js开发最新博客系统, 简单简洁, 响应式设计, 支持完全自定义, 免费, 专注博客\n\n[github源码](https://github.com/TryGhost/ghost)\n\n我在daocloud上部署的ghost镜像站点：[http://lvyafei-myhost.daoapp.io/](http://lvyafei-myhost.daoapp.io/)\n\n## 4.Cheerio/Request -Web爬虫工具包\n\n用nodejs写采集程序还是比较有效率，使用nodejs实现数据采集器，主要使用到request和cheerio。\n\n**request :用于http请求**\n\n[https://github.com/request/request](https://github.com/request/request)\n\n**cheerio:用于提取request返回的html中需要的信息（和jquery用法一致）**\n\n[https://github.com/cheeriojs/cheerio](https://github.com/cheeriojs/cheerio)","source":"_posts/2015-09-25-基于NodeJS的开发框架和优秀项目.md","raw":"---\nlayout: lay_post\ntitle: \"基于NodeJS的开发框架和优秀项目\"\ndate: 2015-09-25 15:00:00\ncategories: 前端\ntags: NodeJS\nauthor: lvyafei\npublished: true\nsummary: [\"/images/express.png\",\"/images/hexo.png\",\"/images/ghost.png\"]\n---\n\n* 目录\n{:toc #meuid}\n\n## 0.如何进阶NodeJS?\n\n通过前面\"四个例子入门NodeJS\"后，我们可以写出一个简单的Web应用，但似乎和真实的大型项目好像有一点不同，原因在哪里？其实我们前面掌握的那些都是NodeJS比较基础但很重要的内容，想要进阶学习,必须要掌握和熟悉至少一个优秀的应用框架和项目。\n<!-- more -->\n\n## 1.Express -NodeJS的Web应用框架\n\n![](/images/express.png)\n\n**Web 应用**\nExpress 是一个基于 Node.js 平台的极简、灵活的 web 应用开发框架，它提供一系列强大的特性，帮助你创建各种 Web 和移动设备应用。\n\n**API**\n丰富的 HTTP 快捷方法和任意排列组合的 Connect 中间件，让你创建健壮、友好的 API 变得既快速又简单。\n\n**性能**\nExpress 不对 Node.js 已有的特性进行二次抽象，我们只是在它之上扩展了 Web 应用所需的基本功能。\n\n**LoopBack 提供赞助**\nDevelop model-driven apps with an Express-based framework.\nFind out more at loopback.io.\n\n[Express官网](http://www.expressjs.com.cn/)\n\n## 2.Hexo -静态博客框架\n\n![](/images/hexo.png)\n\n如果你想在github上部署个人blog的话，有两种方式：一种是使用Jekyll，一种是使用Hexo。这两种是目前github支持的方式。\nHexo比Jekyll有更多的主题，若你是一个Geek，对一切包装过的东西很讨厌的话，选择Jekyll也很不错!\n\n**特性**\n\n**风一般的速度**\nHexo基于Node.js，支持多进程，几百篇文章也可以秒生成。\n\n**流畅的撰写**\n支持GitHub Flavored Markdown和所有Octopress的插件。\n\n**扩展性**\nHexo支持EJS、Swig和Stylus。通过插件支持Haml、Jade和Less.\n\n## 3.Ghost -NodeJS平台最强博客平台\n\n![](/images/ghost.png)\n\nGhost是Node.js开发最新博客系统, 简单简洁, 响应式设计, 支持完全自定义, 免费, 专注博客\n\n[github源码](https://github.com/TryGhost/ghost)\n\n我在daocloud上部署的ghost镜像站点：[http://lvyafei-myhost.daoapp.io/](http://lvyafei-myhost.daoapp.io/)\n\n## 4.Cheerio/Request -Web爬虫工具包\n\n用nodejs写采集程序还是比较有效率，使用nodejs实现数据采集器，主要使用到request和cheerio。\n\n**request :用于http请求**\n\n[https://github.com/request/request](https://github.com/request/request)\n\n**cheerio:用于提取request返回的html中需要的信息（和jquery用法一致）**\n\n[https://github.com/cheeriojs/cheerio](https://github.com/cheeriojs/cheerio)","slug":"2015-09-25-基于NodeJS的开发框架和优秀项目","updated":"2018-11-29T12:51:24.558Z","comments":1,"photos":[],"link":"","_id":"cjskffnw000044glmm803ssdv","content":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-如何进阶NodeJS\"><a href=\"#0-如何进阶NodeJS\" class=\"headerlink\" title=\"0.如何进阶NodeJS?\"></a>0.如何进阶NodeJS?</h2><p>通过前面”四个例子入门NodeJS”后，我们可以写出一个简单的Web应用，但似乎和真实的大型项目好像有一点不同，原因在哪里？其实我们前面掌握的那些都是NodeJS比较基础但很重要的内容，想要进阶学习,必须要掌握和熟悉至少一个优秀的应用框架和项目。<br><a id=\"more\"></a></p>\n<h2 id=\"1-Express-NodeJS的Web应用框架\"><a href=\"#1-Express-NodeJS的Web应用框架\" class=\"headerlink\" title=\"1.Express -NodeJS的Web应用框架\"></a>1.Express -NodeJS的Web应用框架</h2><p><img src=\"/images/express.png\" alt=\"\"></p>\n<p><strong>Web 应用</strong><br>Express 是一个基于 Node.js 平台的极简、灵活的 web 应用开发框架，它提供一系列强大的特性，帮助你创建各种 Web 和移动设备应用。</p>\n<p><strong>API</strong><br>丰富的 HTTP 快捷方法和任意排列组合的 Connect 中间件，让你创建健壮、友好的 API 变得既快速又简单。</p>\n<p><strong>性能</strong><br>Express 不对 Node.js 已有的特性进行二次抽象，我们只是在它之上扩展了 Web 应用所需的基本功能。</p>\n<p><strong>LoopBack 提供赞助</strong><br>Develop model-driven apps with an Express-based framework.<br>Find out more at loopback.io.</p>\n<p><a href=\"http://www.expressjs.com.cn/\" target=\"_blank\" rel=\"noopener\">Express官网</a></p>\n<h2 id=\"2-Hexo-静态博客框架\"><a href=\"#2-Hexo-静态博客框架\" class=\"headerlink\" title=\"2.Hexo -静态博客框架\"></a>2.Hexo -静态博客框架</h2><p><img src=\"/images/hexo.png\" alt=\"\"></p>\n<p>如果你想在github上部署个人blog的话，有两种方式：一种是使用Jekyll，一种是使用Hexo。这两种是目前github支持的方式。<br>Hexo比Jekyll有更多的主题，若你是一个Geek，对一切包装过的东西很讨厌的话，选择Jekyll也很不错!</p>\n<p><strong>特性</strong></p>\n<p><strong>风一般的速度</strong><br>Hexo基于Node.js，支持多进程，几百篇文章也可以秒生成。</p>\n<p><strong>流畅的撰写</strong><br>支持GitHub Flavored Markdown和所有Octopress的插件。</p>\n<p><strong>扩展性</strong><br>Hexo支持EJS、Swig和Stylus。通过插件支持Haml、Jade和Less.</p>\n<h2 id=\"3-Ghost-NodeJS平台最强博客平台\"><a href=\"#3-Ghost-NodeJS平台最强博客平台\" class=\"headerlink\" title=\"3.Ghost -NodeJS平台最强博客平台\"></a>3.Ghost -NodeJS平台最强博客平台</h2><p><img src=\"/images/ghost.png\" alt=\"\"></p>\n<p>Ghost是Node.js开发最新博客系统, 简单简洁, 响应式设计, 支持完全自定义, 免费, 专注博客</p>\n<p><a href=\"https://github.com/TryGhost/ghost\" target=\"_blank\" rel=\"noopener\">github源码</a></p>\n<p>我在daocloud上部署的ghost镜像站点：<a href=\"http://lvyafei-myhost.daoapp.io/\" target=\"_blank\" rel=\"noopener\">http://lvyafei-myhost.daoapp.io/</a></p>\n<h2 id=\"4-Cheerio-Request-Web爬虫工具包\"><a href=\"#4-Cheerio-Request-Web爬虫工具包\" class=\"headerlink\" title=\"4.Cheerio/Request -Web爬虫工具包\"></a>4.Cheerio/Request -Web爬虫工具包</h2><p>用nodejs写采集程序还是比较有效率，使用nodejs实现数据采集器，主要使用到request和cheerio。</p>\n<p><strong>request :用于http请求</strong></p>\n<p><a href=\"https://github.com/request/request\" target=\"_blank\" rel=\"noopener\">https://github.com/request/request</a></p>\n<p><strong>cheerio:用于提取request返回的html中需要的信息（和jquery用法一致）</strong></p>\n<p><a href=\"https://github.com/cheeriojs/cheerio\" target=\"_blank\" rel=\"noopener\">https://github.com/cheeriojs/cheerio</a></p>\n","site":{"data":{}},"excerpt":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-如何进阶NodeJS\"><a href=\"#0-如何进阶NodeJS\" class=\"headerlink\" title=\"0.如何进阶NodeJS?\"></a>0.如何进阶NodeJS?</h2><p>通过前面”四个例子入门NodeJS”后，我们可以写出一个简单的Web应用，但似乎和真实的大型项目好像有一点不同，原因在哪里？其实我们前面掌握的那些都是NodeJS比较基础但很重要的内容，想要进阶学习,必须要掌握和熟悉至少一个优秀的应用框架和项目。<br>","more":"</p>\n<h2 id=\"1-Express-NodeJS的Web应用框架\"><a href=\"#1-Express-NodeJS的Web应用框架\" class=\"headerlink\" title=\"1.Express -NodeJS的Web应用框架\"></a>1.Express -NodeJS的Web应用框架</h2><p><img src=\"/images/express.png\" alt=\"\"></p>\n<p><strong>Web 应用</strong><br>Express 是一个基于 Node.js 平台的极简、灵活的 web 应用开发框架，它提供一系列强大的特性，帮助你创建各种 Web 和移动设备应用。</p>\n<p><strong>API</strong><br>丰富的 HTTP 快捷方法和任意排列组合的 Connect 中间件，让你创建健壮、友好的 API 变得既快速又简单。</p>\n<p><strong>性能</strong><br>Express 不对 Node.js 已有的特性进行二次抽象，我们只是在它之上扩展了 Web 应用所需的基本功能。</p>\n<p><strong>LoopBack 提供赞助</strong><br>Develop model-driven apps with an Express-based framework.<br>Find out more at loopback.io.</p>\n<p><a href=\"http://www.expressjs.com.cn/\" target=\"_blank\" rel=\"noopener\">Express官网</a></p>\n<h2 id=\"2-Hexo-静态博客框架\"><a href=\"#2-Hexo-静态博客框架\" class=\"headerlink\" title=\"2.Hexo -静态博客框架\"></a>2.Hexo -静态博客框架</h2><p><img src=\"/images/hexo.png\" alt=\"\"></p>\n<p>如果你想在github上部署个人blog的话，有两种方式：一种是使用Jekyll，一种是使用Hexo。这两种是目前github支持的方式。<br>Hexo比Jekyll有更多的主题，若你是一个Geek，对一切包装过的东西很讨厌的话，选择Jekyll也很不错!</p>\n<p><strong>特性</strong></p>\n<p><strong>风一般的速度</strong><br>Hexo基于Node.js，支持多进程，几百篇文章也可以秒生成。</p>\n<p><strong>流畅的撰写</strong><br>支持GitHub Flavored Markdown和所有Octopress的插件。</p>\n<p><strong>扩展性</strong><br>Hexo支持EJS、Swig和Stylus。通过插件支持Haml、Jade和Less.</p>\n<h2 id=\"3-Ghost-NodeJS平台最强博客平台\"><a href=\"#3-Ghost-NodeJS平台最强博客平台\" class=\"headerlink\" title=\"3.Ghost -NodeJS平台最强博客平台\"></a>3.Ghost -NodeJS平台最强博客平台</h2><p><img src=\"/images/ghost.png\" alt=\"\"></p>\n<p>Ghost是Node.js开发最新博客系统, 简单简洁, 响应式设计, 支持完全自定义, 免费, 专注博客</p>\n<p><a href=\"https://github.com/TryGhost/ghost\" target=\"_blank\" rel=\"noopener\">github源码</a></p>\n<p>我在daocloud上部署的ghost镜像站点：<a href=\"http://lvyafei-myhost.daoapp.io/\" target=\"_blank\" rel=\"noopener\">http://lvyafei-myhost.daoapp.io/</a></p>\n<h2 id=\"4-Cheerio-Request-Web爬虫工具包\"><a href=\"#4-Cheerio-Request-Web爬虫工具包\" class=\"headerlink\" title=\"4.Cheerio/Request -Web爬虫工具包\"></a>4.Cheerio/Request -Web爬虫工具包</h2><p>用nodejs写采集程序还是比较有效率，使用nodejs实现数据采集器，主要使用到request和cheerio。</p>\n<p><strong>request :用于http请求</strong></p>\n<p><a href=\"https://github.com/request/request\" target=\"_blank\" rel=\"noopener\">https://github.com/request/request</a></p>\n<p><strong>cheerio:用于提取request返回的html中需要的信息（和jquery用法一致）</strong></p>\n<p><a href=\"https://github.com/cheeriojs/cheerio\" target=\"_blank\" rel=\"noopener\">https://github.com/cheeriojs/cheerio</a></p>"},{"layout":"lay_post","title":"开始使用Python吧","date":"2015-09-25T04:24:00.000Z","author":"lvyafei","published":1,"summary":["/images/python.jpg","/images/django.jpg","/images/flask.png"],"_content":"\n* 目录\n{:toc #meuid}\n\n## 0.Python介绍\n\nPython是一种解释型、面向对象、动态数据类型的高级程序设计语言。\n\nPython由Guido van Rossum于1989年底发明，第一个公开发行版发行于1991年。\n像Perl语言一样, Python 源代码同样遵循 GPL(GNU General Public License)协议。\n\nPython语法简洁清晰，特色之一是强制用空白符(white space)作为语句缩进。\n\nPython具有丰富和强大的库。它常被昵称为胶水语言，能够把用其他语言制作的各种模块（尤其是C/C++）很轻松地联结在一起。\n常见的一种应用情形是，使用Python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写.\n<!-- more -->\n\n![](/images/python.jpg)\n\n## 1.Python能做什么?\n\n**系统编程**：提供API，能方便进行系统维护和管理，Linux下标志性语言之一，是很多系统管理员理想的编程工具\n\n**图形处理**：有PIL、Tkinter等图形库支持，能方便进行图形处理。\n\n**数学处理**：NumPy扩展提供大量与许多标准数学库的接口。\n\n**文本处理**：python提供的re模块能支持正则表达式，还提供SGML，XML分析模块，许多程序员利用python进行XML程序的开发。\n数据库编程：程序员可通过遵循Python DB-API（数据库应用程序编程接口）规范的模块与Microsoft SQL Server，Oracle，Sybase，DB2，MySQL、SQLite等数据库通信。python自带有一个Gadfly模块，提供了一个完整的SQL环境。\n\n**网络编程**：提供丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。很多大规模软件开发计划例如Zope，Mnet 及BitTorrent. Google都在广泛地使用它。\n\n**Web编程**：应用的开发语言，如 Pylons(Web应用框架)、Zope(应用服务器)、Plone(内容管理系统)、Twisted(Python的网络应用程序框架)、Webpy(微Web框架)、Reddit(社交分享网站)、Dropbox(文件分享服务)、Fabric(管理Linux主机的程序库)、Trac(BUG管理系统)、Mailman(邮件列表软件)、Mezzanine(基于Django编写的内容管理系统)、Blender(以C与Python开发的开源3D绘图软件).\n\n**多媒体应用**：Python的PyOpenGL模块封装了“OpenGL应用程序编程接口”，能进行二维和三维图像处理。PyGame模块可用于编写游戏软件。\n\n**PYMO引擎**：PYMO全称为python memories off，是一款运行于Symbian S60V3,Symbian3,S60V5, Symbian3, Android系统上的AVG游戏引擎。因其基于python2.0平台开发，并且适用于创建秋之回忆（memories off）风格的AVG游戏，故命名为PYMO。\n\n**黑客编程**：python有一个hack的库,内置了你熟悉的或不熟悉的函数.\n\n**爬虫**: Scrapy-开源Python爬虫框架\n\n## 2.Python学习资源\n\n[RUNOOB.com -Python基础学习](http://www.runoob.com/python/python-tutorial.html)\n\n## 3.Python经典项目\n\n一个好的项目是对学习一个语言或工具是有很大的指引作用的，现在基于Python语言的出色的项目有很多，我自己发现的项目中，其中有几个是对进阶学习Python有很大帮助的。也是自己比较感兴趣的, 这里只做一个简单的引入, 如果你感兴趣，请关注我的后续文章。。\n\n### 3.1 Django- 鼓励快速开发的Web应用框架\n\n![](/images/django.jpg)\n\nDjango 是由 Python 开发的一个免费的开源网站框架，可以用于快速搭建高性能，优雅的网站！\n\n教程: [自强学堂 -Diango开发教程](http://www.ziqiangxuetang.com/django/django-tutorial.html)\n\n### 3.2 Flask- Python微Web框架\n\n![](/images/flask.png)\n\nFlask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2. 使用 BSD 授权。\n\n[Flask -官方教程中文版](http://dormousehole.readthedocs.org/en/latest/)\n\n[Flask -官方](http://flask.pocoo.org/)\n\n### 3.3 Scrapy- Python网络爬虫框架\n\n![](/images/scrapy.png)\n\nScrapy，Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。\nScrapy用途广泛，可以用于数据挖掘、监测和自动化测试。\nScrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等.\n\n[Scrapy教程](http://scrapy-chs.readthedocs.org/zh_CN/latest/index.html)","source":"_posts/2015-09-25-开始使用Python吧.md","raw":"---\nlayout: lay_post\ntitle: \"开始使用Python吧\"\ndate: 2015-09-25 12:24:00\ncategories: 后端脚本\ntags: Python\nauthor: lvyafei\npublished: true\nsummary: [\"/images/python.jpg\",\"/images/django.jpg\",\"/images/flask.png\"]\n---\n\n* 目录\n{:toc #meuid}\n\n## 0.Python介绍\n\nPython是一种解释型、面向对象、动态数据类型的高级程序设计语言。\n\nPython由Guido van Rossum于1989年底发明，第一个公开发行版发行于1991年。\n像Perl语言一样, Python 源代码同样遵循 GPL(GNU General Public License)协议。\n\nPython语法简洁清晰，特色之一是强制用空白符(white space)作为语句缩进。\n\nPython具有丰富和强大的库。它常被昵称为胶水语言，能够把用其他语言制作的各种模块（尤其是C/C++）很轻松地联结在一起。\n常见的一种应用情形是，使用Python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写.\n<!-- more -->\n\n![](/images/python.jpg)\n\n## 1.Python能做什么?\n\n**系统编程**：提供API，能方便进行系统维护和管理，Linux下标志性语言之一，是很多系统管理员理想的编程工具\n\n**图形处理**：有PIL、Tkinter等图形库支持，能方便进行图形处理。\n\n**数学处理**：NumPy扩展提供大量与许多标准数学库的接口。\n\n**文本处理**：python提供的re模块能支持正则表达式，还提供SGML，XML分析模块，许多程序员利用python进行XML程序的开发。\n数据库编程：程序员可通过遵循Python DB-API（数据库应用程序编程接口）规范的模块与Microsoft SQL Server，Oracle，Sybase，DB2，MySQL、SQLite等数据库通信。python自带有一个Gadfly模块，提供了一个完整的SQL环境。\n\n**网络编程**：提供丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。很多大规模软件开发计划例如Zope，Mnet 及BitTorrent. Google都在广泛地使用它。\n\n**Web编程**：应用的开发语言，如 Pylons(Web应用框架)、Zope(应用服务器)、Plone(内容管理系统)、Twisted(Python的网络应用程序框架)、Webpy(微Web框架)、Reddit(社交分享网站)、Dropbox(文件分享服务)、Fabric(管理Linux主机的程序库)、Trac(BUG管理系统)、Mailman(邮件列表软件)、Mezzanine(基于Django编写的内容管理系统)、Blender(以C与Python开发的开源3D绘图软件).\n\n**多媒体应用**：Python的PyOpenGL模块封装了“OpenGL应用程序编程接口”，能进行二维和三维图像处理。PyGame模块可用于编写游戏软件。\n\n**PYMO引擎**：PYMO全称为python memories off，是一款运行于Symbian S60V3,Symbian3,S60V5, Symbian3, Android系统上的AVG游戏引擎。因其基于python2.0平台开发，并且适用于创建秋之回忆（memories off）风格的AVG游戏，故命名为PYMO。\n\n**黑客编程**：python有一个hack的库,内置了你熟悉的或不熟悉的函数.\n\n**爬虫**: Scrapy-开源Python爬虫框架\n\n## 2.Python学习资源\n\n[RUNOOB.com -Python基础学习](http://www.runoob.com/python/python-tutorial.html)\n\n## 3.Python经典项目\n\n一个好的项目是对学习一个语言或工具是有很大的指引作用的，现在基于Python语言的出色的项目有很多，我自己发现的项目中，其中有几个是对进阶学习Python有很大帮助的。也是自己比较感兴趣的, 这里只做一个简单的引入, 如果你感兴趣，请关注我的后续文章。。\n\n### 3.1 Django- 鼓励快速开发的Web应用框架\n\n![](/images/django.jpg)\n\nDjango 是由 Python 开发的一个免费的开源网站框架，可以用于快速搭建高性能，优雅的网站！\n\n教程: [自强学堂 -Diango开发教程](http://www.ziqiangxuetang.com/django/django-tutorial.html)\n\n### 3.2 Flask- Python微Web框架\n\n![](/images/flask.png)\n\nFlask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2. 使用 BSD 授权。\n\n[Flask -官方教程中文版](http://dormousehole.readthedocs.org/en/latest/)\n\n[Flask -官方](http://flask.pocoo.org/)\n\n### 3.3 Scrapy- Python网络爬虫框架\n\n![](/images/scrapy.png)\n\nScrapy，Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。\nScrapy用途广泛，可以用于数据挖掘、监测和自动化测试。\nScrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等.\n\n[Scrapy教程](http://scrapy-chs.readthedocs.org/zh_CN/latest/index.html)","slug":"2015-09-25-开始使用Python吧","updated":"2018-11-29T12:51:24.562Z","comments":1,"photos":[],"link":"","_id":"cjskffnwg00054glmn3fxxoz8","content":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-Python介绍\"><a href=\"#0-Python介绍\" class=\"headerlink\" title=\"0.Python介绍\"></a>0.Python介绍</h2><p>Python是一种解释型、面向对象、动态数据类型的高级程序设计语言。</p>\n<p>Python由Guido van Rossum于1989年底发明，第一个公开发行版发行于1991年。<br>像Perl语言一样, Python 源代码同样遵循 GPL(GNU General Public License)协议。</p>\n<p>Python语法简洁清晰，特色之一是强制用空白符(white space)作为语句缩进。</p>\n<p>Python具有丰富和强大的库。它常被昵称为胶水语言，能够把用其他语言制作的各种模块（尤其是C/C++）很轻松地联结在一起。<br>常见的一种应用情形是，使用Python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写.<br><a id=\"more\"></a></p>\n<p><img src=\"/images/python.jpg\" alt=\"\"></p>\n<h2 id=\"1-Python能做什么\"><a href=\"#1-Python能做什么\" class=\"headerlink\" title=\"1.Python能做什么?\"></a>1.Python能做什么?</h2><p><strong>系统编程</strong>：提供API，能方便进行系统维护和管理，Linux下标志性语言之一，是很多系统管理员理想的编程工具</p>\n<p><strong>图形处理</strong>：有PIL、Tkinter等图形库支持，能方便进行图形处理。</p>\n<p><strong>数学处理</strong>：NumPy扩展提供大量与许多标准数学库的接口。</p>\n<p><strong>文本处理</strong>：python提供的re模块能支持正则表达式，还提供SGML，XML分析模块，许多程序员利用python进行XML程序的开发。<br>数据库编程：程序员可通过遵循Python DB-API（数据库应用程序编程接口）规范的模块与Microsoft SQL Server，Oracle，Sybase，DB2，MySQL、SQLite等数据库通信。python自带有一个Gadfly模块，提供了一个完整的SQL环境。</p>\n<p><strong>网络编程</strong>：提供丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。很多大规模软件开发计划例如Zope，Mnet 及BitTorrent. Google都在广泛地使用它。</p>\n<p><strong>Web编程</strong>：应用的开发语言，如 Pylons(Web应用框架)、Zope(应用服务器)、Plone(内容管理系统)、Twisted(Python的网络应用程序框架)、Webpy(微Web框架)、Reddit(社交分享网站)、Dropbox(文件分享服务)、Fabric(管理Linux主机的程序库)、Trac(BUG管理系统)、Mailman(邮件列表软件)、Mezzanine(基于Django编写的内容管理系统)、Blender(以C与Python开发的开源3D绘图软件).</p>\n<p><strong>多媒体应用</strong>：Python的PyOpenGL模块封装了“OpenGL应用程序编程接口”，能进行二维和三维图像处理。PyGame模块可用于编写游戏软件。</p>\n<p><strong>PYMO引擎</strong>：PYMO全称为python memories off，是一款运行于Symbian S60V3,Symbian3,S60V5, Symbian3, Android系统上的AVG游戏引擎。因其基于python2.0平台开发，并且适用于创建秋之回忆（memories off）风格的AVG游戏，故命名为PYMO。</p>\n<p><strong>黑客编程</strong>：python有一个hack的库,内置了你熟悉的或不熟悉的函数.</p>\n<p><strong>爬虫</strong>: Scrapy-开源Python爬虫框架</p>\n<h2 id=\"2-Python学习资源\"><a href=\"#2-Python学习资源\" class=\"headerlink\" title=\"2.Python学习资源\"></a>2.Python学习资源</h2><p><a href=\"http://www.runoob.com/python/python-tutorial.html\" target=\"_blank\" rel=\"noopener\">RUNOOB.com -Python基础学习</a></p>\n<h2 id=\"3-Python经典项目\"><a href=\"#3-Python经典项目\" class=\"headerlink\" title=\"3.Python经典项目\"></a>3.Python经典项目</h2><p>一个好的项目是对学习一个语言或工具是有很大的指引作用的，现在基于Python语言的出色的项目有很多，我自己发现的项目中，其中有几个是对进阶学习Python有很大帮助的。也是自己比较感兴趣的, 这里只做一个简单的引入, 如果你感兴趣，请关注我的后续文章。。</p>\n<h3 id=\"3-1-Django-鼓励快速开发的Web应用框架\"><a href=\"#3-1-Django-鼓励快速开发的Web应用框架\" class=\"headerlink\" title=\"3.1 Django- 鼓励快速开发的Web应用框架\"></a>3.1 Django- 鼓励快速开发的Web应用框架</h3><p><img src=\"/images/django.jpg\" alt=\"\"></p>\n<p>Django 是由 Python 开发的一个免费的开源网站框架，可以用于快速搭建高性能，优雅的网站！</p>\n<p>教程: <a href=\"http://www.ziqiangxuetang.com/django/django-tutorial.html\" target=\"_blank\" rel=\"noopener\">自强学堂 -Diango开发教程</a></p>\n<h3 id=\"3-2-Flask-Python微Web框架\"><a href=\"#3-2-Flask-Python微Web框架\" class=\"headerlink\" title=\"3.2 Flask- Python微Web框架\"></a>3.2 Flask- Python微Web框架</h3><p><img src=\"/images/flask.png\" alt=\"\"></p>\n<p>Flask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2. 使用 BSD 授权。</p>\n<p><a href=\"http://dormousehole.readthedocs.org/en/latest/\" target=\"_blank\" rel=\"noopener\">Flask -官方教程中文版</a></p>\n<p><a href=\"http://flask.pocoo.org/\" target=\"_blank\" rel=\"noopener\">Flask -官方</a></p>\n<h3 id=\"3-3-Scrapy-Python网络爬虫框架\"><a href=\"#3-3-Scrapy-Python网络爬虫框架\" class=\"headerlink\" title=\"3.3 Scrapy- Python网络爬虫框架\"></a>3.3 Scrapy- Python网络爬虫框架</h3><p><img src=\"/images/scrapy.png\" alt=\"\"></p>\n<p>Scrapy，Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。<br>Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。<br>Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等.</p>\n<p><a href=\"http://scrapy-chs.readthedocs.org/zh_CN/latest/index.html\" target=\"_blank\" rel=\"noopener\">Scrapy教程</a></p>\n","site":{"data":{}},"excerpt":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"0-Python介绍\"><a href=\"#0-Python介绍\" class=\"headerlink\" title=\"0.Python介绍\"></a>0.Python介绍</h2><p>Python是一种解释型、面向对象、动态数据类型的高级程序设计语言。</p>\n<p>Python由Guido van Rossum于1989年底发明，第一个公开发行版发行于1991年。<br>像Perl语言一样, Python 源代码同样遵循 GPL(GNU General Public License)协议。</p>\n<p>Python语法简洁清晰，特色之一是强制用空白符(white space)作为语句缩进。</p>\n<p>Python具有丰富和强大的库。它常被昵称为胶水语言，能够把用其他语言制作的各种模块（尤其是C/C++）很轻松地联结在一起。<br>常见的一种应用情形是，使用Python快速生成程序的原型（有时甚至是程序的最终界面），然后对其中有特别要求的部分，用更合适的语言改写.<br>","more":"</p>\n<p><img src=\"/images/python.jpg\" alt=\"\"></p>\n<h2 id=\"1-Python能做什么\"><a href=\"#1-Python能做什么\" class=\"headerlink\" title=\"1.Python能做什么?\"></a>1.Python能做什么?</h2><p><strong>系统编程</strong>：提供API，能方便进行系统维护和管理，Linux下标志性语言之一，是很多系统管理员理想的编程工具</p>\n<p><strong>图形处理</strong>：有PIL、Tkinter等图形库支持，能方便进行图形处理。</p>\n<p><strong>数学处理</strong>：NumPy扩展提供大量与许多标准数学库的接口。</p>\n<p><strong>文本处理</strong>：python提供的re模块能支持正则表达式，还提供SGML，XML分析模块，许多程序员利用python进行XML程序的开发。<br>数据库编程：程序员可通过遵循Python DB-API（数据库应用程序编程接口）规范的模块与Microsoft SQL Server，Oracle，Sybase，DB2，MySQL、SQLite等数据库通信。python自带有一个Gadfly模块，提供了一个完整的SQL环境。</p>\n<p><strong>网络编程</strong>：提供丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。很多大规模软件开发计划例如Zope，Mnet 及BitTorrent. Google都在广泛地使用它。</p>\n<p><strong>Web编程</strong>：应用的开发语言，如 Pylons(Web应用框架)、Zope(应用服务器)、Plone(内容管理系统)、Twisted(Python的网络应用程序框架)、Webpy(微Web框架)、Reddit(社交分享网站)、Dropbox(文件分享服务)、Fabric(管理Linux主机的程序库)、Trac(BUG管理系统)、Mailman(邮件列表软件)、Mezzanine(基于Django编写的内容管理系统)、Blender(以C与Python开发的开源3D绘图软件).</p>\n<p><strong>多媒体应用</strong>：Python的PyOpenGL模块封装了“OpenGL应用程序编程接口”，能进行二维和三维图像处理。PyGame模块可用于编写游戏软件。</p>\n<p><strong>PYMO引擎</strong>：PYMO全称为python memories off，是一款运行于Symbian S60V3,Symbian3,S60V5, Symbian3, Android系统上的AVG游戏引擎。因其基于python2.0平台开发，并且适用于创建秋之回忆（memories off）风格的AVG游戏，故命名为PYMO。</p>\n<p><strong>黑客编程</strong>：python有一个hack的库,内置了你熟悉的或不熟悉的函数.</p>\n<p><strong>爬虫</strong>: Scrapy-开源Python爬虫框架</p>\n<h2 id=\"2-Python学习资源\"><a href=\"#2-Python学习资源\" class=\"headerlink\" title=\"2.Python学习资源\"></a>2.Python学习资源</h2><p><a href=\"http://www.runoob.com/python/python-tutorial.html\" target=\"_blank\" rel=\"noopener\">RUNOOB.com -Python基础学习</a></p>\n<h2 id=\"3-Python经典项目\"><a href=\"#3-Python经典项目\" class=\"headerlink\" title=\"3.Python经典项目\"></a>3.Python经典项目</h2><p>一个好的项目是对学习一个语言或工具是有很大的指引作用的，现在基于Python语言的出色的项目有很多，我自己发现的项目中，其中有几个是对进阶学习Python有很大帮助的。也是自己比较感兴趣的, 这里只做一个简单的引入, 如果你感兴趣，请关注我的后续文章。。</p>\n<h3 id=\"3-1-Django-鼓励快速开发的Web应用框架\"><a href=\"#3-1-Django-鼓励快速开发的Web应用框架\" class=\"headerlink\" title=\"3.1 Django- 鼓励快速开发的Web应用框架\"></a>3.1 Django- 鼓励快速开发的Web应用框架</h3><p><img src=\"/images/django.jpg\" alt=\"\"></p>\n<p>Django 是由 Python 开发的一个免费的开源网站框架，可以用于快速搭建高性能，优雅的网站！</p>\n<p>教程: <a href=\"http://www.ziqiangxuetang.com/django/django-tutorial.html\" target=\"_blank\" rel=\"noopener\">自强学堂 -Diango开发教程</a></p>\n<h3 id=\"3-2-Flask-Python微Web框架\"><a href=\"#3-2-Flask-Python微Web框架\" class=\"headerlink\" title=\"3.2 Flask- Python微Web框架\"></a>3.2 Flask- Python微Web框架</h3><p><img src=\"/images/flask.png\" alt=\"\"></p>\n<p>Flask是一个使用 Python 编写的轻量级 Web 应用框架。其 WSGI 工具箱采用 Werkzeug ，模板引擎则使用 Jinja2. 使用 BSD 授权。</p>\n<p><a href=\"http://dormousehole.readthedocs.org/en/latest/\" target=\"_blank\" rel=\"noopener\">Flask -官方教程中文版</a></p>\n<p><a href=\"http://flask.pocoo.org/\" target=\"_blank\" rel=\"noopener\">Flask -官方</a></p>\n<h3 id=\"3-3-Scrapy-Python网络爬虫框架\"><a href=\"#3-3-Scrapy-Python网络爬虫框架\" class=\"headerlink\" title=\"3.3 Scrapy- Python网络爬虫框架\"></a>3.3 Scrapy- Python网络爬虫框架</h3><p><img src=\"/images/scrapy.png\" alt=\"\"></p>\n<p>Scrapy，Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。<br>Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。<br>Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等.</p>\n<p><a href=\"http://scrapy-chs.readthedocs.org/zh_CN/latest/index.html\" target=\"_blank\" rel=\"noopener\">Scrapy教程</a></p>"},{"layout":"lay_post","title":"Web技术架构演进","date":"2015-10-27T12:56:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n大型网站的架构都是从简单的、单一的架构不断演进到复杂的、多层次的设计。这个过程中会衍生出好多架构的思想和\n解决办法，我们可以从中看到随着需求的不断变化，架构的重心也会不断的调整。从现有的架构发展可以看出以后的方向，\n更能指引我们向着正确的地方前进。\n<!-- more -->\n\n## 1.架构演进图\n\n![架构](/images/架构/架构演进.png)\n\n## 2.架构思想\n\n从架构的演进过程中我们可以看到这里面有几个重要的分割点，还有对待现实产生的问题对待的解决办法\n\n**1.堆机器**\n\n从单台服务器到多台服务器，硬件方面是为了增大机器的总内存，总CPU，软件方面是为了减少单服务器的访问瓶颈，分流减压。\n\n**2.拆模块**\n\n一个大的模块会导致牵一发而动全身，常规的解决办法是根据分类将一个大的模块拆分成多个小的，这样对于维护来说不仅能够灵活的应对需求的变更，还能够不断优化整体的结构。最终还可以将小的模块作为服务来提供，真正做到面向服务的架构。\n\n**3.做缓冲**\n\n为了不断提高性能，我们可以采用本地缓存，分布式缓存，反向代理，动静分离缓存，CDN加速以及采用消息总线的方式，这些技术都是为了将实际从远处或者获取一些大的数据量时能够对数据做一个缓冲，而不需要局限于网络和IO的瓶颈，真正提高访问的速度。\n\n**4.分分合合**\n\n分的时间长了，或者分的太细了就会很繁琐，不便于管理。我们就要将繁琐的东西归类起来，统一管理，统一配置，SOA服务治理，配置的集中管理等都是在拆分后产生问题的应对措施。\n\n## 3.解决办法\n\n常见的解决办法是，分布式部署，集中式管理。解决了一个现有的需求问题，就会带来其他的问题，我们要有所权重，服务的治理，是在做了服务的拆分后出现的，如果没有提出抽取出服务的方案就不必对服务进行治理。但是我们不能害怕产生新的问题就不采取这种方式，敢于大胆尝试才能创造出跟优良的解决方案。\n\n## 4.发展的方向\n\n随着WEB3.0的到来，技术架构的方向会不断的变化，但是基本的的原点就是应用和存储的不断转移，可以从运维的角度到软件的架构间选择，改变的方式也是在分布式和集中式间变化，各有利弊，关键是当前的架构重心是在哪里，要有取舍才能更出色。","source":"_posts/2015-10-27-Web技术架构演进.md","raw":"---\nlayout: lay_post\ntitle: \"Web技术架构演进\"\ndate: 2015-10-27 20:56:00\ncategories: 架构\ntags: 网站架构\nauthor: lvyafei\n---\n\n## 0.概述\n\n大型网站的架构都是从简单的、单一的架构不断演进到复杂的、多层次的设计。这个过程中会衍生出好多架构的思想和\n解决办法，我们可以从中看到随着需求的不断变化，架构的重心也会不断的调整。从现有的架构发展可以看出以后的方向，\n更能指引我们向着正确的地方前进。\n<!-- more -->\n\n## 1.架构演进图\n\n![架构](/images/架构/架构演进.png)\n\n## 2.架构思想\n\n从架构的演进过程中我们可以看到这里面有几个重要的分割点，还有对待现实产生的问题对待的解决办法\n\n**1.堆机器**\n\n从单台服务器到多台服务器，硬件方面是为了增大机器的总内存，总CPU，软件方面是为了减少单服务器的访问瓶颈，分流减压。\n\n**2.拆模块**\n\n一个大的模块会导致牵一发而动全身，常规的解决办法是根据分类将一个大的模块拆分成多个小的，这样对于维护来说不仅能够灵活的应对需求的变更，还能够不断优化整体的结构。最终还可以将小的模块作为服务来提供，真正做到面向服务的架构。\n\n**3.做缓冲**\n\n为了不断提高性能，我们可以采用本地缓存，分布式缓存，反向代理，动静分离缓存，CDN加速以及采用消息总线的方式，这些技术都是为了将实际从远处或者获取一些大的数据量时能够对数据做一个缓冲，而不需要局限于网络和IO的瓶颈，真正提高访问的速度。\n\n**4.分分合合**\n\n分的时间长了，或者分的太细了就会很繁琐，不便于管理。我们就要将繁琐的东西归类起来，统一管理，统一配置，SOA服务治理，配置的集中管理等都是在拆分后产生问题的应对措施。\n\n## 3.解决办法\n\n常见的解决办法是，分布式部署，集中式管理。解决了一个现有的需求问题，就会带来其他的问题，我们要有所权重，服务的治理，是在做了服务的拆分后出现的，如果没有提出抽取出服务的方案就不必对服务进行治理。但是我们不能害怕产生新的问题就不采取这种方式，敢于大胆尝试才能创造出跟优良的解决方案。\n\n## 4.发展的方向\n\n随着WEB3.0的到来，技术架构的方向会不断的变化，但是基本的的原点就是应用和存储的不断转移，可以从运维的角度到软件的架构间选择，改变的方式也是在分布式和集中式间变化，各有利弊，关键是当前的架构重心是在哪里，要有取舍才能更出色。","slug":"2015-10-27-Web技术架构演进","published":1,"updated":"2018-11-29T12:51:24.571Z","comments":1,"photos":[],"link":"","_id":"cjskffnwg00064glmupt7y625","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>大型网站的架构都是从简单的、单一的架构不断演进到复杂的、多层次的设计。这个过程中会衍生出好多架构的思想和<br>解决办法，我们可以从中看到随着需求的不断变化，架构的重心也会不断的调整。从现有的架构发展可以看出以后的方向，<br>更能指引我们向着正确的地方前进。<br><a id=\"more\"></a></p>\n<h2 id=\"1-架构演进图\"><a href=\"#1-架构演进图\" class=\"headerlink\" title=\"1.架构演进图\"></a>1.架构演进图</h2><p><img src=\"/images/架构/架构演进.png\" alt=\"架构\"></p>\n<h2 id=\"2-架构思想\"><a href=\"#2-架构思想\" class=\"headerlink\" title=\"2.架构思想\"></a>2.架构思想</h2><p>从架构的演进过程中我们可以看到这里面有几个重要的分割点，还有对待现实产生的问题对待的解决办法</p>\n<p><strong>1.堆机器</strong></p>\n<p>从单台服务器到多台服务器，硬件方面是为了增大机器的总内存，总CPU，软件方面是为了减少单服务器的访问瓶颈，分流减压。</p>\n<p><strong>2.拆模块</strong></p>\n<p>一个大的模块会导致牵一发而动全身，常规的解决办法是根据分类将一个大的模块拆分成多个小的，这样对于维护来说不仅能够灵活的应对需求的变更，还能够不断优化整体的结构。最终还可以将小的模块作为服务来提供，真正做到面向服务的架构。</p>\n<p><strong>3.做缓冲</strong></p>\n<p>为了不断提高性能，我们可以采用本地缓存，分布式缓存，反向代理，动静分离缓存，CDN加速以及采用消息总线的方式，这些技术都是为了将实际从远处或者获取一些大的数据量时能够对数据做一个缓冲，而不需要局限于网络和IO的瓶颈，真正提高访问的速度。</p>\n<p><strong>4.分分合合</strong></p>\n<p>分的时间长了，或者分的太细了就会很繁琐，不便于管理。我们就要将繁琐的东西归类起来，统一管理，统一配置，SOA服务治理，配置的集中管理等都是在拆分后产生问题的应对措施。</p>\n<h2 id=\"3-解决办法\"><a href=\"#3-解决办法\" class=\"headerlink\" title=\"3.解决办法\"></a>3.解决办法</h2><p>常见的解决办法是，分布式部署，集中式管理。解决了一个现有的需求问题，就会带来其他的问题，我们要有所权重，服务的治理，是在做了服务的拆分后出现的，如果没有提出抽取出服务的方案就不必对服务进行治理。但是我们不能害怕产生新的问题就不采取这种方式，敢于大胆尝试才能创造出跟优良的解决方案。</p>\n<h2 id=\"4-发展的方向\"><a href=\"#4-发展的方向\" class=\"headerlink\" title=\"4.发展的方向\"></a>4.发展的方向</h2><p>随着WEB3.0的到来，技术架构的方向会不断的变化，但是基本的的原点就是应用和存储的不断转移，可以从运维的角度到软件的架构间选择，改变的方式也是在分布式和集中式间变化，各有利弊，关键是当前的架构重心是在哪里，要有取舍才能更出色。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>大型网站的架构都是从简单的、单一的架构不断演进到复杂的、多层次的设计。这个过程中会衍生出好多架构的思想和<br>解决办法，我们可以从中看到随着需求的不断变化，架构的重心也会不断的调整。从现有的架构发展可以看出以后的方向，<br>更能指引我们向着正确的地方前进。<br>","more":"</p>\n<h2 id=\"1-架构演进图\"><a href=\"#1-架构演进图\" class=\"headerlink\" title=\"1.架构演进图\"></a>1.架构演进图</h2><p><img src=\"/images/架构/架构演进.png\" alt=\"架构\"></p>\n<h2 id=\"2-架构思想\"><a href=\"#2-架构思想\" class=\"headerlink\" title=\"2.架构思想\"></a>2.架构思想</h2><p>从架构的演进过程中我们可以看到这里面有几个重要的分割点，还有对待现实产生的问题对待的解决办法</p>\n<p><strong>1.堆机器</strong></p>\n<p>从单台服务器到多台服务器，硬件方面是为了增大机器的总内存，总CPU，软件方面是为了减少单服务器的访问瓶颈，分流减压。</p>\n<p><strong>2.拆模块</strong></p>\n<p>一个大的模块会导致牵一发而动全身，常规的解决办法是根据分类将一个大的模块拆分成多个小的，这样对于维护来说不仅能够灵活的应对需求的变更，还能够不断优化整体的结构。最终还可以将小的模块作为服务来提供，真正做到面向服务的架构。</p>\n<p><strong>3.做缓冲</strong></p>\n<p>为了不断提高性能，我们可以采用本地缓存，分布式缓存，反向代理，动静分离缓存，CDN加速以及采用消息总线的方式，这些技术都是为了将实际从远处或者获取一些大的数据量时能够对数据做一个缓冲，而不需要局限于网络和IO的瓶颈，真正提高访问的速度。</p>\n<p><strong>4.分分合合</strong></p>\n<p>分的时间长了，或者分的太细了就会很繁琐，不便于管理。我们就要将繁琐的东西归类起来，统一管理，统一配置，SOA服务治理，配置的集中管理等都是在拆分后产生问题的应对措施。</p>\n<h2 id=\"3-解决办法\"><a href=\"#3-解决办法\" class=\"headerlink\" title=\"3.解决办法\"></a>3.解决办法</h2><p>常见的解决办法是，分布式部署，集中式管理。解决了一个现有的需求问题，就会带来其他的问题，我们要有所权重，服务的治理，是在做了服务的拆分后出现的，如果没有提出抽取出服务的方案就不必对服务进行治理。但是我们不能害怕产生新的问题就不采取这种方式，敢于大胆尝试才能创造出跟优良的解决方案。</p>\n<h2 id=\"4-发展的方向\"><a href=\"#4-发展的方向\" class=\"headerlink\" title=\"4.发展的方向\"></a>4.发展的方向</h2><p>随着WEB3.0的到来，技术架构的方向会不断的变化，但是基本的的原点就是应用和存储的不断转移，可以从运维的角度到软件的架构间选择，改变的方式也是在分布式和集中式间变化，各有利弊，关键是当前的架构重心是在哪里，要有取舍才能更出色。</p>"},{"layout":"lay_post","title":"深入理解Java虚拟机-内存区域与内存溢出异常","date":"2016-02-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n内容选自周志明的<<深入理解Java虚拟机-JVM高级特性与最佳实战>>第2版(2013年6月第二版)。内存区域与内存溢出异常章节。\n\n<!-- more -->\n\n![内存结构](/images/JVM/2_内存区域与异常.png)\n\n以下是工具集合和常用命令:\n\n![工具集合](/images/JVM/工具集合与命令.png)\n\n\n","source":"_posts/2016-02-22-深入理解Java虚拟机-内存区域与内存溢出异常.md","raw":"---\nlayout: lay_post\ntitle: \"深入理解Java虚拟机-内存区域与内存溢出异常\"\ndate: 2016-02-22\ncategories: JVM高级特性\ntags: 内存区域\nauthor: lvyafei\n---\n\n## 0.概述\n\n内容选自周志明的<<深入理解Java虚拟机-JVM高级特性与最佳实战>>第2版(2013年6月第二版)。内存区域与内存溢出异常章节。\n\n<!-- more -->\n\n![内存结构](/images/JVM/2_内存区域与异常.png)\n\n以下是工具集合和常用命令:\n\n![工具集合](/images/JVM/工具集合与命令.png)\n\n\n","slug":"2016-02-22-深入理解Java虚拟机-内存区域与内存溢出异常","published":1,"updated":"2018-11-29T12:51:24.597Z","comments":1,"photos":[],"link":"","_id":"cjskffnwv000a4glmg5zomogh","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>内容选自周志明的&lt;&lt;深入理解Java虚拟机-JVM高级特性与最佳实战&gt;&gt;第2版(2013年6月第二版)。内存区域与内存溢出异常章节。</p>\n<a id=\"more\"></a>\n<p><img src=\"/images/JVM/2_内存区域与异常.png\" alt=\"内存结构\"></p>\n<p>以下是工具集合和常用命令:</p>\n<p><img src=\"/images/JVM/工具集合与命令.png\" alt=\"工具集合\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>内容选自周志明的&lt;&lt;深入理解Java虚拟机-JVM高级特性与最佳实战&gt;&gt;第2版(2013年6月第二版)。内存区域与内存溢出异常章节。</p>","more":"<p><img src=\"/images/JVM/2_内存区域与异常.png\" alt=\"内存结构\"></p>\n<p>以下是工具集合和常用命令:</p>\n<p><img src=\"/images/JVM/工具集合与命令.png\" alt=\"工具集合\"></p>"},{"layout":"lay_post","title":"求最短路径算法-Dijkstra","date":"2015-09-28T12:24:00.000Z","author":"lvyafei","_content":"\n## 0.算法属性\n\n**类别**：查找算法\n\n**数据结构**：图\n\n**性能**：O(|E|+|V|log|V|)\n\n## 1.算法介绍\n\nDijkstra算法是求图中两节点间最短路径的一种算法。它可以表示：例如，道路网络。\n\n它的构思是由计算机科学家Edsger W. Dijkstra在1956想出并在三年后提出的。\n\n这个算法存在许多版本；Dijkstra的最初版本是求两结点之间的最短路径，但更常见的版本是将单一节点作为“源”节点，去计算从源头到图中的所有其他节点的最短路径，并生成树。\n\n最短路径的算法被广泛应用于网络的路由协议，比如最著名的是OSPF(优先开放最短路径)。也被用作子算法，如[Johnson's algorithm](https://en.wikipedia.org/wiki/Johnson%27s_algorithm)\n<!-- more -->\n\n![](/images/Dijkstra/path.jpg)\n\nDijkstra原始算法并没有使用最小优先队列，运行时间为O(|V|^2)(其中|V|表示节点的数量)。\n\n这种算法思想在1957年被Leyzorek等人提出。在1984年被Fredman和Tarjan实现在斐波那契堆中，\n并且运行时间为O(|E|+|V|\\log|V|)(其中 |E|为边的数量)\n\n这是在任意有向图和无界非负权重的情况下，一个以渐进的方式最快的算出已知单源最短路径算法。\n\n## 2.算法示意图\n\n**示意一**：\n\n![](/images/Dijkstra/Dijkstra_Animation.gif)\n\n计算a到b的距离。其中：\n\n1.两点间的实际距离为连接线上的数字。\n\n2.节点圆圈中的数字为该节点的标示符。\n\n3.节点边上蓝色数字为起始节点a到该节点的最小距离。\n\n4.若计算出的距离值比当前所标示的距离值小，则更新反之不更新。节点初始值为无限大。\n\n5.访问过的节点标示为红色，下一次忽略该节点(即该节点的最小距离值不再改变,状态为out)。\n\n计算结果：\n\na到节点1的最小距离为：0\n\na到节点2的最小距离为: 7\n\na到节点3的最小距离为: 9\n\na到节点6的最小距离为：11\n\na到节点5的最小距离为: 20\n\n**示意二**：\n\n![](/images/Dijkstra/Dijkstras_progress_animation.gif)\n\n从开始节点(左下角的红色节点)到目标节点(右上角的绿色节点)的查找示意图。其中空心节点表示“暂定”集，填充节点表示\"被访问\"过的。颜色代表距离，颜色越绿代表距离越远。不同方向上的节点是均匀分布的，Dijkstra算法使用了一个启发式恒等于0，像波浪一样渐进发现节点。\n\n**示意三**：\n\n![](/images/Dijkstra/Dijkstra_detail.jpg)\n\n从左到右，从上到下：\n\n图一：以左上角的点为起始节点，计算到图中所有其它节点的最小距离。初始值为99(一个很大的值)，起始节点初始值为0，各相邻节点的实际距离为边线上的值。\n\n图二：以“起始节点”为“当前节点”，计算出到各相邻节点的最小距离，由于各相邻节点的初始值为99，比实际距离要大，所以更新各自的值，依次为2,6,9.\n\n图三：在2、6、9中最小的是2，所以将2作为“当前节点”，更新2的相邻节点为3(2+1=3),5(2+3=5<6).注意发现过的节点不能再计算，并且要遵守图的有向性。\n\n图四：在3、5中最小的是3，所以将3当做“当前节点”，更新3的相邻节点为4(3+1=4<5),9(3+6=9).\n\n图五：在4、9中最小的为4，所以将4当做“当前节点”，更新4的相邻节点为13(4+9=13),11(4+7=11),6(4+2=6<9).\n\n图六：在13,11,6中最小的为6，所以将6当做“当前节点”，更新6的相邻节点为10(6+4=10<11).\n\n图七：只有10这条路，所以更新10相邻的节点为11(10+1)\n\n图八：....\n\n图九：....\n\n## 3.算法思路\n\n让我们把开始的节点称为“起始节点”，从“起始节点”到节点Y的距离标记为Y。Dijkstra算法事先分配一些初始的距离值，并在后面逐步提高他们。\n\n1.分配给每个节点一个暂定的距离值，设置起始节点值为0，其余节点值为无限大。\n\n2.设置起始节点为当前(current)。标记其它所有节点为未发现(unvisited)。创建一个数据集合(包含所有未发现的节点),称作未发现数据集(unvisited set).\n\n3.对于当前的节点，考虑所有未访问过的邻居并计算出他们“暂时距离”。比较新计算出的“暂时距离”和当前分配的值，并分配较小的一个。例如，如果当前节点A被标记距离值为6，A距离邻居节点B的长度为2，计算出一个临时值(通过A)为6+2=8.如果B事先标记的值大于8，则将其改为8。否则，保持当前值。\n\n4.当我们考虑完所有当前节点的邻居节点后，标记当前节点为已发现节点(visited node)并且把它从未发现数据集(unvisited set)中移除。已发现节点(visited node)永远不会被再次检查。\n\n5.如果目标节点被标记为已发现(当规划两个节点之间的路径时)或者如果这个最小距离在未发现节点集合中被计算为无限大(当计划一个完整的遍历，发现没有一个连接从起始节点到剩余未访问的节点)，然后就停止，这个算法就结束了。\n\n6.否则，选择一个未访问过的节点(被标记为最小临时距离的)作为新的“当前节点”，然后回到步骤3重复执行。\n\n## 4.伪代码\n\n\t1\tfunction Dijkstra(Graph,source):\n\t2\n\t3\tdist[source] ← 0\t\t\t//从起始节点到起始节点的距离\n\t4\tprev[source] ← undefined\t//最优路径初始化中的前一个节点\n\t5\n\t6\tcreate vertex set Q \t\t//创建节点集\n\t7\t\n\t8\tfor each vertex v in Graph: //初始化\n\t9\t\t if v ≠ source:\t\t\t//v 还没从Q中移除(未发现的节点)\n\t10\t\t \tdist[v] ← INFINITY\t//不知道从source到v的距离\n\t11\t\t \tprev[v] ← UNDEFINED //上一个到source最佳路径的节点\n\t12\t\t add v to Q \t\t\t//Q中所有初始的节点(未发现的节点)\n\t13\n\t14\twhile Q is not empty:\n\t15\t\tu ← vertex in Q with min dist[u]\t//第一种情况下的源节点\n\t16\t\tremove u from Q\n\t17\n\t18\t\t\tfor each neighbor v of u:\t\t//v还在Q中\n\t19\t\t\t\talt ← dist[u] + length(u,v)\n\t20\t\t\t\tif alt < dist[v]:\t\t\t//到V的最短路径被发现\n\t21\t\t\t\t\tdist[v] ← alt\n\t22\t\t\t\t\tprev[v] ← u\n\t23\n\t24\treturn dist[],prev[]\n\n如果我们只是计算从源节点到目标节点的最短路径，我们可以在第16行后终止搜索，如果u = target。现在我们可以通过反向迭代的方式读取从源到目标的最短路径：\n\n\t1  S ← empty sequence\n\t2  u ← target\n\t3  while prev[u] is defined:                   // 用栈S构建最短路径\n\t4      insert u at the beginning of S          // 将顶点推到堆栈上\n\t5      u ← prev[u]                             // 从目标转向源节点\n\n**使用优先队列**：\n\n最小优先队列是一个抽象数据类型，它提供了3个基本操作：add_with_priority()，decrease_priority()和extract_min()。如前所述，使用这样的数据结构可以比使用一个基本队列产生更快的计算时间。值得注意的是，斐波那契堆（Fredman和Tarjan 1984提出的）或Brodal队列提供了这3个操作的最佳实现。由于算法是有点不同的，我们在这里提到了，它的伪代码：\n\n\t1  function Dijkstra(Graph, source):\n\t2      dist[source] ← 0                                    // 初始化\n\t3\n\t4      create vertex set Q\n\t5\n\t6      for each vertex v in Graph:           \n\t7          if v ≠ source\n\t8              dist[v] ← INFINITY                          // 不知道从源节点到V的距离\n\t9              prev[v] ← UNDEFINED                         // v的前一个节点\n\t10\n\t11         Q.add_with_priority(v, dist[v])\n\t12\n\t13\n\t14      while Q is not empty:                              // 主循环\n\t15         u ← Q.extract_min()                             // 删除并返回最佳顶点\n\t16         for each neighbor v of u:                       // 只有v仍然在Q中\n\t17             alt = dist[u] + length(u, v) \n\t18             if alt < dist[v]\n\t19                 dist[v] ← alt\n\t20                 prev[v] ← u\n\t21                 Q.decrease_priority(v, alt)\n\t22\n\t23     return dist[], prev[]\n\n不是在初始化时将所有节点都填充到优先级队列中，也可以在初始化时只包含源节点，当alt < dist[v]时，并且没有在队列中，那么这个节点必须被插入。\n\n## 5.代码实现\n\njava版：\n\n\n## 6.参考说明\n\n[MBA lib](http://wiki.mbalib.com/wiki/Dijkstra%E7%AE%97%E6%B3%95),\n[Wikipedia](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)","source":"_posts/2015-09-28-求最短路径算法-Dijkstra.md","raw":"---\nlayout: lay_post\ntitle: \"求最短路径算法-Dijkstra\"\ndate: 2015-09-28 20:24:00\ncategories: 算法\ntags: Search-algorithm\nauthor: lvyafei\n---\n\n## 0.算法属性\n\n**类别**：查找算法\n\n**数据结构**：图\n\n**性能**：O(|E|+|V|log|V|)\n\n## 1.算法介绍\n\nDijkstra算法是求图中两节点间最短路径的一种算法。它可以表示：例如，道路网络。\n\n它的构思是由计算机科学家Edsger W. Dijkstra在1956想出并在三年后提出的。\n\n这个算法存在许多版本；Dijkstra的最初版本是求两结点之间的最短路径，但更常见的版本是将单一节点作为“源”节点，去计算从源头到图中的所有其他节点的最短路径，并生成树。\n\n最短路径的算法被广泛应用于网络的路由协议，比如最著名的是OSPF(优先开放最短路径)。也被用作子算法，如[Johnson's algorithm](https://en.wikipedia.org/wiki/Johnson%27s_algorithm)\n<!-- more -->\n\n![](/images/Dijkstra/path.jpg)\n\nDijkstra原始算法并没有使用最小优先队列，运行时间为O(|V|^2)(其中|V|表示节点的数量)。\n\n这种算法思想在1957年被Leyzorek等人提出。在1984年被Fredman和Tarjan实现在斐波那契堆中，\n并且运行时间为O(|E|+|V|\\log|V|)(其中 |E|为边的数量)\n\n这是在任意有向图和无界非负权重的情况下，一个以渐进的方式最快的算出已知单源最短路径算法。\n\n## 2.算法示意图\n\n**示意一**：\n\n![](/images/Dijkstra/Dijkstra_Animation.gif)\n\n计算a到b的距离。其中：\n\n1.两点间的实际距离为连接线上的数字。\n\n2.节点圆圈中的数字为该节点的标示符。\n\n3.节点边上蓝色数字为起始节点a到该节点的最小距离。\n\n4.若计算出的距离值比当前所标示的距离值小，则更新反之不更新。节点初始值为无限大。\n\n5.访问过的节点标示为红色，下一次忽略该节点(即该节点的最小距离值不再改变,状态为out)。\n\n计算结果：\n\na到节点1的最小距离为：0\n\na到节点2的最小距离为: 7\n\na到节点3的最小距离为: 9\n\na到节点6的最小距离为：11\n\na到节点5的最小距离为: 20\n\n**示意二**：\n\n![](/images/Dijkstra/Dijkstras_progress_animation.gif)\n\n从开始节点(左下角的红色节点)到目标节点(右上角的绿色节点)的查找示意图。其中空心节点表示“暂定”集，填充节点表示\"被访问\"过的。颜色代表距离，颜色越绿代表距离越远。不同方向上的节点是均匀分布的，Dijkstra算法使用了一个启发式恒等于0，像波浪一样渐进发现节点。\n\n**示意三**：\n\n![](/images/Dijkstra/Dijkstra_detail.jpg)\n\n从左到右，从上到下：\n\n图一：以左上角的点为起始节点，计算到图中所有其它节点的最小距离。初始值为99(一个很大的值)，起始节点初始值为0，各相邻节点的实际距离为边线上的值。\n\n图二：以“起始节点”为“当前节点”，计算出到各相邻节点的最小距离，由于各相邻节点的初始值为99，比实际距离要大，所以更新各自的值，依次为2,6,9.\n\n图三：在2、6、9中最小的是2，所以将2作为“当前节点”，更新2的相邻节点为3(2+1=3),5(2+3=5<6).注意发现过的节点不能再计算，并且要遵守图的有向性。\n\n图四：在3、5中最小的是3，所以将3当做“当前节点”，更新3的相邻节点为4(3+1=4<5),9(3+6=9).\n\n图五：在4、9中最小的为4，所以将4当做“当前节点”，更新4的相邻节点为13(4+9=13),11(4+7=11),6(4+2=6<9).\n\n图六：在13,11,6中最小的为6，所以将6当做“当前节点”，更新6的相邻节点为10(6+4=10<11).\n\n图七：只有10这条路，所以更新10相邻的节点为11(10+1)\n\n图八：....\n\n图九：....\n\n## 3.算法思路\n\n让我们把开始的节点称为“起始节点”，从“起始节点”到节点Y的距离标记为Y。Dijkstra算法事先分配一些初始的距离值，并在后面逐步提高他们。\n\n1.分配给每个节点一个暂定的距离值，设置起始节点值为0，其余节点值为无限大。\n\n2.设置起始节点为当前(current)。标记其它所有节点为未发现(unvisited)。创建一个数据集合(包含所有未发现的节点),称作未发现数据集(unvisited set).\n\n3.对于当前的节点，考虑所有未访问过的邻居并计算出他们“暂时距离”。比较新计算出的“暂时距离”和当前分配的值，并分配较小的一个。例如，如果当前节点A被标记距离值为6，A距离邻居节点B的长度为2，计算出一个临时值(通过A)为6+2=8.如果B事先标记的值大于8，则将其改为8。否则，保持当前值。\n\n4.当我们考虑完所有当前节点的邻居节点后，标记当前节点为已发现节点(visited node)并且把它从未发现数据集(unvisited set)中移除。已发现节点(visited node)永远不会被再次检查。\n\n5.如果目标节点被标记为已发现(当规划两个节点之间的路径时)或者如果这个最小距离在未发现节点集合中被计算为无限大(当计划一个完整的遍历，发现没有一个连接从起始节点到剩余未访问的节点)，然后就停止，这个算法就结束了。\n\n6.否则，选择一个未访问过的节点(被标记为最小临时距离的)作为新的“当前节点”，然后回到步骤3重复执行。\n\n## 4.伪代码\n\n\t1\tfunction Dijkstra(Graph,source):\n\t2\n\t3\tdist[source] ← 0\t\t\t//从起始节点到起始节点的距离\n\t4\tprev[source] ← undefined\t//最优路径初始化中的前一个节点\n\t5\n\t6\tcreate vertex set Q \t\t//创建节点集\n\t7\t\n\t8\tfor each vertex v in Graph: //初始化\n\t9\t\t if v ≠ source:\t\t\t//v 还没从Q中移除(未发现的节点)\n\t10\t\t \tdist[v] ← INFINITY\t//不知道从source到v的距离\n\t11\t\t \tprev[v] ← UNDEFINED //上一个到source最佳路径的节点\n\t12\t\t add v to Q \t\t\t//Q中所有初始的节点(未发现的节点)\n\t13\n\t14\twhile Q is not empty:\n\t15\t\tu ← vertex in Q with min dist[u]\t//第一种情况下的源节点\n\t16\t\tremove u from Q\n\t17\n\t18\t\t\tfor each neighbor v of u:\t\t//v还在Q中\n\t19\t\t\t\talt ← dist[u] + length(u,v)\n\t20\t\t\t\tif alt < dist[v]:\t\t\t//到V的最短路径被发现\n\t21\t\t\t\t\tdist[v] ← alt\n\t22\t\t\t\t\tprev[v] ← u\n\t23\n\t24\treturn dist[],prev[]\n\n如果我们只是计算从源节点到目标节点的最短路径，我们可以在第16行后终止搜索，如果u = target。现在我们可以通过反向迭代的方式读取从源到目标的最短路径：\n\n\t1  S ← empty sequence\n\t2  u ← target\n\t3  while prev[u] is defined:                   // 用栈S构建最短路径\n\t4      insert u at the beginning of S          // 将顶点推到堆栈上\n\t5      u ← prev[u]                             // 从目标转向源节点\n\n**使用优先队列**：\n\n最小优先队列是一个抽象数据类型，它提供了3个基本操作：add_with_priority()，decrease_priority()和extract_min()。如前所述，使用这样的数据结构可以比使用一个基本队列产生更快的计算时间。值得注意的是，斐波那契堆（Fredman和Tarjan 1984提出的）或Brodal队列提供了这3个操作的最佳实现。由于算法是有点不同的，我们在这里提到了，它的伪代码：\n\n\t1  function Dijkstra(Graph, source):\n\t2      dist[source] ← 0                                    // 初始化\n\t3\n\t4      create vertex set Q\n\t5\n\t6      for each vertex v in Graph:           \n\t7          if v ≠ source\n\t8              dist[v] ← INFINITY                          // 不知道从源节点到V的距离\n\t9              prev[v] ← UNDEFINED                         // v的前一个节点\n\t10\n\t11         Q.add_with_priority(v, dist[v])\n\t12\n\t13\n\t14      while Q is not empty:                              // 主循环\n\t15         u ← Q.extract_min()                             // 删除并返回最佳顶点\n\t16         for each neighbor v of u:                       // 只有v仍然在Q中\n\t17             alt = dist[u] + length(u, v) \n\t18             if alt < dist[v]\n\t19                 dist[v] ← alt\n\t20                 prev[v] ← u\n\t21                 Q.decrease_priority(v, alt)\n\t22\n\t23     return dist[], prev[]\n\n不是在初始化时将所有节点都填充到优先级队列中，也可以在初始化时只包含源节点，当alt < dist[v]时，并且没有在队列中，那么这个节点必须被插入。\n\n## 5.代码实现\n\njava版：\n\n\n## 6.参考说明\n\n[MBA lib](http://wiki.mbalib.com/wiki/Dijkstra%E7%AE%97%E6%B3%95),\n[Wikipedia](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)","slug":"2015-09-28-求最短路径算法-Dijkstra","published":1,"updated":"2018-11-29T12:51:24.567Z","comments":1,"photos":[],"link":"","_id":"cjskffnwv000b4glm2w66ci9s","content":"<h2 id=\"0-算法属性\"><a href=\"#0-算法属性\" class=\"headerlink\" title=\"0.算法属性\"></a>0.算法属性</h2><p><strong>类别</strong>：查找算法</p>\n<p><strong>数据结构</strong>：图</p>\n<p><strong>性能</strong>：O(|E|+|V|log|V|)</p>\n<h2 id=\"1-算法介绍\"><a href=\"#1-算法介绍\" class=\"headerlink\" title=\"1.算法介绍\"></a>1.算法介绍</h2><p>Dijkstra算法是求图中两节点间最短路径的一种算法。它可以表示：例如，道路网络。</p>\n<p>它的构思是由计算机科学家Edsger W. Dijkstra在1956想出并在三年后提出的。</p>\n<p>这个算法存在许多版本；Dijkstra的最初版本是求两结点之间的最短路径，但更常见的版本是将单一节点作为“源”节点，去计算从源头到图中的所有其他节点的最短路径，并生成树。</p>\n<p>最短路径的算法被广泛应用于网络的路由协议，比如最著名的是OSPF(优先开放最短路径)。也被用作子算法，如<a href=\"https://en.wikipedia.org/wiki/Johnson%27s_algorithm\" target=\"_blank\" rel=\"noopener\">Johnson’s algorithm</a><br><a id=\"more\"></a></p>\n<p><img src=\"/images/Dijkstra/path.jpg\" alt=\"\"></p>\n<p>Dijkstra原始算法并没有使用最小优先队列，运行时间为O(|V|^2)(其中|V|表示节点的数量)。</p>\n<p>这种算法思想在1957年被Leyzorek等人提出。在1984年被Fredman和Tarjan实现在斐波那契堆中，<br>并且运行时间为O(|E|+|V|\\log|V|)(其中 |E|为边的数量)</p>\n<p>这是在任意有向图和无界非负权重的情况下，一个以渐进的方式最快的算出已知单源最短路径算法。</p>\n<h2 id=\"2-算法示意图\"><a href=\"#2-算法示意图\" class=\"headerlink\" title=\"2.算法示意图\"></a>2.算法示意图</h2><p><strong>示意一</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstra_Animation.gif\" alt=\"\"></p>\n<p>计算a到b的距离。其中：</p>\n<p>1.两点间的实际距离为连接线上的数字。</p>\n<p>2.节点圆圈中的数字为该节点的标示符。</p>\n<p>3.节点边上蓝色数字为起始节点a到该节点的最小距离。</p>\n<p>4.若计算出的距离值比当前所标示的距离值小，则更新反之不更新。节点初始值为无限大。</p>\n<p>5.访问过的节点标示为红色，下一次忽略该节点(即该节点的最小距离值不再改变,状态为out)。</p>\n<p>计算结果：</p>\n<p>a到节点1的最小距离为：0</p>\n<p>a到节点2的最小距离为: 7</p>\n<p>a到节点3的最小距离为: 9</p>\n<p>a到节点6的最小距离为：11</p>\n<p>a到节点5的最小距离为: 20</p>\n<p><strong>示意二</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstras_progress_animation.gif\" alt=\"\"></p>\n<p>从开始节点(左下角的红色节点)到目标节点(右上角的绿色节点)的查找示意图。其中空心节点表示“暂定”集，填充节点表示”被访问”过的。颜色代表距离，颜色越绿代表距离越远。不同方向上的节点是均匀分布的，Dijkstra算法使用了一个启发式恒等于0，像波浪一样渐进发现节点。</p>\n<p><strong>示意三</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstra_detail.jpg\" alt=\"\"></p>\n<p>从左到右，从上到下：</p>\n<p>图一：以左上角的点为起始节点，计算到图中所有其它节点的最小距离。初始值为99(一个很大的值)，起始节点初始值为0，各相邻节点的实际距离为边线上的值。</p>\n<p>图二：以“起始节点”为“当前节点”，计算出到各相邻节点的最小距离，由于各相邻节点的初始值为99，比实际距离要大，所以更新各自的值，依次为2,6,9.</p>\n<p>图三：在2、6、9中最小的是2，所以将2作为“当前节点”，更新2的相邻节点为3(2+1=3),5(2+3=5&lt;6).注意发现过的节点不能再计算，并且要遵守图的有向性。</p>\n<p>图四：在3、5中最小的是3，所以将3当做“当前节点”，更新3的相邻节点为4(3+1=4&lt;5),9(3+6=9).</p>\n<p>图五：在4、9中最小的为4，所以将4当做“当前节点”，更新4的相邻节点为13(4+9=13),11(4+7=11),6(4+2=6&lt;9).</p>\n<p>图六：在13,11,6中最小的为6，所以将6当做“当前节点”，更新6的相邻节点为10(6+4=10&lt;11).</p>\n<p>图七：只有10这条路，所以更新10相邻的节点为11(10+1)</p>\n<p>图八：….</p>\n<p>图九：….</p>\n<h2 id=\"3-算法思路\"><a href=\"#3-算法思路\" class=\"headerlink\" title=\"3.算法思路\"></a>3.算法思路</h2><p>让我们把开始的节点称为“起始节点”，从“起始节点”到节点Y的距离标记为Y。Dijkstra算法事先分配一些初始的距离值，并在后面逐步提高他们。</p>\n<p>1.分配给每个节点一个暂定的距离值，设置起始节点值为0，其余节点值为无限大。</p>\n<p>2.设置起始节点为当前(current)。标记其它所有节点为未发现(unvisited)。创建一个数据集合(包含所有未发现的节点),称作未发现数据集(unvisited set).</p>\n<p>3.对于当前的节点，考虑所有未访问过的邻居并计算出他们“暂时距离”。比较新计算出的“暂时距离”和当前分配的值，并分配较小的一个。例如，如果当前节点A被标记距离值为6，A距离邻居节点B的长度为2，计算出一个临时值(通过A)为6+2=8.如果B事先标记的值大于8，则将其改为8。否则，保持当前值。</p>\n<p>4.当我们考虑完所有当前节点的邻居节点后，标记当前节点为已发现节点(visited node)并且把它从未发现数据集(unvisited set)中移除。已发现节点(visited node)永远不会被再次检查。</p>\n<p>5.如果目标节点被标记为已发现(当规划两个节点之间的路径时)或者如果这个最小距离在未发现节点集合中被计算为无限大(当计划一个完整的遍历，发现没有一个连接从起始节点到剩余未访问的节点)，然后就停止，这个算法就结束了。</p>\n<p>6.否则，选择一个未访问过的节点(被标记为最小临时距离的)作为新的“当前节点”，然后回到步骤3重复执行。</p>\n<h2 id=\"4-伪代码\"><a href=\"#4-伪代码\" class=\"headerlink\" title=\"4.伪代码\"></a>4.伪代码</h2><pre><code>1    function Dijkstra(Graph,source):\n2\n3    dist[source] ← 0            //从起始节点到起始节点的距离\n4    prev[source] ← undefined    //最优路径初始化中的前一个节点\n5\n6    create vertex set Q         //创建节点集\n7    \n8    for each vertex v in Graph: //初始化\n9         if v ≠ source:            //v 还没从Q中移除(未发现的节点)\n10             dist[v] ← INFINITY    //不知道从source到v的距离\n11             prev[v] ← UNDEFINED //上一个到source最佳路径的节点\n12         add v to Q             //Q中所有初始的节点(未发现的节点)\n13\n14    while Q is not empty:\n15        u ← vertex in Q with min dist[u]    //第一种情况下的源节点\n16        remove u from Q\n17\n18            for each neighbor v of u:        //v还在Q中\n19                alt ← dist[u] + length(u,v)\n20                if alt &lt; dist[v]:            //到V的最短路径被发现\n21                    dist[v] ← alt\n22                    prev[v] ← u\n23\n24    return dist[],prev[]\n</code></pre><p>如果我们只是计算从源节点到目标节点的最短路径，我们可以在第16行后终止搜索，如果u = target。现在我们可以通过反向迭代的方式读取从源到目标的最短路径：</p>\n<pre><code>1  S ← empty sequence\n2  u ← target\n3  while prev[u] is defined:                   // 用栈S构建最短路径\n4      insert u at the beginning of S          // 将顶点推到堆栈上\n5      u ← prev[u]                             // 从目标转向源节点\n</code></pre><p><strong>使用优先队列</strong>：</p>\n<p>最小优先队列是一个抽象数据类型，它提供了3个基本操作：add_with_priority()，decrease_priority()和extract_min()。如前所述，使用这样的数据结构可以比使用一个基本队列产生更快的计算时间。值得注意的是，斐波那契堆（Fredman和Tarjan 1984提出的）或Brodal队列提供了这3个操作的最佳实现。由于算法是有点不同的，我们在这里提到了，它的伪代码：</p>\n<pre><code>1  function Dijkstra(Graph, source):\n2      dist[source] ← 0                                    // 初始化\n3\n4      create vertex set Q\n5\n6      for each vertex v in Graph:           \n7          if v ≠ source\n8              dist[v] ← INFINITY                          // 不知道从源节点到V的距离\n9              prev[v] ← UNDEFINED                         // v的前一个节点\n10\n11         Q.add_with_priority(v, dist[v])\n12\n13\n14      while Q is not empty:                              // 主循环\n15         u ← Q.extract_min()                             // 删除并返回最佳顶点\n16         for each neighbor v of u:                       // 只有v仍然在Q中\n17             alt = dist[u] + length(u, v) \n18             if alt &lt; dist[v]\n19                 dist[v] ← alt\n20                 prev[v] ← u\n21                 Q.decrease_priority(v, alt)\n22\n23     return dist[], prev[]\n</code></pre><p>不是在初始化时将所有节点都填充到优先级队列中，也可以在初始化时只包含源节点，当alt &lt; dist[v]时，并且没有在队列中，那么这个节点必须被插入。</p>\n<h2 id=\"5-代码实现\"><a href=\"#5-代码实现\" class=\"headerlink\" title=\"5.代码实现\"></a>5.代码实现</h2><p>java版：</p>\n<h2 id=\"6-参考说明\"><a href=\"#6-参考说明\" class=\"headerlink\" title=\"6.参考说明\"></a>6.参考说明</h2><p><a href=\"http://wiki.mbalib.com/wiki/Dijkstra%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"noopener\">MBA lib</a>,<br><a href=\"https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm\" target=\"_blank\" rel=\"noopener\">Wikipedia</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-算法属性\"><a href=\"#0-算法属性\" class=\"headerlink\" title=\"0.算法属性\"></a>0.算法属性</h2><p><strong>类别</strong>：查找算法</p>\n<p><strong>数据结构</strong>：图</p>\n<p><strong>性能</strong>：O(|E|+|V|log|V|)</p>\n<h2 id=\"1-算法介绍\"><a href=\"#1-算法介绍\" class=\"headerlink\" title=\"1.算法介绍\"></a>1.算法介绍</h2><p>Dijkstra算法是求图中两节点间最短路径的一种算法。它可以表示：例如，道路网络。</p>\n<p>它的构思是由计算机科学家Edsger W. Dijkstra在1956想出并在三年后提出的。</p>\n<p>这个算法存在许多版本；Dijkstra的最初版本是求两结点之间的最短路径，但更常见的版本是将单一节点作为“源”节点，去计算从源头到图中的所有其他节点的最短路径，并生成树。</p>\n<p>最短路径的算法被广泛应用于网络的路由协议，比如最著名的是OSPF(优先开放最短路径)。也被用作子算法，如<a href=\"https://en.wikipedia.org/wiki/Johnson%27s_algorithm\" target=\"_blank\" rel=\"noopener\">Johnson’s algorithm</a><br>","more":"</p>\n<p><img src=\"/images/Dijkstra/path.jpg\" alt=\"\"></p>\n<p>Dijkstra原始算法并没有使用最小优先队列，运行时间为O(|V|^2)(其中|V|表示节点的数量)。</p>\n<p>这种算法思想在1957年被Leyzorek等人提出。在1984年被Fredman和Tarjan实现在斐波那契堆中，<br>并且运行时间为O(|E|+|V|\\log|V|)(其中 |E|为边的数量)</p>\n<p>这是在任意有向图和无界非负权重的情况下，一个以渐进的方式最快的算出已知单源最短路径算法。</p>\n<h2 id=\"2-算法示意图\"><a href=\"#2-算法示意图\" class=\"headerlink\" title=\"2.算法示意图\"></a>2.算法示意图</h2><p><strong>示意一</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstra_Animation.gif\" alt=\"\"></p>\n<p>计算a到b的距离。其中：</p>\n<p>1.两点间的实际距离为连接线上的数字。</p>\n<p>2.节点圆圈中的数字为该节点的标示符。</p>\n<p>3.节点边上蓝色数字为起始节点a到该节点的最小距离。</p>\n<p>4.若计算出的距离值比当前所标示的距离值小，则更新反之不更新。节点初始值为无限大。</p>\n<p>5.访问过的节点标示为红色，下一次忽略该节点(即该节点的最小距离值不再改变,状态为out)。</p>\n<p>计算结果：</p>\n<p>a到节点1的最小距离为：0</p>\n<p>a到节点2的最小距离为: 7</p>\n<p>a到节点3的最小距离为: 9</p>\n<p>a到节点6的最小距离为：11</p>\n<p>a到节点5的最小距离为: 20</p>\n<p><strong>示意二</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstras_progress_animation.gif\" alt=\"\"></p>\n<p>从开始节点(左下角的红色节点)到目标节点(右上角的绿色节点)的查找示意图。其中空心节点表示“暂定”集，填充节点表示”被访问”过的。颜色代表距离，颜色越绿代表距离越远。不同方向上的节点是均匀分布的，Dijkstra算法使用了一个启发式恒等于0，像波浪一样渐进发现节点。</p>\n<p><strong>示意三</strong>：</p>\n<p><img src=\"/images/Dijkstra/Dijkstra_detail.jpg\" alt=\"\"></p>\n<p>从左到右，从上到下：</p>\n<p>图一：以左上角的点为起始节点，计算到图中所有其它节点的最小距离。初始值为99(一个很大的值)，起始节点初始值为0，各相邻节点的实际距离为边线上的值。</p>\n<p>图二：以“起始节点”为“当前节点”，计算出到各相邻节点的最小距离，由于各相邻节点的初始值为99，比实际距离要大，所以更新各自的值，依次为2,6,9.</p>\n<p>图三：在2、6、9中最小的是2，所以将2作为“当前节点”，更新2的相邻节点为3(2+1=3),5(2+3=5&lt;6).注意发现过的节点不能再计算，并且要遵守图的有向性。</p>\n<p>图四：在3、5中最小的是3，所以将3当做“当前节点”，更新3的相邻节点为4(3+1=4&lt;5),9(3+6=9).</p>\n<p>图五：在4、9中最小的为4，所以将4当做“当前节点”，更新4的相邻节点为13(4+9=13),11(4+7=11),6(4+2=6&lt;9).</p>\n<p>图六：在13,11,6中最小的为6，所以将6当做“当前节点”，更新6的相邻节点为10(6+4=10&lt;11).</p>\n<p>图七：只有10这条路，所以更新10相邻的节点为11(10+1)</p>\n<p>图八：….</p>\n<p>图九：….</p>\n<h2 id=\"3-算法思路\"><a href=\"#3-算法思路\" class=\"headerlink\" title=\"3.算法思路\"></a>3.算法思路</h2><p>让我们把开始的节点称为“起始节点”，从“起始节点”到节点Y的距离标记为Y。Dijkstra算法事先分配一些初始的距离值，并在后面逐步提高他们。</p>\n<p>1.分配给每个节点一个暂定的距离值，设置起始节点值为0，其余节点值为无限大。</p>\n<p>2.设置起始节点为当前(current)。标记其它所有节点为未发现(unvisited)。创建一个数据集合(包含所有未发现的节点),称作未发现数据集(unvisited set).</p>\n<p>3.对于当前的节点，考虑所有未访问过的邻居并计算出他们“暂时距离”。比较新计算出的“暂时距离”和当前分配的值，并分配较小的一个。例如，如果当前节点A被标记距离值为6，A距离邻居节点B的长度为2，计算出一个临时值(通过A)为6+2=8.如果B事先标记的值大于8，则将其改为8。否则，保持当前值。</p>\n<p>4.当我们考虑完所有当前节点的邻居节点后，标记当前节点为已发现节点(visited node)并且把它从未发现数据集(unvisited set)中移除。已发现节点(visited node)永远不会被再次检查。</p>\n<p>5.如果目标节点被标记为已发现(当规划两个节点之间的路径时)或者如果这个最小距离在未发现节点集合中被计算为无限大(当计划一个完整的遍历，发现没有一个连接从起始节点到剩余未访问的节点)，然后就停止，这个算法就结束了。</p>\n<p>6.否则，选择一个未访问过的节点(被标记为最小临时距离的)作为新的“当前节点”，然后回到步骤3重复执行。</p>\n<h2 id=\"4-伪代码\"><a href=\"#4-伪代码\" class=\"headerlink\" title=\"4.伪代码\"></a>4.伪代码</h2><pre><code>1    function Dijkstra(Graph,source):\n2\n3    dist[source] ← 0            //从起始节点到起始节点的距离\n4    prev[source] ← undefined    //最优路径初始化中的前一个节点\n5\n6    create vertex set Q         //创建节点集\n7    \n8    for each vertex v in Graph: //初始化\n9         if v ≠ source:            //v 还没从Q中移除(未发现的节点)\n10             dist[v] ← INFINITY    //不知道从source到v的距离\n11             prev[v] ← UNDEFINED //上一个到source最佳路径的节点\n12         add v to Q             //Q中所有初始的节点(未发现的节点)\n13\n14    while Q is not empty:\n15        u ← vertex in Q with min dist[u]    //第一种情况下的源节点\n16        remove u from Q\n17\n18            for each neighbor v of u:        //v还在Q中\n19                alt ← dist[u] + length(u,v)\n20                if alt &lt; dist[v]:            //到V的最短路径被发现\n21                    dist[v] ← alt\n22                    prev[v] ← u\n23\n24    return dist[],prev[]\n</code></pre><p>如果我们只是计算从源节点到目标节点的最短路径，我们可以在第16行后终止搜索，如果u = target。现在我们可以通过反向迭代的方式读取从源到目标的最短路径：</p>\n<pre><code>1  S ← empty sequence\n2  u ← target\n3  while prev[u] is defined:                   // 用栈S构建最短路径\n4      insert u at the beginning of S          // 将顶点推到堆栈上\n5      u ← prev[u]                             // 从目标转向源节点\n</code></pre><p><strong>使用优先队列</strong>：</p>\n<p>最小优先队列是一个抽象数据类型，它提供了3个基本操作：add_with_priority()，decrease_priority()和extract_min()。如前所述，使用这样的数据结构可以比使用一个基本队列产生更快的计算时间。值得注意的是，斐波那契堆（Fredman和Tarjan 1984提出的）或Brodal队列提供了这3个操作的最佳实现。由于算法是有点不同的，我们在这里提到了，它的伪代码：</p>\n<pre><code>1  function Dijkstra(Graph, source):\n2      dist[source] ← 0                                    // 初始化\n3\n4      create vertex set Q\n5\n6      for each vertex v in Graph:           \n7          if v ≠ source\n8              dist[v] ← INFINITY                          // 不知道从源节点到V的距离\n9              prev[v] ← UNDEFINED                         // v的前一个节点\n10\n11         Q.add_with_priority(v, dist[v])\n12\n13\n14      while Q is not empty:                              // 主循环\n15         u ← Q.extract_min()                             // 删除并返回最佳顶点\n16         for each neighbor v of u:                       // 只有v仍然在Q中\n17             alt = dist[u] + length(u, v) \n18             if alt &lt; dist[v]\n19                 dist[v] ← alt\n20                 prev[v] ← u\n21                 Q.decrease_priority(v, alt)\n22\n23     return dist[], prev[]\n</code></pre><p>不是在初始化时将所有节点都填充到优先级队列中，也可以在初始化时只包含源节点，当alt &lt; dist[v]时，并且没有在队列中，那么这个节点必须被插入。</p>\n<h2 id=\"5-代码实现\"><a href=\"#5-代码实现\" class=\"headerlink\" title=\"5.代码实现\"></a>5.代码实现</h2><p>java版：</p>\n<h2 id=\"6-参考说明\"><a href=\"#6-参考说明\" class=\"headerlink\" title=\"6.参考说明\"></a>6.参考说明</h2><p><a href=\"http://wiki.mbalib.com/wiki/Dijkstra%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"noopener\">MBA lib</a>,<br><a href=\"https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm\" target=\"_blank\" rel=\"noopener\">Wikipedia</a></p>"},{"layout":"lay_post","title":"项目管理之如何提高工作效率","date":"2015-11-01T11:47:00.000Z","author":"lvyafei","_content":"\n## 0.背景\n\n最近项目马上就要进入攻坚阶段了，前期的需求分析和目前的工作进度都存在一定程度的不足。作为这个项目中的参与者，我身有体会当时间越来越短，客户要的东西越来越逼近，我们会忙得不可开交。会议一个接一个，客户在不断的要求我们交付一些中间产物，而我们也在马不停蹄的赶功能，按着前期的需求分析一步一步在实现每个模块。\n<!-- more -->\n突然间感到想迈开步子大步向前，但是脚下好像绊着很多的障碍，项目的进度缓慢，我需要把自己理解的东西一遍一遍的向别人讲述，但是作用不是很大，我在思考到底是什么影响了项目的进度？从众多的因素中我慢慢看清了一些，比如客户的需求还在变动，一些外围的支持不到位，团队的整体能力不强，时间的规划不科学等。\n\n这么多的因素中我能自己改变的东西很少，并且很多因素是做项目常遇到的，比如客户需求的不断变化，有的需求客户也只是前期的一个想法，但后期会不断的讨论讨论，耽误了真正需要花费时间的内容。外围的支持不到位，这个是项目的决策者去改变的，我只能及时提出发现的问题，不能等到真正遇到的时候才提出来。还有时间的规划，这一点我也没有权利去要求，合同上写的时间既然你签了就要在这个时间点内交出东西，别的都是屁话。最后一点：团队的效率问题，这一点就是我自己认为能够稍稍改变的东西，我自己也身为其中一员，自己能看到一些问题。\n\n## 1.在一个项目中个人工作效率与哪些因素有关？\n\n一个项目是由一个团队去完成的，团队的整体力量是否强看的是每个人的能力，最短的板子决定了木桶装水的总量。一个人的工作效率的高低和自己的能力还有外围的阻力有关系。\n\n能力一般的人，可能是这样：\n\n![能力一般](/images/项目管理/能力一般.png)\n\n能力较强的人，可能是这样：\n\n![能力较强](/images/项目管理/能力较强.png)\n\n能力较差的人，可能是这样：\n\n![能力较差](/images/项目管理/能力较差.png)\n\n可以看到同样的工作量，在规定的时间内，能力不一样的人完成需要的时间也是不一样的。但是工作效率不仅和个人的工作能力有关系，还与工作中遇到的阻力有关系，试想如果一个能力很很高的人，但是相关资源不到位，也同样会延期完成任务。\n\n**能力**：能力是一个队员在完成任务时平均花费的时间。能力与自己的工作经验，工作习惯、技术的积累、理解能力、沟通能力等因素有关。并且随着工作年限的增长每个人的能力都会不同程度的提升。\n\n**阻力**：阻力是分配给一个队员的任务中遇到的外围因素的干扰。比如相关资源不到位，外围环境的影响，生活琐事的影响等，作为项目的管理者和负责人应当尽量减少队员的阻力，这样对整体的工作效率都会有很大的提升。\n\n## 2.项目中的风险把控\n\n项目中的风险有一些会在前期暴露出来，有些是在项目中暴露出来。项目前期的风险可以做到风险防御和风险规避，但是中期的风险是最可怕的，如果处理不好，将会影响整个项目的进度和最终的效果。\n\n需求分析过程中要把项目会遇到的风险主管推断出来，不然后期就会一直遇到问题，让人精疲力尽，这个阶段也是发现问题，推断问题的关键时期，要把项目中的问题整理梳理一遍，讨论解决，要是等到建设过程中才发现就会害死人的。\n\n项目中期发现风险要及时提出，及时解决。项目负责人和管理者要阶段性的总结发现问题，如果想一劳永逸的靠前期的需求分析就会漏洞百出，因为风险的出现和外围的因素有很大的关系，比如客户的主观改变、实际的发展和预期不一致等。\n\n## 3.关于团队建设\n\n团队的建设是一个很需要思考的问题，整体人员的水平决定了项目的最终的效果。客户对这个也很看重，尤其对于投标性的项目，很注重团队的建设。做项目是在和人打交道，和客户和领导和同事。管项目是在和人打交道，分配任务要看人看内容，不能蒙着眼分配。一些风投在投资项目时如果是一个黄金团队就会很愿意投，如果没有背景的团队(当然是实力了),再好的点子也会犹豫不定的。","source":"_posts/2015-11-01-项目管理之如何提高工作效率.md","raw":"---\nlayout: lay_post\ntitle: \"项目管理之如何提高工作效率\"\ndate: 2015-11-1 19:47:00\ncategories: 项目管理\ntags: 工作效率\nauthor: lvyafei\n---\n\n## 0.背景\n\n最近项目马上就要进入攻坚阶段了，前期的需求分析和目前的工作进度都存在一定程度的不足。作为这个项目中的参与者，我身有体会当时间越来越短，客户要的东西越来越逼近，我们会忙得不可开交。会议一个接一个，客户在不断的要求我们交付一些中间产物，而我们也在马不停蹄的赶功能，按着前期的需求分析一步一步在实现每个模块。\n<!-- more -->\n突然间感到想迈开步子大步向前，但是脚下好像绊着很多的障碍，项目的进度缓慢，我需要把自己理解的东西一遍一遍的向别人讲述，但是作用不是很大，我在思考到底是什么影响了项目的进度？从众多的因素中我慢慢看清了一些，比如客户的需求还在变动，一些外围的支持不到位，团队的整体能力不强，时间的规划不科学等。\n\n这么多的因素中我能自己改变的东西很少，并且很多因素是做项目常遇到的，比如客户需求的不断变化，有的需求客户也只是前期的一个想法，但后期会不断的讨论讨论，耽误了真正需要花费时间的内容。外围的支持不到位，这个是项目的决策者去改变的，我只能及时提出发现的问题，不能等到真正遇到的时候才提出来。还有时间的规划，这一点我也没有权利去要求，合同上写的时间既然你签了就要在这个时间点内交出东西，别的都是屁话。最后一点：团队的效率问题，这一点就是我自己认为能够稍稍改变的东西，我自己也身为其中一员，自己能看到一些问题。\n\n## 1.在一个项目中个人工作效率与哪些因素有关？\n\n一个项目是由一个团队去完成的，团队的整体力量是否强看的是每个人的能力，最短的板子决定了木桶装水的总量。一个人的工作效率的高低和自己的能力还有外围的阻力有关系。\n\n能力一般的人，可能是这样：\n\n![能力一般](/images/项目管理/能力一般.png)\n\n能力较强的人，可能是这样：\n\n![能力较强](/images/项目管理/能力较强.png)\n\n能力较差的人，可能是这样：\n\n![能力较差](/images/项目管理/能力较差.png)\n\n可以看到同样的工作量，在规定的时间内，能力不一样的人完成需要的时间也是不一样的。但是工作效率不仅和个人的工作能力有关系，还与工作中遇到的阻力有关系，试想如果一个能力很很高的人，但是相关资源不到位，也同样会延期完成任务。\n\n**能力**：能力是一个队员在完成任务时平均花费的时间。能力与自己的工作经验，工作习惯、技术的积累、理解能力、沟通能力等因素有关。并且随着工作年限的增长每个人的能力都会不同程度的提升。\n\n**阻力**：阻力是分配给一个队员的任务中遇到的外围因素的干扰。比如相关资源不到位，外围环境的影响，生活琐事的影响等，作为项目的管理者和负责人应当尽量减少队员的阻力，这样对整体的工作效率都会有很大的提升。\n\n## 2.项目中的风险把控\n\n项目中的风险有一些会在前期暴露出来，有些是在项目中暴露出来。项目前期的风险可以做到风险防御和风险规避，但是中期的风险是最可怕的，如果处理不好，将会影响整个项目的进度和最终的效果。\n\n需求分析过程中要把项目会遇到的风险主管推断出来，不然后期就会一直遇到问题，让人精疲力尽，这个阶段也是发现问题，推断问题的关键时期，要把项目中的问题整理梳理一遍，讨论解决，要是等到建设过程中才发现就会害死人的。\n\n项目中期发现风险要及时提出，及时解决。项目负责人和管理者要阶段性的总结发现问题，如果想一劳永逸的靠前期的需求分析就会漏洞百出，因为风险的出现和外围的因素有很大的关系，比如客户的主观改变、实际的发展和预期不一致等。\n\n## 3.关于团队建设\n\n团队的建设是一个很需要思考的问题，整体人员的水平决定了项目的最终的效果。客户对这个也很看重，尤其对于投标性的项目，很注重团队的建设。做项目是在和人打交道，和客户和领导和同事。管项目是在和人打交道，分配任务要看人看内容，不能蒙着眼分配。一些风投在投资项目时如果是一个黄金团队就会很愿意投，如果没有背景的团队(当然是实力了),再好的点子也会犹豫不定的。","slug":"2015-11-01-项目管理之如何提高工作效率","published":1,"updated":"2018-11-29T12:51:24.579Z","comments":1,"photos":[],"link":"","_id":"cjskffnxb000f4glmraz90dp7","content":"<h2 id=\"0-背景\"><a href=\"#0-背景\" class=\"headerlink\" title=\"0.背景\"></a>0.背景</h2><p>最近项目马上就要进入攻坚阶段了，前期的需求分析和目前的工作进度都存在一定程度的不足。作为这个项目中的参与者，我身有体会当时间越来越短，客户要的东西越来越逼近，我们会忙得不可开交。会议一个接一个，客户在不断的要求我们交付一些中间产物，而我们也在马不停蹄的赶功能，按着前期的需求分析一步一步在实现每个模块。<br><a id=\"more\"></a><br>突然间感到想迈开步子大步向前，但是脚下好像绊着很多的障碍，项目的进度缓慢，我需要把自己理解的东西一遍一遍的向别人讲述，但是作用不是很大，我在思考到底是什么影响了项目的进度？从众多的因素中我慢慢看清了一些，比如客户的需求还在变动，一些外围的支持不到位，团队的整体能力不强，时间的规划不科学等。</p>\n<p>这么多的因素中我能自己改变的东西很少，并且很多因素是做项目常遇到的，比如客户需求的不断变化，有的需求客户也只是前期的一个想法，但后期会不断的讨论讨论，耽误了真正需要花费时间的内容。外围的支持不到位，这个是项目的决策者去改变的，我只能及时提出发现的问题，不能等到真正遇到的时候才提出来。还有时间的规划，这一点我也没有权利去要求，合同上写的时间既然你签了就要在这个时间点内交出东西，别的都是屁话。最后一点：团队的效率问题，这一点就是我自己认为能够稍稍改变的东西，我自己也身为其中一员，自己能看到一些问题。</p>\n<h2 id=\"1-在一个项目中个人工作效率与哪些因素有关？\"><a href=\"#1-在一个项目中个人工作效率与哪些因素有关？\" class=\"headerlink\" title=\"1.在一个项目中个人工作效率与哪些因素有关？\"></a>1.在一个项目中个人工作效率与哪些因素有关？</h2><p>一个项目是由一个团队去完成的，团队的整体力量是否强看的是每个人的能力，最短的板子决定了木桶装水的总量。一个人的工作效率的高低和自己的能力还有外围的阻力有关系。</p>\n<p>能力一般的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力一般.png\" alt=\"能力一般\"></p>\n<p>能力较强的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力较强.png\" alt=\"能力较强\"></p>\n<p>能力较差的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力较差.png\" alt=\"能力较差\"></p>\n<p>可以看到同样的工作量，在规定的时间内，能力不一样的人完成需要的时间也是不一样的。但是工作效率不仅和个人的工作能力有关系，还与工作中遇到的阻力有关系，试想如果一个能力很很高的人，但是相关资源不到位，也同样会延期完成任务。</p>\n<p><strong>能力</strong>：能力是一个队员在完成任务时平均花费的时间。能力与自己的工作经验，工作习惯、技术的积累、理解能力、沟通能力等因素有关。并且随着工作年限的增长每个人的能力都会不同程度的提升。</p>\n<p><strong>阻力</strong>：阻力是分配给一个队员的任务中遇到的外围因素的干扰。比如相关资源不到位，外围环境的影响，生活琐事的影响等，作为项目的管理者和负责人应当尽量减少队员的阻力，这样对整体的工作效率都会有很大的提升。</p>\n<h2 id=\"2-项目中的风险把控\"><a href=\"#2-项目中的风险把控\" class=\"headerlink\" title=\"2.项目中的风险把控\"></a>2.项目中的风险把控</h2><p>项目中的风险有一些会在前期暴露出来，有些是在项目中暴露出来。项目前期的风险可以做到风险防御和风险规避，但是中期的风险是最可怕的，如果处理不好，将会影响整个项目的进度和最终的效果。</p>\n<p>需求分析过程中要把项目会遇到的风险主管推断出来，不然后期就会一直遇到问题，让人精疲力尽，这个阶段也是发现问题，推断问题的关键时期，要把项目中的问题整理梳理一遍，讨论解决，要是等到建设过程中才发现就会害死人的。</p>\n<p>项目中期发现风险要及时提出，及时解决。项目负责人和管理者要阶段性的总结发现问题，如果想一劳永逸的靠前期的需求分析就会漏洞百出，因为风险的出现和外围的因素有很大的关系，比如客户的主观改变、实际的发展和预期不一致等。</p>\n<h2 id=\"3-关于团队建设\"><a href=\"#3-关于团队建设\" class=\"headerlink\" title=\"3.关于团队建设\"></a>3.关于团队建设</h2><p>团队的建设是一个很需要思考的问题，整体人员的水平决定了项目的最终的效果。客户对这个也很看重，尤其对于投标性的项目，很注重团队的建设。做项目是在和人打交道，和客户和领导和同事。管项目是在和人打交道，分配任务要看人看内容，不能蒙着眼分配。一些风投在投资项目时如果是一个黄金团队就会很愿意投，如果没有背景的团队(当然是实力了),再好的点子也会犹豫不定的。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-背景\"><a href=\"#0-背景\" class=\"headerlink\" title=\"0.背景\"></a>0.背景</h2><p>最近项目马上就要进入攻坚阶段了，前期的需求分析和目前的工作进度都存在一定程度的不足。作为这个项目中的参与者，我身有体会当时间越来越短，客户要的东西越来越逼近，我们会忙得不可开交。会议一个接一个，客户在不断的要求我们交付一些中间产物，而我们也在马不停蹄的赶功能，按着前期的需求分析一步一步在实现每个模块。<br>","more":"<br>突然间感到想迈开步子大步向前，但是脚下好像绊着很多的障碍，项目的进度缓慢，我需要把自己理解的东西一遍一遍的向别人讲述，但是作用不是很大，我在思考到底是什么影响了项目的进度？从众多的因素中我慢慢看清了一些，比如客户的需求还在变动，一些外围的支持不到位，团队的整体能力不强，时间的规划不科学等。</p>\n<p>这么多的因素中我能自己改变的东西很少，并且很多因素是做项目常遇到的，比如客户需求的不断变化，有的需求客户也只是前期的一个想法，但后期会不断的讨论讨论，耽误了真正需要花费时间的内容。外围的支持不到位，这个是项目的决策者去改变的，我只能及时提出发现的问题，不能等到真正遇到的时候才提出来。还有时间的规划，这一点我也没有权利去要求，合同上写的时间既然你签了就要在这个时间点内交出东西，别的都是屁话。最后一点：团队的效率问题，这一点就是我自己认为能够稍稍改变的东西，我自己也身为其中一员，自己能看到一些问题。</p>\n<h2 id=\"1-在一个项目中个人工作效率与哪些因素有关？\"><a href=\"#1-在一个项目中个人工作效率与哪些因素有关？\" class=\"headerlink\" title=\"1.在一个项目中个人工作效率与哪些因素有关？\"></a>1.在一个项目中个人工作效率与哪些因素有关？</h2><p>一个项目是由一个团队去完成的，团队的整体力量是否强看的是每个人的能力，最短的板子决定了木桶装水的总量。一个人的工作效率的高低和自己的能力还有外围的阻力有关系。</p>\n<p>能力一般的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力一般.png\" alt=\"能力一般\"></p>\n<p>能力较强的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力较强.png\" alt=\"能力较强\"></p>\n<p>能力较差的人，可能是这样：</p>\n<p><img src=\"/images/项目管理/能力较差.png\" alt=\"能力较差\"></p>\n<p>可以看到同样的工作量，在规定的时间内，能力不一样的人完成需要的时间也是不一样的。但是工作效率不仅和个人的工作能力有关系，还与工作中遇到的阻力有关系，试想如果一个能力很很高的人，但是相关资源不到位，也同样会延期完成任务。</p>\n<p><strong>能力</strong>：能力是一个队员在完成任务时平均花费的时间。能力与自己的工作经验，工作习惯、技术的积累、理解能力、沟通能力等因素有关。并且随着工作年限的增长每个人的能力都会不同程度的提升。</p>\n<p><strong>阻力</strong>：阻力是分配给一个队员的任务中遇到的外围因素的干扰。比如相关资源不到位，外围环境的影响，生活琐事的影响等，作为项目的管理者和负责人应当尽量减少队员的阻力，这样对整体的工作效率都会有很大的提升。</p>\n<h2 id=\"2-项目中的风险把控\"><a href=\"#2-项目中的风险把控\" class=\"headerlink\" title=\"2.项目中的风险把控\"></a>2.项目中的风险把控</h2><p>项目中的风险有一些会在前期暴露出来，有些是在项目中暴露出来。项目前期的风险可以做到风险防御和风险规避，但是中期的风险是最可怕的，如果处理不好，将会影响整个项目的进度和最终的效果。</p>\n<p>需求分析过程中要把项目会遇到的风险主管推断出来，不然后期就会一直遇到问题，让人精疲力尽，这个阶段也是发现问题，推断问题的关键时期，要把项目中的问题整理梳理一遍，讨论解决，要是等到建设过程中才发现就会害死人的。</p>\n<p>项目中期发现风险要及时提出，及时解决。项目负责人和管理者要阶段性的总结发现问题，如果想一劳永逸的靠前期的需求分析就会漏洞百出，因为风险的出现和外围的因素有很大的关系，比如客户的主观改变、实际的发展和预期不一致等。</p>\n<h2 id=\"3-关于团队建设\"><a href=\"#3-关于团队建设\" class=\"headerlink\" title=\"3.关于团队建设\"></a>3.关于团队建设</h2><p>团队的建设是一个很需要思考的问题，整体人员的水平决定了项目的最终的效果。客户对这个也很看重，尤其对于投标性的项目，很注重团队的建设。做项目是在和人打交道，和客户和领导和同事。管项目是在和人打交道，分配任务要看人看内容，不能蒙着眼分配。一些风投在投资项目时如果是一个黄金团队就会很愿意投，如果没有背景的团队(当然是实力了),再好的点子也会犹豫不定的。</p>"},{"layout":"lay_post","title":"如何做好一个项目型的需求分析","date":"2016-01-17T01:56:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n无论你是一个产品经理或者项目经理,你都不能避免一件事情-需求分析。对于一个产品经理来说，需求分析就是挖掘用户的需求点，找到正确的、合理的、有效的、潜在的需求，对挖掘到的需求进行分析、归类、筛选，不断完善产品的功能，巩固产品的核心要素。而对于项目经理来说，由于是从一个项目的角度出发，所有的需求都是由客户发出的，要做的工作就是整理需求、理解需求，筛选需求，实现需求。无论怎样，都要经过下面的几个过程：对需求的收集、分析理解、筛选、管理以及挖掘。\n<!-- more -->\n\n![架构](/images/项目管理/需求分析.png)\n\n## 1.收集需求\n\n作为项目型的经理，在需求收集阶段需要数次和客户沟通。对于一个投标型的项目来说，客户的需求在规格说明书中会有所阐述，这个说明只是对客户的需求的一个自我的表述，不能很有调理的整理出来，需要我们沟通和确认。前期的沟通一定要充分的理解客户的需求，若对客户现有的需求不太理解，可以向客户阐述自己的理解。比较好的方式是画出架构图，逻辑图等，不断的和客户确认，直到客户认可未知，在这个阶段不仅要去理解，还要去把现有的产品和技术往需求上靠拢，最好能确定大致的模块，这个阶段能确认的东西越多后面遇到的问题就越少，最后一定要落实的文档或者线框图上，这对后期的需求管理留下了基础，也为需求的挖掘留下了依据。\n\n![架构](/images/项目管理/搜集需求.png)\n\n## 2.分析理解\n\n对收集过的需求进行分析的时候，要做到有理有据，结合现有的技术或者产品将客户的需求转换为解决方案，其实做需求分析的结果就是要产出一个符合客户的诉求和能够结合自身的产品或者技术优势的交付物。客户不仅仅是想我们去理解他的想法和愿景，更多的是在想我们发出帮助的信号，我们若能够帮着他来解决现有的问题将会得到很大的反响。有的时候提出需求的人其实未必是真的想好了如何去做，我们要及时的去理解和沟通它们真正的想法，只是一味的梳理客户的需求，而不去理解这些需求的本质，只能让我们后期被客户的无理需求牵着鼻子走。\n\n需求的最终交付物是一个能让客户满意的解决方案，这个方案和客户原本的需求规格说明书可能有很多的差异，这才是对需求理解的最终目的。因为人的想法在刚产生的时候会有很多不确定的因素在里面，随着和客户的不断交流，我们能够替他们去挑出一些真正的需求，在最终的剩下的需求里面，我们又能够将多个不同的想法组合和精简成一个可行的功能点。\n\n## 3.筛选需求\n\n筛选需求是在整理需求之后必经的一个阶段，该阶段中会有很多我们可以遵循的方法。最常用的有：做减法、做加法。\n\n需求分析人员要做的就是从这些林林总总的需求当中找出可实现的，有价值的需求，排除那些无意义，不可实现的需求，或者是当前暂时先不实现，或者是这个产品不实现但可以利用在别的产品身上的，反正与当前产品无关的需求，都需要排除掉，这个过程就是在做减法。比如说，我们收集到10个功能需求，觉得其中有两个是没必要做的，或者是可以以后再做的，就把这2个需求功能先排除掉，先做剩下的8个功能需求。应该来说，做减法是需求分析人员最\n基本的素养了，一般都是有东西去给你做减法的。\n\n需求分析人员依靠自身的工作经验，和对产品设计理念的理解，可以提出新的需求，这些新的需求不一定就是最终的需求，但需求分析人员要有能力去总结发现。因为往往人们在考虑问题的时候都是不全面的，所以才古语有云，三个臭皮匠顶个诸葛亮，把所有的意见综合在一起，很有可能就是个非常棒的点。这里做加法主要还是要依靠自身的经验来取决，比如要做5个功能需求，需求分析人员觉得应该再加上报表统计的功能，这就是在做加法。\n\n当我们面对一件全新的产品设计任务时，没有任何现成的数据去提供给我们做分析，或者说数据很少，这个时候需求分析人员要去挖掘需求，也可以说是发现新需求，这个新需求是全新的，没有任何经验可借鉴的。挖掘需求对于产品经理来说是必不可备的，因为一个产品的发展过程中需要不断地注入新鲜的元素，才能符合适合市场的需要。而对一个项目来说，深挖需求能够孵化出其他的潜在项目，这也是评价一个项目经理是否具有“可持续发展”的潜质。\n\n## 4.需求的管理\n\n对于很多刚入行做需求的人来说，分析需求可能是他们认为很重要的一个点，其实如果不能有效地把控需求，归纳和整理，在项目后期将会遇到一些让人不可预料的新的问题。因此，需求的管理是至关重要的，我们要不断地坚持总结和分析，这样才能够在客户提出问题之前，我们能够做到未雨绸缪。最好的办法是将每个阶段的需求按照时间线来整理，这样从一个时间的角度发现问题的本质。\n","source":"_posts/2016-01-17-如何做好一个项目型的需求分析.md","raw":"---\nlayout: lay_post\ntitle: \"如何做好一个项目型的需求分析\"\ndate: 2016-01-17 9:56:00\ncategories: 项目管理\ntags: 需求分析\nauthor: lvyafei\n---\n\n## 0.概述\n\n无论你是一个产品经理或者项目经理,你都不能避免一件事情-需求分析。对于一个产品经理来说，需求分析就是挖掘用户的需求点，找到正确的、合理的、有效的、潜在的需求，对挖掘到的需求进行分析、归类、筛选，不断完善产品的功能，巩固产品的核心要素。而对于项目经理来说，由于是从一个项目的角度出发，所有的需求都是由客户发出的，要做的工作就是整理需求、理解需求，筛选需求，实现需求。无论怎样，都要经过下面的几个过程：对需求的收集、分析理解、筛选、管理以及挖掘。\n<!-- more -->\n\n![架构](/images/项目管理/需求分析.png)\n\n## 1.收集需求\n\n作为项目型的经理，在需求收集阶段需要数次和客户沟通。对于一个投标型的项目来说，客户的需求在规格说明书中会有所阐述，这个说明只是对客户的需求的一个自我的表述，不能很有调理的整理出来，需要我们沟通和确认。前期的沟通一定要充分的理解客户的需求，若对客户现有的需求不太理解，可以向客户阐述自己的理解。比较好的方式是画出架构图，逻辑图等，不断的和客户确认，直到客户认可未知，在这个阶段不仅要去理解，还要去把现有的产品和技术往需求上靠拢，最好能确定大致的模块，这个阶段能确认的东西越多后面遇到的问题就越少，最后一定要落实的文档或者线框图上，这对后期的需求管理留下了基础，也为需求的挖掘留下了依据。\n\n![架构](/images/项目管理/搜集需求.png)\n\n## 2.分析理解\n\n对收集过的需求进行分析的时候，要做到有理有据，结合现有的技术或者产品将客户的需求转换为解决方案，其实做需求分析的结果就是要产出一个符合客户的诉求和能够结合自身的产品或者技术优势的交付物。客户不仅仅是想我们去理解他的想法和愿景，更多的是在想我们发出帮助的信号，我们若能够帮着他来解决现有的问题将会得到很大的反响。有的时候提出需求的人其实未必是真的想好了如何去做，我们要及时的去理解和沟通它们真正的想法，只是一味的梳理客户的需求，而不去理解这些需求的本质，只能让我们后期被客户的无理需求牵着鼻子走。\n\n需求的最终交付物是一个能让客户满意的解决方案，这个方案和客户原本的需求规格说明书可能有很多的差异，这才是对需求理解的最终目的。因为人的想法在刚产生的时候会有很多不确定的因素在里面，随着和客户的不断交流，我们能够替他们去挑出一些真正的需求，在最终的剩下的需求里面，我们又能够将多个不同的想法组合和精简成一个可行的功能点。\n\n## 3.筛选需求\n\n筛选需求是在整理需求之后必经的一个阶段，该阶段中会有很多我们可以遵循的方法。最常用的有：做减法、做加法。\n\n需求分析人员要做的就是从这些林林总总的需求当中找出可实现的，有价值的需求，排除那些无意义，不可实现的需求，或者是当前暂时先不实现，或者是这个产品不实现但可以利用在别的产品身上的，反正与当前产品无关的需求，都需要排除掉，这个过程就是在做减法。比如说，我们收集到10个功能需求，觉得其中有两个是没必要做的，或者是可以以后再做的，就把这2个需求功能先排除掉，先做剩下的8个功能需求。应该来说，做减法是需求分析人员最\n基本的素养了，一般都是有东西去给你做减法的。\n\n需求分析人员依靠自身的工作经验，和对产品设计理念的理解，可以提出新的需求，这些新的需求不一定就是最终的需求，但需求分析人员要有能力去总结发现。因为往往人们在考虑问题的时候都是不全面的，所以才古语有云，三个臭皮匠顶个诸葛亮，把所有的意见综合在一起，很有可能就是个非常棒的点。这里做加法主要还是要依靠自身的经验来取决，比如要做5个功能需求，需求分析人员觉得应该再加上报表统计的功能，这就是在做加法。\n\n当我们面对一件全新的产品设计任务时，没有任何现成的数据去提供给我们做分析，或者说数据很少，这个时候需求分析人员要去挖掘需求，也可以说是发现新需求，这个新需求是全新的，没有任何经验可借鉴的。挖掘需求对于产品经理来说是必不可备的，因为一个产品的发展过程中需要不断地注入新鲜的元素，才能符合适合市场的需要。而对一个项目来说，深挖需求能够孵化出其他的潜在项目，这也是评价一个项目经理是否具有“可持续发展”的潜质。\n\n## 4.需求的管理\n\n对于很多刚入行做需求的人来说，分析需求可能是他们认为很重要的一个点，其实如果不能有效地把控需求，归纳和整理，在项目后期将会遇到一些让人不可预料的新的问题。因此，需求的管理是至关重要的，我们要不断地坚持总结和分析，这样才能够在客户提出问题之前，我们能够做到未雨绸缪。最好的办法是将每个阶段的需求按照时间线来整理，这样从一个时间的角度发现问题的本质。\n","slug":"2016-01-17-如何做好一个项目型的需求分析","published":1,"updated":"2018-11-29T12:51:24.591Z","comments":1,"photos":[],"link":"","_id":"cjskffnxb000h4glmy1a3gzk7","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>无论你是一个产品经理或者项目经理,你都不能避免一件事情-需求分析。对于一个产品经理来说，需求分析就是挖掘用户的需求点，找到正确的、合理的、有效的、潜在的需求，对挖掘到的需求进行分析、归类、筛选，不断完善产品的功能，巩固产品的核心要素。而对于项目经理来说，由于是从一个项目的角度出发，所有的需求都是由客户发出的，要做的工作就是整理需求、理解需求，筛选需求，实现需求。无论怎样，都要经过下面的几个过程：对需求的收集、分析理解、筛选、管理以及挖掘。<br><a id=\"more\"></a></p>\n<p><img src=\"/images/项目管理/需求分析.png\" alt=\"架构\"></p>\n<h2 id=\"1-收集需求\"><a href=\"#1-收集需求\" class=\"headerlink\" title=\"1.收集需求\"></a>1.收集需求</h2><p>作为项目型的经理，在需求收集阶段需要数次和客户沟通。对于一个投标型的项目来说，客户的需求在规格说明书中会有所阐述，这个说明只是对客户的需求的一个自我的表述，不能很有调理的整理出来，需要我们沟通和确认。前期的沟通一定要充分的理解客户的需求，若对客户现有的需求不太理解，可以向客户阐述自己的理解。比较好的方式是画出架构图，逻辑图等，不断的和客户确认，直到客户认可未知，在这个阶段不仅要去理解，还要去把现有的产品和技术往需求上靠拢，最好能确定大致的模块，这个阶段能确认的东西越多后面遇到的问题就越少，最后一定要落实的文档或者线框图上，这对后期的需求管理留下了基础，也为需求的挖掘留下了依据。</p>\n<p><img src=\"/images/项目管理/搜集需求.png\" alt=\"架构\"></p>\n<h2 id=\"2-分析理解\"><a href=\"#2-分析理解\" class=\"headerlink\" title=\"2.分析理解\"></a>2.分析理解</h2><p>对收集过的需求进行分析的时候，要做到有理有据，结合现有的技术或者产品将客户的需求转换为解决方案，其实做需求分析的结果就是要产出一个符合客户的诉求和能够结合自身的产品或者技术优势的交付物。客户不仅仅是想我们去理解他的想法和愿景，更多的是在想我们发出帮助的信号，我们若能够帮着他来解决现有的问题将会得到很大的反响。有的时候提出需求的人其实未必是真的想好了如何去做，我们要及时的去理解和沟通它们真正的想法，只是一味的梳理客户的需求，而不去理解这些需求的本质，只能让我们后期被客户的无理需求牵着鼻子走。</p>\n<p>需求的最终交付物是一个能让客户满意的解决方案，这个方案和客户原本的需求规格说明书可能有很多的差异，这才是对需求理解的最终目的。因为人的想法在刚产生的时候会有很多不确定的因素在里面，随着和客户的不断交流，我们能够替他们去挑出一些真正的需求，在最终的剩下的需求里面，我们又能够将多个不同的想法组合和精简成一个可行的功能点。</p>\n<h2 id=\"3-筛选需求\"><a href=\"#3-筛选需求\" class=\"headerlink\" title=\"3.筛选需求\"></a>3.筛选需求</h2><p>筛选需求是在整理需求之后必经的一个阶段，该阶段中会有很多我们可以遵循的方法。最常用的有：做减法、做加法。</p>\n<p>需求分析人员要做的就是从这些林林总总的需求当中找出可实现的，有价值的需求，排除那些无意义，不可实现的需求，或者是当前暂时先不实现，或者是这个产品不实现但可以利用在别的产品身上的，反正与当前产品无关的需求，都需要排除掉，这个过程就是在做减法。比如说，我们收集到10个功能需求，觉得其中有两个是没必要做的，或者是可以以后再做的，就把这2个需求功能先排除掉，先做剩下的8个功能需求。应该来说，做减法是需求分析人员最<br>基本的素养了，一般都是有东西去给你做减法的。</p>\n<p>需求分析人员依靠自身的工作经验，和对产品设计理念的理解，可以提出新的需求，这些新的需求不一定就是最终的需求，但需求分析人员要有能力去总结发现。因为往往人们在考虑问题的时候都是不全面的，所以才古语有云，三个臭皮匠顶个诸葛亮，把所有的意见综合在一起，很有可能就是个非常棒的点。这里做加法主要还是要依靠自身的经验来取决，比如要做5个功能需求，需求分析人员觉得应该再加上报表统计的功能，这就是在做加法。</p>\n<p>当我们面对一件全新的产品设计任务时，没有任何现成的数据去提供给我们做分析，或者说数据很少，这个时候需求分析人员要去挖掘需求，也可以说是发现新需求，这个新需求是全新的，没有任何经验可借鉴的。挖掘需求对于产品经理来说是必不可备的，因为一个产品的发展过程中需要不断地注入新鲜的元素，才能符合适合市场的需要。而对一个项目来说，深挖需求能够孵化出其他的潜在项目，这也是评价一个项目经理是否具有“可持续发展”的潜质。</p>\n<h2 id=\"4-需求的管理\"><a href=\"#4-需求的管理\" class=\"headerlink\" title=\"4.需求的管理\"></a>4.需求的管理</h2><p>对于很多刚入行做需求的人来说，分析需求可能是他们认为很重要的一个点，其实如果不能有效地把控需求，归纳和整理，在项目后期将会遇到一些让人不可预料的新的问题。因此，需求的管理是至关重要的，我们要不断地坚持总结和分析，这样才能够在客户提出问题之前，我们能够做到未雨绸缪。最好的办法是将每个阶段的需求按照时间线来整理，这样从一个时间的角度发现问题的本质。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>无论你是一个产品经理或者项目经理,你都不能避免一件事情-需求分析。对于一个产品经理来说，需求分析就是挖掘用户的需求点，找到正确的、合理的、有效的、潜在的需求，对挖掘到的需求进行分析、归类、筛选，不断完善产品的功能，巩固产品的核心要素。而对于项目经理来说，由于是从一个项目的角度出发，所有的需求都是由客户发出的，要做的工作就是整理需求、理解需求，筛选需求，实现需求。无论怎样，都要经过下面的几个过程：对需求的收集、分析理解、筛选、管理以及挖掘。<br>","more":"</p>\n<p><img src=\"/images/项目管理/需求分析.png\" alt=\"架构\"></p>\n<h2 id=\"1-收集需求\"><a href=\"#1-收集需求\" class=\"headerlink\" title=\"1.收集需求\"></a>1.收集需求</h2><p>作为项目型的经理，在需求收集阶段需要数次和客户沟通。对于一个投标型的项目来说，客户的需求在规格说明书中会有所阐述，这个说明只是对客户的需求的一个自我的表述，不能很有调理的整理出来，需要我们沟通和确认。前期的沟通一定要充分的理解客户的需求，若对客户现有的需求不太理解，可以向客户阐述自己的理解。比较好的方式是画出架构图，逻辑图等，不断的和客户确认，直到客户认可未知，在这个阶段不仅要去理解，还要去把现有的产品和技术往需求上靠拢，最好能确定大致的模块，这个阶段能确认的东西越多后面遇到的问题就越少，最后一定要落实的文档或者线框图上，这对后期的需求管理留下了基础，也为需求的挖掘留下了依据。</p>\n<p><img src=\"/images/项目管理/搜集需求.png\" alt=\"架构\"></p>\n<h2 id=\"2-分析理解\"><a href=\"#2-分析理解\" class=\"headerlink\" title=\"2.分析理解\"></a>2.分析理解</h2><p>对收集过的需求进行分析的时候，要做到有理有据，结合现有的技术或者产品将客户的需求转换为解决方案，其实做需求分析的结果就是要产出一个符合客户的诉求和能够结合自身的产品或者技术优势的交付物。客户不仅仅是想我们去理解他的想法和愿景，更多的是在想我们发出帮助的信号，我们若能够帮着他来解决现有的问题将会得到很大的反响。有的时候提出需求的人其实未必是真的想好了如何去做，我们要及时的去理解和沟通它们真正的想法，只是一味的梳理客户的需求，而不去理解这些需求的本质，只能让我们后期被客户的无理需求牵着鼻子走。</p>\n<p>需求的最终交付物是一个能让客户满意的解决方案，这个方案和客户原本的需求规格说明书可能有很多的差异，这才是对需求理解的最终目的。因为人的想法在刚产生的时候会有很多不确定的因素在里面，随着和客户的不断交流，我们能够替他们去挑出一些真正的需求，在最终的剩下的需求里面，我们又能够将多个不同的想法组合和精简成一个可行的功能点。</p>\n<h2 id=\"3-筛选需求\"><a href=\"#3-筛选需求\" class=\"headerlink\" title=\"3.筛选需求\"></a>3.筛选需求</h2><p>筛选需求是在整理需求之后必经的一个阶段，该阶段中会有很多我们可以遵循的方法。最常用的有：做减法、做加法。</p>\n<p>需求分析人员要做的就是从这些林林总总的需求当中找出可实现的，有价值的需求，排除那些无意义，不可实现的需求，或者是当前暂时先不实现，或者是这个产品不实现但可以利用在别的产品身上的，反正与当前产品无关的需求，都需要排除掉，这个过程就是在做减法。比如说，我们收集到10个功能需求，觉得其中有两个是没必要做的，或者是可以以后再做的，就把这2个需求功能先排除掉，先做剩下的8个功能需求。应该来说，做减法是需求分析人员最<br>基本的素养了，一般都是有东西去给你做减法的。</p>\n<p>需求分析人员依靠自身的工作经验，和对产品设计理念的理解，可以提出新的需求，这些新的需求不一定就是最终的需求，但需求分析人员要有能力去总结发现。因为往往人们在考虑问题的时候都是不全面的，所以才古语有云，三个臭皮匠顶个诸葛亮，把所有的意见综合在一起，很有可能就是个非常棒的点。这里做加法主要还是要依靠自身的经验来取决，比如要做5个功能需求，需求分析人员觉得应该再加上报表统计的功能，这就是在做加法。</p>\n<p>当我们面对一件全新的产品设计任务时，没有任何现成的数据去提供给我们做分析，或者说数据很少，这个时候需求分析人员要去挖掘需求，也可以说是发现新需求，这个新需求是全新的，没有任何经验可借鉴的。挖掘需求对于产品经理来说是必不可备的，因为一个产品的发展过程中需要不断地注入新鲜的元素，才能符合适合市场的需要。而对一个项目来说，深挖需求能够孵化出其他的潜在项目，这也是评价一个项目经理是否具有“可持续发展”的潜质。</p>\n<h2 id=\"4-需求的管理\"><a href=\"#4-需求的管理\" class=\"headerlink\" title=\"4.需求的管理\"></a>4.需求的管理</h2><p>对于很多刚入行做需求的人来说，分析需求可能是他们认为很重要的一个点，其实如果不能有效地把控需求，归纳和整理，在项目后期将会遇到一些让人不可预料的新的问题。因此，需求的管理是至关重要的，我们要不断地坚持总结和分析，这样才能够在客户提出问题之前，我们能够做到未雨绸缪。最好的办法是将每个阶段的需求按照时间线来整理，这样从一个时间的角度发现问题的本质。</p>"},{"layout":"lay_post","title":"消息中间件ActiveMQ双高架构演进","date":"2015-12-27T07:33:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n对于高可用高并发的架构需求，有很多方案，但每种方案都要和具体的使用场景相结合，比如网站的双高方案，中间件的双高方案。\n工作中遇到的消息中间件的双高需求，结合了ActiveMQ官网的指导，整理了以下的架构演进方案。\n<!-- more -->\n\n## 1.架构演进图\n\n![架构](/images/架构/消息队列-分布式.png)","source":"_posts/2015-12-27-消息中间件ActiveMQ双高架构演进.md","raw":"---\nlayout: lay_post\ntitle: \"消息中间件ActiveMQ双高架构演进\"\ndate: 2015-12-27 15:33:00\ncategories: 架构\ntags: 消息中间件\nauthor: lvyafei\n---\n\n## 0.概述\n\n对于高可用高并发的架构需求，有很多方案，但每种方案都要和具体的使用场景相结合，比如网站的双高方案，中间件的双高方案。\n工作中遇到的消息中间件的双高需求，结合了ActiveMQ官网的指导，整理了以下的架构演进方案。\n<!-- more -->\n\n## 1.架构演进图\n\n![架构](/images/架构/消息队列-分布式.png)","slug":"2015-12-27-消息中间件ActiveMQ双高架构演进","published":1,"updated":"2018-11-29T12:51:24.585Z","comments":1,"photos":[],"link":"","_id":"cjskffnxq000l4glmg9x6e8e6","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对于高可用高并发的架构需求，有很多方案，但每种方案都要和具体的使用场景相结合，比如网站的双高方案，中间件的双高方案。<br>工作中遇到的消息中间件的双高需求，结合了ActiveMQ官网的指导，整理了以下的架构演进方案。<br><a id=\"more\"></a></p>\n<h2 id=\"1-架构演进图\"><a href=\"#1-架构演进图\" class=\"headerlink\" title=\"1.架构演进图\"></a>1.架构演进图</h2><p><img src=\"/images/架构/消息队列-分布式.png\" alt=\"架构\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对于高可用高并发的架构需求，有很多方案，但每种方案都要和具体的使用场景相结合，比如网站的双高方案，中间件的双高方案。<br>工作中遇到的消息中间件的双高需求，结合了ActiveMQ官网的指导，整理了以下的架构演进方案。<br>","more":"</p>\n<h2 id=\"1-架构演进图\"><a href=\"#1-架构演进图\" class=\"headerlink\" title=\"1.架构演进图\"></a>1.架构演进图</h2><p><img src=\"/images/架构/消息队列-分布式.png\" alt=\"架构\"></p>"},{"layout":"lay_post","title":"系统架构总结之高可用高负载","date":"2016-03-10T09:26:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n现有项目的一次架构总结,对一般的高可用、高负载策略也比较全面的接触了。\n\n<!-- more -->\n\n**现行方案：**\n\n![笔记](/images/架构/系统架构图-双高.png)\n\n**备案：**\n\n![笔记](/images/架构/系统架构图-备案.png)\n\n**ActiveMQ使用场景:**\n\n![笔记](/images/架构/ActiveMQ使用场景总结.png)\n\n**postgres方案：**\n\n![笔记](/images/架构/postgres方案.png)\n\n\n","source":"_posts/2016-03-10-系统架构总结之高可用高负载.md","raw":"---\nlayout: lay_post\ntitle: \"系统架构总结之高可用高负载\"\ndate: 2016-03-10 17:26:00\ncategories: 架构\ntags: 双高架构\nauthor: lvyafei\n---\n\n## 0.概述\n\n现有项目的一次架构总结,对一般的高可用、高负载策略也比较全面的接触了。\n\n<!-- more -->\n\n**现行方案：**\n\n![笔记](/images/架构/系统架构图-双高.png)\n\n**备案：**\n\n![笔记](/images/架构/系统架构图-备案.png)\n\n**ActiveMQ使用场景:**\n\n![笔记](/images/架构/ActiveMQ使用场景总结.png)\n\n**postgres方案：**\n\n![笔记](/images/架构/postgres方案.png)\n\n\n","slug":"2016-03-10-系统架构总结之高可用高负载","published":1,"updated":"2018-11-29T12:51:24.603Z","comments":1,"photos":[],"link":"","_id":"cjskffnxq000n4glmvtpu5wbw","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>现有项目的一次架构总结,对一般的高可用、高负载策略也比较全面的接触了。</p>\n<a id=\"more\"></a>\n<p><strong>现行方案：</strong></p>\n<p><img src=\"/images/架构/系统架构图-双高.png\" alt=\"笔记\"></p>\n<p><strong>备案：</strong></p>\n<p><img src=\"/images/架构/系统架构图-备案.png\" alt=\"笔记\"></p>\n<p><strong>ActiveMQ使用场景:</strong></p>\n<p><img src=\"/images/架构/ActiveMQ使用场景总结.png\" alt=\"笔记\"></p>\n<p><strong>postgres方案：</strong></p>\n<p><img src=\"/images/架构/postgres方案.png\" alt=\"笔记\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>现有项目的一次架构总结,对一般的高可用、高负载策略也比较全面的接触了。</p>","more":"<p><strong>现行方案：</strong></p>\n<p><img src=\"/images/架构/系统架构图-双高.png\" alt=\"笔记\"></p>\n<p><strong>备案：</strong></p>\n<p><img src=\"/images/架构/系统架构图-备案.png\" alt=\"笔记\"></p>\n<p><strong>ActiveMQ使用场景:</strong></p>\n<p><img src=\"/images/架构/ActiveMQ使用场景总结.png\" alt=\"笔记\"></p>\n<p><strong>postgres方案：</strong></p>\n<p><img src=\"/images/架构/postgres方案.png\" alt=\"笔记\"></p>"},{"layout":"lay_post","title":"JDK源码分析之BIO类汇总","date":"2016-04-07T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nJDK中包含的IO类的梳理，对IO操作有一个全面的认识，在JDK中IO操作还有一个包NIO。都是对IO的操作，但是实现的原理还是不一样的。\n<!-- more -->\n\n## 1.BIO类图\n\n![BIO类图](/images/java源码/BIO-类图.jpg)\n\n![BIO-字节流](/images/java源码/BIO-字节流.png)\n\n![BIO-字节流](/images/java源码/BIO-字符流.png)\n\n## 2.流的概念和作用\n\n流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。\n\n**IO流的分类**\n\n根据处理数据类型的不同分为：字符流和字节流\n根据数据流向不同分为：输入流和输出流\n\n### 2.1 字符流和字节流\n\n字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。 \n字节流和字符流的区别：\n读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。\n处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。\n字节流：一次读入或读出是8位二进制。\n字符流：一次读入或读出是16位二进制。\n设备上的数据无论是图片或者视频，文字，它们都以二进制存储的。二进制的最终都是以一个8位为数据单元进行体现，所以计算机中的最小数据单元就是字节。意味着，字节流可以处理设备上的所有数据，所以字节流一样可以处理字符数据。\n\n结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。\n\n### 2.2 输入流和输出流\n\n输入流只能进行读操作，输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。\n\n## 3.字节流用法\n\n### 3.1 输入字节流 InputStream\n\nInputStream 是所有的输入字节流的父类，它是一个抽象类。\nByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。\nPipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。\nObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。\n\n### 3.2 输出字节流 OutputStream\n\nOutputStream 是所有的输出字节流的父类，它是一个抽象类。\nByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。\nPipedOutputStream 是向与其它线程共用的管道中写入数据。\nObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。\n\n总结：\n输入流：InputStream或者Reader：从文件中读到程序中；\n输出流：OutputStream或者Writer：从程序中输出到文件中；\n\n## 4.节点流-处理流-转换流\n\n### 4.1 节点流\n\n直接与数据源相连，读入或读出。直接使用节点流，读写不方便，为了更快的读写文件，才有了处理流。\n\n常用的节点流\n父　类 ：InputStream 、OutputStream、 Reader、 Writer\n文　件 ：FileInputStream 、 FileOutputStrean 、FileReader 、FileWriter 文件进行处理的节点流\n数　组 ：ByteArrayInputStream、 ByteArrayOutputStream、 CharArrayReader 、CharArrayWriter \n对数组进行处理的节点流（对应的不再是文件，而是内存中的一个数组）\n字符串 ：StringReader、 StringWriter 对字符串进行处理的节点流\n管　道 ：PipedInputStream 、PipedOutputStream 、PipedReader 、PipedWriter 对管道进行处理的节点流\n\n### 4.2 处理流\n\n和节点流一块使用，在节点流的基础上，再套接一层，套接在节点流上的就是处理流。如BufferedReader.处理流的构造方法总是要带一个其他的流对象做参数。一个流对象经过其他流的多次包装，称为流的链接。\n\n常用的处理流\n缓冲流：BufferedInputStrean 、BufferedOutputStream、 BufferedReader、 BufferedWriter 增加缓冲功能，避免频繁读写硬盘。\n转换流：InputStreamReader 、OutputStreamReader实现字节流和字符流之间的转换。\n数据流： DataInputStream 、DataOutputStream 等-提供将基础数据类型写入到文件中，或者读取出来。\n\n### 4.3 转换流\n\n实现从字节流到字符流的转换。\n\n常用的转换流\nInputStreamReader 、OutputStreamWriter。(需要InputStream或OutputStream作为参数)\n\n## 5.第三方IO包\n\nApache Commons IO是Apache基金会创建并维护的Java函数库。它提供了许多类使得开发者的常见任务变得简单，同时减少重复代码，这些代码可能遍布于每个独立的项目中，你却不得不重复的编写。这些类由经验丰富的开发者维护，对各种问题的边界条件考虑周到，并持续修复相关bug。\n\n常用类：\nFileUtils：https://www.cnblogs.com/zhaoyanjun/p/6396419.html\nIOUtils：https://www.cnblogs.com/zhaoyanjun/p/6401314.html\n\n## 6.参考\n\nhttps://www.cnblogs.com/zhaoyanjun/p/6292384.html\n","source":"_posts/2016-04-08-JDK源码分析之BIO类汇总.md","raw":"---\nlayout: lay_post\ntitle: JDK源码分析之BIO类汇总\ndate: 2016-04-08\ncategories: JAVA源码\ntags: IO类\nauthor: lvyafei\n---\n\n## 0.概述\n\nJDK中包含的IO类的梳理，对IO操作有一个全面的认识，在JDK中IO操作还有一个包NIO。都是对IO的操作，但是实现的原理还是不一样的。\n<!-- more -->\n\n## 1.BIO类图\n\n![BIO类图](/images/java源码/BIO-类图.jpg)\n\n![BIO-字节流](/images/java源码/BIO-字节流.png)\n\n![BIO-字节流](/images/java源码/BIO-字符流.png)\n\n## 2.流的概念和作用\n\n流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。\n\n**IO流的分类**\n\n根据处理数据类型的不同分为：字符流和字节流\n根据数据流向不同分为：输入流和输出流\n\n### 2.1 字符流和字节流\n\n字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。 \n字节流和字符流的区别：\n读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。\n处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。\n字节流：一次读入或读出是8位二进制。\n字符流：一次读入或读出是16位二进制。\n设备上的数据无论是图片或者视频，文字，它们都以二进制存储的。二进制的最终都是以一个8位为数据单元进行体现，所以计算机中的最小数据单元就是字节。意味着，字节流可以处理设备上的所有数据，所以字节流一样可以处理字符数据。\n\n结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。\n\n### 2.2 输入流和输出流\n\n输入流只能进行读操作，输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。\n\n## 3.字节流用法\n\n### 3.1 输入字节流 InputStream\n\nInputStream 是所有的输入字节流的父类，它是一个抽象类。\nByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。\nPipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。\nObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。\n\n### 3.2 输出字节流 OutputStream\n\nOutputStream 是所有的输出字节流的父类，它是一个抽象类。\nByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。\nPipedOutputStream 是向与其它线程共用的管道中写入数据。\nObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。\n\n总结：\n输入流：InputStream或者Reader：从文件中读到程序中；\n输出流：OutputStream或者Writer：从程序中输出到文件中；\n\n## 4.节点流-处理流-转换流\n\n### 4.1 节点流\n\n直接与数据源相连，读入或读出。直接使用节点流，读写不方便，为了更快的读写文件，才有了处理流。\n\n常用的节点流\n父　类 ：InputStream 、OutputStream、 Reader、 Writer\n文　件 ：FileInputStream 、 FileOutputStrean 、FileReader 、FileWriter 文件进行处理的节点流\n数　组 ：ByteArrayInputStream、 ByteArrayOutputStream、 CharArrayReader 、CharArrayWriter \n对数组进行处理的节点流（对应的不再是文件，而是内存中的一个数组）\n字符串 ：StringReader、 StringWriter 对字符串进行处理的节点流\n管　道 ：PipedInputStream 、PipedOutputStream 、PipedReader 、PipedWriter 对管道进行处理的节点流\n\n### 4.2 处理流\n\n和节点流一块使用，在节点流的基础上，再套接一层，套接在节点流上的就是处理流。如BufferedReader.处理流的构造方法总是要带一个其他的流对象做参数。一个流对象经过其他流的多次包装，称为流的链接。\n\n常用的处理流\n缓冲流：BufferedInputStrean 、BufferedOutputStream、 BufferedReader、 BufferedWriter 增加缓冲功能，避免频繁读写硬盘。\n转换流：InputStreamReader 、OutputStreamReader实现字节流和字符流之间的转换。\n数据流： DataInputStream 、DataOutputStream 等-提供将基础数据类型写入到文件中，或者读取出来。\n\n### 4.3 转换流\n\n实现从字节流到字符流的转换。\n\n常用的转换流\nInputStreamReader 、OutputStreamWriter。(需要InputStream或OutputStream作为参数)\n\n## 5.第三方IO包\n\nApache Commons IO是Apache基金会创建并维护的Java函数库。它提供了许多类使得开发者的常见任务变得简单，同时减少重复代码，这些代码可能遍布于每个独立的项目中，你却不得不重复的编写。这些类由经验丰富的开发者维护，对各种问题的边界条件考虑周到，并持续修复相关bug。\n\n常用类：\nFileUtils：https://www.cnblogs.com/zhaoyanjun/p/6396419.html\nIOUtils：https://www.cnblogs.com/zhaoyanjun/p/6401314.html\n\n## 6.参考\n\nhttps://www.cnblogs.com/zhaoyanjun/p/6292384.html\n","slug":"2016-04-08-JDK源码分析之BIO类汇总","published":1,"updated":"2019-02-25T13:53:56.689Z","comments":1,"photos":[],"link":"","_id":"cjskffny6000r4glm53t9dmpy","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JDK中包含的IO类的梳理，对IO操作有一个全面的认识，在JDK中IO操作还有一个包NIO。都是对IO的操作，但是实现的原理还是不一样的。<br><a id=\"more\"></a></p>\n<h2 id=\"1-BIO类图\"><a href=\"#1-BIO类图\" class=\"headerlink\" title=\"1.BIO类图\"></a>1.BIO类图</h2><p><img src=\"/images/java源码/BIO-类图.jpg\" alt=\"BIO类图\"></p>\n<p><img src=\"/images/java源码/BIO-字节流.png\" alt=\"BIO-字节流\"></p>\n<p><img src=\"/images/java源码/BIO-字符流.png\" alt=\"BIO-字节流\"></p>\n<h2 id=\"2-流的概念和作用\"><a href=\"#2-流的概念和作用\" class=\"headerlink\" title=\"2.流的概念和作用\"></a>2.流的概念和作用</h2><p>流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。</p>\n<p><strong>IO流的分类</strong></p>\n<p>根据处理数据类型的不同分为：字符流和字节流<br>根据数据流向不同分为：输入流和输出流</p>\n<h3 id=\"2-1-字符流和字节流\"><a href=\"#2-1-字符流和字节流\" class=\"headerlink\" title=\"2.1 字符流和字节流\"></a>2.1 字符流和字节流</h3><p>字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。<br>字节流和字符流的区别：<br>读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。<br>处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。<br>字节流：一次读入或读出是8位二进制。<br>字符流：一次读入或读出是16位二进制。<br>设备上的数据无论是图片或者视频，文字，它们都以二进制存储的。二进制的最终都是以一个8位为数据单元进行体现，所以计算机中的最小数据单元就是字节。意味着，字节流可以处理设备上的所有数据，所以字节流一样可以处理字符数据。</p>\n<p>结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。</p>\n<h3 id=\"2-2-输入流和输出流\"><a href=\"#2-2-输入流和输出流\" class=\"headerlink\" title=\"2.2 输入流和输出流\"></a>2.2 输入流和输出流</h3><p>输入流只能进行读操作，输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。</p>\n<h2 id=\"3-字节流用法\"><a href=\"#3-字节流用法\" class=\"headerlink\" title=\"3.字节流用法\"></a>3.字节流用法</h2><h3 id=\"3-1-输入字节流-InputStream\"><a href=\"#3-1-输入字节流-InputStream\" class=\"headerlink\" title=\"3.1 输入字节流 InputStream\"></a>3.1 输入字节流 InputStream</h3><p>InputStream 是所有的输入字节流的父类，它是一个抽象类。<br>ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。<br>PipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。<br>ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。</p>\n<h3 id=\"3-2-输出字节流-OutputStream\"><a href=\"#3-2-输出字节流-OutputStream\" class=\"headerlink\" title=\"3.2 输出字节流 OutputStream\"></a>3.2 输出字节流 OutputStream</h3><p>OutputStream 是所有的输出字节流的父类，它是一个抽象类。<br>ByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。<br>PipedOutputStream 是向与其它线程共用的管道中写入数据。<br>ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。</p>\n<p>总结：<br>输入流：InputStream或者Reader：从文件中读到程序中；<br>输出流：OutputStream或者Writer：从程序中输出到文件中；</p>\n<h2 id=\"4-节点流-处理流-转换流\"><a href=\"#4-节点流-处理流-转换流\" class=\"headerlink\" title=\"4.节点流-处理流-转换流\"></a>4.节点流-处理流-转换流</h2><h3 id=\"4-1-节点流\"><a href=\"#4-1-节点流\" class=\"headerlink\" title=\"4.1 节点流\"></a>4.1 节点流</h3><p>直接与数据源相连，读入或读出。直接使用节点流，读写不方便，为了更快的读写文件，才有了处理流。</p>\n<p>常用的节点流<br>父　类 ：InputStream 、OutputStream、 Reader、 Writer<br>文　件 ：FileInputStream 、 FileOutputStrean 、FileReader 、FileWriter 文件进行处理的节点流<br>数　组 ：ByteArrayInputStream、 ByteArrayOutputStream、 CharArrayReader 、CharArrayWriter<br>对数组进行处理的节点流（对应的不再是文件，而是内存中的一个数组）<br>字符串 ：StringReader、 StringWriter 对字符串进行处理的节点流<br>管　道 ：PipedInputStream 、PipedOutputStream 、PipedReader 、PipedWriter 对管道进行处理的节点流</p>\n<h3 id=\"4-2-处理流\"><a href=\"#4-2-处理流\" class=\"headerlink\" title=\"4.2 处理流\"></a>4.2 处理流</h3><p>和节点流一块使用，在节点流的基础上，再套接一层，套接在节点流上的就是处理流。如BufferedReader.处理流的构造方法总是要带一个其他的流对象做参数。一个流对象经过其他流的多次包装，称为流的链接。</p>\n<p>常用的处理流<br>缓冲流：BufferedInputStrean 、BufferedOutputStream、 BufferedReader、 BufferedWriter 增加缓冲功能，避免频繁读写硬盘。<br>转换流：InputStreamReader 、OutputStreamReader实现字节流和字符流之间的转换。<br>数据流： DataInputStream 、DataOutputStream 等-提供将基础数据类型写入到文件中，或者读取出来。</p>\n<h3 id=\"4-3-转换流\"><a href=\"#4-3-转换流\" class=\"headerlink\" title=\"4.3 转换流\"></a>4.3 转换流</h3><p>实现从字节流到字符流的转换。</p>\n<p>常用的转换流<br>InputStreamReader 、OutputStreamWriter。(需要InputStream或OutputStream作为参数)</p>\n<h2 id=\"5-第三方IO包\"><a href=\"#5-第三方IO包\" class=\"headerlink\" title=\"5.第三方IO包\"></a>5.第三方IO包</h2><p>Apache Commons IO是Apache基金会创建并维护的Java函数库。它提供了许多类使得开发者的常见任务变得简单，同时减少重复代码，这些代码可能遍布于每个独立的项目中，你却不得不重复的编写。这些类由经验丰富的开发者维护，对各种问题的边界条件考虑周到，并持续修复相关bug。</p>\n<p>常用类：<br>FileUtils：<a href=\"https://www.cnblogs.com/zhaoyanjun/p/6396419.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6396419.html</a><br>IOUtils：<a href=\"https://www.cnblogs.com/zhaoyanjun/p/6401314.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6401314.html</a></p>\n<h2 id=\"6-参考\"><a href=\"#6-参考\" class=\"headerlink\" title=\"6.参考\"></a>6.参考</h2><p><a href=\"https://www.cnblogs.com/zhaoyanjun/p/6292384.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6292384.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JDK中包含的IO类的梳理，对IO操作有一个全面的认识，在JDK中IO操作还有一个包NIO。都是对IO的操作，但是实现的原理还是不一样的。<br>","more":"</p>\n<h2 id=\"1-BIO类图\"><a href=\"#1-BIO类图\" class=\"headerlink\" title=\"1.BIO类图\"></a>1.BIO类图</h2><p><img src=\"/images/java源码/BIO-类图.jpg\" alt=\"BIO类图\"></p>\n<p><img src=\"/images/java源码/BIO-字节流.png\" alt=\"BIO-字节流\"></p>\n<p><img src=\"/images/java源码/BIO-字符流.png\" alt=\"BIO-字节流\"></p>\n<h2 id=\"2-流的概念和作用\"><a href=\"#2-流的概念和作用\" class=\"headerlink\" title=\"2.流的概念和作用\"></a>2.流的概念和作用</h2><p>流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。</p>\n<p><strong>IO流的分类</strong></p>\n<p>根据处理数据类型的不同分为：字符流和字节流<br>根据数据流向不同分为：输入流和输出流</p>\n<h3 id=\"2-1-字符流和字节流\"><a href=\"#2-1-字符流和字节流\" class=\"headerlink\" title=\"2.1 字符流和字节流\"></a>2.1 字符流和字节流</h3><p>字符流的由来： 因为数据编码的不同，而有了对字符进行高效操作的流对象。本质其实就是基于字节流读取时，去查了指定的码表。<br>字节流和字符流的区别：<br>读写单位不同：字节流以字节（8bit）为单位，字符流以字符为单位，根据码表映射字符，一次可能读多个字节。<br>处理对象不同：字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。<br>字节流：一次读入或读出是8位二进制。<br>字符流：一次读入或读出是16位二进制。<br>设备上的数据无论是图片或者视频，文字，它们都以二进制存储的。二进制的最终都是以一个8位为数据单元进行体现，所以计算机中的最小数据单元就是字节。意味着，字节流可以处理设备上的所有数据，所以字节流一样可以处理字符数据。</p>\n<p>结论：只要是处理纯文本数据，就优先考虑使用字符流。 除此之外都使用字节流。</p>\n<h3 id=\"2-2-输入流和输出流\"><a href=\"#2-2-输入流和输出流\" class=\"headerlink\" title=\"2.2 输入流和输出流\"></a>2.2 输入流和输出流</h3><p>输入流只能进行读操作，输出流只能进行写操作，程序中需要根据待传输数据的不同特性而使用不同的流。</p>\n<h2 id=\"3-字节流用法\"><a href=\"#3-字节流用法\" class=\"headerlink\" title=\"3.字节流用法\"></a>3.字节流用法</h2><h3 id=\"3-1-输入字节流-InputStream\"><a href=\"#3-1-输入字节流-InputStream\" class=\"headerlink\" title=\"3.1 输入字节流 InputStream\"></a>3.1 输入字节流 InputStream</h3><p>InputStream 是所有的输入字节流的父类，它是一个抽象类。<br>ByteArrayInputStream、StringBufferInputStream、FileInputStream 是三种基本的介质流，它们分别从Byte 数组、StringBuffer、和本地文件中读取数据。<br>PipedInputStream 是从与其它线程共用的管道中读取数据，与Piped 相关的知识后续单独介绍。<br>ObjectInputStream 和所有FilterInputStream 的子类都是装饰流（装饰器模式的主角）。</p>\n<h3 id=\"3-2-输出字节流-OutputStream\"><a href=\"#3-2-输出字节流-OutputStream\" class=\"headerlink\" title=\"3.2 输出字节流 OutputStream\"></a>3.2 输出字节流 OutputStream</h3><p>OutputStream 是所有的输出字节流的父类，它是一个抽象类。<br>ByteArrayOutputStream、FileOutputStream 是两种基本的介质流，它们分别向Byte 数组、和本地文件中写入数据。<br>PipedOutputStream 是向与其它线程共用的管道中写入数据。<br>ObjectOutputStream 和所有FilterOutputStream 的子类都是装饰流。</p>\n<p>总结：<br>输入流：InputStream或者Reader：从文件中读到程序中；<br>输出流：OutputStream或者Writer：从程序中输出到文件中；</p>\n<h2 id=\"4-节点流-处理流-转换流\"><a href=\"#4-节点流-处理流-转换流\" class=\"headerlink\" title=\"4.节点流-处理流-转换流\"></a>4.节点流-处理流-转换流</h2><h3 id=\"4-1-节点流\"><a href=\"#4-1-节点流\" class=\"headerlink\" title=\"4.1 节点流\"></a>4.1 节点流</h3><p>直接与数据源相连，读入或读出。直接使用节点流，读写不方便，为了更快的读写文件，才有了处理流。</p>\n<p>常用的节点流<br>父　类 ：InputStream 、OutputStream、 Reader、 Writer<br>文　件 ：FileInputStream 、 FileOutputStrean 、FileReader 、FileWriter 文件进行处理的节点流<br>数　组 ：ByteArrayInputStream、 ByteArrayOutputStream、 CharArrayReader 、CharArrayWriter<br>对数组进行处理的节点流（对应的不再是文件，而是内存中的一个数组）<br>字符串 ：StringReader、 StringWriter 对字符串进行处理的节点流<br>管　道 ：PipedInputStream 、PipedOutputStream 、PipedReader 、PipedWriter 对管道进行处理的节点流</p>\n<h3 id=\"4-2-处理流\"><a href=\"#4-2-处理流\" class=\"headerlink\" title=\"4.2 处理流\"></a>4.2 处理流</h3><p>和节点流一块使用，在节点流的基础上，再套接一层，套接在节点流上的就是处理流。如BufferedReader.处理流的构造方法总是要带一个其他的流对象做参数。一个流对象经过其他流的多次包装，称为流的链接。</p>\n<p>常用的处理流<br>缓冲流：BufferedInputStrean 、BufferedOutputStream、 BufferedReader、 BufferedWriter 增加缓冲功能，避免频繁读写硬盘。<br>转换流：InputStreamReader 、OutputStreamReader实现字节流和字符流之间的转换。<br>数据流： DataInputStream 、DataOutputStream 等-提供将基础数据类型写入到文件中，或者读取出来。</p>\n<h3 id=\"4-3-转换流\"><a href=\"#4-3-转换流\" class=\"headerlink\" title=\"4.3 转换流\"></a>4.3 转换流</h3><p>实现从字节流到字符流的转换。</p>\n<p>常用的转换流<br>InputStreamReader 、OutputStreamWriter。(需要InputStream或OutputStream作为参数)</p>\n<h2 id=\"5-第三方IO包\"><a href=\"#5-第三方IO包\" class=\"headerlink\" title=\"5.第三方IO包\"></a>5.第三方IO包</h2><p>Apache Commons IO是Apache基金会创建并维护的Java函数库。它提供了许多类使得开发者的常见任务变得简单，同时减少重复代码，这些代码可能遍布于每个独立的项目中，你却不得不重复的编写。这些类由经验丰富的开发者维护，对各种问题的边界条件考虑周到，并持续修复相关bug。</p>\n<p>常用类：<br>FileUtils：<a href=\"https://www.cnblogs.com/zhaoyanjun/p/6396419.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6396419.html</a><br>IOUtils：<a href=\"https://www.cnblogs.com/zhaoyanjun/p/6401314.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6401314.html</a></p>\n<h2 id=\"6-参考\"><a href=\"#6-参考\" class=\"headerlink\" title=\"6.参考\"></a>6.参考</h2><p><a href=\"https://www.cnblogs.com/zhaoyanjun/p/6292384.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhaoyanjun/p/6292384.html</a></p>"},{"layout":"lay_post","title":"JDK源码分析之NIO类汇总","date":"2016-04-07T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nJava NIO 由以下几个核心部分组成：Channels、Buffers、Selectors。虽然Java NIO 中除此之外还有很多类和组件，但Channel，Buffer 和 Selector 构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。\n<!-- more -->\n\n## 1.NIO -Channel类图\n\n![NIO类图](/images/java源码/NIO-Channel类图.png)\n\n### 1.1 同步非阻塞通道\n\nFileChannel(文件通道)\nSocketChannel(收发TCP包的通道)\nServerSocketChannel(收发TCP包的通道)\nDatagramChannel(收发UDP包的通道)\n\n### 1.2 异步非阻塞通道\n\nAsynchronousFileChannel(异步文件通道)\nAsynchronousSocketChannel(异步TCP通道)\nAsynchronousServerSocketChannel(异步TCP通道)\n\n### 1.3 管道\n\nPipe(管道)\n\n### 1.4 接口\n\nAsynchronousChannel(异步通道)\nNetworkChannel(网络通道)\nInterruptibleChannel(可中断通道)\nWritableByteChannel(可写通道)\nReadableByteChannel(可读通道)\n\nAsynchronousByteChannel(异步字节通道)\nMulticastChannel(组播通道)\nGatheringByteChannel(聚集通道)\nByteChannel(字节通道)\nScatteringByteChannel(分散通道)\n\nSeekableByteChannel(可随机通道)\n\n### 1.5 抽象类\n\nAbstractInterruptibleChannel（可中断通道）\nSelectableChannel(可选择通道)\nAbstractSelectableChannel(可选择通道)\n\n## 2.参考\n\nhttp://ifeve.com/java-nio-all/","source":"_posts/2016-04-08-JDK源码分析之NIO类汇总.md","raw":"---\nlayout: lay_post\ntitle: JDK源码分析之NIO类汇总\ndate: 2016-04-08\ncategories: JAVA源码\ntags: IO类\nauthor: lvyafei\n---\n\n## 0.概述\n\nJava NIO 由以下几个核心部分组成：Channels、Buffers、Selectors。虽然Java NIO 中除此之外还有很多类和组件，但Channel，Buffer 和 Selector 构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。\n<!-- more -->\n\n## 1.NIO -Channel类图\n\n![NIO类图](/images/java源码/NIO-Channel类图.png)\n\n### 1.1 同步非阻塞通道\n\nFileChannel(文件通道)\nSocketChannel(收发TCP包的通道)\nServerSocketChannel(收发TCP包的通道)\nDatagramChannel(收发UDP包的通道)\n\n### 1.2 异步非阻塞通道\n\nAsynchronousFileChannel(异步文件通道)\nAsynchronousSocketChannel(异步TCP通道)\nAsynchronousServerSocketChannel(异步TCP通道)\n\n### 1.3 管道\n\nPipe(管道)\n\n### 1.4 接口\n\nAsynchronousChannel(异步通道)\nNetworkChannel(网络通道)\nInterruptibleChannel(可中断通道)\nWritableByteChannel(可写通道)\nReadableByteChannel(可读通道)\n\nAsynchronousByteChannel(异步字节通道)\nMulticastChannel(组播通道)\nGatheringByteChannel(聚集通道)\nByteChannel(字节通道)\nScatteringByteChannel(分散通道)\n\nSeekableByteChannel(可随机通道)\n\n### 1.5 抽象类\n\nAbstractInterruptibleChannel（可中断通道）\nSelectableChannel(可选择通道)\nAbstractSelectableChannel(可选择通道)\n\n## 2.参考\n\nhttp://ifeve.com/java-nio-all/","slug":"2016-04-08-JDK源码分析之NIO类汇总","published":1,"updated":"2019-02-25T14:11:10.003Z","comments":1,"photos":[],"link":"","_id":"cjskffny6000t4glm5v7h7qt5","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Java NIO 由以下几个核心部分组成：Channels、Buffers、Selectors。虽然Java NIO 中除此之外还有很多类和组件，但Channel，Buffer 和 Selector 构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。<br><a id=\"more\"></a></p>\n<h2 id=\"1-NIO-Channel类图\"><a href=\"#1-NIO-Channel类图\" class=\"headerlink\" title=\"1.NIO -Channel类图\"></a>1.NIO -Channel类图</h2><p><img src=\"/images/java源码/NIO-Channel类图.png\" alt=\"NIO类图\"></p>\n<h3 id=\"1-1-同步非阻塞通道\"><a href=\"#1-1-同步非阻塞通道\" class=\"headerlink\" title=\"1.1 同步非阻塞通道\"></a>1.1 同步非阻塞通道</h3><p>FileChannel(文件通道)<br>SocketChannel(收发TCP包的通道)<br>ServerSocketChannel(收发TCP包的通道)<br>DatagramChannel(收发UDP包的通道)</p>\n<h3 id=\"1-2-异步非阻塞通道\"><a href=\"#1-2-异步非阻塞通道\" class=\"headerlink\" title=\"1.2 异步非阻塞通道\"></a>1.2 异步非阻塞通道</h3><p>AsynchronousFileChannel(异步文件通道)<br>AsynchronousSocketChannel(异步TCP通道)<br>AsynchronousServerSocketChannel(异步TCP通道)</p>\n<h3 id=\"1-3-管道\"><a href=\"#1-3-管道\" class=\"headerlink\" title=\"1.3 管道\"></a>1.3 管道</h3><p>Pipe(管道)</p>\n<h3 id=\"1-4-接口\"><a href=\"#1-4-接口\" class=\"headerlink\" title=\"1.4 接口\"></a>1.4 接口</h3><p>AsynchronousChannel(异步通道)<br>NetworkChannel(网络通道)<br>InterruptibleChannel(可中断通道)<br>WritableByteChannel(可写通道)<br>ReadableByteChannel(可读通道)</p>\n<p>AsynchronousByteChannel(异步字节通道)<br>MulticastChannel(组播通道)<br>GatheringByteChannel(聚集通道)<br>ByteChannel(字节通道)<br>ScatteringByteChannel(分散通道)</p>\n<p>SeekableByteChannel(可随机通道)</p>\n<h3 id=\"1-5-抽象类\"><a href=\"#1-5-抽象类\" class=\"headerlink\" title=\"1.5 抽象类\"></a>1.5 抽象类</h3><p>AbstractInterruptibleChannel（可中断通道）<br>SelectableChannel(可选择通道)<br>AbstractSelectableChannel(可选择通道)</p>\n<h2 id=\"2-参考\"><a href=\"#2-参考\" class=\"headerlink\" title=\"2.参考\"></a>2.参考</h2><p><a href=\"http://ifeve.com/java-nio-all/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/java-nio-all/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Java NIO 由以下几个核心部分组成：Channels、Buffers、Selectors。虽然Java NIO 中除此之外还有很多类和组件，但Channel，Buffer 和 Selector 构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。<br>","more":"</p>\n<h2 id=\"1-NIO-Channel类图\"><a href=\"#1-NIO-Channel类图\" class=\"headerlink\" title=\"1.NIO -Channel类图\"></a>1.NIO -Channel类图</h2><p><img src=\"/images/java源码/NIO-Channel类图.png\" alt=\"NIO类图\"></p>\n<h3 id=\"1-1-同步非阻塞通道\"><a href=\"#1-1-同步非阻塞通道\" class=\"headerlink\" title=\"1.1 同步非阻塞通道\"></a>1.1 同步非阻塞通道</h3><p>FileChannel(文件通道)<br>SocketChannel(收发TCP包的通道)<br>ServerSocketChannel(收发TCP包的通道)<br>DatagramChannel(收发UDP包的通道)</p>\n<h3 id=\"1-2-异步非阻塞通道\"><a href=\"#1-2-异步非阻塞通道\" class=\"headerlink\" title=\"1.2 异步非阻塞通道\"></a>1.2 异步非阻塞通道</h3><p>AsynchronousFileChannel(异步文件通道)<br>AsynchronousSocketChannel(异步TCP通道)<br>AsynchronousServerSocketChannel(异步TCP通道)</p>\n<h3 id=\"1-3-管道\"><a href=\"#1-3-管道\" class=\"headerlink\" title=\"1.3 管道\"></a>1.3 管道</h3><p>Pipe(管道)</p>\n<h3 id=\"1-4-接口\"><a href=\"#1-4-接口\" class=\"headerlink\" title=\"1.4 接口\"></a>1.4 接口</h3><p>AsynchronousChannel(异步通道)<br>NetworkChannel(网络通道)<br>InterruptibleChannel(可中断通道)<br>WritableByteChannel(可写通道)<br>ReadableByteChannel(可读通道)</p>\n<p>AsynchronousByteChannel(异步字节通道)<br>MulticastChannel(组播通道)<br>GatheringByteChannel(聚集通道)<br>ByteChannel(字节通道)<br>ScatteringByteChannel(分散通道)</p>\n<p>SeekableByteChannel(可随机通道)</p>\n<h3 id=\"1-5-抽象类\"><a href=\"#1-5-抽象类\" class=\"headerlink\" title=\"1.5 抽象类\"></a>1.5 抽象类</h3><p>AbstractInterruptibleChannel（可中断通道）<br>SelectableChannel(可选择通道)<br>AbstractSelectableChannel(可选择通道)</p>\n<h2 id=\"2-参考\"><a href=\"#2-参考\" class=\"headerlink\" title=\"2.参考\"></a>2.参考</h2><p><a href=\"http://ifeve.com/java-nio-all/\" target=\"_blank\" rel=\"noopener\">http://ifeve.com/java-nio-all/</a></p>"},{"layout":"lay_post","title":"JDK源码分析之并发类汇总","date":"2016-04-07T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nJDK中包含的并发类的梳理。主要集中在java.util.concurrent包中。\n<!-- more -->\n\n## 1.类图\n\n![IO类图](/images/java源码/concurrent-self类图.jpg)\n\n","source":"_posts/2016-04-08-JDK源码分析之并发类汇总.md","raw":"---\nlayout: lay_post\ntitle: JDK源码分析之并发类汇总\ndate: 2016-04-08\ncategories: JAVA源码\ntags: 并发类\nauthor: lvyafei\n---\n\n## 0.概述\n\nJDK中包含的并发类的梳理。主要集中在java.util.concurrent包中。\n<!-- more -->\n\n## 1.类图\n\n![IO类图](/images/java源码/concurrent-self类图.jpg)\n\n","slug":"2016-04-08-JDK源码分析之并发类汇总","published":1,"updated":"2018-11-29T12:51:24.655Z","comments":1,"photos":[],"link":"","_id":"cjskffnym000x4glmlrvuwxgh","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JDK中包含的并发类的梳理。主要集中在java.util.concurrent包中。<br><a id=\"more\"></a></p>\n<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p><img src=\"/images/java源码/concurrent-self类图.jpg\" alt=\"IO类图\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JDK中包含的并发类的梳理。主要集中在java.util.concurrent包中。<br>","more":"</p>\n<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p><img src=\"/images/java源码/concurrent-self类图.jpg\" alt=\"IO类图\"></p>"},{"layout":"lay_post","title":"SSO解决方案汇总","date":"2016-03-13T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nSSO英文全称Single Sign On（单点登录）。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一.\n\n<!-- more -->\n\n随着SSO技术的流行，SSO的产品也是满天飞扬。所有著名的软件厂商都提供了相应的解决方案。常见的开源解决方案有：JA-SIG CAS、OpenSSO、JOSSO、Passport.js、Atlassian Crowd、GodAuth等。商业解决方案有Tivoli、Siteminder、RSA Secure SSO等。商业产品的安全性和用户体验比开源的相对来说比较好点。但是接触最多的还属于开源的方案。\n\n基本上SSO的实现分为3类：基于WEB的WEB SSO、基于Windows域的桌面SSO、SAML(Security Assertion Markup Language安全断言标记语言)。\n\n## 1.SSO原理\n\n### 1.1 SSO体系中的角色\n\n> 1.User （多个）\n\n> 2.Web 应用（多个）\n\n> 3.SSO 认证中心（ 1 个 ）\n\n### 1.2 SSO 实现模式的原则\n\n> 1.所有的认证登录都在 SSO 认证中心进行；\n\n> 2.SSO 认证中心通过一些方法来告诉 Web 应用当前访问用户究竟是不是已通过认证的用户；\n\n> 3.SSO 认证中心和所有的 Web 应用建立一种信任关系，也就是说 web 应用必须信任认证中心。（单点信任）\n\n### 1.3 SSO 主要实现方式\n\n>1.共享 cookies\n\n基于共享同域的 cookie 是 Web 刚开始阶段时使用的一种方式，它利用浏览同域名之间自动传递 cookies 机制，实现两个域名之间系统令牌传递问题；另外，关于跨域问题，虽然 cookies本身不跨域，但可以利用它实现跨域的 SSO 。如：代理、暴露 SSO 令牌值等。\n\n缺点：不灵活而且有不少安全隐患，已经被抛弃。\n\n>2.Broker-based(基于经纪人)\n\n这种技术的特点就是，有一个集中的认证和用户帐号管理的服务器。经纪人给被用于进一步请求的电子身份存取。中央数据库的使用减少了管理的代价，并为认证提供一个公共和独立的 \"第三方 \" 。例如 Kerberos 、 Sesame 、 IBM KryptoKnight （凭证库思想 ) 等。 Kerberos是由麻省理工大学发明的安全认证服务，已经被 UNIX 和 Windows 作为默认的安全认证服务集成进操作系统。\n\n>3.Agent-based(基于代理人)\n\n在这种解决方案中，有一个自动地为不同的应用程序认证用户身份的代理程序。这个代理程序需要设计有不同的功能。比如，它可以使用口令表或加密密钥来自动地将认证的负担从用户移开。代理人被放在服务器上面，在服务器的认证系统和客户端认证方法之间充当一个 \" 翻译 \"。例如 SSH 等。\n\n>4.Token-based\n\n例如 SecureID,WebID ，现在被广泛使用的口令认证，比如 FTP 、邮件服务器的登录认证，这是一种简单易用的方式，实现一个口令在多种应用当中使用。\n\n>5.基于网关\n\n在网关处实现身份认证。\n\n>6.基于SAML\n\nSAML(Security Assertion Markup Language ，安全断言标记语言）的出现大大简化了 SSO ，并被 OASIS 批准为 SSO 的执行标准 。开源组织 OpenSAML 实现了 SAML 规范。\n\n## 2.SSO开源解决方案-CAS概述\n\nCAS(Central Authentication Service) 是 Yale 大学发起的一个开源项目，据统计使用开源SSO方案的大部分选择CAS，CAS简单高效并且足够安全。这也是本文介绍的主角。\n\n### 2.1 CAS的特征:\n \n>* 开源的、多协议:支持的协议包括 Custom Protocol 、 CAS 、 OAuth 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。\n \n>* 支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等。\n \n>* 安全策略：使用票据(Ticket)来实现支持的认证协议。\n \n>* 支持授权:可以决定哪些服务可以请求和验证服务票据(Service Ticket)。\n \n>* 高可用性支持：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS TreeCache 、 JpaTicketRegistry 、 MemcacheTicketRegistry 等。\n \n>* 支持多种客户端: Java 、 .Net 、 PHP 、 Perl 、 Apache, uPortal 等。\n \n### 2.2 CAS的结构体系\n\n从结构体系看， CAS 包括两部分： CAS Server 和 CAS Client 。\n \n** CAS Server **\n \nCAS Server 负责完成对用户的认证工作 , 需要独立部署 , CAS Server 会处理用户名 / 密码等凭证(Credentials) 。\n \n**CAS Client**\n \n负责处理对客户端受保护资源的访问请求，需要对请求方进行身份认证时，重定向到 CAS Server 进行认证。（原则上，客户端应用不再接受任何的用户名密码等 Credentials ）。CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。\n \n### 2.3 CAS原理和协议\n\nCAS协议是由Drew Mazurek编写，最新版本为3.0.1，发布时间为:2015-01-13。\n\n从 CAS v1 到现在的 CAS v3 ，整个协议的基础思想都是基于 Kerberos 的票据方式。\n\nCAS v1 非常原始，传送一个用户名居然是 ”yes\"ndavid.turing” 的方式， CAS v2 开始使用了 XML 规范，大大增强了可扩展性， CAS v3 开始使用 AOP 技术，让 Spring 爱好者可以轻松配置 CAS Server 到现有的应用环境中。\n\n*CAS 是通过 TGT(Ticket Granting Ticket) 来获取 ST(Service Ticket) ，通过 ST 来访问服务，而 CAS 也有对应 TGT ， ST 的实体，而且他们在保护 TGT 的方法上虽然有所区别，但是，最终都可以实现这样一个目的——免去多次登录的麻烦。*\n\nCAS协议分为**基础模式**和**代理模式**两种。\n\n[CAS协议官方规范](http://jasig.github.io/cas/4.1.x/protocol/CAS-Protocol-Specification.html)\n\n#### 2.3.1 基础模式的认证过程：\n\n![基础模式-时序图](http://jasig.github.io/cas/4.1.x/images/cas_flow_diagram.png)\n\nCAS服务端控制台日志：\n\n![CAS服务端控制台](/images/架构/cas认证流程.png)\n\n#### 2.3.2 代理模式的认证过程：\n\n![代理模式-时序图](http://jasig.github.io/cas/4.1.x/images/cas_proxy_flow_diagram.jpg)\n\n### 3.CAS安全性\n\nCAS 的安全性仅仅依赖于 SSL，使用的是 secure cookie，CAS 协议从几个方面让认证变得更加安全。 \n\n有关CAS安全特性，请看[CAS v4 安全手册](http://jasig.github.io/cas/4.1.x/planning/Security-Guide.html)\n\n### 3.1 TGC/PGT 安全性 \n\n对于一个 CAS 用户来说，最重要是要保护它的 TGC ，如果 TGC 不慎被 CAS Server 以外的实体获得， Hacker 能够找到该 TGC ，然后冒充 CAS 用户访问 所有 授权资源。 PGT 的角色跟 TGC 是一样的。\n\n从基础模式可以看出， TGC 是 CAS Server 通过 SSL 方式发送给终端用户，因此，要截取 TGC 难度非常大，从而确保 CAS 的安全性。\n\nTGT 的存活周期默认为 120 分钟。\n\n### 3.2 ST/PT 安全性\n\nST （ Service Ticket ）是通过 Http 传送的，因此网络中的其他人可以 Sniffer 到其他人的 Ticket 。 CAS 通过以下几方面来使 ST 变得更加安全（事实上都是可以配置的）：\n\n1、ST 只能使用一次\n\nCAS 协议规定，无论 Service Ticket 验证是否成功， CAS Server 都会清除服务端缓存中的该Ticket ，从而可以确保一个 Service Ticket 不被使用两次。\n\n2、ST 在一段时间内失效\n\nCAS 规定 ST 只能存活一定的时间，然后 CAS Server 会让它失效。默认有效时间为 5 分钟。\n\n3、ST 是基于随机数生成的\n\nST 必须足够随机，如果 ST 生成规则被猜出， Hacker 就等于绕过 CAS 认证，直接访问 对应的服务。\n\n\n","source":"_posts/2016-03-14-SSO解决方案汇总.md","raw":"---\nlayout: lay_post\ntitle: \"SSO解决方案汇总\"\ndate: 2016-03-14\ncategories: 架构\ntags: 单点登录\nauthor: lvyafei\n---\n\n## 0.概述\n\nSSO英文全称Single Sign On（单点登录）。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一.\n\n<!-- more -->\n\n随着SSO技术的流行，SSO的产品也是满天飞扬。所有著名的软件厂商都提供了相应的解决方案。常见的开源解决方案有：JA-SIG CAS、OpenSSO、JOSSO、Passport.js、Atlassian Crowd、GodAuth等。商业解决方案有Tivoli、Siteminder、RSA Secure SSO等。商业产品的安全性和用户体验比开源的相对来说比较好点。但是接触最多的还属于开源的方案。\n\n基本上SSO的实现分为3类：基于WEB的WEB SSO、基于Windows域的桌面SSO、SAML(Security Assertion Markup Language安全断言标记语言)。\n\n## 1.SSO原理\n\n### 1.1 SSO体系中的角色\n\n> 1.User （多个）\n\n> 2.Web 应用（多个）\n\n> 3.SSO 认证中心（ 1 个 ）\n\n### 1.2 SSO 实现模式的原则\n\n> 1.所有的认证登录都在 SSO 认证中心进行；\n\n> 2.SSO 认证中心通过一些方法来告诉 Web 应用当前访问用户究竟是不是已通过认证的用户；\n\n> 3.SSO 认证中心和所有的 Web 应用建立一种信任关系，也就是说 web 应用必须信任认证中心。（单点信任）\n\n### 1.3 SSO 主要实现方式\n\n>1.共享 cookies\n\n基于共享同域的 cookie 是 Web 刚开始阶段时使用的一种方式，它利用浏览同域名之间自动传递 cookies 机制，实现两个域名之间系统令牌传递问题；另外，关于跨域问题，虽然 cookies本身不跨域，但可以利用它实现跨域的 SSO 。如：代理、暴露 SSO 令牌值等。\n\n缺点：不灵活而且有不少安全隐患，已经被抛弃。\n\n>2.Broker-based(基于经纪人)\n\n这种技术的特点就是，有一个集中的认证和用户帐号管理的服务器。经纪人给被用于进一步请求的电子身份存取。中央数据库的使用减少了管理的代价，并为认证提供一个公共和独立的 \"第三方 \" 。例如 Kerberos 、 Sesame 、 IBM KryptoKnight （凭证库思想 ) 等。 Kerberos是由麻省理工大学发明的安全认证服务，已经被 UNIX 和 Windows 作为默认的安全认证服务集成进操作系统。\n\n>3.Agent-based(基于代理人)\n\n在这种解决方案中，有一个自动地为不同的应用程序认证用户身份的代理程序。这个代理程序需要设计有不同的功能。比如，它可以使用口令表或加密密钥来自动地将认证的负担从用户移开。代理人被放在服务器上面，在服务器的认证系统和客户端认证方法之间充当一个 \" 翻译 \"。例如 SSH 等。\n\n>4.Token-based\n\n例如 SecureID,WebID ，现在被广泛使用的口令认证，比如 FTP 、邮件服务器的登录认证，这是一种简单易用的方式，实现一个口令在多种应用当中使用。\n\n>5.基于网关\n\n在网关处实现身份认证。\n\n>6.基于SAML\n\nSAML(Security Assertion Markup Language ，安全断言标记语言）的出现大大简化了 SSO ，并被 OASIS 批准为 SSO 的执行标准 。开源组织 OpenSAML 实现了 SAML 规范。\n\n## 2.SSO开源解决方案-CAS概述\n\nCAS(Central Authentication Service) 是 Yale 大学发起的一个开源项目，据统计使用开源SSO方案的大部分选择CAS，CAS简单高效并且足够安全。这也是本文介绍的主角。\n\n### 2.1 CAS的特征:\n \n>* 开源的、多协议:支持的协议包括 Custom Protocol 、 CAS 、 OAuth 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。\n \n>* 支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等。\n \n>* 安全策略：使用票据(Ticket)来实现支持的认证协议。\n \n>* 支持授权:可以决定哪些服务可以请求和验证服务票据(Service Ticket)。\n \n>* 高可用性支持：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS TreeCache 、 JpaTicketRegistry 、 MemcacheTicketRegistry 等。\n \n>* 支持多种客户端: Java 、 .Net 、 PHP 、 Perl 、 Apache, uPortal 等。\n \n### 2.2 CAS的结构体系\n\n从结构体系看， CAS 包括两部分： CAS Server 和 CAS Client 。\n \n** CAS Server **\n \nCAS Server 负责完成对用户的认证工作 , 需要独立部署 , CAS Server 会处理用户名 / 密码等凭证(Credentials) 。\n \n**CAS Client**\n \n负责处理对客户端受保护资源的访问请求，需要对请求方进行身份认证时，重定向到 CAS Server 进行认证。（原则上，客户端应用不再接受任何的用户名密码等 Credentials ）。CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。\n \n### 2.3 CAS原理和协议\n\nCAS协议是由Drew Mazurek编写，最新版本为3.0.1，发布时间为:2015-01-13。\n\n从 CAS v1 到现在的 CAS v3 ，整个协议的基础思想都是基于 Kerberos 的票据方式。\n\nCAS v1 非常原始，传送一个用户名居然是 ”yes\"ndavid.turing” 的方式， CAS v2 开始使用了 XML 规范，大大增强了可扩展性， CAS v3 开始使用 AOP 技术，让 Spring 爱好者可以轻松配置 CAS Server 到现有的应用环境中。\n\n*CAS 是通过 TGT(Ticket Granting Ticket) 来获取 ST(Service Ticket) ，通过 ST 来访问服务，而 CAS 也有对应 TGT ， ST 的实体，而且他们在保护 TGT 的方法上虽然有所区别，但是，最终都可以实现这样一个目的——免去多次登录的麻烦。*\n\nCAS协议分为**基础模式**和**代理模式**两种。\n\n[CAS协议官方规范](http://jasig.github.io/cas/4.1.x/protocol/CAS-Protocol-Specification.html)\n\n#### 2.3.1 基础模式的认证过程：\n\n![基础模式-时序图](http://jasig.github.io/cas/4.1.x/images/cas_flow_diagram.png)\n\nCAS服务端控制台日志：\n\n![CAS服务端控制台](/images/架构/cas认证流程.png)\n\n#### 2.3.2 代理模式的认证过程：\n\n![代理模式-时序图](http://jasig.github.io/cas/4.1.x/images/cas_proxy_flow_diagram.jpg)\n\n### 3.CAS安全性\n\nCAS 的安全性仅仅依赖于 SSL，使用的是 secure cookie，CAS 协议从几个方面让认证变得更加安全。 \n\n有关CAS安全特性，请看[CAS v4 安全手册](http://jasig.github.io/cas/4.1.x/planning/Security-Guide.html)\n\n### 3.1 TGC/PGT 安全性 \n\n对于一个 CAS 用户来说，最重要是要保护它的 TGC ，如果 TGC 不慎被 CAS Server 以外的实体获得， Hacker 能够找到该 TGC ，然后冒充 CAS 用户访问 所有 授权资源。 PGT 的角色跟 TGC 是一样的。\n\n从基础模式可以看出， TGC 是 CAS Server 通过 SSL 方式发送给终端用户，因此，要截取 TGC 难度非常大，从而确保 CAS 的安全性。\n\nTGT 的存活周期默认为 120 分钟。\n\n### 3.2 ST/PT 安全性\n\nST （ Service Ticket ）是通过 Http 传送的，因此网络中的其他人可以 Sniffer 到其他人的 Ticket 。 CAS 通过以下几方面来使 ST 变得更加安全（事实上都是可以配置的）：\n\n1、ST 只能使用一次\n\nCAS 协议规定，无论 Service Ticket 验证是否成功， CAS Server 都会清除服务端缓存中的该Ticket ，从而可以确保一个 Service Ticket 不被使用两次。\n\n2、ST 在一段时间内失效\n\nCAS 规定 ST 只能存活一定的时间，然后 CAS Server 会让它失效。默认有效时间为 5 分钟。\n\n3、ST 是基于随机数生成的\n\nST 必须足够随机，如果 ST 生成规则被猜出， Hacker 就等于绕过 CAS 认证，直接访问 对应的服务。\n\n\n","slug":"2016-03-14-SSO解决方案汇总","published":1,"updated":"2018-11-29T12:51:24.641Z","comments":1,"photos":[],"link":"","_id":"cjskffnym000z4glmods45xgl","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>SSO英文全称Single Sign On（单点登录）。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一.</p>\n<a id=\"more\"></a>\n<p>随着SSO技术的流行，SSO的产品也是满天飞扬。所有著名的软件厂商都提供了相应的解决方案。常见的开源解决方案有：JA-SIG CAS、OpenSSO、JOSSO、Passport.js、Atlassian Crowd、GodAuth等。商业解决方案有Tivoli、Siteminder、RSA Secure SSO等。商业产品的安全性和用户体验比开源的相对来说比较好点。但是接触最多的还属于开源的方案。</p>\n<p>基本上SSO的实现分为3类：基于WEB的WEB SSO、基于Windows域的桌面SSO、SAML(Security Assertion Markup Language安全断言标记语言)。</p>\n<h2 id=\"1-SSO原理\"><a href=\"#1-SSO原理\" class=\"headerlink\" title=\"1.SSO原理\"></a>1.SSO原理</h2><h3 id=\"1-1-SSO体系中的角色\"><a href=\"#1-1-SSO体系中的角色\" class=\"headerlink\" title=\"1.1 SSO体系中的角色\"></a>1.1 SSO体系中的角色</h3><blockquote>\n<p>1.User （多个）</p>\n</blockquote>\n<blockquote>\n<p>2.Web 应用（多个）</p>\n</blockquote>\n<blockquote>\n<p>3.SSO 认证中心（ 1 个 ）</p>\n</blockquote>\n<h3 id=\"1-2-SSO-实现模式的原则\"><a href=\"#1-2-SSO-实现模式的原则\" class=\"headerlink\" title=\"1.2 SSO 实现模式的原则\"></a>1.2 SSO 实现模式的原则</h3><blockquote>\n<p>1.所有的认证登录都在 SSO 认证中心进行；</p>\n</blockquote>\n<blockquote>\n<p>2.SSO 认证中心通过一些方法来告诉 Web 应用当前访问用户究竟是不是已通过认证的用户；</p>\n</blockquote>\n<blockquote>\n<p>3.SSO 认证中心和所有的 Web 应用建立一种信任关系，也就是说 web 应用必须信任认证中心。（单点信任）</p>\n</blockquote>\n<h3 id=\"1-3-SSO-主要实现方式\"><a href=\"#1-3-SSO-主要实现方式\" class=\"headerlink\" title=\"1.3 SSO 主要实现方式\"></a>1.3 SSO 主要实现方式</h3><blockquote>\n<p>1.共享 cookies</p>\n</blockquote>\n<p>基于共享同域的 cookie 是 Web 刚开始阶段时使用的一种方式，它利用浏览同域名之间自动传递 cookies 机制，实现两个域名之间系统令牌传递问题；另外，关于跨域问题，虽然 cookies本身不跨域，但可以利用它实现跨域的 SSO 。如：代理、暴露 SSO 令牌值等。</p>\n<p>缺点：不灵活而且有不少安全隐患，已经被抛弃。</p>\n<blockquote>\n<p>2.Broker-based(基于经纪人)</p>\n</blockquote>\n<p>这种技术的特点就是，有一个集中的认证和用户帐号管理的服务器。经纪人给被用于进一步请求的电子身份存取。中央数据库的使用减少了管理的代价，并为认证提供一个公共和独立的 “第三方 “ 。例如 Kerberos 、 Sesame 、 IBM KryptoKnight （凭证库思想 ) 等。 Kerberos是由麻省理工大学发明的安全认证服务，已经被 UNIX 和 Windows 作为默认的安全认证服务集成进操作系统。</p>\n<blockquote>\n<p>3.Agent-based(基于代理人)</p>\n</blockquote>\n<p>在这种解决方案中，有一个自动地为不同的应用程序认证用户身份的代理程序。这个代理程序需要设计有不同的功能。比如，它可以使用口令表或加密密钥来自动地将认证的负担从用户移开。代理人被放在服务器上面，在服务器的认证系统和客户端认证方法之间充当一个 “ 翻译 “。例如 SSH 等。</p>\n<blockquote>\n<p>4.Token-based</p>\n</blockquote>\n<p>例如 SecureID,WebID ，现在被广泛使用的口令认证，比如 FTP 、邮件服务器的登录认证，这是一种简单易用的方式，实现一个口令在多种应用当中使用。</p>\n<blockquote>\n<p>5.基于网关</p>\n</blockquote>\n<p>在网关处实现身份认证。</p>\n<blockquote>\n<p>6.基于SAML</p>\n</blockquote>\n<p>SAML(Security Assertion Markup Language ，安全断言标记语言）的出现大大简化了 SSO ，并被 OASIS 批准为 SSO 的执行标准 。开源组织 OpenSAML 实现了 SAML 规范。</p>\n<h2 id=\"2-SSO开源解决方案-CAS概述\"><a href=\"#2-SSO开源解决方案-CAS概述\" class=\"headerlink\" title=\"2.SSO开源解决方案-CAS概述\"></a>2.SSO开源解决方案-CAS概述</h2><p>CAS(Central Authentication Service) 是 Yale 大学发起的一个开源项目，据统计使用开源SSO方案的大部分选择CAS，CAS简单高效并且足够安全。这也是本文介绍的主角。</p>\n<h3 id=\"2-1-CAS的特征\"><a href=\"#2-1-CAS的特征\" class=\"headerlink\" title=\"2.1 CAS的特征:\"></a>2.1 CAS的特征:</h3><blockquote>\n<ul>\n<li>开源的、多协议:支持的协议包括 Custom Protocol 、 CAS 、 OAuth 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>安全策略：使用票据(Ticket)来实现支持的认证协议。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持授权:可以决定哪些服务可以请求和验证服务票据(Service Ticket)。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>高可用性支持：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS TreeCache 、 JpaTicketRegistry 、 MemcacheTicketRegistry 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持多种客户端: Java 、 .Net 、 PHP 、 Perl 、 Apache, uPortal 等。</li>\n</ul>\n</blockquote>\n<h3 id=\"2-2-CAS的结构体系\"><a href=\"#2-2-CAS的结构体系\" class=\"headerlink\" title=\"2.2 CAS的结构体系\"></a>2.2 CAS的结构体系</h3><p>从结构体系看， CAS 包括两部分： CAS Server 和 CAS Client 。</p>\n<p><strong> CAS Server </strong></p>\n<p>CAS Server 负责完成对用户的认证工作 , 需要独立部署 , CAS Server 会处理用户名 / 密码等凭证(Credentials) 。</p>\n<p><strong>CAS Client</strong></p>\n<p>负责处理对客户端受保护资源的访问请求，需要对请求方进行身份认证时，重定向到 CAS Server 进行认证。（原则上，客户端应用不再接受任何的用户名密码等 Credentials ）。CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。</p>\n<h3 id=\"2-3-CAS原理和协议\"><a href=\"#2-3-CAS原理和协议\" class=\"headerlink\" title=\"2.3 CAS原理和协议\"></a>2.3 CAS原理和协议</h3><p>CAS协议是由Drew Mazurek编写，最新版本为3.0.1，发布时间为:2015-01-13。</p>\n<p>从 CAS v1 到现在的 CAS v3 ，整个协议的基础思想都是基于 Kerberos 的票据方式。</p>\n<p>CAS v1 非常原始，传送一个用户名居然是 ”yes”ndavid.turing” 的方式， CAS v2 开始使用了 XML 规范，大大增强了可扩展性， CAS v3 开始使用 AOP 技术，让 Spring 爱好者可以轻松配置 CAS Server 到现有的应用环境中。</p>\n<p><em>CAS 是通过 TGT(Ticket Granting Ticket) 来获取 ST(Service Ticket) ，通过 ST 来访问服务，而 CAS 也有对应 TGT ， ST 的实体，而且他们在保护 TGT 的方法上虽然有所区别，但是，最终都可以实现这样一个目的——免去多次登录的麻烦。</em></p>\n<p>CAS协议分为<strong>基础模式</strong>和<strong>代理模式</strong>两种。</p>\n<p><a href=\"http://jasig.github.io/cas/4.1.x/protocol/CAS-Protocol-Specification.html\" target=\"_blank\" rel=\"noopener\">CAS协议官方规范</a></p>\n<h4 id=\"2-3-1-基础模式的认证过程：\"><a href=\"#2-3-1-基础模式的认证过程：\" class=\"headerlink\" title=\"2.3.1 基础模式的认证过程：\"></a>2.3.1 基础模式的认证过程：</h4><p><img src=\"http://jasig.github.io/cas/4.1.x/images/cas_flow_diagram.png\" alt=\"基础模式-时序图\"></p>\n<p>CAS服务端控制台日志：</p>\n<p><img src=\"/images/架构/cas认证流程.png\" alt=\"CAS服务端控制台\"></p>\n<h4 id=\"2-3-2-代理模式的认证过程：\"><a href=\"#2-3-2-代理模式的认证过程：\" class=\"headerlink\" title=\"2.3.2 代理模式的认证过程：\"></a>2.3.2 代理模式的认证过程：</h4><p><img src=\"http://jasig.github.io/cas/4.1.x/images/cas_proxy_flow_diagram.jpg\" alt=\"代理模式-时序图\"></p>\n<h3 id=\"3-CAS安全性\"><a href=\"#3-CAS安全性\" class=\"headerlink\" title=\"3.CAS安全性\"></a>3.CAS安全性</h3><p>CAS 的安全性仅仅依赖于 SSL，使用的是 secure cookie，CAS 协议从几个方面让认证变得更加安全。 </p>\n<p>有关CAS安全特性，请看<a href=\"http://jasig.github.io/cas/4.1.x/planning/Security-Guide.html\" target=\"_blank\" rel=\"noopener\">CAS v4 安全手册</a></p>\n<h3 id=\"3-1-TGC-PGT-安全性\"><a href=\"#3-1-TGC-PGT-安全性\" class=\"headerlink\" title=\"3.1 TGC/PGT 安全性\"></a>3.1 TGC/PGT 安全性</h3><p>对于一个 CAS 用户来说，最重要是要保护它的 TGC ，如果 TGC 不慎被 CAS Server 以外的实体获得， Hacker 能够找到该 TGC ，然后冒充 CAS 用户访问 所有 授权资源。 PGT 的角色跟 TGC 是一样的。</p>\n<p>从基础模式可以看出， TGC 是 CAS Server 通过 SSL 方式发送给终端用户，因此，要截取 TGC 难度非常大，从而确保 CAS 的安全性。</p>\n<p>TGT 的存活周期默认为 120 分钟。</p>\n<h3 id=\"3-2-ST-PT-安全性\"><a href=\"#3-2-ST-PT-安全性\" class=\"headerlink\" title=\"3.2 ST/PT 安全性\"></a>3.2 ST/PT 安全性</h3><p>ST （ Service Ticket ）是通过 Http 传送的，因此网络中的其他人可以 Sniffer 到其他人的 Ticket 。 CAS 通过以下几方面来使 ST 变得更加安全（事实上都是可以配置的）：</p>\n<p>1、ST 只能使用一次</p>\n<p>CAS 协议规定，无论 Service Ticket 验证是否成功， CAS Server 都会清除服务端缓存中的该Ticket ，从而可以确保一个 Service Ticket 不被使用两次。</p>\n<p>2、ST 在一段时间内失效</p>\n<p>CAS 规定 ST 只能存活一定的时间，然后 CAS Server 会让它失效。默认有效时间为 5 分钟。</p>\n<p>3、ST 是基于随机数生成的</p>\n<p>ST 必须足够随机，如果 ST 生成规则被猜出， Hacker 就等于绕过 CAS 认证，直接访问 对应的服务。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>SSO英文全称Single Sign On（单点登录）。SSO是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。它是目前比较流行的企业业务整合的解决方案之一.</p>","more":"<p>随着SSO技术的流行，SSO的产品也是满天飞扬。所有著名的软件厂商都提供了相应的解决方案。常见的开源解决方案有：JA-SIG CAS、OpenSSO、JOSSO、Passport.js、Atlassian Crowd、GodAuth等。商业解决方案有Tivoli、Siteminder、RSA Secure SSO等。商业产品的安全性和用户体验比开源的相对来说比较好点。但是接触最多的还属于开源的方案。</p>\n<p>基本上SSO的实现分为3类：基于WEB的WEB SSO、基于Windows域的桌面SSO、SAML(Security Assertion Markup Language安全断言标记语言)。</p>\n<h2 id=\"1-SSO原理\"><a href=\"#1-SSO原理\" class=\"headerlink\" title=\"1.SSO原理\"></a>1.SSO原理</h2><h3 id=\"1-1-SSO体系中的角色\"><a href=\"#1-1-SSO体系中的角色\" class=\"headerlink\" title=\"1.1 SSO体系中的角色\"></a>1.1 SSO体系中的角色</h3><blockquote>\n<p>1.User （多个）</p>\n</blockquote>\n<blockquote>\n<p>2.Web 应用（多个）</p>\n</blockquote>\n<blockquote>\n<p>3.SSO 认证中心（ 1 个 ）</p>\n</blockquote>\n<h3 id=\"1-2-SSO-实现模式的原则\"><a href=\"#1-2-SSO-实现模式的原则\" class=\"headerlink\" title=\"1.2 SSO 实现模式的原则\"></a>1.2 SSO 实现模式的原则</h3><blockquote>\n<p>1.所有的认证登录都在 SSO 认证中心进行；</p>\n</blockquote>\n<blockquote>\n<p>2.SSO 认证中心通过一些方法来告诉 Web 应用当前访问用户究竟是不是已通过认证的用户；</p>\n</blockquote>\n<blockquote>\n<p>3.SSO 认证中心和所有的 Web 应用建立一种信任关系，也就是说 web 应用必须信任认证中心。（单点信任）</p>\n</blockquote>\n<h3 id=\"1-3-SSO-主要实现方式\"><a href=\"#1-3-SSO-主要实现方式\" class=\"headerlink\" title=\"1.3 SSO 主要实现方式\"></a>1.3 SSO 主要实现方式</h3><blockquote>\n<p>1.共享 cookies</p>\n</blockquote>\n<p>基于共享同域的 cookie 是 Web 刚开始阶段时使用的一种方式，它利用浏览同域名之间自动传递 cookies 机制，实现两个域名之间系统令牌传递问题；另外，关于跨域问题，虽然 cookies本身不跨域，但可以利用它实现跨域的 SSO 。如：代理、暴露 SSO 令牌值等。</p>\n<p>缺点：不灵活而且有不少安全隐患，已经被抛弃。</p>\n<blockquote>\n<p>2.Broker-based(基于经纪人)</p>\n</blockquote>\n<p>这种技术的特点就是，有一个集中的认证和用户帐号管理的服务器。经纪人给被用于进一步请求的电子身份存取。中央数据库的使用减少了管理的代价，并为认证提供一个公共和独立的 “第三方 “ 。例如 Kerberos 、 Sesame 、 IBM KryptoKnight （凭证库思想 ) 等。 Kerberos是由麻省理工大学发明的安全认证服务，已经被 UNIX 和 Windows 作为默认的安全认证服务集成进操作系统。</p>\n<blockquote>\n<p>3.Agent-based(基于代理人)</p>\n</blockquote>\n<p>在这种解决方案中，有一个自动地为不同的应用程序认证用户身份的代理程序。这个代理程序需要设计有不同的功能。比如，它可以使用口令表或加密密钥来自动地将认证的负担从用户移开。代理人被放在服务器上面，在服务器的认证系统和客户端认证方法之间充当一个 “ 翻译 “。例如 SSH 等。</p>\n<blockquote>\n<p>4.Token-based</p>\n</blockquote>\n<p>例如 SecureID,WebID ，现在被广泛使用的口令认证，比如 FTP 、邮件服务器的登录认证，这是一种简单易用的方式，实现一个口令在多种应用当中使用。</p>\n<blockquote>\n<p>5.基于网关</p>\n</blockquote>\n<p>在网关处实现身份认证。</p>\n<blockquote>\n<p>6.基于SAML</p>\n</blockquote>\n<p>SAML(Security Assertion Markup Language ，安全断言标记语言）的出现大大简化了 SSO ，并被 OASIS 批准为 SSO 的执行标准 。开源组织 OpenSAML 实现了 SAML 规范。</p>\n<h2 id=\"2-SSO开源解决方案-CAS概述\"><a href=\"#2-SSO开源解决方案-CAS概述\" class=\"headerlink\" title=\"2.SSO开源解决方案-CAS概述\"></a>2.SSO开源解决方案-CAS概述</h2><p>CAS(Central Authentication Service) 是 Yale 大学发起的一个开源项目，据统计使用开源SSO方案的大部分选择CAS，CAS简单高效并且足够安全。这也是本文介绍的主角。</p>\n<h3 id=\"2-1-CAS的特征\"><a href=\"#2-1-CAS的特征\" class=\"headerlink\" title=\"2.1 CAS的特征:\"></a>2.1 CAS的特征:</h3><blockquote>\n<ul>\n<li>开源的、多协议:支持的协议包括 Custom Protocol 、 CAS 、 OAuth 、 OpenID 、 RESTful API 、 SAML1.1 、 SAML2.0 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持多种认证机制： Active Directory 、 JAAS 、 JDBC 、 LDAP 、 X.509 Certificates 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>安全策略：使用票据(Ticket)来实现支持的认证协议。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持授权:可以决定哪些服务可以请求和验证服务票据(Service Ticket)。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>高可用性支持：通过把认证过的状态数据存储在 TicketRegistry 组件中，这些组件有很多支持分布式环境的实现，如： BerkleyDB 、 Default 、 EhcacheTicketRegistry 、 JDBCTicketRegistry 、 JBOSS TreeCache 、 JpaTicketRegistry 、 MemcacheTicketRegistry 等。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>支持多种客户端: Java 、 .Net 、 PHP 、 Perl 、 Apache, uPortal 等。</li>\n</ul>\n</blockquote>\n<h3 id=\"2-2-CAS的结构体系\"><a href=\"#2-2-CAS的结构体系\" class=\"headerlink\" title=\"2.2 CAS的结构体系\"></a>2.2 CAS的结构体系</h3><p>从结构体系看， CAS 包括两部分： CAS Server 和 CAS Client 。</p>\n<p><strong> CAS Server </strong></p>\n<p>CAS Server 负责完成对用户的认证工作 , 需要独立部署 , CAS Server 会处理用户名 / 密码等凭证(Credentials) 。</p>\n<p><strong>CAS Client</strong></p>\n<p>负责处理对客户端受保护资源的访问请求，需要对请求方进行身份认证时，重定向到 CAS Server 进行认证。（原则上，客户端应用不再接受任何的用户名密码等 Credentials ）。CAS Client 与受保护的客户端应用部署在一起，以 Filter 方式保护受保护的资源。</p>\n<h3 id=\"2-3-CAS原理和协议\"><a href=\"#2-3-CAS原理和协议\" class=\"headerlink\" title=\"2.3 CAS原理和协议\"></a>2.3 CAS原理和协议</h3><p>CAS协议是由Drew Mazurek编写，最新版本为3.0.1，发布时间为:2015-01-13。</p>\n<p>从 CAS v1 到现在的 CAS v3 ，整个协议的基础思想都是基于 Kerberos 的票据方式。</p>\n<p>CAS v1 非常原始，传送一个用户名居然是 ”yes”ndavid.turing” 的方式， CAS v2 开始使用了 XML 规范，大大增强了可扩展性， CAS v3 开始使用 AOP 技术，让 Spring 爱好者可以轻松配置 CAS Server 到现有的应用环境中。</p>\n<p><em>CAS 是通过 TGT(Ticket Granting Ticket) 来获取 ST(Service Ticket) ，通过 ST 来访问服务，而 CAS 也有对应 TGT ， ST 的实体，而且他们在保护 TGT 的方法上虽然有所区别，但是，最终都可以实现这样一个目的——免去多次登录的麻烦。</em></p>\n<p>CAS协议分为<strong>基础模式</strong>和<strong>代理模式</strong>两种。</p>\n<p><a href=\"http://jasig.github.io/cas/4.1.x/protocol/CAS-Protocol-Specification.html\" target=\"_blank\" rel=\"noopener\">CAS协议官方规范</a></p>\n<h4 id=\"2-3-1-基础模式的认证过程：\"><a href=\"#2-3-1-基础模式的认证过程：\" class=\"headerlink\" title=\"2.3.1 基础模式的认证过程：\"></a>2.3.1 基础模式的认证过程：</h4><p><img src=\"http://jasig.github.io/cas/4.1.x/images/cas_flow_diagram.png\" alt=\"基础模式-时序图\"></p>\n<p>CAS服务端控制台日志：</p>\n<p><img src=\"/images/架构/cas认证流程.png\" alt=\"CAS服务端控制台\"></p>\n<h4 id=\"2-3-2-代理模式的认证过程：\"><a href=\"#2-3-2-代理模式的认证过程：\" class=\"headerlink\" title=\"2.3.2 代理模式的认证过程：\"></a>2.3.2 代理模式的认证过程：</h4><p><img src=\"http://jasig.github.io/cas/4.1.x/images/cas_proxy_flow_diagram.jpg\" alt=\"代理模式-时序图\"></p>\n<h3 id=\"3-CAS安全性\"><a href=\"#3-CAS安全性\" class=\"headerlink\" title=\"3.CAS安全性\"></a>3.CAS安全性</h3><p>CAS 的安全性仅仅依赖于 SSL，使用的是 secure cookie，CAS 协议从几个方面让认证变得更加安全。 </p>\n<p>有关CAS安全特性，请看<a href=\"http://jasig.github.io/cas/4.1.x/planning/Security-Guide.html\" target=\"_blank\" rel=\"noopener\">CAS v4 安全手册</a></p>\n<h3 id=\"3-1-TGC-PGT-安全性\"><a href=\"#3-1-TGC-PGT-安全性\" class=\"headerlink\" title=\"3.1 TGC/PGT 安全性\"></a>3.1 TGC/PGT 安全性</h3><p>对于一个 CAS 用户来说，最重要是要保护它的 TGC ，如果 TGC 不慎被 CAS Server 以外的实体获得， Hacker 能够找到该 TGC ，然后冒充 CAS 用户访问 所有 授权资源。 PGT 的角色跟 TGC 是一样的。</p>\n<p>从基础模式可以看出， TGC 是 CAS Server 通过 SSL 方式发送给终端用户，因此，要截取 TGC 难度非常大，从而确保 CAS 的安全性。</p>\n<p>TGT 的存活周期默认为 120 分钟。</p>\n<h3 id=\"3-2-ST-PT-安全性\"><a href=\"#3-2-ST-PT-安全性\" class=\"headerlink\" title=\"3.2 ST/PT 安全性\"></a>3.2 ST/PT 安全性</h3><p>ST （ Service Ticket ）是通过 Http 传送的，因此网络中的其他人可以 Sniffer 到其他人的 Ticket 。 CAS 通过以下几方面来使 ST 变得更加安全（事实上都是可以配置的）：</p>\n<p>1、ST 只能使用一次</p>\n<p>CAS 协议规定，无论 Service Ticket 验证是否成功， CAS Server 都会清除服务端缓存中的该Ticket ，从而可以确保一个 Service Ticket 不被使用两次。</p>\n<p>2、ST 在一段时间内失效</p>\n<p>CAS 规定 ST 只能存活一定的时间，然后 CAS Server 会让它失效。默认有效时间为 5 分钟。</p>\n<p>3、ST 是基于随机数生成的</p>\n<p>ST 必须足够随机，如果 ST 生成规则被猜出， Hacker 就等于绕过 CAS 认证，直接访问 对应的服务。</p>"},{"layout":"lay_post","title":"互联网团队技术-新浪微博","date":"2016-04-09T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n新浪微博的技术分享。\n<!-- more -->\n\n## 1.微博技术介绍\n\n新浪微博：[http://weibo.com/timyang](http://weibo.com/timyang)\nTimYang站点-后端技术 [http://timyang.net/category/architecture/](http://timyang.net/category/architecture/)\n微信号：高可用架构\n\n","source":"_posts/2016-04-10-互联网团队技术架构-新浪微博.md","raw":"---\nlayout: lay_post\ntitle: 互联网团队技术-新浪微博\ndate: 2016-04-10\ncategories: 互联网团队技术\ntags: 新浪微博\nauthor: lvyafei\n---\n\n## 0.概述\n\n新浪微博的技术分享。\n<!-- more -->\n\n## 1.微博技术介绍\n\n新浪微博：[http://weibo.com/timyang](http://weibo.com/timyang)\nTimYang站点-后端技术 [http://timyang.net/category/architecture/](http://timyang.net/category/architecture/)\n微信号：高可用架构\n\n","slug":"2016-04-10-互联网团队技术架构-新浪微博","published":1,"updated":"2018-11-29T12:51:24.659Z","comments":1,"photos":[],"link":"","_id":"cjskffo5z00224glmu92mduiv","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>新浪微博的技术分享。<br><a id=\"more\"></a></p>\n<h2 id=\"1-微博技术介绍\"><a href=\"#1-微博技术介绍\" class=\"headerlink\" title=\"1.微博技术介绍\"></a>1.微博技术介绍</h2><p>新浪微博：<a href=\"http://weibo.com/timyang\" target=\"_blank\" rel=\"noopener\">http://weibo.com/timyang</a><br>TimYang站点-后端技术 <a href=\"http://timyang.net/category/architecture/\" target=\"_blank\" rel=\"noopener\">http://timyang.net/category/architecture/</a><br>微信号：高可用架构</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>新浪微博的技术分享。<br>","more":"</p>\n<h2 id=\"1-微博技术介绍\"><a href=\"#1-微博技术介绍\" class=\"headerlink\" title=\"1.微博技术介绍\"></a>1.微博技术介绍</h2><p>新浪微博：<a href=\"http://weibo.com/timyang\" target=\"_blank\" rel=\"noopener\">http://weibo.com/timyang</a><br>TimYang站点-后端技术 <a href=\"http://timyang.net/category/architecture/\" target=\"_blank\" rel=\"noopener\">http://timyang.net/category/architecture/</a><br>微信号：高可用架构</p>"},{"layout":"lay_post","title":"数字签名过程图解","date":"2016-06-27T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n常见的对称加密:DES,AES。常见的非对称加密:RSA,DSA。常见的不可逆加密:MD5等。\n\n<!-- more -->\n\n## 1.图解\n\n![相似度类图](/images/密码学/加密.png)\n\n","source":"_posts/2016-06-28-数字签名过程图解.md","raw":"---\nlayout: lay_post\ntitle: \"数字签名过程图解\"\ndate: 2016-06-28\ncategories: 密码学\ntags: [加密解密]\nauthor: lvyafei\n---\n\n## 0.概述\n\n常见的对称加密:DES,AES。常见的非对称加密:RSA,DSA。常见的不可逆加密:MD5等。\n\n<!-- more -->\n\n## 1.图解\n\n![相似度类图](/images/密码学/加密.png)\n\n","slug":"2016-06-28-数字签名过程图解","published":1,"updated":"2019-02-25T14:16:48.058Z","comments":1,"photos":[],"link":"","_id":"cjskffo5z00244glm06rmvutr","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>常见的对称加密:DES,AES。常见的非对称加密:RSA,DSA。常见的不可逆加密:MD5等。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-图解\"><a href=\"#1-图解\" class=\"headerlink\" title=\"1.图解\"></a>1.图解</h2><p><img src=\"/images/密码学/加密.png\" alt=\"相似度类图\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>常见的对称加密:DES,AES。常见的非对称加密:RSA,DSA。常见的不可逆加密:MD5等。</p>","more":"<h2 id=\"1-图解\"><a href=\"#1-图解\" class=\"headerlink\" title=\"1.图解\"></a>1.图解</h2><p><img src=\"/images/密码学/加密.png\" alt=\"相似度类图\"></p>"},{"layout":"lay_post","title":"Mahout构建推荐系统-相似度算法","date":"2016-06-12T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nMahout中包含了相似度、邻间，推荐算法。了解每种算法的原来和使用场景对构建推荐系统非常有必要。\n\n<!-- more -->\n\n## 1.类图\n\n相似度类图：\n\n![相似度类图](/images/mahout/similarDiagram.jpg)\n\n邻居类图：\n\n![邻居类](/images/mahout/neighbDiagram.jpg)\n\n推荐类图:\n\n![推荐类](/images/mahout/recommendDiagram.jpg)","source":"_posts/2016-06-13-Mahout构建推荐系统-相似度算法.md","raw":"---\nlayout: lay_post\ntitle: \"Mahout构建推荐系统-相似度算法\"\ndate: 2016-06-13\ncategories: 相似度算法\ntags: 推荐系统\nauthor: lvyafei\n---\n\n## 0.概述\n\nMahout中包含了相似度、邻间，推荐算法。了解每种算法的原来和使用场景对构建推荐系统非常有必要。\n\n<!-- more -->\n\n## 1.类图\n\n相似度类图：\n\n![相似度类图](/images/mahout/similarDiagram.jpg)\n\n邻居类图：\n\n![邻居类](/images/mahout/neighbDiagram.jpg)\n\n推荐类图:\n\n![推荐类](/images/mahout/recommendDiagram.jpg)","slug":"2016-06-13-Mahout构建推荐系统-相似度算法","published":1,"updated":"2018-11-29T12:51:24.668Z","comments":1,"photos":[],"link":"","_id":"cjskffo6e00284glm46n6iftl","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Mahout中包含了相似度、邻间，推荐算法。了解每种算法的原来和使用场景对构建推荐系统非常有必要。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p>相似度类图：</p>\n<p><img src=\"/images/mahout/similarDiagram.jpg\" alt=\"相似度类图\"></p>\n<p>邻居类图：</p>\n<p><img src=\"/images/mahout/neighbDiagram.jpg\" alt=\"邻居类\"></p>\n<p>推荐类图:</p>\n<p><img src=\"/images/mahout/recommendDiagram.jpg\" alt=\"推荐类\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Mahout中包含了相似度、邻间，推荐算法。了解每种算法的原来和使用场景对构建推荐系统非常有必要。</p>","more":"<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p>相似度类图：</p>\n<p><img src=\"/images/mahout/similarDiagram.jpg\" alt=\"相似度类图\"></p>\n<p>邻居类图：</p>\n<p><img src=\"/images/mahout/neighbDiagram.jpg\" alt=\"邻居类\"></p>\n<p>推荐类图:</p>\n<p><img src=\"/images/mahout/recommendDiagram.jpg\" alt=\"推荐类\"></p>"},{"layout":"lay_post","title":"推荐系统建设流程","date":"2016-07-19T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n推荐系统的三要素：推荐内容，推荐算法，推荐流程。\n\n<!-- more -->\n\n## 1.图解\n\n![推荐系统](/images/推荐/推荐系统.png)\n\n","source":"_posts/2016-07-20-推荐系统建设流程.md","raw":"---\nlayout: lay_post\ntitle: \"推荐系统建设流程\"\ndate: 2016-07-20\ncategories: 系统架构\ntags: 推荐系统\nauthor: lvyafei\n---\n\n## 0.概述\n\n推荐系统的三要素：推荐内容，推荐算法，推荐流程。\n\n<!-- more -->\n\n## 1.图解\n\n![推荐系统](/images/推荐/推荐系统.png)\n\n","slug":"2016-07-20-推荐系统建设流程","published":1,"updated":"2018-11-29T12:51:24.675Z","comments":1,"photos":[],"link":"","_id":"cjskffo6u002a4glm6pq5101m","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>推荐系统的三要素：推荐内容，推荐算法，推荐流程。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-图解\"><a href=\"#1-图解\" class=\"headerlink\" title=\"1.图解\"></a>1.图解</h2><p><img src=\"/images/推荐/推荐系统.png\" alt=\"推荐系统\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>推荐系统的三要素：推荐内容，推荐算法，推荐流程。</p>","more":"<h2 id=\"1-图解\"><a href=\"#1-图解\" class=\"headerlink\" title=\"1.图解\"></a>1.图解</h2><p><img src=\"/images/推荐/推荐系统.png\" alt=\"推荐系统\"></p>"},{"layout":"lay_post","title":"JDK源码分析之集合类汇总","date":"2016-04-03T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nJAVA中包含了好多集合类，这些类在我们日常开发中非常重要，这些类主要集中在java.util包中，熟悉和掌握这些类的使用和原理，对我们提高代码质量非常重要。\n<!-- more -->\n\n## 1.类图\n\n![集合类图](/images/java源码/集合-类图.jpg)\n\n## 2.总结\n\nhttp://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html\n\nhttp://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html\n\nhttp://www.cnblogs.com/end/archive/2012/10/25/2738493.html\n","source":"_posts/2016-04-04-JDK源码分析之集合类汇总.md","raw":"---\nlayout: lay_post\ntitle: JDK源码分析之集合类汇总\ndate: 2016-04-04\ncategories: JAVA源码\ntags: Collection集合类\nauthor: lvyafei\n---\n\n## 0.概述\n\nJAVA中包含了好多集合类，这些类在我们日常开发中非常重要，这些类主要集中在java.util包中，熟悉和掌握这些类的使用和原理，对我们提高代码质量非常重要。\n<!-- more -->\n\n## 1.类图\n\n![集合类图](/images/java源码/集合-类图.jpg)\n\n## 2.总结\n\nhttp://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html\n\nhttp://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html\n\nhttp://www.cnblogs.com/end/archive/2012/10/25/2738493.html\n","slug":"2016-04-04-JDK源码分析之集合类汇总","published":1,"updated":"2018-11-29T12:51:24.645Z","comments":1,"photos":[],"link":"","_id":"cjskffo6u002b4glmqtblogt9","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JAVA中包含了好多集合类，这些类在我们日常开发中非常重要，这些类主要集中在java.util包中，熟悉和掌握这些类的使用和原理，对我们提高代码质量非常重要。<br><a id=\"more\"></a></p>\n<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p><img src=\"/images/java源码/集合-类图.jpg\" alt=\"集合类图\"></p>\n<h2 id=\"2-总结\"><a href=\"#2-总结\" class=\"headerlink\" title=\"2.总结\"></a>2.总结</h2><p><a href=\"http://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html</a></p>\n<p><a href=\"http://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html</a></p>\n<p><a href=\"http://www.cnblogs.com/end/archive/2012/10/25/2738493.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/end/archive/2012/10/25/2738493.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>JAVA中包含了好多集合类，这些类在我们日常开发中非常重要，这些类主要集中在java.util包中，熟悉和掌握这些类的使用和原理，对我们提高代码质量非常重要。<br>","more":"</p>\n<h2 id=\"1-类图\"><a href=\"#1-类图\" class=\"headerlink\" title=\"1.类图\"></a>1.类图</h2><p><img src=\"/images/java源码/集合-类图.jpg\" alt=\"集合类图\"></p>\n<h2 id=\"2-总结\"><a href=\"#2-总结\" class=\"headerlink\" title=\"2.总结\"></a>2.总结</h2><p><a href=\"http://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/linjiqin/archive/2013/05/30/3107785.html</a></p>\n<p><a href=\"http://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/devinzhang/archive/2012/01/25/2329434.html</a></p>\n<p><a href=\"http://www.cnblogs.com/end/archive/2012/10/25/2738493.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/end/archive/2012/10/25/2738493.html</a></p>"},{"layout":"lay_post","title":"中英文词性表","date":"2016-09-14T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n中文词性和英文词性表，方便查阅。\n\n<!-- more -->\n\n## 1.中英文词性表\n\n英文词性表：\n\n![英文词性](/images/推荐/英文单词词性表.jpg)\n\n中文词性表：\n\n![中文词性](/images/推荐/中文单词词性表.png)","source":"_posts/2016-09-15-中英文词性表.md","raw":"---\nlayout: lay_post\ntitle: \"中英文词性表\"\ndate: 2016-09-15\ncategories: 推荐\ntags: 文本挖掘\nauthor: lvyafei\n---\n\n## 0.概述\n\n中文词性和英文词性表，方便查阅。\n\n<!-- more -->\n\n## 1.中英文词性表\n\n英文词性表：\n\n![英文词性](/images/推荐/英文单词词性表.jpg)\n\n中文词性表：\n\n![中文词性](/images/推荐/中文单词词性表.png)","slug":"2016-09-15-中英文词性表","published":1,"updated":"2018-11-29T12:51:24.696Z","comments":1,"photos":[],"link":"","_id":"cjskffo7a002f4glmfkd0o943","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>中文词性和英文词性表，方便查阅。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-中英文词性表\"><a href=\"#1-中英文词性表\" class=\"headerlink\" title=\"1.中英文词性表\"></a>1.中英文词性表</h2><p>英文词性表：</p>\n<p><img src=\"/images/推荐/英文单词词性表.jpg\" alt=\"英文词性\"></p>\n<p>中文词性表：</p>\n<p><img src=\"/images/推荐/中文单词词性表.png\" alt=\"中文词性\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>中文词性和英文词性表，方便查阅。</p>","more":"<h2 id=\"1-中英文词性表\"><a href=\"#1-中英文词性表\" class=\"headerlink\" title=\"1.中英文词性表\"></a>1.中英文词性表</h2><p>英文词性表：</p>\n<p><img src=\"/images/推荐/英文单词词性表.jpg\" alt=\"英文词性\"></p>\n<p>中文词性表：</p>\n<p><img src=\"/images/推荐/中文单词词性表.png\" alt=\"中文词性\"></p>"},{"layout":"lay_post","title":"Java内存模型与线程同步问题整理","date":"2016-04-14T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n对高并发程序编写需要对JAVA内存模型有一个清晰的认识。以下是整理的JAVA内存模型和线程的相关内容，内容转自互联网。\n\n<!-- more -->\n\n## 1.硬件的效率与一致性\n\n由于计算机的存储设备与处理器的运算能力之间有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。\n\n基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议可以保障数据的一致性，这类协议有MSI、MESI、MOSI及Dragon Protocol等。Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的，后续将介绍Java内存模型。\n\n![硬件模型](http://images.cnitblog.com/i/475287/201403/091102484251967.jpg)\n\n除此之外，为了使得处理器内部的运算单元能竟可能被充分利用，处理器可能会对输入代码进行乱起执行（Out-Of-Order Execution）优化，处理器会在计算之后将对乱序执行的代码进行结果重组，保证结果准确性。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Recorder）优化。\n\n## 2.Java内存模型\n\n定义Java内存模型并不是一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发操作不会产生歧义；但是，也必须得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存等）来获取更好的执行速度。经过长时间的验证和修补，在JDK1.5发布后，Java内存模型就已经成熟和完善起来了。\n\n### 2.1 主内存与工作内存\n\n　Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。\n\n　　Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示，和上图很类似。\n\n![内存模型](http://images.cnitblog.com/i/475287/201403/091134177063947.jpg)\n\n这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。\n\n### 2.2 内存间交互操作\n\n关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成：\n\n\t• lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。\n\n\t• unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n\n\t• read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用\n\n\t• load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。\n\n\t• use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。\n\n\t• assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n\n\t• store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。\n\n\t• write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。\n\n如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的，如对主内存中的变量a、b进行访问时，可能的顺序是read a，read b，load b， load a。Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：\n\n\t• 不允许read和load、store和write操作之一单独出现\n\n\t• 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。\n\n\t• 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。\n\n\t• 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。\n\n\t• 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现\n\n\t• 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值\n\n\t• 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。\n\n\t•对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。\n\n### 2.3 重排序\n\n在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型：\n\n1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。\n\n2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n\n3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n从Java源代码到最终实际执行的指令序列，会经过下面三种重排序：\n\n![重排序](http://images.cnitblog.com/i/475287/201403/091511346284594.png)\n\n为了保证内存的可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java内存模型把内存屏障分为LoadLoad、LoadStore、StoreLoad和StoreStore四种：\n\n![内存屏障](http://images.cnitblog.com/i/475287/201403/091516513623330.png)\n\n### 2.4 线程同步的方法\n\n介绍volatile、synchronized和final\n\n### 2.5 多线程并发的三个特性\n\n分别为“原子性”、“可见性”、“有序性”三个特性。\n\n**原子性** \n\n    原子性是指不可再分的最小操作指令，即单条机器指令，原子性操作任意时刻只能有一个线程，因此是线程安全的。 \nJava内存模型中通过read、load、assign、use、store和write这6个操作保证变量的原子性操作。 \n\nlong和double这两个64位长度的数据类型java虚拟机并没有强制规定他们的read、load、store和write操作的原子性，即所谓的非原子性协定，但是目前的各种商业java虚拟机都把long和double数据类型的4中非原子性协定操作实现为原子性。所以java中基本数据类型的访问读写是原子性操作。 \n\n对于大范围的原子性保证需要通过lock和unlock操作以及synchronized同步块来保证。 \n\n**可见性** \n\n    可见性是指当一个线程修改了共享变量的值，其他线程可以立即得知这个修改。 \nJava内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 \n\nJava中通过volatile、final和synchronized这三个关键字保证可见性：\n\nvolatile：通过刷新变量值确保可见性。\n\nsynchronized：同步块通过变量lock锁定前必须清空工作内存中变量值，重新从主内存中读取变量值，unlock解锁前必须把变量值同步回主内存来确保可见性。\n\nfinal：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。\n\n**有序性** \n\n    线程的有序性是指：在线程内部，所有的操作都是有序执行的，而在线程之间，因为工作内存和主内存同步的延迟，操作是乱序执行的。 \n\nJava通过volatile和synchronized关键字确保线程之间操作的有序性。 \n\nvolatile禁止指令重排序优化实现有序性。\n\nsynchronized通过一个变量在同一时刻只允许一个线程对其进行lock锁定操作来确保有序性。\n\n### 2.6 线程实现的三种方式\n\n内核线程（Kernal thread） \n    \n    内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型。轻量级进程要消耗一定的内核资源（如内核线程的栈空间），而且系统调用的代价相对较高，因此一个系统支持轻量级进程的数量是有限的。 \n\n轻量级用户进程（Light weight process） \n\n    广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（User Thread，UT），而狭义的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现，用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型。（Windows和Linux使用的是这种方式） \n\n    使用用户线程的优势在于不需要系统内核的支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，因而使用用户线程实现的程序一般都比较复杂，现在使用用户线程的程序越来越少了。 \n\n用户线程/混合线程（User thread） \n\n    既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，而操作系统所支持的轻量级进程则作为用户线程和内核线程之间的桥梁。这种混合模式下，用户线程与轻量级进程的数量比是不定的，是M：N的关系。许多Unix系列的系统，都提供了M：N的线程模型实现。 \n\n### 2.7 线程调度\n\nJava线程在JDK1.2之前，是基于名为“绿色线程”的用户线程实现的，而在JDK1.2中，线程模型被替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上就决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也未限定Java线程需要使用哪种线程模型来实现。\n\n线程调度有两种方式 \n\n**协同式：**线程的执行时间由线程本身来控制，线程任务执行完成之后主动通知系统切换到另一个线程去执行。（ 不推荐） \n    优点：实现简单，线程切换操作对线程本身是可知的，不存在线程同步问题。 \n    缺点：线程执行时间不可控制，如果线程长时间执行不让出CPU执行时间可能导致系统崩溃。 \n\n**抢占式：**每个线程的执行时间有操作系统来分配，操作系统给每个线程分配执行的时间片，抢到时间片的线程执行，时间片用完之后重新抢占执行时间，线程的切换不由线程本身来决定（ Java使用的线程调度方式就是抢占式调度）。 \n    优点：线程执行时间可控制，不会因为一个线程阻塞问题导致系统崩溃\n\n### 2.8 线程安全等级\n\n不可变： \n\n    可以是基本类型的final；可以是final对象，但对象的行为不会对其状态产生任何影响，比如String的subString就是new一个String对象各种Number类型如BigInteger和BigDecimal等大数据类型都是不可变的，但是同为Number子类型的AtomicInteger和AtomicLong则并非不可变。原因与它里面状态对象是unsafe对象有关，所做的操作都是CAS操作，可以保证原子性。 \n\n绝对线程安全： \n\n    不管运行时环境如何，调用者都不需要任何额外的同步措施。 \n\n相对线程安全： \n\n    这是我们通常意义上的线程安全。需要保证对象单独的操作是线程安全的。比如Vector，HashTable，synchronizedCollection包装集合等。 \n\n线程兼容： \n\n    对象本身不是线程安全的，但可以通过同步手段实现。一般我们说的不是线程安全的，绝大多数是指这个。比如ArrayList，HashMap等。 \n\n线程对立： \n\n    不管调用端是否采用了同步的措施，都无法在并发中使用的代码。\n\n### 2.9 线程安全的实现方式\n\n**互斥同步** \n\n    在多线程访问的时候，保证同一时间只有一条线程使用。 \n    临界区(Critical Section)，互斥量(Mutex)，信号量(Semaphore)都是同步的一种手段 \n     java里最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。 \n\n     其实在“Java与线程”里已经提到，java的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮忙完成，都需要从用户态转换到核心态，这是很耗费时间的，是java语言中的一个重量级(Heavyweight)操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。 \n\nReentrantLock相比于synchronized的优势： \n等待可中断：在持有锁的线程长时间不释放锁的时候,等待的线程可以选择放弃等待.\n公平锁：按照申请锁的顺序来一次获得锁称为公平锁.synchronized的是非公平锁,ReentrantLock可以通过构造函数实现公平锁.    new RenentrantLock(boolean fair)\n锁绑定多个条件：通过多次newCondition可以获得多个Condition对象,可以简单的实现比较复杂的线程同步的功能.通过await(),signal();\n\n**非阻塞同步**\n\n互斥和同步最主要的问题就是阻塞和唤醒所带来的性能问题，所以这通常叫阻塞同步(悲观的并发策略)。随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿(最常见就是不断的重试)，这种乐观的并发策略许多实现都不需要把线程挂起，这种同步操作被称为非阻塞同步。 \n\n这类的指令有： \n    1)测试并设置(test-and-set) \n    2)获取并增加 \n    3)交换 \n    4)比较并交换(CAS) \n    5)加载链接/条件储存(Load-Linked/Store-Conditional  LL/SC) \n\n    后面两条是现代处理器新增的处理器指令，在JDK1.5之后，java中才可以使用CAS操作，就是传说中的sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法的包装提供，虚拟机对这些方法做了特殊的处理，及时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，可以认为是无条件的内联进去。 \n\n    原来需要对i++进行同步，但现在有了这种CAS操作来保证原子性，比如用AtomicInteger。 但是CAS存在一个ABA的问题。可以通过AtomicStampedReference来解决（鸡肋）。 \n\n**无同步** \n\n    有一些代码天生就是线程安全的，不需要同步。其中有如下两类： \n\n    可重入代码（Reentrant Code）：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。 \n\n    线程本地存储（Thread Local Storage）：把共享数据的可见范围限制在同一个线程之内，这样就无须同步也能保证线程之间不出现数据争用问题。可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。\n\n\n### 2.10 锁机制\n\n悲观锁 \n\n    假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他线程企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。 \n\n乐观锁 \n\n    假设不会发生并发冲突。轻易不加锁。 \n\n自旋锁与自适应自旋 \n\n    线程挂起和恢复的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力，在许多应用中，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得，可以让后请求锁的线程等待一会儿，但不放弃处理器的执行时间，让线程执行一个忙循环（自旋）。 \n\n    自旋锁默认的自旋次数值是10次，可以使用参数-XX:PreBlockSpin更改。 \n\n    自适应自旋意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 \n\n锁清除： \n\n    虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。 \n\n锁粗化： \n\n    如果虚拟机探测到有一系列连续操作都对同一个对象反复加锁和解锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 \n\n锁升级 \n\n    Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 \n\n \n\n偏向锁 \n\n    Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 \n\n    偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 \n\n \n\n关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 \n\n轻量级锁： \n\n    轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 \n\n    轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 \n\n \n\n    因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 \n\n重量级锁： \n\n    重量锁在JVM中又叫对象监视器（Monitor），它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 \n\n偏向锁轻量级锁概念参考文章： http://www.infoq.com/cn/articles/java-se-16-synchronized \n","source":"_posts/2016-04-15-Java内存模型与线程同步问题整理.md","raw":"---\nlayout: lay_post\ntitle: \"Java内存模型与线程同步问题整理\"\ndate: 2016-04-15\ncategories: JVM高级特性\ntags: 内存模型\nauthor: lvyafei\n---\n\n## 0.概述\n\n对高并发程序编写需要对JAVA内存模型有一个清晰的认识。以下是整理的JAVA内存模型和线程的相关内容，内容转自互联网。\n\n<!-- more -->\n\n## 1.硬件的效率与一致性\n\n由于计算机的存储设备与处理器的运算能力之间有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。\n\n基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议可以保障数据的一致性，这类协议有MSI、MESI、MOSI及Dragon Protocol等。Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的，后续将介绍Java内存模型。\n\n![硬件模型](http://images.cnitblog.com/i/475287/201403/091102484251967.jpg)\n\n除此之外，为了使得处理器内部的运算单元能竟可能被充分利用，处理器可能会对输入代码进行乱起执行（Out-Of-Order Execution）优化，处理器会在计算之后将对乱序执行的代码进行结果重组，保证结果准确性。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Recorder）优化。\n\n## 2.Java内存模型\n\n定义Java内存模型并不是一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发操作不会产生歧义；但是，也必须得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存等）来获取更好的执行速度。经过长时间的验证和修补，在JDK1.5发布后，Java内存模型就已经成熟和完善起来了。\n\n### 2.1 主内存与工作内存\n\n　Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。\n\n　　Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示，和上图很类似。\n\n![内存模型](http://images.cnitblog.com/i/475287/201403/091134177063947.jpg)\n\n这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。\n\n### 2.2 内存间交互操作\n\n关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成：\n\n\t• lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。\n\n\t• unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n\n\t• read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用\n\n\t• load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。\n\n\t• use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。\n\n\t• assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n\n\t• store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。\n\n\t• write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。\n\n如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的，如对主内存中的变量a、b进行访问时，可能的顺序是read a，read b，load b， load a。Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：\n\n\t• 不允许read和load、store和write操作之一单独出现\n\n\t• 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。\n\n\t• 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。\n\n\t• 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。\n\n\t• 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现\n\n\t• 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值\n\n\t• 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。\n\n\t•对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。\n\n### 2.3 重排序\n\n在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型：\n\n1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。\n\n2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n\n3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n从Java源代码到最终实际执行的指令序列，会经过下面三种重排序：\n\n![重排序](http://images.cnitblog.com/i/475287/201403/091511346284594.png)\n\n为了保证内存的可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java内存模型把内存屏障分为LoadLoad、LoadStore、StoreLoad和StoreStore四种：\n\n![内存屏障](http://images.cnitblog.com/i/475287/201403/091516513623330.png)\n\n### 2.4 线程同步的方法\n\n介绍volatile、synchronized和final\n\n### 2.5 多线程并发的三个特性\n\n分别为“原子性”、“可见性”、“有序性”三个特性。\n\n**原子性** \n\n    原子性是指不可再分的最小操作指令，即单条机器指令，原子性操作任意时刻只能有一个线程，因此是线程安全的。 \nJava内存模型中通过read、load、assign、use、store和write这6个操作保证变量的原子性操作。 \n\nlong和double这两个64位长度的数据类型java虚拟机并没有强制规定他们的read、load、store和write操作的原子性，即所谓的非原子性协定，但是目前的各种商业java虚拟机都把long和double数据类型的4中非原子性协定操作实现为原子性。所以java中基本数据类型的访问读写是原子性操作。 \n\n对于大范围的原子性保证需要通过lock和unlock操作以及synchronized同步块来保证。 \n\n**可见性** \n\n    可见性是指当一个线程修改了共享变量的值，其他线程可以立即得知这个修改。 \nJava内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 \n\nJava中通过volatile、final和synchronized这三个关键字保证可见性：\n\nvolatile：通过刷新变量值确保可见性。\n\nsynchronized：同步块通过变量lock锁定前必须清空工作内存中变量值，重新从主内存中读取变量值，unlock解锁前必须把变量值同步回主内存来确保可见性。\n\nfinal：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。\n\n**有序性** \n\n    线程的有序性是指：在线程内部，所有的操作都是有序执行的，而在线程之间，因为工作内存和主内存同步的延迟，操作是乱序执行的。 \n\nJava通过volatile和synchronized关键字确保线程之间操作的有序性。 \n\nvolatile禁止指令重排序优化实现有序性。\n\nsynchronized通过一个变量在同一时刻只允许一个线程对其进行lock锁定操作来确保有序性。\n\n### 2.6 线程实现的三种方式\n\n内核线程（Kernal thread） \n    \n    内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型。轻量级进程要消耗一定的内核资源（如内核线程的栈空间），而且系统调用的代价相对较高，因此一个系统支持轻量级进程的数量是有限的。 \n\n轻量级用户进程（Light weight process） \n\n    广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（User Thread，UT），而狭义的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现，用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型。（Windows和Linux使用的是这种方式） \n\n    使用用户线程的优势在于不需要系统内核的支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，因而使用用户线程实现的程序一般都比较复杂，现在使用用户线程的程序越来越少了。 \n\n用户线程/混合线程（User thread） \n\n    既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，而操作系统所支持的轻量级进程则作为用户线程和内核线程之间的桥梁。这种混合模式下，用户线程与轻量级进程的数量比是不定的，是M：N的关系。许多Unix系列的系统，都提供了M：N的线程模型实现。 \n\n### 2.7 线程调度\n\nJava线程在JDK1.2之前，是基于名为“绿色线程”的用户线程实现的，而在JDK1.2中，线程模型被替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上就决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也未限定Java线程需要使用哪种线程模型来实现。\n\n线程调度有两种方式 \n\n**协同式：**线程的执行时间由线程本身来控制，线程任务执行完成之后主动通知系统切换到另一个线程去执行。（ 不推荐） \n    优点：实现简单，线程切换操作对线程本身是可知的，不存在线程同步问题。 \n    缺点：线程执行时间不可控制，如果线程长时间执行不让出CPU执行时间可能导致系统崩溃。 \n\n**抢占式：**每个线程的执行时间有操作系统来分配，操作系统给每个线程分配执行的时间片，抢到时间片的线程执行，时间片用完之后重新抢占执行时间，线程的切换不由线程本身来决定（ Java使用的线程调度方式就是抢占式调度）。 \n    优点：线程执行时间可控制，不会因为一个线程阻塞问题导致系统崩溃\n\n### 2.8 线程安全等级\n\n不可变： \n\n    可以是基本类型的final；可以是final对象，但对象的行为不会对其状态产生任何影响，比如String的subString就是new一个String对象各种Number类型如BigInteger和BigDecimal等大数据类型都是不可变的，但是同为Number子类型的AtomicInteger和AtomicLong则并非不可变。原因与它里面状态对象是unsafe对象有关，所做的操作都是CAS操作，可以保证原子性。 \n\n绝对线程安全： \n\n    不管运行时环境如何，调用者都不需要任何额外的同步措施。 \n\n相对线程安全： \n\n    这是我们通常意义上的线程安全。需要保证对象单独的操作是线程安全的。比如Vector，HashTable，synchronizedCollection包装集合等。 \n\n线程兼容： \n\n    对象本身不是线程安全的，但可以通过同步手段实现。一般我们说的不是线程安全的，绝大多数是指这个。比如ArrayList，HashMap等。 \n\n线程对立： \n\n    不管调用端是否采用了同步的措施，都无法在并发中使用的代码。\n\n### 2.9 线程安全的实现方式\n\n**互斥同步** \n\n    在多线程访问的时候，保证同一时间只有一条线程使用。 \n    临界区(Critical Section)，互斥量(Mutex)，信号量(Semaphore)都是同步的一种手段 \n     java里最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。 \n\n     其实在“Java与线程”里已经提到，java的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮忙完成，都需要从用户态转换到核心态，这是很耗费时间的，是java语言中的一个重量级(Heavyweight)操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。 \n\nReentrantLock相比于synchronized的优势： \n等待可中断：在持有锁的线程长时间不释放锁的时候,等待的线程可以选择放弃等待.\n公平锁：按照申请锁的顺序来一次获得锁称为公平锁.synchronized的是非公平锁,ReentrantLock可以通过构造函数实现公平锁.    new RenentrantLock(boolean fair)\n锁绑定多个条件：通过多次newCondition可以获得多个Condition对象,可以简单的实现比较复杂的线程同步的功能.通过await(),signal();\n\n**非阻塞同步**\n\n互斥和同步最主要的问题就是阻塞和唤醒所带来的性能问题，所以这通常叫阻塞同步(悲观的并发策略)。随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿(最常见就是不断的重试)，这种乐观的并发策略许多实现都不需要把线程挂起，这种同步操作被称为非阻塞同步。 \n\n这类的指令有： \n    1)测试并设置(test-and-set) \n    2)获取并增加 \n    3)交换 \n    4)比较并交换(CAS) \n    5)加载链接/条件储存(Load-Linked/Store-Conditional  LL/SC) \n\n    后面两条是现代处理器新增的处理器指令，在JDK1.5之后，java中才可以使用CAS操作，就是传说中的sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法的包装提供，虚拟机对这些方法做了特殊的处理，及时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，可以认为是无条件的内联进去。 \n\n    原来需要对i++进行同步，但现在有了这种CAS操作来保证原子性，比如用AtomicInteger。 但是CAS存在一个ABA的问题。可以通过AtomicStampedReference来解决（鸡肋）。 \n\n**无同步** \n\n    有一些代码天生就是线程安全的，不需要同步。其中有如下两类： \n\n    可重入代码（Reentrant Code）：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。 \n\n    线程本地存储（Thread Local Storage）：把共享数据的可见范围限制在同一个线程之内，这样就无须同步也能保证线程之间不出现数据争用问题。可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。\n\n\n### 2.10 锁机制\n\n悲观锁 \n\n    假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他线程企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。 \n\n乐观锁 \n\n    假设不会发生并发冲突。轻易不加锁。 \n\n自旋锁与自适应自旋 \n\n    线程挂起和恢复的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力，在许多应用中，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得，可以让后请求锁的线程等待一会儿，但不放弃处理器的执行时间，让线程执行一个忙循环（自旋）。 \n\n    自旋锁默认的自旋次数值是10次，可以使用参数-XX:PreBlockSpin更改。 \n\n    自适应自旋意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 \n\n锁清除： \n\n    虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。 \n\n锁粗化： \n\n    如果虚拟机探测到有一系列连续操作都对同一个对象反复加锁和解锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 \n\n锁升级 \n\n    Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 \n\n \n\n偏向锁 \n\n    Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 \n\n    偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 \n\n \n\n关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 \n\n轻量级锁： \n\n    轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 \n\n    轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 \n\n \n\n    因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 \n\n重量级锁： \n\n    重量锁在JVM中又叫对象监视器（Monitor），它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 \n\n偏向锁轻量级锁概念参考文章： http://www.infoq.com/cn/articles/java-se-16-synchronized \n","slug":"2016-04-15-Java内存模型与线程同步问题整理","published":1,"updated":"2018-11-29T12:51:24.664Z","comments":1,"photos":[],"link":"","_id":"cjskffo7a002g4glmgb2fqhvg","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对高并发程序编写需要对JAVA内存模型有一个清晰的认识。以下是整理的JAVA内存模型和线程的相关内容，内容转自互联网。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-硬件的效率与一致性\"><a href=\"#1-硬件的效率与一致性\" class=\"headerlink\" title=\"1.硬件的效率与一致性\"></a>1.硬件的效率与一致性</h2><p>由于计算机的存储设备与处理器的运算能力之间有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。</p>\n<p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议可以保障数据的一致性，这类协议有MSI、MESI、MOSI及Dragon Protocol等。Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的，后续将介绍Java内存模型。</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091102484251967.jpg\" alt=\"硬件模型\"></p>\n<p>除此之外，为了使得处理器内部的运算单元能竟可能被充分利用，处理器可能会对输入代码进行乱起执行（Out-Of-Order Execution）优化，处理器会在计算之后将对乱序执行的代码进行结果重组，保证结果准确性。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Recorder）优化。</p>\n<h2 id=\"2-Java内存模型\"><a href=\"#2-Java内存模型\" class=\"headerlink\" title=\"2.Java内存模型\"></a>2.Java内存模型</h2><p>定义Java内存模型并不是一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发操作不会产生歧义；但是，也必须得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存等）来获取更好的执行速度。经过长时间的验证和修补，在JDK1.5发布后，Java内存模型就已经成熟和完善起来了。</p>\n<h3 id=\"2-1-主内存与工作内存\"><a href=\"#2-1-主内存与工作内存\" class=\"headerlink\" title=\"2.1 主内存与工作内存\"></a>2.1 主内存与工作内存</h3><p>　Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。</p>\n<p>　　Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示，和上图很类似。</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091134177063947.jpg\" alt=\"内存模型\"></p>\n<p>这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。</p>\n<h3 id=\"2-2-内存间交互操作\"><a href=\"#2-2-内存间交互操作\" class=\"headerlink\" title=\"2.2 内存间交互操作\"></a>2.2 内存间交互操作</h3><p>关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成：</p>\n<pre><code>• lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。\n\n• unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n\n• read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用\n\n• load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。\n\n• use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。\n\n• assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n\n• store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。\n\n• write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。\n</code></pre><p>如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的，如对主内存中的变量a、b进行访问时，可能的顺序是read a，read b，load b， load a。Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：</p>\n<pre><code>• 不允许read和load、store和write操作之一单独出现\n\n• 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。\n\n• 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。\n\n• 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。\n\n• 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现\n\n• 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值\n\n• 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。\n\n•对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。\n</code></pre><h3 id=\"2-3-重排序\"><a href=\"#2-3-重排序\" class=\"headerlink\" title=\"2.3 重排序\"></a>2.3 重排序</h3><p>在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型：</p>\n<p>1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。</p>\n<p>2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p>\n<p>3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p>\n<p>从Java源代码到最终实际执行的指令序列，会经过下面三种重排序：</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091511346284594.png\" alt=\"重排序\"></p>\n<p>为了保证内存的可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java内存模型把内存屏障分为LoadLoad、LoadStore、StoreLoad和StoreStore四种：</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091516513623330.png\" alt=\"内存屏障\"></p>\n<h3 id=\"2-4-线程同步的方法\"><a href=\"#2-4-线程同步的方法\" class=\"headerlink\" title=\"2.4 线程同步的方法\"></a>2.4 线程同步的方法</h3><p>介绍volatile、synchronized和final</p>\n<h3 id=\"2-5-多线程并发的三个特性\"><a href=\"#2-5-多线程并发的三个特性\" class=\"headerlink\" title=\"2.5 多线程并发的三个特性\"></a>2.5 多线程并发的三个特性</h3><p>分别为“原子性”、“可见性”、“有序性”三个特性。</p>\n<p><strong>原子性</strong> </p>\n<pre><code>原子性是指不可再分的最小操作指令，即单条机器指令，原子性操作任意时刻只能有一个线程，因此是线程安全的。 \n</code></pre><p>Java内存模型中通过read、load、assign、use、store和write这6个操作保证变量的原子性操作。 </p>\n<p>long和double这两个64位长度的数据类型java虚拟机并没有强制规定他们的read、load、store和write操作的原子性，即所谓的非原子性协定，但是目前的各种商业java虚拟机都把long和double数据类型的4中非原子性协定操作实现为原子性。所以java中基本数据类型的访问读写是原子性操作。 </p>\n<p>对于大范围的原子性保证需要通过lock和unlock操作以及synchronized同步块来保证。 </p>\n<p><strong>可见性</strong> </p>\n<pre><code>可见性是指当一个线程修改了共享变量的值，其他线程可以立即得知这个修改。 \n</code></pre><p>Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 </p>\n<p>Java中通过volatile、final和synchronized这三个关键字保证可见性：</p>\n<p>volatile：通过刷新变量值确保可见性。</p>\n<p>synchronized：同步块通过变量lock锁定前必须清空工作内存中变量值，重新从主内存中读取变量值，unlock解锁前必须把变量值同步回主内存来确保可见性。</p>\n<p>final：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。</p>\n<p><strong>有序性</strong> </p>\n<pre><code>线程的有序性是指：在线程内部，所有的操作都是有序执行的，而在线程之间，因为工作内存和主内存同步的延迟，操作是乱序执行的。 \n</code></pre><p>Java通过volatile和synchronized关键字确保线程之间操作的有序性。 </p>\n<p>volatile禁止指令重排序优化实现有序性。</p>\n<p>synchronized通过一个变量在同一时刻只允许一个线程对其进行lock锁定操作来确保有序性。</p>\n<h3 id=\"2-6-线程实现的三种方式\"><a href=\"#2-6-线程实现的三种方式\" class=\"headerlink\" title=\"2.6 线程实现的三种方式\"></a>2.6 线程实现的三种方式</h3><p>内核线程（Kernal thread） </p>\n<pre><code>内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型。轻量级进程要消耗一定的内核资源（如内核线程的栈空间），而且系统调用的代价相对较高，因此一个系统支持轻量级进程的数量是有限的。 \n</code></pre><p>轻量级用户进程（Light weight process） </p>\n<pre><code>广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（User Thread，UT），而狭义的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现，用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型。（Windows和Linux使用的是这种方式） \n\n使用用户线程的优势在于不需要系统内核的支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，因而使用用户线程实现的程序一般都比较复杂，现在使用用户线程的程序越来越少了。 \n</code></pre><p>用户线程/混合线程（User thread） </p>\n<pre><code>既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，而操作系统所支持的轻量级进程则作为用户线程和内核线程之间的桥梁。这种混合模式下，用户线程与轻量级进程的数量比是不定的，是M：N的关系。许多Unix系列的系统，都提供了M：N的线程模型实现。 \n</code></pre><h3 id=\"2-7-线程调度\"><a href=\"#2-7-线程调度\" class=\"headerlink\" title=\"2.7 线程调度\"></a>2.7 线程调度</h3><p>Java线程在JDK1.2之前，是基于名为“绿色线程”的用户线程实现的，而在JDK1.2中，线程模型被替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上就决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也未限定Java线程需要使用哪种线程模型来实现。</p>\n<p>线程调度有两种方式 </p>\n<p><strong>协同式：</strong>线程的执行时间由线程本身来控制，线程任务执行完成之后主动通知系统切换到另一个线程去执行。（ 不推荐）<br>    优点：实现简单，线程切换操作对线程本身是可知的，不存在线程同步问题。<br>    缺点：线程执行时间不可控制，如果线程长时间执行不让出CPU执行时间可能导致系统崩溃。 </p>\n<p><strong>抢占式：</strong>每个线程的执行时间有操作系统来分配，操作系统给每个线程分配执行的时间片，抢到时间片的线程执行，时间片用完之后重新抢占执行时间，线程的切换不由线程本身来决定（ Java使用的线程调度方式就是抢占式调度）。<br>    优点：线程执行时间可控制，不会因为一个线程阻塞问题导致系统崩溃</p>\n<h3 id=\"2-8-线程安全等级\"><a href=\"#2-8-线程安全等级\" class=\"headerlink\" title=\"2.8 线程安全等级\"></a>2.8 线程安全等级</h3><p>不可变： </p>\n<pre><code>可以是基本类型的final；可以是final对象，但对象的行为不会对其状态产生任何影响，比如String的subString就是new一个String对象各种Number类型如BigInteger和BigDecimal等大数据类型都是不可变的，但是同为Number子类型的AtomicInteger和AtomicLong则并非不可变。原因与它里面状态对象是unsafe对象有关，所做的操作都是CAS操作，可以保证原子性。 \n</code></pre><p>绝对线程安全： </p>\n<pre><code>不管运行时环境如何，调用者都不需要任何额外的同步措施。 \n</code></pre><p>相对线程安全： </p>\n<pre><code>这是我们通常意义上的线程安全。需要保证对象单独的操作是线程安全的。比如Vector，HashTable，synchronizedCollection包装集合等。 \n</code></pre><p>线程兼容： </p>\n<pre><code>对象本身不是线程安全的，但可以通过同步手段实现。一般我们说的不是线程安全的，绝大多数是指这个。比如ArrayList，HashMap等。 \n</code></pre><p>线程对立： </p>\n<pre><code>不管调用端是否采用了同步的措施，都无法在并发中使用的代码。\n</code></pre><h3 id=\"2-9-线程安全的实现方式\"><a href=\"#2-9-线程安全的实现方式\" class=\"headerlink\" title=\"2.9 线程安全的实现方式\"></a>2.9 线程安全的实现方式</h3><p><strong>互斥同步</strong> </p>\n<pre><code>在多线程访问的时候，保证同一时间只有一条线程使用。 \n临界区(Critical Section)，互斥量(Mutex)，信号量(Semaphore)都是同步的一种手段 \n java里最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。 \n\n 其实在“Java与线程”里已经提到，java的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮忙完成，都需要从用户态转换到核心态，这是很耗费时间的，是java语言中的一个重量级(Heavyweight)操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。 \n</code></pre><p>ReentrantLock相比于synchronized的优势：<br>等待可中断：在持有锁的线程长时间不释放锁的时候,等待的线程可以选择放弃等待.<br>公平锁：按照申请锁的顺序来一次获得锁称为公平锁.synchronized的是非公平锁,ReentrantLock可以通过构造函数实现公平锁.    new RenentrantLock(boolean fair)<br>锁绑定多个条件：通过多次newCondition可以获得多个Condition对象,可以简单的实现比较复杂的线程同步的功能.通过await(),signal();</p>\n<p><strong>非阻塞同步</strong></p>\n<p>互斥和同步最主要的问题就是阻塞和唤醒所带来的性能问题，所以这通常叫阻塞同步(悲观的并发策略)。随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿(最常见就是不断的重试)，这种乐观的并发策略许多实现都不需要把线程挂起，这种同步操作被称为非阻塞同步。 </p>\n<p>这类的指令有：<br>    1)测试并设置(test-and-set)<br>    2)获取并增加<br>    3)交换<br>    4)比较并交换(CAS)<br>    5)加载链接/条件储存(Load-Linked/Store-Conditional  LL/SC) </p>\n<pre><code>后面两条是现代处理器新增的处理器指令，在JDK1.5之后，java中才可以使用CAS操作，就是传说中的sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法的包装提供，虚拟机对这些方法做了特殊的处理，及时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，可以认为是无条件的内联进去。 \n\n原来需要对i++进行同步，但现在有了这种CAS操作来保证原子性，比如用AtomicInteger。 但是CAS存在一个ABA的问题。可以通过AtomicStampedReference来解决（鸡肋）。 \n</code></pre><p><strong>无同步</strong> </p>\n<pre><code>有一些代码天生就是线程安全的，不需要同步。其中有如下两类： \n\n可重入代码（Reentrant Code）：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。 \n\n线程本地存储（Thread Local Storage）：把共享数据的可见范围限制在同一个线程之内，这样就无须同步也能保证线程之间不出现数据争用问题。可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。\n</code></pre><h3 id=\"2-10-锁机制\"><a href=\"#2-10-锁机制\" class=\"headerlink\" title=\"2.10 锁机制\"></a>2.10 锁机制</h3><p>悲观锁 </p>\n<pre><code>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他线程企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。 \n</code></pre><p>乐观锁 </p>\n<pre><code>假设不会发生并发冲突。轻易不加锁。 \n</code></pre><p>自旋锁与自适应自旋 </p>\n<pre><code>线程挂起和恢复的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力，在许多应用中，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得，可以让后请求锁的线程等待一会儿，但不放弃处理器的执行时间，让线程执行一个忙循环（自旋）。 \n\n自旋锁默认的自旋次数值是10次，可以使用参数-XX:PreBlockSpin更改。 \n\n自适应自旋意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 \n</code></pre><p>锁清除： </p>\n<pre><code>虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。 \n</code></pre><p>锁粗化： </p>\n<pre><code>如果虚拟机探测到有一系列连续操作都对同一个对象反复加锁和解锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 \n</code></pre><p>锁升级 </p>\n<pre><code>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 \n</code></pre><p>偏向锁 </p>\n<pre><code>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 \n\n偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 \n</code></pre><p>关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 </p>\n<p>轻量级锁： </p>\n<pre><code>轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 \n\n轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 \n\n\n\n因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 \n</code></pre><p>重量级锁： </p>\n<pre><code>重量锁在JVM中又叫对象监视器（Monitor），它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 \n</code></pre><p>偏向锁轻量级锁概念参考文章： <a href=\"http://www.infoq.com/cn/articles/java-se-16-synchronized\" target=\"_blank\" rel=\"noopener\">http://www.infoq.com/cn/articles/java-se-16-synchronized</a> </p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对高并发程序编写需要对JAVA内存模型有一个清晰的认识。以下是整理的JAVA内存模型和线程的相关内容，内容转自互联网。</p>","more":"<h2 id=\"1-硬件的效率与一致性\"><a href=\"#1-硬件的效率与一致性\" class=\"headerlink\" title=\"1.硬件的效率与一致性\"></a>1.硬件的效率与一致性</h2><p>由于计算机的存储设备与处理器的运算能力之间有几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存（cache）来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中没这样处理器就无需等待缓慢的内存读写了。</p>\n<p>基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是引入了一个新的问题：缓存一致性（Cache Coherence）。在多处理器系统中，每个处理都有自己的高速缓存，而他们又共享同一主存，如下图所示：多个处理器运算任务都涉及同一块主存，需要一种协议可以保障数据的一致性，这类协议有MSI、MESI、MOSI及Dragon Protocol等。Java虚拟机内存模型中定义的内存访问操作与硬件的缓存访问操作是具有可比性的，后续将介绍Java内存模型。</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091102484251967.jpg\" alt=\"硬件模型\"></p>\n<p>除此之外，为了使得处理器内部的运算单元能竟可能被充分利用，处理器可能会对输入代码进行乱起执行（Out-Of-Order Execution）优化，处理器会在计算之后将对乱序执行的代码进行结果重组，保证结果准确性。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序（Instruction Recorder）优化。</p>\n<h2 id=\"2-Java内存模型\"><a href=\"#2-Java内存模型\" class=\"headerlink\" title=\"2.Java内存模型\"></a>2.Java内存模型</h2><p>定义Java内存模型并不是一件容易的事情，这个模型必须定义得足够严谨，才能让Java的并发操作不会产生歧义；但是，也必须得足够宽松，使得虚拟机的实现能有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存等）来获取更好的执行速度。经过长时间的验证和修补，在JDK1.5发布后，Java内存模型就已经成熟和完善起来了。</p>\n<h3 id=\"2-1-主内存与工作内存\"><a href=\"#2-1-主内存与工作内存\" class=\"headerlink\" title=\"2.1 主内存与工作内存\"></a>2.1 主内存与工作内存</h3><p>　Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样底层细节。此处的变量与Java编程时所说的变量不一样，指包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量与方法参数，后者是线程私有的，不会被共享。</p>\n<p>　　Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示，和上图很类似。</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091134177063947.jpg\" alt=\"内存模型\"></p>\n<p>这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。</p>\n<h3 id=\"2-2-内存间交互操作\"><a href=\"#2-2-内存间交互操作\" class=\"headerlink\" title=\"2.2 内存间交互操作\"></a>2.2 内存间交互操作</h3><p>关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成：</p>\n<pre><code>• lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。\n\n• unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。\n\n• read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用\n\n• load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。\n\n• use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。\n\n• assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。\n\n• store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。\n\n• write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中。\n</code></pre><p>如果要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。Java内存模型只要求上述操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的，如对主内存中的变量a、b进行访问时，可能的顺序是read a，read b，load b， load a。Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：</p>\n<pre><code>• 不允许read和load、store和write操作之一单独出现\n\n• 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。\n\n• 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。\n\n• 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。\n\n• 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现\n\n• 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值\n\n• 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。\n\n•对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。\n</code></pre><h3 id=\"2-3-重排序\"><a href=\"#2-3-重排序\" class=\"headerlink\" title=\"2.3 重排序\"></a>2.3 重排序</h3><p>在执行程序时为了提高性能，编译器和处理器经常会对指令进行重排序。重排序分成三种类型：</p>\n<p>1.编译器优化的重排序。编译器在不改变单线程程序语义放入前提下，可以重新安排语句的执行顺序。</p>\n<p>2.指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p>\n<p>3.内存系统的重排序。由于处理器使用缓存和读写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p>\n<p>从Java源代码到最终实际执行的指令序列，会经过下面三种重排序：</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091511346284594.png\" alt=\"重排序\"></p>\n<p>为了保证内存的可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。Java内存模型把内存屏障分为LoadLoad、LoadStore、StoreLoad和StoreStore四种：</p>\n<p><img src=\"http://images.cnitblog.com/i/475287/201403/091516513623330.png\" alt=\"内存屏障\"></p>\n<h3 id=\"2-4-线程同步的方法\"><a href=\"#2-4-线程同步的方法\" class=\"headerlink\" title=\"2.4 线程同步的方法\"></a>2.4 线程同步的方法</h3><p>介绍volatile、synchronized和final</p>\n<h3 id=\"2-5-多线程并发的三个特性\"><a href=\"#2-5-多线程并发的三个特性\" class=\"headerlink\" title=\"2.5 多线程并发的三个特性\"></a>2.5 多线程并发的三个特性</h3><p>分别为“原子性”、“可见性”、“有序性”三个特性。</p>\n<p><strong>原子性</strong> </p>\n<pre><code>原子性是指不可再分的最小操作指令，即单条机器指令，原子性操作任意时刻只能有一个线程，因此是线程安全的。 \n</code></pre><p>Java内存模型中通过read、load、assign、use、store和write这6个操作保证变量的原子性操作。 </p>\n<p>long和double这两个64位长度的数据类型java虚拟机并没有强制规定他们的read、load、store和write操作的原子性，即所谓的非原子性协定，但是目前的各种商业java虚拟机都把long和double数据类型的4中非原子性协定操作实现为原子性。所以java中基本数据类型的访问读写是原子性操作。 </p>\n<p>对于大范围的原子性保证需要通过lock和unlock操作以及synchronized同步块来保证。 </p>\n<p><strong>可见性</strong> </p>\n<pre><code>可见性是指当一个线程修改了共享变量的值，其他线程可以立即得知这个修改。 \n</code></pre><p>Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。 </p>\n<p>Java中通过volatile、final和synchronized这三个关键字保证可见性：</p>\n<p>volatile：通过刷新变量值确保可见性。</p>\n<p>synchronized：同步块通过变量lock锁定前必须清空工作内存中变量值，重新从主内存中读取变量值，unlock解锁前必须把变量值同步回主内存来确保可见性。</p>\n<p>final：被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把this引用传递进去，那么在其他线程中就能看见final字段的值，无需同步就可以被其他线程正确访问。</p>\n<p><strong>有序性</strong> </p>\n<pre><code>线程的有序性是指：在线程内部，所有的操作都是有序执行的，而在线程之间，因为工作内存和主内存同步的延迟，操作是乱序执行的。 \n</code></pre><p>Java通过volatile和synchronized关键字确保线程之间操作的有序性。 </p>\n<p>volatile禁止指令重排序优化实现有序性。</p>\n<p>synchronized通过一个变量在同一时刻只允许一个线程对其进行lock锁定操作来确保有序性。</p>\n<h3 id=\"2-6-线程实现的三种方式\"><a href=\"#2-6-线程实现的三种方式\" class=\"headerlink\" title=\"2.6 线程实现的三种方式\"></a>2.6 线程实现的三种方式</h3><p>内核线程（Kernal thread） </p>\n<pre><code>内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。这种轻量级进程与内核线程之间1：1的关系称为一对一的线程模型。轻量级进程要消耗一定的内核资源（如内核线程的栈空间），而且系统调用的代价相对较高，因此一个系统支持轻量级进程的数量是有限的。 \n</code></pre><p>轻量级用户进程（Light weight process） </p>\n<pre><code>广义上来讲，一个线程只要不是内核线程，那就可以认为是用户线程（User Thread，UT），而狭义的用户线程指的是完全建立在用户空间的线程库上，系统内核不能感知到线程存在的实现，用户线程的建立、同步、销毁和调度完全在用户态中完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作可以是非常快速且低消耗的，也可以支持规模更大的线程数量，部分高性能数据库中的多线程就是由用户线程实现的。这种进程与用户线程之间1：N的关系称为一对多的线程模型。（Windows和Linux使用的是这种方式） \n\n使用用户线程的优势在于不需要系统内核的支援，劣势在于没有系统内核的支援，所有的线程操作都需要用户程序自己处理，因而使用用户线程实现的程序一般都比较复杂，现在使用用户线程的程序越来越少了。 \n</code></pre><p>用户线程/混合线程（User thread） </p>\n<pre><code>既存在用户线程，又存在轻量级进程。用户线程还是完全建立在用户空间中，而操作系统所支持的轻量级进程则作为用户线程和内核线程之间的桥梁。这种混合模式下，用户线程与轻量级进程的数量比是不定的，是M：N的关系。许多Unix系列的系统，都提供了M：N的线程模型实现。 \n</code></pre><h3 id=\"2-7-线程调度\"><a href=\"#2-7-线程调度\" class=\"headerlink\" title=\"2.7 线程调度\"></a>2.7 线程调度</h3><p>Java线程在JDK1.2之前，是基于名为“绿色线程”的用户线程实现的，而在JDK1.2中，线程模型被替换为基于操作系统原生线程模型来实现。因此，在目前的JDK版本中，操作系统支持怎样的线程模型，在很大程度上就决定了Java虚拟机的线程是怎样映射的，这点在不同的平台上没有办法达成一致，虚拟机规范中也未限定Java线程需要使用哪种线程模型来实现。</p>\n<p>线程调度有两种方式 </p>\n<p><strong>协同式：</strong>线程的执行时间由线程本身来控制，线程任务执行完成之后主动通知系统切换到另一个线程去执行。（ 不推荐）<br>    优点：实现简单，线程切换操作对线程本身是可知的，不存在线程同步问题。<br>    缺点：线程执行时间不可控制，如果线程长时间执行不让出CPU执行时间可能导致系统崩溃。 </p>\n<p><strong>抢占式：</strong>每个线程的执行时间有操作系统来分配，操作系统给每个线程分配执行的时间片，抢到时间片的线程执行，时间片用完之后重新抢占执行时间，线程的切换不由线程本身来决定（ Java使用的线程调度方式就是抢占式调度）。<br>    优点：线程执行时间可控制，不会因为一个线程阻塞问题导致系统崩溃</p>\n<h3 id=\"2-8-线程安全等级\"><a href=\"#2-8-线程安全等级\" class=\"headerlink\" title=\"2.8 线程安全等级\"></a>2.8 线程安全等级</h3><p>不可变： </p>\n<pre><code>可以是基本类型的final；可以是final对象，但对象的行为不会对其状态产生任何影响，比如String的subString就是new一个String对象各种Number类型如BigInteger和BigDecimal等大数据类型都是不可变的，但是同为Number子类型的AtomicInteger和AtomicLong则并非不可变。原因与它里面状态对象是unsafe对象有关，所做的操作都是CAS操作，可以保证原子性。 \n</code></pre><p>绝对线程安全： </p>\n<pre><code>不管运行时环境如何，调用者都不需要任何额外的同步措施。 \n</code></pre><p>相对线程安全： </p>\n<pre><code>这是我们通常意义上的线程安全。需要保证对象单独的操作是线程安全的。比如Vector，HashTable，synchronizedCollection包装集合等。 \n</code></pre><p>线程兼容： </p>\n<pre><code>对象本身不是线程安全的，但可以通过同步手段实现。一般我们说的不是线程安全的，绝大多数是指这个。比如ArrayList，HashMap等。 \n</code></pre><p>线程对立： </p>\n<pre><code>不管调用端是否采用了同步的措施，都无法在并发中使用的代码。\n</code></pre><h3 id=\"2-9-线程安全的实现方式\"><a href=\"#2-9-线程安全的实现方式\" class=\"headerlink\" title=\"2.9 线程安全的实现方式\"></a>2.9 线程安全的实现方式</h3><p><strong>互斥同步</strong> </p>\n<pre><code>在多线程访问的时候，保证同一时间只有一条线程使用。 \n临界区(Critical Section)，互斥量(Mutex)，信号量(Semaphore)都是同步的一种手段 \n java里最基本的互斥同步手段是synchronized，编译之后会形成monitorenter和monitorexit这两个字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象，还有一个锁的计数器，来记录加锁的次数，加锁几次就要同样解锁几次才能恢复到无锁状态。 \n\n 其实在“Java与线程”里已经提到，java的线程是映射到操作系统的原生线程之上的，不管阻塞还是唤醒都需要操作系统的帮忙完成，都需要从用户态转换到核心态，这是很耗费时间的，是java语言中的一个重量级(Heavyweight)操作，虽然虚拟机本身会做一点优化的操作，比如通知操作系统阻塞之前会加一段自旋等待的过程，避免频繁切换到核心态。 \n</code></pre><p>ReentrantLock相比于synchronized的优势：<br>等待可中断：在持有锁的线程长时间不释放锁的时候,等待的线程可以选择放弃等待.<br>公平锁：按照申请锁的顺序来一次获得锁称为公平锁.synchronized的是非公平锁,ReentrantLock可以通过构造函数实现公平锁.    new RenentrantLock(boolean fair)<br>锁绑定多个条件：通过多次newCondition可以获得多个Condition对象,可以简单的实现比较复杂的线程同步的功能.通过await(),signal();</p>\n<p><strong>非阻塞同步</strong></p>\n<p>互斥和同步最主要的问题就是阻塞和唤醒所带来的性能问题，所以这通常叫阻塞同步(悲观的并发策略)。随着硬件指令集的发展，我们有另外的选择：基于冲突检测的乐观并发策略，通俗讲就是先操作，如果没有其他线程争用共享的数据，操作就成功，如果有，则进行其他的补偿(最常见就是不断的重试)，这种乐观的并发策略许多实现都不需要把线程挂起，这种同步操作被称为非阻塞同步。 </p>\n<p>这类的指令有：<br>    1)测试并设置(test-and-set)<br>    2)获取并增加<br>    3)交换<br>    4)比较并交换(CAS)<br>    5)加载链接/条件储存(Load-Linked/Store-Conditional  LL/SC) </p>\n<pre><code>后面两条是现代处理器新增的处理器指令，在JDK1.5之后，java中才可以使用CAS操作，就是传说中的sun.misc.Unsafe类里面的compareAndSwapInt()和compareAndSwapLong()等几个方法的包装提供，虚拟机对这些方法做了特殊的处理，及时编译出来的结果就是一条平台相关的处理器CAS指令，没有方法调用的过程，可以认为是无条件的内联进去。 \n\n原来需要对i++进行同步，但现在有了这种CAS操作来保证原子性，比如用AtomicInteger。 但是CAS存在一个ABA的问题。可以通过AtomicStampedReference来解决（鸡肋）。 \n</code></pre><p><strong>无同步</strong> </p>\n<pre><code>有一些代码天生就是线程安全的，不需要同步。其中有如下两类： \n\n可重入代码（Reentrant Code）：纯代码，具有不依赖存储在堆上的数据和公用的系统资源，用到的状态量都由参数中传入，不调用非可重入的方法等特征，它的返回结果是可以预测的。 \n\n线程本地存储（Thread Local Storage）：把共享数据的可见范围限制在同一个线程之内，这样就无须同步也能保证线程之间不出现数据争用问题。可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。\n</code></pre><h3 id=\"2-10-锁机制\"><a href=\"#2-10-锁机制\" class=\"headerlink\" title=\"2.10 锁机制\"></a>2.10 锁机制</h3><p>悲观锁 </p>\n<pre><code>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁假定其他线程企图访问或者改变你正在访问、更改的对象的概率是很高的，因此在悲观锁的环境中，在你开始改变此对象之前就将该对象锁住，并且直到你提交了所作的更改之后才释放锁。 \n</code></pre><p>乐观锁 </p>\n<pre><code>假设不会发生并发冲突。轻易不加锁。 \n</code></pre><p>自旋锁与自适应自旋 </p>\n<pre><code>线程挂起和恢复的操作都需要转入内核态中完成，这些操作给系统的并发性能带来了很大的压力，在许多应用中，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得，可以让后请求锁的线程等待一会儿，但不放弃处理器的执行时间，让线程执行一个忙循环（自旋）。 \n\n自旋锁默认的自旋次数值是10次，可以使用参数-XX:PreBlockSpin更改。 \n\n自适应自旋意味着自旋的时间不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 \n</code></pre><p>锁清除： </p>\n<pre><code>虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。 \n</code></pre><p>锁粗化： </p>\n<pre><code>如果虚拟机探测到有一系列连续操作都对同一个对象反复加锁和解锁，将会把加锁同步的范围扩展（粗化）到整个操作序列的外部。 \n</code></pre><p>锁升级 </p>\n<pre><code>Java SE1.6为了减少获得锁和释放锁所带来的性能消耗，引入了“偏向锁”和“轻量级锁”，所以在Java SE1.6里锁一共有四种状态，无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态，它会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。 \n</code></pre><p>偏向锁 </p>\n<pre><code>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要花费CAS操作来加锁和解锁，而只需简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果测试成功，表示线程已经获得了锁，如果测试失败，则需要再测试下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁），如果没有设置，则使用CAS竞争锁，如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 \n\n偏向锁的撤销：偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态，如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。下图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。 \n</code></pre><p>关闭偏向锁：偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟-XX：BiasedLockingStartupDelay = 0。如果你确定自己应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁-XX:-UseBiasedLocking=false，那么默认会进入轻量级锁状态。 </p>\n<p>轻量级锁： </p>\n<pre><code>轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。 \n\n轻量级锁解锁：轻量级解锁时，会使用原子的CAS操作来将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。 \n\n\n\n因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 \n</code></pre><p>重量级锁： </p>\n<pre><code>重量锁在JVM中又叫对象监视器（Monitor），它至少包含一个竞争锁的队列，和一个信号阻塞队列（wait队列），前者负责做互斥，后一个用于做线程同步。 \n</code></pre><p>偏向锁轻量级锁概念参考文章： <a href=\"http://www.infoq.com/cn/articles/java-se-16-synchronized\" target=\"_blank\" rel=\"noopener\">http://www.infoq.com/cn/articles/java-se-16-synchronized</a> </p>"},{"layout":"lay_post","title":"推荐场景1-推荐用户已购买的内容","date":"2016-07-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n推荐场景中，存在给用户推荐自己已经购买的商品，其实用户对自己购买过的商品基本上不会再去买了，没有挖掘出用户的下一步诉求，就不能引导用户进行新的尝试。用户买过手机后我们可以在推荐列表中去放入用户下一步可能要买的商品，比如说：耳机，充电器，其他品牌的手机。不要把用户买过的商品大量的放入推荐列表中，转换效果不好，用户点击欲望也不会高。\n\n<!-- more -->\n\n## 1.购物场景\n\n用户买了手机套，给用户的推荐结果是手机套，手机套，手机套。。。其实我们应该让用户看到其他和手机套的相关的内容，而不是一味的去推荐已经购买的商品。推荐系统应该要自己猜测到用户其实是拥有一部什么样牌子的手机，用户的年龄是多少？用户的购物能力有多高？可以给用户推荐一些其他领域的商品。\n\n![推荐场景](/images/推荐/推荐场景.png)\n\n","source":"_posts/2016-07-22-推荐场景1-推荐用户已购买的内容.md","raw":"---\nlayout: lay_post\ntitle: \"推荐场景1-推荐用户已购买的内容\"\ndate: 2016-07-22\ncategories: 用户场景\ntags: 推荐系统\nauthor: lvyafei\n---\n\n## 0.概述\n\n推荐场景中，存在给用户推荐自己已经购买的商品，其实用户对自己购买过的商品基本上不会再去买了，没有挖掘出用户的下一步诉求，就不能引导用户进行新的尝试。用户买过手机后我们可以在推荐列表中去放入用户下一步可能要买的商品，比如说：耳机，充电器，其他品牌的手机。不要把用户买过的商品大量的放入推荐列表中，转换效果不好，用户点击欲望也不会高。\n\n<!-- more -->\n\n## 1.购物场景\n\n用户买了手机套，给用户的推荐结果是手机套，手机套，手机套。。。其实我们应该让用户看到其他和手机套的相关的内容，而不是一味的去推荐已经购买的商品。推荐系统应该要自己猜测到用户其实是拥有一部什么样牌子的手机，用户的年龄是多少？用户的购物能力有多高？可以给用户推荐一些其他领域的商品。\n\n![推荐场景](/images/推荐/推荐场景.png)\n\n","slug":"2016-07-22-推荐场景1-推荐用户已购买的内容","published":1,"updated":"2018-11-29T12:51:24.682Z","comments":1,"photos":[],"link":"","_id":"cjskffo7p002k4glmrfydiw8h","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>推荐场景中，存在给用户推荐自己已经购买的商品，其实用户对自己购买过的商品基本上不会再去买了，没有挖掘出用户的下一步诉求，就不能引导用户进行新的尝试。用户买过手机后我们可以在推荐列表中去放入用户下一步可能要买的商品，比如说：耳机，充电器，其他品牌的手机。不要把用户买过的商品大量的放入推荐列表中，转换效果不好，用户点击欲望也不会高。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-购物场景\"><a href=\"#1-购物场景\" class=\"headerlink\" title=\"1.购物场景\"></a>1.购物场景</h2><p>用户买了手机套，给用户的推荐结果是手机套，手机套，手机套。。。其实我们应该让用户看到其他和手机套的相关的内容，而不是一味的去推荐已经购买的商品。推荐系统应该要自己猜测到用户其实是拥有一部什么样牌子的手机，用户的年龄是多少？用户的购物能力有多高？可以给用户推荐一些其他领域的商品。</p>\n<p><img src=\"/images/推荐/推荐场景.png\" alt=\"推荐场景\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>推荐场景中，存在给用户推荐自己已经购买的商品，其实用户对自己购买过的商品基本上不会再去买了，没有挖掘出用户的下一步诉求，就不能引导用户进行新的尝试。用户买过手机后我们可以在推荐列表中去放入用户下一步可能要买的商品，比如说：耳机，充电器，其他品牌的手机。不要把用户买过的商品大量的放入推荐列表中，转换效果不好，用户点击欲望也不会高。</p>","more":"<h2 id=\"1-购物场景\"><a href=\"#1-购物场景\" class=\"headerlink\" title=\"1.购物场景\"></a>1.购物场景</h2><p>用户买了手机套，给用户的推荐结果是手机套，手机套，手机套。。。其实我们应该让用户看到其他和手机套的相关的内容，而不是一味的去推荐已经购买的商品。推荐系统应该要自己猜测到用户其实是拥有一部什么样牌子的手机，用户的年龄是多少？用户的购物能力有多高？可以给用户推荐一些其他领域的商品。</p>\n<p><img src=\"/images/推荐/推荐场景.png\" alt=\"推荐场景\"></p>"},{"layout":"lay_post","title":"Docker常用指令备忘录","date":"2016-07-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nDocker常用的指令，方便以后查找\n\n<!-- more -->\n\n## 1.查看镜像\n\ndocker images\n\n## 2.拉取镜像\n\ndocker pull <镜像名:tag> #从官网拉取镜像 \n\ndocker search <镜像名> #搜索在线可用镜像名 \n\n## 3.查看容器\n\ndocker ps #查看正在运行的容器 \n\ndocker ps -l #查看最后退出的容器的ID\n\ndocker ps -a #查看所有的容器，包括退出的。\n\ndocker start [PID] //启动停止的容器\n\ndocker stop  [PID] //停止运行的容器\n\ndocker kill [PID]  //杀死容器\n\n## 4.设置后台运行容器\n\ndocker run -d -i --name zkServer -p 2181:2181 index.tenxcloud.com/sdvdxl/zookeeper\n\n-d :后台运行\n\n--name：设置容器名称\n\n-p：设置端口对应\n\n-i:保持输入流开放即使没有附加输入流\n\n-t=false:分配一个伪造的终端输入\n\n## 5.删除容器与删除镜像\n\ndocker rm$(docker ps -a -q) #删除所有容器\n\ndocker rm <容器名or ID> #删除单个容器  \n\ndocker rmi <ID> #删除单个镜像  \n\ndocker rmi$(docker images | grep none | awk '{print $3}' | sort -r) \n\n## 6.进入容器\n\n**docker attach [ID或名称]**\n\n可以attach到一个已经运行的容器的stdin，然后进行命令执行的动作。 \n但是需要注意的是，如果从这个stdin中exit，会导致容器的停止。\n\n**docker exec -it [ID或名称] /bin/sh**\n\n只使用-i时，由于没有分配伪终端，看起来像pipe执行一样。但是执行结果、命令 \n返回值都可以正确获取。\n\n只使用-t参数，则可以看到一个console窗口，但是执行命令会发现由于没有获得stdin \n的输出，无法看到命令执行情况。\n\n使用-it时，则和我们平常操作console界面类似。而且也不会像attach方式因为退出，导致 \n整个容器退出。 \n这种方式可以替代ssh或者nsenter、nsinit方式，在容器内进行操作。\n\n## 7.常见错误\n\n端口映射配置前需要确保iptables服务开启\n\n若遇到以下错误:COMMAND_FAILED: '/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 --dport 8111 -j DNAT --to-destination 172.17.0.6:8111 ! -i docker0' failed: iptables: No chain/target/match by that name.\n\n执行以下操作:\n\nservice docker stop\n\niptables -t nat -F\n\nifconfig docker0 down\n\nbrctl delbr docker0\n\nservice docker start\n\n## 8.Dockerfile构建命令\n\n从fesaDockerFile中构建容器\n\ndocker build -t fesa:latest - < fesaDockerFile\n\n","source":"_posts/2016-07-22-Docker常用指令备忘录.md","raw":"---\nlayout: lay_post\ntitle: \"Docker常用指令备忘录\"\ndate: 2016-07-22\ncategories: Docker指令\ntags: 备忘录\nauthor: lvyafei\n---\n\n## 0.概述\n\nDocker常用的指令，方便以后查找\n\n<!-- more -->\n\n## 1.查看镜像\n\ndocker images\n\n## 2.拉取镜像\n\ndocker pull <镜像名:tag> #从官网拉取镜像 \n\ndocker search <镜像名> #搜索在线可用镜像名 \n\n## 3.查看容器\n\ndocker ps #查看正在运行的容器 \n\ndocker ps -l #查看最后退出的容器的ID\n\ndocker ps -a #查看所有的容器，包括退出的。\n\ndocker start [PID] //启动停止的容器\n\ndocker stop  [PID] //停止运行的容器\n\ndocker kill [PID]  //杀死容器\n\n## 4.设置后台运行容器\n\ndocker run -d -i --name zkServer -p 2181:2181 index.tenxcloud.com/sdvdxl/zookeeper\n\n-d :后台运行\n\n--name：设置容器名称\n\n-p：设置端口对应\n\n-i:保持输入流开放即使没有附加输入流\n\n-t=false:分配一个伪造的终端输入\n\n## 5.删除容器与删除镜像\n\ndocker rm$(docker ps -a -q) #删除所有容器\n\ndocker rm <容器名or ID> #删除单个容器  \n\ndocker rmi <ID> #删除单个镜像  \n\ndocker rmi$(docker images | grep none | awk '{print $3}' | sort -r) \n\n## 6.进入容器\n\n**docker attach [ID或名称]**\n\n可以attach到一个已经运行的容器的stdin，然后进行命令执行的动作。 \n但是需要注意的是，如果从这个stdin中exit，会导致容器的停止。\n\n**docker exec -it [ID或名称] /bin/sh**\n\n只使用-i时，由于没有分配伪终端，看起来像pipe执行一样。但是执行结果、命令 \n返回值都可以正确获取。\n\n只使用-t参数，则可以看到一个console窗口，但是执行命令会发现由于没有获得stdin \n的输出，无法看到命令执行情况。\n\n使用-it时，则和我们平常操作console界面类似。而且也不会像attach方式因为退出，导致 \n整个容器退出。 \n这种方式可以替代ssh或者nsenter、nsinit方式，在容器内进行操作。\n\n## 7.常见错误\n\n端口映射配置前需要确保iptables服务开启\n\n若遇到以下错误:COMMAND_FAILED: '/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 --dport 8111 -j DNAT --to-destination 172.17.0.6:8111 ! -i docker0' failed: iptables: No chain/target/match by that name.\n\n执行以下操作:\n\nservice docker stop\n\niptables -t nat -F\n\nifconfig docker0 down\n\nbrctl delbr docker0\n\nservice docker start\n\n## 8.Dockerfile构建命令\n\n从fesaDockerFile中构建容器\n\ndocker build -t fesa:latest - < fesaDockerFile\n\n","slug":"2016-07-22-Docker常用指令备忘录","published":1,"updated":"2018-11-29T12:51:24.679Z","comments":1,"photos":[],"link":"","_id":"cjskffo7p002n4glm9w5k1ka5","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Docker常用的指令，方便以后查找</p>\n<a id=\"more\"></a>\n<h2 id=\"1-查看镜像\"><a href=\"#1-查看镜像\" class=\"headerlink\" title=\"1.查看镜像\"></a>1.查看镜像</h2><p>docker images</p>\n<h2 id=\"2-拉取镜像\"><a href=\"#2-拉取镜像\" class=\"headerlink\" title=\"2.拉取镜像\"></a>2.拉取镜像</h2><p>docker pull &lt;镜像名:tag&gt; #从官网拉取镜像 </p>\n<p>docker search &lt;镜像名&gt; #搜索在线可用镜像名 </p>\n<h2 id=\"3-查看容器\"><a href=\"#3-查看容器\" class=\"headerlink\" title=\"3.查看容器\"></a>3.查看容器</h2><p>docker ps #查看正在运行的容器 </p>\n<p>docker ps -l #查看最后退出的容器的ID</p>\n<p>docker ps -a #查看所有的容器，包括退出的。</p>\n<p>docker start [PID] //启动停止的容器</p>\n<p>docker stop  [PID] //停止运行的容器</p>\n<p>docker kill [PID]  //杀死容器</p>\n<h2 id=\"4-设置后台运行容器\"><a href=\"#4-设置后台运行容器\" class=\"headerlink\" title=\"4.设置后台运行容器\"></a>4.设置后台运行容器</h2><p>docker run -d -i –name zkServer -p 2181:2181 index.tenxcloud.com/sdvdxl/zookeeper</p>\n<p>-d :后台运行</p>\n<p>–name：设置容器名称</p>\n<p>-p：设置端口对应</p>\n<p>-i:保持输入流开放即使没有附加输入流</p>\n<p>-t=false:分配一个伪造的终端输入</p>\n<h2 id=\"5-删除容器与删除镜像\"><a href=\"#5-删除容器与删除镜像\" class=\"headerlink\" title=\"5.删除容器与删除镜像\"></a>5.删除容器与删除镜像</h2><p>docker rm$(docker ps -a -q) #删除所有容器</p>\n<p>docker rm &lt;容器名or ID&gt; #删除单个容器  </p>\n<p>docker rmi <id> #删除单个镜像  </id></p>\n<p>docker rmi$(docker images | grep none | awk ‘{print $3}’ | sort -r) </p>\n<h2 id=\"6-进入容器\"><a href=\"#6-进入容器\" class=\"headerlink\" title=\"6.进入容器\"></a>6.进入容器</h2><p><strong>docker attach [ID或名称]</strong></p>\n<p>可以attach到一个已经运行的容器的stdin，然后进行命令执行的动作。<br>但是需要注意的是，如果从这个stdin中exit，会导致容器的停止。</p>\n<p><strong>docker exec -it [ID或名称] /bin/sh</strong></p>\n<p>只使用-i时，由于没有分配伪终端，看起来像pipe执行一样。但是执行结果、命令<br>返回值都可以正确获取。</p>\n<p>只使用-t参数，则可以看到一个console窗口，但是执行命令会发现由于没有获得stdin<br>的输出，无法看到命令执行情况。</p>\n<p>使用-it时，则和我们平常操作console界面类似。而且也不会像attach方式因为退出，导致<br>整个容器退出。<br>这种方式可以替代ssh或者nsenter、nsinit方式，在容器内进行操作。</p>\n<h2 id=\"7-常见错误\"><a href=\"#7-常见错误\" class=\"headerlink\" title=\"7.常见错误\"></a>7.常见错误</h2><p>端口映射配置前需要确保iptables服务开启</p>\n<p>若遇到以下错误:COMMAND_FAILED: ‘/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 –dport 8111 -j DNAT –to-destination 172.17.0.6:8111 ! -i docker0’ failed: iptables: No chain/target/match by that name.</p>\n<p>执行以下操作:</p>\n<p>service docker stop</p>\n<p>iptables -t nat -F</p>\n<p>ifconfig docker0 down</p>\n<p>brctl delbr docker0</p>\n<p>service docker start</p>\n<h2 id=\"8-Dockerfile构建命令\"><a href=\"#8-Dockerfile构建命令\" class=\"headerlink\" title=\"8.Dockerfile构建命令\"></a>8.Dockerfile构建命令</h2><p>从fesaDockerFile中构建容器</p>\n<p>docker build -t fesa:latest - &lt; fesaDockerFile</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Docker常用的指令，方便以后查找</p>","more":"<h2 id=\"1-查看镜像\"><a href=\"#1-查看镜像\" class=\"headerlink\" title=\"1.查看镜像\"></a>1.查看镜像</h2><p>docker images</p>\n<h2 id=\"2-拉取镜像\"><a href=\"#2-拉取镜像\" class=\"headerlink\" title=\"2.拉取镜像\"></a>2.拉取镜像</h2><p>docker pull &lt;镜像名:tag&gt; #从官网拉取镜像 </p>\n<p>docker search &lt;镜像名&gt; #搜索在线可用镜像名 </p>\n<h2 id=\"3-查看容器\"><a href=\"#3-查看容器\" class=\"headerlink\" title=\"3.查看容器\"></a>3.查看容器</h2><p>docker ps #查看正在运行的容器 </p>\n<p>docker ps -l #查看最后退出的容器的ID</p>\n<p>docker ps -a #查看所有的容器，包括退出的。</p>\n<p>docker start [PID] //启动停止的容器</p>\n<p>docker stop  [PID] //停止运行的容器</p>\n<p>docker kill [PID]  //杀死容器</p>\n<h2 id=\"4-设置后台运行容器\"><a href=\"#4-设置后台运行容器\" class=\"headerlink\" title=\"4.设置后台运行容器\"></a>4.设置后台运行容器</h2><p>docker run -d -i –name zkServer -p 2181:2181 index.tenxcloud.com/sdvdxl/zookeeper</p>\n<p>-d :后台运行</p>\n<p>–name：设置容器名称</p>\n<p>-p：设置端口对应</p>\n<p>-i:保持输入流开放即使没有附加输入流</p>\n<p>-t=false:分配一个伪造的终端输入</p>\n<h2 id=\"5-删除容器与删除镜像\"><a href=\"#5-删除容器与删除镜像\" class=\"headerlink\" title=\"5.删除容器与删除镜像\"></a>5.删除容器与删除镜像</h2><p>docker rm$(docker ps -a -q) #删除所有容器</p>\n<p>docker rm &lt;容器名or ID&gt; #删除单个容器  </p>\n<p>docker rmi <id> #删除单个镜像  </id></p>\n<p>docker rmi$(docker images | grep none | awk ‘{print $3}’ | sort -r) </p>\n<h2 id=\"6-进入容器\"><a href=\"#6-进入容器\" class=\"headerlink\" title=\"6.进入容器\"></a>6.进入容器</h2><p><strong>docker attach [ID或名称]</strong></p>\n<p>可以attach到一个已经运行的容器的stdin，然后进行命令执行的动作。<br>但是需要注意的是，如果从这个stdin中exit，会导致容器的停止。</p>\n<p><strong>docker exec -it [ID或名称] /bin/sh</strong></p>\n<p>只使用-i时，由于没有分配伪终端，看起来像pipe执行一样。但是执行结果、命令<br>返回值都可以正确获取。</p>\n<p>只使用-t参数，则可以看到一个console窗口，但是执行命令会发现由于没有获得stdin<br>的输出，无法看到命令执行情况。</p>\n<p>使用-it时，则和我们平常操作console界面类似。而且也不会像attach方式因为退出，导致<br>整个容器退出。<br>这种方式可以替代ssh或者nsenter、nsinit方式，在容器内进行操作。</p>\n<h2 id=\"7-常见错误\"><a href=\"#7-常见错误\" class=\"headerlink\" title=\"7.常见错误\"></a>7.常见错误</h2><p>端口映射配置前需要确保iptables服务开启</p>\n<p>若遇到以下错误:COMMAND_FAILED: ‘/sbin/iptables -t nat -A DOCKER -p tcp -d 0/0 –dport 8111 -j DNAT –to-destination 172.17.0.6:8111 ! -i docker0’ failed: iptables: No chain/target/match by that name.</p>\n<p>执行以下操作:</p>\n<p>service docker stop</p>\n<p>iptables -t nat -F</p>\n<p>ifconfig docker0 down</p>\n<p>brctl delbr docker0</p>\n<p>service docker start</p>\n<h2 id=\"8-Dockerfile构建命令\"><a href=\"#8-Dockerfile构建命令\" class=\"headerlink\" title=\"8.Dockerfile构建命令\"></a>8.Dockerfile构建命令</h2><p>从fesaDockerFile中构建容器</p>\n<p>docker build -t fesa:latest - &lt; fesaDockerFile</p>"},{"layout":"lay_post","title":"Servlet配置总结","date":"2016-08-19T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nServlet在web.xml中的配置总结，对Servlet的生命周期和加载顺序的熟悉将会对系统架构有很大的帮助。\n\n<!-- more -->\n\n## 1.Servlet是什么\n\nServlet 通过创建一个框架来扩展服务器的能力，以提供在 Web 上进行请求和响应服务。当客户机发送请求至服务器时，服务器可以将请求信息发送给 Servlet，并让 Servlet 建立起服务器返回给客户机的响应。 当启动 Web 服务器或客户机第一次请求服务时，可以自动装入 Servlet。装入后， Servlet 继续运行直到其它客户机发出请求。Servlet 的功能涉及范围很广。例如，Servlet 可完成如下功能：\n\n　　(1) 创建并返回一个包含基于客户请求性质的动态内容的完整的 HTML页面。\n\n　　(2) 创建可嵌入到现有 HTML 页面中的一部分 HTML 页面（HTML 片段）。\n\n　　(3) 与其它服务器资源（包括数据库和基于 Java 的应用程序）进行通信。\n\n　　(4) 用多个客户机处理连接，接收多个客户机的输入，并将结果广播到多个客户机上。例如，Servlet 可以是多参与者的游戏服务器。\n\n　　(5) 当允许在单连接方式下传送数据的情况下，在浏览器上打开服务器至applet的新连接，并将该连\n接保持在打开状态。当允许客户机和服务器简单、高效地执行会话的情况下，applet也可以启动客户浏览器和服务器之间的连接。可以通过定制协议或标准（如 IIOP）进行通信。\n\n　　(6) 对特殊的处理采用 MIME 类型过滤数据，例如图像转换和服务器端包括（SSI）。\n\n　　(7) 将定制的处理提供给所有服务器的标准例行程序。例如，Servlet 可以修改如何认证用户。\n\n## 2.Servlet的配置\n\nServlet的配置是在web.xml中，与该配置相关的节点有filter,listener,context-param等。context-param，它用于向 ServletContext 提供键值对，即应用程序上下文信息。我们的 listener, filter 等在初始化时会用到这些上下文中的信息，正确的加载顺序为：context-param -> listener -> filter -> servlet。\n\n对于某类配置节而言，与它们出现的顺序是有关的。以 filter 为例，web.xml 中当然可以定义多个 filter，与 filter 相关的一个配置节是 filter-mapping，这里一定要注意，对于拥有相同 filter-name 的 filter 和 filter-mapping 配置节而言，filter-mapping 必须出现在 filter 之后，否则当解析到 filter-mapping 时，它所对应的 filter-name 还未定义。web 容器启动时初始化每个 filter 时，是按照 filter 配置节出现的顺序来初始化的，当请求资源匹配多个 filter-mapping 时，filter 拦截资源是按照 filter-mapping 配置节出现的顺序来依次调用 doFilter() 方法的。\n\n## 3.Filter的功能\n\nfilter功能，它使用户可以改变一个 request和修改一个response. Filter 不是一个servlet,它不能产生一个response,它能够在一个request到达servlet之前预处理request,也可以在离开 servlet时处理response.换种说法,filter其实是一个”servlet chaining”(servlet 链).\n\n一个Filter包括：\n1）、在servlet被调用之前截获;\n2）、在servlet被调用之前检查servlet request;\n3）、根据需要修改request头和request数据;\n4）、根据需要修改response头和response数据;\n5）、在servlet被调用之后截获.\n\n## 4.listener的功能\n\n它是基于观察者模式设计的，Listener 的设计对开发 Servlet 应用程序提供了一种快捷的手段，能够方便的从另一个纵向维度控制程序和数据。目前 Servlet 中提供了 5 种两类事件的观察者接口，它们分别是：4 个 EventListeners 类型的，ServletContextAttributeListener、ServletRequestAttributeListener、ServletRequestListener、HttpSessionAttributeListener 和 2 个 LifecycleListeners 类型的，ServletContextListener、HttpSessionListener。如下图所示：\n\n![listener](/images/架构/listener.png)\n\nListener是Servlet的监听器，它可以监听客户端的请求、服务端的操作等。通过监听器，可以自动激发一些操作，比如监听在线的用户的数量。当增加一个HttpSession时，就激发sessionCreated(HttpSessionEvent se)方法，这样就可以给在线人数加1。\n\n常用的监听接口有以下几个：\n\nServletContextAttributeListener监听对ServletContext属性的操作，比如增加、删除、修改属性。\n\nServletContextListener监听ServletContext。当创建ServletContext时，激发contextInitialized(ServletContextEvent sce)方法；当销毁ServletContext时，激发contextDestroyed(ServletContextEvent sce)方法。\n\nHttpSessionListener监听HttpSession的操作。当创建一个Session时，激发session Created(HttpSessionEvent se)方法；当销毁一个Session时，激发sessionDestroyed (HttpSessionEvent se)方法。\n\nHttpSessionAttributeListener监听HttpSession中的属性的操作。当在Session增加一个属性时，激发attributeAdded(HttpSessionBindingEvent se) 方法；当在Session删除一个属性时，激发attributeRemoved(HttpSessionBindingEvent se)方法；当在Session属性被重新设置时，激发attributeReplaced(HttpSessionBindingEvent se) 方法。\n\n## 5.web.xml文件详解\n\nWeb.xml常用元素  \n\n![listener](/images/架构/webxml.png)\n\n","source":"_posts/2016-08-20-Servlet配置总结.md","raw":"---\nlayout: lay_post\ntitle: \"Servlet配置总结\"\ndate: 2016-08-20\ncategories: 架构\ntags: Servlet3.0\nauthor: lvyafei\n---\n\n## 0.概述\n\nServlet在web.xml中的配置总结，对Servlet的生命周期和加载顺序的熟悉将会对系统架构有很大的帮助。\n\n<!-- more -->\n\n## 1.Servlet是什么\n\nServlet 通过创建一个框架来扩展服务器的能力，以提供在 Web 上进行请求和响应服务。当客户机发送请求至服务器时，服务器可以将请求信息发送给 Servlet，并让 Servlet 建立起服务器返回给客户机的响应。 当启动 Web 服务器或客户机第一次请求服务时，可以自动装入 Servlet。装入后， Servlet 继续运行直到其它客户机发出请求。Servlet 的功能涉及范围很广。例如，Servlet 可完成如下功能：\n\n　　(1) 创建并返回一个包含基于客户请求性质的动态内容的完整的 HTML页面。\n\n　　(2) 创建可嵌入到现有 HTML 页面中的一部分 HTML 页面（HTML 片段）。\n\n　　(3) 与其它服务器资源（包括数据库和基于 Java 的应用程序）进行通信。\n\n　　(4) 用多个客户机处理连接，接收多个客户机的输入，并将结果广播到多个客户机上。例如，Servlet 可以是多参与者的游戏服务器。\n\n　　(5) 当允许在单连接方式下传送数据的情况下，在浏览器上打开服务器至applet的新连接，并将该连\n接保持在打开状态。当允许客户机和服务器简单、高效地执行会话的情况下，applet也可以启动客户浏览器和服务器之间的连接。可以通过定制协议或标准（如 IIOP）进行通信。\n\n　　(6) 对特殊的处理采用 MIME 类型过滤数据，例如图像转换和服务器端包括（SSI）。\n\n　　(7) 将定制的处理提供给所有服务器的标准例行程序。例如，Servlet 可以修改如何认证用户。\n\n## 2.Servlet的配置\n\nServlet的配置是在web.xml中，与该配置相关的节点有filter,listener,context-param等。context-param，它用于向 ServletContext 提供键值对，即应用程序上下文信息。我们的 listener, filter 等在初始化时会用到这些上下文中的信息，正确的加载顺序为：context-param -> listener -> filter -> servlet。\n\n对于某类配置节而言，与它们出现的顺序是有关的。以 filter 为例，web.xml 中当然可以定义多个 filter，与 filter 相关的一个配置节是 filter-mapping，这里一定要注意，对于拥有相同 filter-name 的 filter 和 filter-mapping 配置节而言，filter-mapping 必须出现在 filter 之后，否则当解析到 filter-mapping 时，它所对应的 filter-name 还未定义。web 容器启动时初始化每个 filter 时，是按照 filter 配置节出现的顺序来初始化的，当请求资源匹配多个 filter-mapping 时，filter 拦截资源是按照 filter-mapping 配置节出现的顺序来依次调用 doFilter() 方法的。\n\n## 3.Filter的功能\n\nfilter功能，它使用户可以改变一个 request和修改一个response. Filter 不是一个servlet,它不能产生一个response,它能够在一个request到达servlet之前预处理request,也可以在离开 servlet时处理response.换种说法,filter其实是一个”servlet chaining”(servlet 链).\n\n一个Filter包括：\n1）、在servlet被调用之前截获;\n2）、在servlet被调用之前检查servlet request;\n3）、根据需要修改request头和request数据;\n4）、根据需要修改response头和response数据;\n5）、在servlet被调用之后截获.\n\n## 4.listener的功能\n\n它是基于观察者模式设计的，Listener 的设计对开发 Servlet 应用程序提供了一种快捷的手段，能够方便的从另一个纵向维度控制程序和数据。目前 Servlet 中提供了 5 种两类事件的观察者接口，它们分别是：4 个 EventListeners 类型的，ServletContextAttributeListener、ServletRequestAttributeListener、ServletRequestListener、HttpSessionAttributeListener 和 2 个 LifecycleListeners 类型的，ServletContextListener、HttpSessionListener。如下图所示：\n\n![listener](/images/架构/listener.png)\n\nListener是Servlet的监听器，它可以监听客户端的请求、服务端的操作等。通过监听器，可以自动激发一些操作，比如监听在线的用户的数量。当增加一个HttpSession时，就激发sessionCreated(HttpSessionEvent se)方法，这样就可以给在线人数加1。\n\n常用的监听接口有以下几个：\n\nServletContextAttributeListener监听对ServletContext属性的操作，比如增加、删除、修改属性。\n\nServletContextListener监听ServletContext。当创建ServletContext时，激发contextInitialized(ServletContextEvent sce)方法；当销毁ServletContext时，激发contextDestroyed(ServletContextEvent sce)方法。\n\nHttpSessionListener监听HttpSession的操作。当创建一个Session时，激发session Created(HttpSessionEvent se)方法；当销毁一个Session时，激发sessionDestroyed (HttpSessionEvent se)方法。\n\nHttpSessionAttributeListener监听HttpSession中的属性的操作。当在Session增加一个属性时，激发attributeAdded(HttpSessionBindingEvent se) 方法；当在Session删除一个属性时，激发attributeRemoved(HttpSessionBindingEvent se)方法；当在Session属性被重新设置时，激发attributeReplaced(HttpSessionBindingEvent se) 方法。\n\n## 5.web.xml文件详解\n\nWeb.xml常用元素  \n\n![listener](/images/架构/webxml.png)\n\n","slug":"2016-08-20-Servlet配置总结","published":1,"updated":"2018-11-29T12:51:24.689Z","comments":1,"photos":[],"link":"","_id":"cjskffo85002s4glmnlunc0xl","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Servlet在web.xml中的配置总结，对Servlet的生命周期和加载顺序的熟悉将会对系统架构有很大的帮助。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-Servlet是什么\"><a href=\"#1-Servlet是什么\" class=\"headerlink\" title=\"1.Servlet是什么\"></a>1.Servlet是什么</h2><p>Servlet 通过创建一个框架来扩展服务器的能力，以提供在 Web 上进行请求和响应服务。当客户机发送请求至服务器时，服务器可以将请求信息发送给 Servlet，并让 Servlet 建立起服务器返回给客户机的响应。 当启动 Web 服务器或客户机第一次请求服务时，可以自动装入 Servlet。装入后， Servlet 继续运行直到其它客户机发出请求。Servlet 的功能涉及范围很广。例如，Servlet 可完成如下功能：</p>\n<p>　　(1) 创建并返回一个包含基于客户请求性质的动态内容的完整的 HTML页面。</p>\n<p>　　(2) 创建可嵌入到现有 HTML 页面中的一部分 HTML 页面（HTML 片段）。</p>\n<p>　　(3) 与其它服务器资源（包括数据库和基于 Java 的应用程序）进行通信。</p>\n<p>　　(4) 用多个客户机处理连接，接收多个客户机的输入，并将结果广播到多个客户机上。例如，Servlet 可以是多参与者的游戏服务器。</p>\n<p>　　(5) 当允许在单连接方式下传送数据的情况下，在浏览器上打开服务器至applet的新连接，并将该连<br>接保持在打开状态。当允许客户机和服务器简单、高效地执行会话的情况下，applet也可以启动客户浏览器和服务器之间的连接。可以通过定制协议或标准（如 IIOP）进行通信。</p>\n<p>　　(6) 对特殊的处理采用 MIME 类型过滤数据，例如图像转换和服务器端包括（SSI）。</p>\n<p>　　(7) 将定制的处理提供给所有服务器的标准例行程序。例如，Servlet 可以修改如何认证用户。</p>\n<h2 id=\"2-Servlet的配置\"><a href=\"#2-Servlet的配置\" class=\"headerlink\" title=\"2.Servlet的配置\"></a>2.Servlet的配置</h2><p>Servlet的配置是在web.xml中，与该配置相关的节点有filter,listener,context-param等。context-param，它用于向 ServletContext 提供键值对，即应用程序上下文信息。我们的 listener, filter 等在初始化时会用到这些上下文中的信息，正确的加载顺序为：context-param -&gt; listener -&gt; filter -&gt; servlet。</p>\n<p>对于某类配置节而言，与它们出现的顺序是有关的。以 filter 为例，web.xml 中当然可以定义多个 filter，与 filter 相关的一个配置节是 filter-mapping，这里一定要注意，对于拥有相同 filter-name 的 filter 和 filter-mapping 配置节而言，filter-mapping 必须出现在 filter 之后，否则当解析到 filter-mapping 时，它所对应的 filter-name 还未定义。web 容器启动时初始化每个 filter 时，是按照 filter 配置节出现的顺序来初始化的，当请求资源匹配多个 filter-mapping 时，filter 拦截资源是按照 filter-mapping 配置节出现的顺序来依次调用 doFilter() 方法的。</p>\n<h2 id=\"3-Filter的功能\"><a href=\"#3-Filter的功能\" class=\"headerlink\" title=\"3.Filter的功能\"></a>3.Filter的功能</h2><p>filter功能，它使用户可以改变一个 request和修改一个response. Filter 不是一个servlet,它不能产生一个response,它能够在一个request到达servlet之前预处理request,也可以在离开 servlet时处理response.换种说法,filter其实是一个”servlet chaining”(servlet 链).</p>\n<p>一个Filter包括：<br>1）、在servlet被调用之前截获;<br>2）、在servlet被调用之前检查servlet request;<br>3）、根据需要修改request头和request数据;<br>4）、根据需要修改response头和response数据;<br>5）、在servlet被调用之后截获.</p>\n<h2 id=\"4-listener的功能\"><a href=\"#4-listener的功能\" class=\"headerlink\" title=\"4.listener的功能\"></a>4.listener的功能</h2><p>它是基于观察者模式设计的，Listener 的设计对开发 Servlet 应用程序提供了一种快捷的手段，能够方便的从另一个纵向维度控制程序和数据。目前 Servlet 中提供了 5 种两类事件的观察者接口，它们分别是：4 个 EventListeners 类型的，ServletContextAttributeListener、ServletRequestAttributeListener、ServletRequestListener、HttpSessionAttributeListener 和 2 个 LifecycleListeners 类型的，ServletContextListener、HttpSessionListener。如下图所示：</p>\n<p><img src=\"/images/架构/listener.png\" alt=\"listener\"></p>\n<p>Listener是Servlet的监听器，它可以监听客户端的请求、服务端的操作等。通过监听器，可以自动激发一些操作，比如监听在线的用户的数量。当增加一个HttpSession时，就激发sessionCreated(HttpSessionEvent se)方法，这样就可以给在线人数加1。</p>\n<p>常用的监听接口有以下几个：</p>\n<p>ServletContextAttributeListener监听对ServletContext属性的操作，比如增加、删除、修改属性。</p>\n<p>ServletContextListener监听ServletContext。当创建ServletContext时，激发contextInitialized(ServletContextEvent sce)方法；当销毁ServletContext时，激发contextDestroyed(ServletContextEvent sce)方法。</p>\n<p>HttpSessionListener监听HttpSession的操作。当创建一个Session时，激发session Created(HttpSessionEvent se)方法；当销毁一个Session时，激发sessionDestroyed (HttpSessionEvent se)方法。</p>\n<p>HttpSessionAttributeListener监听HttpSession中的属性的操作。当在Session增加一个属性时，激发attributeAdded(HttpSessionBindingEvent se) 方法；当在Session删除一个属性时，激发attributeRemoved(HttpSessionBindingEvent se)方法；当在Session属性被重新设置时，激发attributeReplaced(HttpSessionBindingEvent se) 方法。</p>\n<h2 id=\"5-web-xml文件详解\"><a href=\"#5-web-xml文件详解\" class=\"headerlink\" title=\"5.web.xml文件详解\"></a>5.web.xml文件详解</h2><p>Web.xml常用元素  </p>\n<p><img src=\"/images/架构/webxml.png\" alt=\"listener\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Servlet在web.xml中的配置总结，对Servlet的生命周期和加载顺序的熟悉将会对系统架构有很大的帮助。</p>","more":"<h2 id=\"1-Servlet是什么\"><a href=\"#1-Servlet是什么\" class=\"headerlink\" title=\"1.Servlet是什么\"></a>1.Servlet是什么</h2><p>Servlet 通过创建一个框架来扩展服务器的能力，以提供在 Web 上进行请求和响应服务。当客户机发送请求至服务器时，服务器可以将请求信息发送给 Servlet，并让 Servlet 建立起服务器返回给客户机的响应。 当启动 Web 服务器或客户机第一次请求服务时，可以自动装入 Servlet。装入后， Servlet 继续运行直到其它客户机发出请求。Servlet 的功能涉及范围很广。例如，Servlet 可完成如下功能：</p>\n<p>　　(1) 创建并返回一个包含基于客户请求性质的动态内容的完整的 HTML页面。</p>\n<p>　　(2) 创建可嵌入到现有 HTML 页面中的一部分 HTML 页面（HTML 片段）。</p>\n<p>　　(3) 与其它服务器资源（包括数据库和基于 Java 的应用程序）进行通信。</p>\n<p>　　(4) 用多个客户机处理连接，接收多个客户机的输入，并将结果广播到多个客户机上。例如，Servlet 可以是多参与者的游戏服务器。</p>\n<p>　　(5) 当允许在单连接方式下传送数据的情况下，在浏览器上打开服务器至applet的新连接，并将该连<br>接保持在打开状态。当允许客户机和服务器简单、高效地执行会话的情况下，applet也可以启动客户浏览器和服务器之间的连接。可以通过定制协议或标准（如 IIOP）进行通信。</p>\n<p>　　(6) 对特殊的处理采用 MIME 类型过滤数据，例如图像转换和服务器端包括（SSI）。</p>\n<p>　　(7) 将定制的处理提供给所有服务器的标准例行程序。例如，Servlet 可以修改如何认证用户。</p>\n<h2 id=\"2-Servlet的配置\"><a href=\"#2-Servlet的配置\" class=\"headerlink\" title=\"2.Servlet的配置\"></a>2.Servlet的配置</h2><p>Servlet的配置是在web.xml中，与该配置相关的节点有filter,listener,context-param等。context-param，它用于向 ServletContext 提供键值对，即应用程序上下文信息。我们的 listener, filter 等在初始化时会用到这些上下文中的信息，正确的加载顺序为：context-param -&gt; listener -&gt; filter -&gt; servlet。</p>\n<p>对于某类配置节而言，与它们出现的顺序是有关的。以 filter 为例，web.xml 中当然可以定义多个 filter，与 filter 相关的一个配置节是 filter-mapping，这里一定要注意，对于拥有相同 filter-name 的 filter 和 filter-mapping 配置节而言，filter-mapping 必须出现在 filter 之后，否则当解析到 filter-mapping 时，它所对应的 filter-name 还未定义。web 容器启动时初始化每个 filter 时，是按照 filter 配置节出现的顺序来初始化的，当请求资源匹配多个 filter-mapping 时，filter 拦截资源是按照 filter-mapping 配置节出现的顺序来依次调用 doFilter() 方法的。</p>\n<h2 id=\"3-Filter的功能\"><a href=\"#3-Filter的功能\" class=\"headerlink\" title=\"3.Filter的功能\"></a>3.Filter的功能</h2><p>filter功能，它使用户可以改变一个 request和修改一个response. Filter 不是一个servlet,它不能产生一个response,它能够在一个request到达servlet之前预处理request,也可以在离开 servlet时处理response.换种说法,filter其实是一个”servlet chaining”(servlet 链).</p>\n<p>一个Filter包括：<br>1）、在servlet被调用之前截获;<br>2）、在servlet被调用之前检查servlet request;<br>3）、根据需要修改request头和request数据;<br>4）、根据需要修改response头和response数据;<br>5）、在servlet被调用之后截获.</p>\n<h2 id=\"4-listener的功能\"><a href=\"#4-listener的功能\" class=\"headerlink\" title=\"4.listener的功能\"></a>4.listener的功能</h2><p>它是基于观察者模式设计的，Listener 的设计对开发 Servlet 应用程序提供了一种快捷的手段，能够方便的从另一个纵向维度控制程序和数据。目前 Servlet 中提供了 5 种两类事件的观察者接口，它们分别是：4 个 EventListeners 类型的，ServletContextAttributeListener、ServletRequestAttributeListener、ServletRequestListener、HttpSessionAttributeListener 和 2 个 LifecycleListeners 类型的，ServletContextListener、HttpSessionListener。如下图所示：</p>\n<p><img src=\"/images/架构/listener.png\" alt=\"listener\"></p>\n<p>Listener是Servlet的监听器，它可以监听客户端的请求、服务端的操作等。通过监听器，可以自动激发一些操作，比如监听在线的用户的数量。当增加一个HttpSession时，就激发sessionCreated(HttpSessionEvent se)方法，这样就可以给在线人数加1。</p>\n<p>常用的监听接口有以下几个：</p>\n<p>ServletContextAttributeListener监听对ServletContext属性的操作，比如增加、删除、修改属性。</p>\n<p>ServletContextListener监听ServletContext。当创建ServletContext时，激发contextInitialized(ServletContextEvent sce)方法；当销毁ServletContext时，激发contextDestroyed(ServletContextEvent sce)方法。</p>\n<p>HttpSessionListener监听HttpSession的操作。当创建一个Session时，激发session Created(HttpSessionEvent se)方法；当销毁一个Session时，激发sessionDestroyed (HttpSessionEvent se)方法。</p>\n<p>HttpSessionAttributeListener监听HttpSession中的属性的操作。当在Session增加一个属性时，激发attributeAdded(HttpSessionBindingEvent se) 方法；当在Session删除一个属性时，激发attributeRemoved(HttpSessionBindingEvent se)方法；当在Session属性被重新设置时，激发attributeReplaced(HttpSessionBindingEvent se) 方法。</p>\n<h2 id=\"5-web-xml文件详解\"><a href=\"#5-web-xml文件详解\" class=\"headerlink\" title=\"5.web.xml文件详解\"></a>5.web.xml文件详解</h2><p>Web.xml常用元素  </p>\n<p><img src=\"/images/架构/webxml.png\" alt=\"listener\"></p>"},{"layout":"lay_post","title":"均值公式推导","date":"2016-09-20T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n均值算法在机器学习中应用的比较多，使用的时候直接是公式，若对其中的推导过程不熟悉则会很疑惑，为什么要这样计算，下面就是详细的推导过程。\n\n<!-- more -->\n\n## 1.一个算法问题\n\n已知：现有均值midle,现有次数:simples\n\n输入：新值\n\n输出：新的均值\n\n以上是一个算法的基本描述，求计算新的均值公式。\n\n![算法推导](/images/算法/均值推导过程.JPG)\n\nJava代码：\n\n![代码](/images/算法/Java代码.png)\n\n## 2.mahout中的使用\n\n在mahout中评测分类效果的Auc类中，有一段将分类概率的均值更新到变量中就是使用的是该公式，注意新的值是Math.log1p(-limited) - v0) ，该值中的log1p(-limited)是指ln(1-limited)，转换为自然对数的形式。\n\n![代码](/images/算法/mahout代码.png)\n\n","source":"_posts/2016-09-21-均值公式推导.md","raw":"---\nlayout: lay_post\ntitle: \"均值公式推导\"\ndate: 2016-09-21\ncategories: 文本挖掘\ntags: 均值算法\nauthor: lvyafei\n---\n\n## 0.概述\n\n均值算法在机器学习中应用的比较多，使用的时候直接是公式，若对其中的推导过程不熟悉则会很疑惑，为什么要这样计算，下面就是详细的推导过程。\n\n<!-- more -->\n\n## 1.一个算法问题\n\n已知：现有均值midle,现有次数:simples\n\n输入：新值\n\n输出：新的均值\n\n以上是一个算法的基本描述，求计算新的均值公式。\n\n![算法推导](/images/算法/均值推导过程.JPG)\n\nJava代码：\n\n![代码](/images/算法/Java代码.png)\n\n## 2.mahout中的使用\n\n在mahout中评测分类效果的Auc类中，有一段将分类概率的均值更新到变量中就是使用的是该公式，注意新的值是Math.log1p(-limited) - v0) ，该值中的log1p(-limited)是指ln(1-limited)，转换为自然对数的形式。\n\n![代码](/images/算法/mahout代码.png)\n\n","slug":"2016-09-21-均值公式推导","published":1,"updated":"2018-11-29T12:51:24.702Z","comments":1,"photos":[],"link":"","_id":"cjskffo85002v4glmzyies7sx","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>均值算法在机器学习中应用的比较多，使用的时候直接是公式，若对其中的推导过程不熟悉则会很疑惑，为什么要这样计算，下面就是详细的推导过程。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-一个算法问题\"><a href=\"#1-一个算法问题\" class=\"headerlink\" title=\"1.一个算法问题\"></a>1.一个算法问题</h2><p>已知：现有均值midle,现有次数:simples</p>\n<p>输入：新值</p>\n<p>输出：新的均值</p>\n<p>以上是一个算法的基本描述，求计算新的均值公式。</p>\n<p><img src=\"/images/算法/均值推导过程.JPG\" alt=\"算法推导\"></p>\n<p>Java代码：</p>\n<p><img src=\"/images/算法/Java代码.png\" alt=\"代码\"></p>\n<h2 id=\"2-mahout中的使用\"><a href=\"#2-mahout中的使用\" class=\"headerlink\" title=\"2.mahout中的使用\"></a>2.mahout中的使用</h2><p>在mahout中评测分类效果的Auc类中，有一段将分类概率的均值更新到变量中就是使用的是该公式，注意新的值是Math.log1p(-limited) - v0) ，该值中的log1p(-limited)是指ln(1-limited)，转换为自然对数的形式。</p>\n<p><img src=\"/images/算法/mahout代码.png\" alt=\"代码\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>均值算法在机器学习中应用的比较多，使用的时候直接是公式，若对其中的推导过程不熟悉则会很疑惑，为什么要这样计算，下面就是详细的推导过程。</p>","more":"<h2 id=\"1-一个算法问题\"><a href=\"#1-一个算法问题\" class=\"headerlink\" title=\"1.一个算法问题\"></a>1.一个算法问题</h2><p>已知：现有均值midle,现有次数:simples</p>\n<p>输入：新值</p>\n<p>输出：新的均值</p>\n<p>以上是一个算法的基本描述，求计算新的均值公式。</p>\n<p><img src=\"/images/算法/均值推导过程.JPG\" alt=\"算法推导\"></p>\n<p>Java代码：</p>\n<p><img src=\"/images/算法/Java代码.png\" alt=\"代码\"></p>\n<h2 id=\"2-mahout中的使用\"><a href=\"#2-mahout中的使用\" class=\"headerlink\" title=\"2.mahout中的使用\"></a>2.mahout中的使用</h2><p>在mahout中评测分类效果的Auc类中，有一段将分类概率的均值更新到变量中就是使用的是该公式，注意新的值是Math.log1p(-limited) - v0) ，该值中的log1p(-limited)是指ln(1-limited)，转换为自然对数的形式。</p>\n<p><img src=\"/images/算法/mahout代码.png\" alt=\"代码\"></p>"},{"layout":"lay_post","title":"ROC曲线生成器","date":"2016-09-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，[ROC和AUC介绍以及如何计算AUC](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。但该文中只介绍ROC曲线生成的方法，没有对具体的实现细节做说明，了解实现的细节将是对理论的最好证明。\n\n<!-- more -->\n\n## 1.ROC曲线生成\n\n公式:\n\n![公式](/images/算法/fpr-and-tpr.png)\n\n测试数据集:\n\n![数据集](/images/算法/score-ranking.png)\n\nROC曲线:\n\n![ROC曲线](/images/算法/roc-example.png)\n\n代码实现:\n\n![JAVA代码](/images/算法/Java代码-roc.png)\n\n代码输出:\n\n![JAVA代码输出](/images/算法/roc_output.png)","source":"_posts/2016-09-22-ROC曲线生成器.md","raw":"---\nlayout: lay_post\ntitle: \"ROC曲线生成器\"\ndate: 2016-09-22\ncategories: 文本挖掘\ntags: ROC曲线\nauthor: lvyafei\n---\n\n## 0.概述\n\nROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，[ROC和AUC介绍以及如何计算AUC](http://alexkong.net/2013/06/introduction-to-auc-and-roc/)这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。但该文中只介绍ROC曲线生成的方法，没有对具体的实现细节做说明，了解实现的细节将是对理论的最好证明。\n\n<!-- more -->\n\n## 1.ROC曲线生成\n\n公式:\n\n![公式](/images/算法/fpr-and-tpr.png)\n\n测试数据集:\n\n![数据集](/images/算法/score-ranking.png)\n\nROC曲线:\n\n![ROC曲线](/images/算法/roc-example.png)\n\n代码实现:\n\n![JAVA代码](/images/算法/Java代码-roc.png)\n\n代码输出:\n\n![JAVA代码输出](/images/算法/roc_output.png)","slug":"2016-09-22-ROC曲线生成器","published":1,"updated":"2018-11-29T12:51:24.940Z","comments":1,"photos":[],"link":"","_id":"cjskffo85002z4glm6ok3lgl6","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>ROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，<a href=\"http://alexkong.net/2013/06/introduction-to-auc-and-roc/\" target=\"_blank\" rel=\"noopener\">ROC和AUC介绍以及如何计算AUC</a>这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。但该文中只介绍ROC曲线生成的方法，没有对具体的实现细节做说明，了解实现的细节将是对理论的最好证明。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-ROC曲线生成\"><a href=\"#1-ROC曲线生成\" class=\"headerlink\" title=\"1.ROC曲线生成\"></a>1.ROC曲线生成</h2><p>公式:</p>\n<p><img src=\"/images/算法/fpr-and-tpr.png\" alt=\"公式\"></p>\n<p>测试数据集:</p>\n<p><img src=\"/images/算法/score-ranking.png\" alt=\"数据集\"></p>\n<p>ROC曲线:</p>\n<p><img src=\"/images/算法/roc-example.png\" alt=\"ROC曲线\"></p>\n<p>代码实现:</p>\n<p><img src=\"/images/算法/Java代码-roc.png\" alt=\"JAVA代码\"></p>\n<p>代码输出:</p>\n<p><img src=\"/images/算法/roc_output.png\" alt=\"JAVA代码输出\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>ROC（Receiver Operating Characteristic）曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣，<a href=\"http://alexkong.net/2013/06/introduction-to-auc-and-roc/\" target=\"_blank\" rel=\"noopener\">ROC和AUC介绍以及如何计算AUC</a>这篇博文简单介绍ROC和AUC的特点，以及更为深入地，讨论如何作出ROC曲线图以及计算AUC。但该文中只介绍ROC曲线生成的方法，没有对具体的实现细节做说明，了解实现的细节将是对理论的最好证明。</p>","more":"<h2 id=\"1-ROC曲线生成\"><a href=\"#1-ROC曲线生成\" class=\"headerlink\" title=\"1.ROC曲线生成\"></a>1.ROC曲线生成</h2><p>公式:</p>\n<p><img src=\"/images/算法/fpr-and-tpr.png\" alt=\"公式\"></p>\n<p>测试数据集:</p>\n<p><img src=\"/images/算法/score-ranking.png\" alt=\"数据集\"></p>\n<p>ROC曲线:</p>\n<p><img src=\"/images/算法/roc-example.png\" alt=\"ROC曲线\"></p>\n<p>代码实现:</p>\n<p><img src=\"/images/算法/Java代码-roc.png\" alt=\"JAVA代码\"></p>\n<p>代码输出:</p>\n<p><img src=\"/images/算法/roc_output.png\" alt=\"JAVA代码输出\"></p>"},{"layout":"lay_post","title":"机器学习算法总览表","date":"2016-11-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n机器学习包含了许多的算法和设计规则，掌握这些算法对机器学习的设计和改善将会有很大的帮助。参考内容有Standford大学的NG老师的公开课\nmachine-learning以及自己收集的一些算法介绍资料。\n<!-- more -->\n\n下面是常用算法列表，分类，聚类，相似度常用的算法。我会对每一个算法进行概述在以后的系列文章中。\n\n## 1.算法列表\n\n**分类算法：**\n\n1.LogisticRegression(逻辑回归)\n\n2.NeuralNetwork(神经网络)\n\n3.SVM(支持向量机)\n\n4.Bayesian(朴素贝叶斯)\n\n5.HMM(隐含马尔科夫模型)\n\n6.DecisionForest(决策森林)\n\n7.RandomForests(随机森林)\n\n8.Perceptron(感知器算法)\n\n9.RestrictedBoltzmannMachines(有限波尔兹曼)\n\n10.KNN(K邻近)\n\n**聚类算法：**\n\n1.K-meansClustering(K均值算法)\n\n2.FuzzyK-means(模糊K均值)\n\n3.CanopyClustering(Canopy聚类)\n\n4.LatentDirichletAllocation(LDA聚类)\n\n5.SpectralClustering(谱聚类)\n\n6.ExpectationMaximization(期望最大化聚类)\n\n7.MeanShiftClustering(均值漂移聚类)\n\n8.HierarchicalClustering(层次聚类)\n\n9.DirichletProcessClustering(狄利克雷过程聚类)\n\n**相似度算法：**\n\n1.EuclideanDistance(欧几里得距离相似度)\n\n2.ManhattanDistance(曼哈顿距离相似度)\n\n3.ChebyshevDistance(切比雪夫距离相似度)\n\n4.MinkowskiDistance(闵可夫斯基距离相似度)\n\n5.MahalanobisDistance(马氏距离)\n\n6.UncenteredCosineSimilarity(余弦相似度)\n\n7.PearsonCorrelationSimilarity(皮尔森相似度)\n\n8.SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)\n\n9.LogLikelihoodSimilarity(对数似然相似度)\n\n10.TanimotoCoefficientSimilarity(谷本系数相似度)\n\n11.HammingDistance(汉明距离)\n\n12.JaccardSimilarityCoefficient(杰卡德相似系数)\n\n13.CorrelationCoefficient(相关系数)与CorrelationDistance(相关距离)\n\n14.InformationEntropy(信息熵)\n\n## 2.机器学习概述\n\nTom Mitchell 给机器学习一个明确的定义: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"\n\n一般来说，任何机器学习问题可以分为两大分类:Supervised Learning(监督学习)和Unsupervised Learning(无监督学习).\n\n**Supervised Learning(监督学习):**\n\n在监督学习中，我们给出了一个数据集，已经知道我们的正确的输出应该是什么样子的，输入和输出之间有一定关系。\n\n监督学习问题分为“回归”(regression)和“分类”(classification)问题。在一个回归问题中，我们试图预测结果在一个连续的输出，这意味着我们正在试图将输入变量映射到一些连续函数。在一个分类问题中，我们试图预测结果在一个离散的输出。换句话说，我们正在试图将输入变量映射到离散的类别中。这是关于连续数据和离散数据的数学描述。\n\n**Unsupervised Learning(无监督学习):**\n\n无监督学习，使我们能够在很少或根本不知道我们的研究结果应该是什么样的情况下。从数据中获得结构，尽管我们不一定知道变量之间的关系。\n我们可以根据这种结构化的聚类数据，得出数据中变量之间的关系。\n\n无监督学习，对预测结果没有任何反馈，也就是说，没有老师纠正你的结果。\n\n## 3.机器学习笔记\n\n网上看到有人把NG老师的课程做成笔记的形式，可以回顾下学习的内容，不错。记到这里了。\n\n[知乎-机器学习笔记](https://zhuanlan.zhihu.com/mlearn)","source":"_posts/2016-11-22-机器学习算法总览表.md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法总览表\"\ndate: 2016-11-22\ncategories: 算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n机器学习包含了许多的算法和设计规则，掌握这些算法对机器学习的设计和改善将会有很大的帮助。参考内容有Standford大学的NG老师的公开课\nmachine-learning以及自己收集的一些算法介绍资料。\n<!-- more -->\n\n下面是常用算法列表，分类，聚类，相似度常用的算法。我会对每一个算法进行概述在以后的系列文章中。\n\n## 1.算法列表\n\n**分类算法：**\n\n1.LogisticRegression(逻辑回归)\n\n2.NeuralNetwork(神经网络)\n\n3.SVM(支持向量机)\n\n4.Bayesian(朴素贝叶斯)\n\n5.HMM(隐含马尔科夫模型)\n\n6.DecisionForest(决策森林)\n\n7.RandomForests(随机森林)\n\n8.Perceptron(感知器算法)\n\n9.RestrictedBoltzmannMachines(有限波尔兹曼)\n\n10.KNN(K邻近)\n\n**聚类算法：**\n\n1.K-meansClustering(K均值算法)\n\n2.FuzzyK-means(模糊K均值)\n\n3.CanopyClustering(Canopy聚类)\n\n4.LatentDirichletAllocation(LDA聚类)\n\n5.SpectralClustering(谱聚类)\n\n6.ExpectationMaximization(期望最大化聚类)\n\n7.MeanShiftClustering(均值漂移聚类)\n\n8.HierarchicalClustering(层次聚类)\n\n9.DirichletProcessClustering(狄利克雷过程聚类)\n\n**相似度算法：**\n\n1.EuclideanDistance(欧几里得距离相似度)\n\n2.ManhattanDistance(曼哈顿距离相似度)\n\n3.ChebyshevDistance(切比雪夫距离相似度)\n\n4.MinkowskiDistance(闵可夫斯基距离相似度)\n\n5.MahalanobisDistance(马氏距离)\n\n6.UncenteredCosineSimilarity(余弦相似度)\n\n7.PearsonCorrelationSimilarity(皮尔森相似度)\n\n8.SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)\n\n9.LogLikelihoodSimilarity(对数似然相似度)\n\n10.TanimotoCoefficientSimilarity(谷本系数相似度)\n\n11.HammingDistance(汉明距离)\n\n12.JaccardSimilarityCoefficient(杰卡德相似系数)\n\n13.CorrelationCoefficient(相关系数)与CorrelationDistance(相关距离)\n\n14.InformationEntropy(信息熵)\n\n## 2.机器学习概述\n\nTom Mitchell 给机器学习一个明确的定义: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.\"\n\n一般来说，任何机器学习问题可以分为两大分类:Supervised Learning(监督学习)和Unsupervised Learning(无监督学习).\n\n**Supervised Learning(监督学习):**\n\n在监督学习中，我们给出了一个数据集，已经知道我们的正确的输出应该是什么样子的，输入和输出之间有一定关系。\n\n监督学习问题分为“回归”(regression)和“分类”(classification)问题。在一个回归问题中，我们试图预测结果在一个连续的输出，这意味着我们正在试图将输入变量映射到一些连续函数。在一个分类问题中，我们试图预测结果在一个离散的输出。换句话说，我们正在试图将输入变量映射到离散的类别中。这是关于连续数据和离散数据的数学描述。\n\n**Unsupervised Learning(无监督学习):**\n\n无监督学习，使我们能够在很少或根本不知道我们的研究结果应该是什么样的情况下。从数据中获得结构，尽管我们不一定知道变量之间的关系。\n我们可以根据这种结构化的聚类数据，得出数据中变量之间的关系。\n\n无监督学习，对预测结果没有任何反馈，也就是说，没有老师纠正你的结果。\n\n## 3.机器学习笔记\n\n网上看到有人把NG老师的课程做成笔记的形式，可以回顾下学习的内容，不错。记到这里了。\n\n[知乎-机器学习笔记](https://zhuanlan.zhihu.com/mlearn)","slug":"2016-11-22-机器学习算法总览表","published":1,"updated":"2018-11-29T12:51:24.944Z","comments":1,"photos":[],"link":"","_id":"cjskffo8k00314glm17y1ok96","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>机器学习包含了许多的算法和设计规则，掌握这些算法对机器学习的设计和改善将会有很大的帮助。参考内容有Standford大学的NG老师的公开课<br>machine-learning以及自己收集的一些算法介绍资料。<br><a id=\"more\"></a></p>\n<p>下面是常用算法列表，分类，聚类，相似度常用的算法。我会对每一个算法进行概述在以后的系列文章中。</p>\n<h2 id=\"1-算法列表\"><a href=\"#1-算法列表\" class=\"headerlink\" title=\"1.算法列表\"></a>1.算法列表</h2><p><strong>分类算法：</strong></p>\n<p>1.LogisticRegression(逻辑回归)</p>\n<p>2.NeuralNetwork(神经网络)</p>\n<p>3.SVM(支持向量机)</p>\n<p>4.Bayesian(朴素贝叶斯)</p>\n<p>5.HMM(隐含马尔科夫模型)</p>\n<p>6.DecisionForest(决策森林)</p>\n<p>7.RandomForests(随机森林)</p>\n<p>8.Perceptron(感知器算法)</p>\n<p>9.RestrictedBoltzmannMachines(有限波尔兹曼)</p>\n<p>10.KNN(K邻近)</p>\n<p><strong>聚类算法：</strong></p>\n<p>1.K-meansClustering(K均值算法)</p>\n<p>2.FuzzyK-means(模糊K均值)</p>\n<p>3.CanopyClustering(Canopy聚类)</p>\n<p>4.LatentDirichletAllocation(LDA聚类)</p>\n<p>5.SpectralClustering(谱聚类)</p>\n<p>6.ExpectationMaximization(期望最大化聚类)</p>\n<p>7.MeanShiftClustering(均值漂移聚类)</p>\n<p>8.HierarchicalClustering(层次聚类)</p>\n<p>9.DirichletProcessClustering(狄利克雷过程聚类)</p>\n<p><strong>相似度算法：</strong></p>\n<p>1.EuclideanDistance(欧几里得距离相似度)</p>\n<p>2.ManhattanDistance(曼哈顿距离相似度)</p>\n<p>3.ChebyshevDistance(切比雪夫距离相似度)</p>\n<p>4.MinkowskiDistance(闵可夫斯基距离相似度)</p>\n<p>5.MahalanobisDistance(马氏距离)</p>\n<p>6.UncenteredCosineSimilarity(余弦相似度)</p>\n<p>7.PearsonCorrelationSimilarity(皮尔森相似度)</p>\n<p>8.SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)</p>\n<p>9.LogLikelihoodSimilarity(对数似然相似度)</p>\n<p>10.TanimotoCoefficientSimilarity(谷本系数相似度)</p>\n<p>11.HammingDistance(汉明距离)</p>\n<p>12.JaccardSimilarityCoefficient(杰卡德相似系数)</p>\n<p>13.CorrelationCoefficient(相关系数)与CorrelationDistance(相关距离)</p>\n<p>14.InformationEntropy(信息熵)</p>\n<h2 id=\"2-机器学习概述\"><a href=\"#2-机器学习概述\" class=\"headerlink\" title=\"2.机器学习概述\"></a>2.机器学习概述</h2><p>Tom Mitchell 给机器学习一个明确的定义: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”</p>\n<p>一般来说，任何机器学习问题可以分为两大分类:Supervised Learning(监督学习)和Unsupervised Learning(无监督学习).</p>\n<p><strong>Supervised Learning(监督学习):</strong></p>\n<p>在监督学习中，我们给出了一个数据集，已经知道我们的正确的输出应该是什么样子的，输入和输出之间有一定关系。</p>\n<p>监督学习问题分为“回归”(regression)和“分类”(classification)问题。在一个回归问题中，我们试图预测结果在一个连续的输出，这意味着我们正在试图将输入变量映射到一些连续函数。在一个分类问题中，我们试图预测结果在一个离散的输出。换句话说，我们正在试图将输入变量映射到离散的类别中。这是关于连续数据和离散数据的数学描述。</p>\n<p><strong>Unsupervised Learning(无监督学习):</strong></p>\n<p>无监督学习，使我们能够在很少或根本不知道我们的研究结果应该是什么样的情况下。从数据中获得结构，尽管我们不一定知道变量之间的关系。<br>我们可以根据这种结构化的聚类数据，得出数据中变量之间的关系。</p>\n<p>无监督学习，对预测结果没有任何反馈，也就是说，没有老师纠正你的结果。</p>\n<h2 id=\"3-机器学习笔记\"><a href=\"#3-机器学习笔记\" class=\"headerlink\" title=\"3.机器学习笔记\"></a>3.机器学习笔记</h2><p>网上看到有人把NG老师的课程做成笔记的形式，可以回顾下学习的内容，不错。记到这里了。</p>\n<p><a href=\"https://zhuanlan.zhihu.com/mlearn\" target=\"_blank\" rel=\"noopener\">知乎-机器学习笔记</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>机器学习包含了许多的算法和设计规则，掌握这些算法对机器学习的设计和改善将会有很大的帮助。参考内容有Standford大学的NG老师的公开课<br>machine-learning以及自己收集的一些算法介绍资料。<br>","more":"</p>\n<p>下面是常用算法列表，分类，聚类，相似度常用的算法。我会对每一个算法进行概述在以后的系列文章中。</p>\n<h2 id=\"1-算法列表\"><a href=\"#1-算法列表\" class=\"headerlink\" title=\"1.算法列表\"></a>1.算法列表</h2><p><strong>分类算法：</strong></p>\n<p>1.LogisticRegression(逻辑回归)</p>\n<p>2.NeuralNetwork(神经网络)</p>\n<p>3.SVM(支持向量机)</p>\n<p>4.Bayesian(朴素贝叶斯)</p>\n<p>5.HMM(隐含马尔科夫模型)</p>\n<p>6.DecisionForest(决策森林)</p>\n<p>7.RandomForests(随机森林)</p>\n<p>8.Perceptron(感知器算法)</p>\n<p>9.RestrictedBoltzmannMachines(有限波尔兹曼)</p>\n<p>10.KNN(K邻近)</p>\n<p><strong>聚类算法：</strong></p>\n<p>1.K-meansClustering(K均值算法)</p>\n<p>2.FuzzyK-means(模糊K均值)</p>\n<p>3.CanopyClustering(Canopy聚类)</p>\n<p>4.LatentDirichletAllocation(LDA聚类)</p>\n<p>5.SpectralClustering(谱聚类)</p>\n<p>6.ExpectationMaximization(期望最大化聚类)</p>\n<p>7.MeanShiftClustering(均值漂移聚类)</p>\n<p>8.HierarchicalClustering(层次聚类)</p>\n<p>9.DirichletProcessClustering(狄利克雷过程聚类)</p>\n<p><strong>相似度算法：</strong></p>\n<p>1.EuclideanDistance(欧几里得距离相似度)</p>\n<p>2.ManhattanDistance(曼哈顿距离相似度)</p>\n<p>3.ChebyshevDistance(切比雪夫距离相似度)</p>\n<p>4.MinkowskiDistance(闵可夫斯基距离相似度)</p>\n<p>5.MahalanobisDistance(马氏距离)</p>\n<p>6.UncenteredCosineSimilarity(余弦相似度)</p>\n<p>7.PearsonCorrelationSimilarity(皮尔森相似度)</p>\n<p>8.SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)</p>\n<p>9.LogLikelihoodSimilarity(对数似然相似度)</p>\n<p>10.TanimotoCoefficientSimilarity(谷本系数相似度)</p>\n<p>11.HammingDistance(汉明距离)</p>\n<p>12.JaccardSimilarityCoefficient(杰卡德相似系数)</p>\n<p>13.CorrelationCoefficient(相关系数)与CorrelationDistance(相关距离)</p>\n<p>14.InformationEntropy(信息熵)</p>\n<h2 id=\"2-机器学习概述\"><a href=\"#2-机器学习概述\" class=\"headerlink\" title=\"2.机器学习概述\"></a>2.机器学习概述</h2><p>Tom Mitchell 给机器学习一个明确的定义: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”</p>\n<p>一般来说，任何机器学习问题可以分为两大分类:Supervised Learning(监督学习)和Unsupervised Learning(无监督学习).</p>\n<p><strong>Supervised Learning(监督学习):</strong></p>\n<p>在监督学习中，我们给出了一个数据集，已经知道我们的正确的输出应该是什么样子的，输入和输出之间有一定关系。</p>\n<p>监督学习问题分为“回归”(regression)和“分类”(classification)问题。在一个回归问题中，我们试图预测结果在一个连续的输出，这意味着我们正在试图将输入变量映射到一些连续函数。在一个分类问题中，我们试图预测结果在一个离散的输出。换句话说，我们正在试图将输入变量映射到离散的类别中。这是关于连续数据和离散数据的数学描述。</p>\n<p><strong>Unsupervised Learning(无监督学习):</strong></p>\n<p>无监督学习，使我们能够在很少或根本不知道我们的研究结果应该是什么样的情况下。从数据中获得结构，尽管我们不一定知道变量之间的关系。<br>我们可以根据这种结构化的聚类数据，得出数据中变量之间的关系。</p>\n<p>无监督学习，对预测结果没有任何反馈，也就是说，没有老师纠正你的结果。</p>\n<h2 id=\"3-机器学习笔记\"><a href=\"#3-机器学习笔记\" class=\"headerlink\" title=\"3.机器学习笔记\"></a>3.机器学习笔记</h2><p>网上看到有人把NG老师的课程做成笔记的形式，可以回顾下学习的内容，不错。记到这里了。</p>\n<p><a href=\"https://zhuanlan.zhihu.com/mlearn\" target=\"_blank\" rel=\"noopener\">知乎-机器学习笔记</a></p>"},{"layout":"lay_post","title":"机器学习算法-回归-梯度下降(GradientDescent)","date":"2016-11-22T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n回归分析（regression analysis)是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。运用十分广泛，回归分析按照涉及的变量的多少，分为一元回归和多元回归分析；在线性回归中，按照因变量的多少，可分为简单回归分析和多重回归分析；按照自变量和因变量之间的关系类型，可分为线性回归分析和非线性回归分析。如果在回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且自变量之间存在线性相关，则称为多元线性回归分析。\n\n在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。线性回归的主要问题是参数估计。\n<!-- more -->\n\n## 1.单参数-LinearRegression(线性回归)\n\n**Hypothesis Function(假设函数):**\n\n![假设函数](/images/算法/逻辑回归/单参数-线性-假设函数.png)\n\n**Cost Function(代价函数):**\n\n![代价函数](/images/算法/逻辑回归/单参数-线性-代价函数.png)\n\n**Gradient Descent(梯度下降算法):**\n\n![梯度下降](/images/算法/逻辑回归/单参数-线性-梯度下降.png)\n\n重复执行，直至收敛\n\n**Gradient Descent for Linear Regression(针对线性回归的梯度下降算法):**\n\n![梯度下降1](/images/算法/逻辑回归/单参数-线性-线性梯度下降.png)\n\n## 2.多参数-LinearRegression(线性回归)\n\n**Hypothesis Function(假设函数):**\n\n![假设函数](/images/算法/逻辑回归/多参数-线性-假设函数.png)\n\n向量化表示:\n\n![假设函数向量化](/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png)\n\n多训练集下：\n\n![多训练集](/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png)\n\n对应的假设函数:\n\n![假设函数](/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png)\n\n**Cost Function(代价函数):**\n\n![代价函数](/images/算法/逻辑回归/多参数-线性-代价函数.png)\n\n**Gradient Descent for Multiple Linear Regression(针对多参数线性回归的梯度下降算法):**\n\n![梯度下降](/images/算法/逻辑回归/多参数-线性-梯度下降.png)\n\n**Normal Equation(正规方程):**\n\n正规方程是从最小二乘法(矩阵形式)推导过来的，其本质是对代价函数求导，让导数等于0即可求极值，得到最优参数。\n\n![正规方程](/images/算法/逻辑回归/多参数-线性-正规方程.png)\n\n## 3.参数估计算法概述\n\n参数估计是指在已知系统模型结构时，用系统的输入和输出数据计算系统模型参数的过程。18世纪末德国数学家C.F.高斯首先提出参数估计的方法，他用最小二乘法计算天体运行的轨道。20世纪60年代，随着电子计算机的普及，参数估计有了飞速的发展。参数估计有多种方法，有矩估计、极大似然法、一致最小方差无偏估计、最小风险估计、同变估计、最小二乘法、贝叶斯估计、极大验后法、最小风险法和极小化极大熵法等。最基本的方法是最小二乘法和极大似然法。\n\n最小二乘法的目标：求误差的最小平方和，对应有两种：线性和非线性。线性最小二乘的解是closed-form即，而非线性最小二乘没有closed-form，通常用迭代法求解。\n\n迭代法，即在每一步update未知量逐渐逼近解，可以用于各种各样的问题（包括最小二乘），比如求的不是误差的最小平方和而是最小立方和。梯度下降是迭代法的一种，可以用于求解最小二乘问题（线性和非线性都可以）。高斯-牛顿法是另一种经常用于求解非线性最小二乘的迭代法（一定程度上可视为标准非线性最小二乘求解方法）。\n\n还有一种叫做Levenberg-Marquardt的迭代法用于求解非线性最小二乘问题，就结合了梯度下降和高斯-牛顿法。","source":"_posts/2016-11-23-机器学习算法-回归-梯度下降(GradientDescent).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-回归-梯度下降(GradientDescent)\"\ndate: 2016-11-23\ncategories: 回归算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n回归分析（regression analysis)是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。运用十分广泛，回归分析按照涉及的变量的多少，分为一元回归和多元回归分析；在线性回归中，按照因变量的多少，可分为简单回归分析和多重回归分析；按照自变量和因变量之间的关系类型，可分为线性回归分析和非线性回归分析。如果在回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且自变量之间存在线性相关，则称为多元线性回归分析。\n\n在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。线性回归的主要问题是参数估计。\n<!-- more -->\n\n## 1.单参数-LinearRegression(线性回归)\n\n**Hypothesis Function(假设函数):**\n\n![假设函数](/images/算法/逻辑回归/单参数-线性-假设函数.png)\n\n**Cost Function(代价函数):**\n\n![代价函数](/images/算法/逻辑回归/单参数-线性-代价函数.png)\n\n**Gradient Descent(梯度下降算法):**\n\n![梯度下降](/images/算法/逻辑回归/单参数-线性-梯度下降.png)\n\n重复执行，直至收敛\n\n**Gradient Descent for Linear Regression(针对线性回归的梯度下降算法):**\n\n![梯度下降1](/images/算法/逻辑回归/单参数-线性-线性梯度下降.png)\n\n## 2.多参数-LinearRegression(线性回归)\n\n**Hypothesis Function(假设函数):**\n\n![假设函数](/images/算法/逻辑回归/多参数-线性-假设函数.png)\n\n向量化表示:\n\n![假设函数向量化](/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png)\n\n多训练集下：\n\n![多训练集](/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png)\n\n对应的假设函数:\n\n![假设函数](/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png)\n\n**Cost Function(代价函数):**\n\n![代价函数](/images/算法/逻辑回归/多参数-线性-代价函数.png)\n\n**Gradient Descent for Multiple Linear Regression(针对多参数线性回归的梯度下降算法):**\n\n![梯度下降](/images/算法/逻辑回归/多参数-线性-梯度下降.png)\n\n**Normal Equation(正规方程):**\n\n正规方程是从最小二乘法(矩阵形式)推导过来的，其本质是对代价函数求导，让导数等于0即可求极值，得到最优参数。\n\n![正规方程](/images/算法/逻辑回归/多参数-线性-正规方程.png)\n\n## 3.参数估计算法概述\n\n参数估计是指在已知系统模型结构时，用系统的输入和输出数据计算系统模型参数的过程。18世纪末德国数学家C.F.高斯首先提出参数估计的方法，他用最小二乘法计算天体运行的轨道。20世纪60年代，随着电子计算机的普及，参数估计有了飞速的发展。参数估计有多种方法，有矩估计、极大似然法、一致最小方差无偏估计、最小风险估计、同变估计、最小二乘法、贝叶斯估计、极大验后法、最小风险法和极小化极大熵法等。最基本的方法是最小二乘法和极大似然法。\n\n最小二乘法的目标：求误差的最小平方和，对应有两种：线性和非线性。线性最小二乘的解是closed-form即，而非线性最小二乘没有closed-form，通常用迭代法求解。\n\n迭代法，即在每一步update未知量逐渐逼近解，可以用于各种各样的问题（包括最小二乘），比如求的不是误差的最小平方和而是最小立方和。梯度下降是迭代法的一种，可以用于求解最小二乘问题（线性和非线性都可以）。高斯-牛顿法是另一种经常用于求解非线性最小二乘的迭代法（一定程度上可视为标准非线性最小二乘求解方法）。\n\n还有一种叫做Levenberg-Marquardt的迭代法用于求解非线性最小二乘问题，就结合了梯度下降和高斯-牛顿法。","slug":"2016-11-23-机器学习算法-回归-梯度下降(GradientDescent)","published":1,"updated":"2018-11-29T12:51:24.953Z","comments":1,"photos":[],"link":"","_id":"cjskffo8k00344glm454658n9","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>回归分析（regression analysis)是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。运用十分广泛，回归分析按照涉及的变量的多少，分为一元回归和多元回归分析；在线性回归中，按照因变量的多少，可分为简单回归分析和多重回归分析；按照自变量和因变量之间的关系类型，可分为线性回归分析和非线性回归分析。如果在回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且自变量之间存在线性相关，则称为多元线性回归分析。</p>\n<p>在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。线性回归的主要问题是参数估计。<br><a id=\"more\"></a></p>\n<h2 id=\"1-单参数-LinearRegression-线性回归\"><a href=\"#1-单参数-LinearRegression-线性回归\" class=\"headerlink\" title=\"1.单参数-LinearRegression(线性回归)\"></a>1.单参数-LinearRegression(线性回归)</h2><p><strong>Hypothesis Function(假设函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-假设函数.png\" alt=\"假设函数\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-代价函数.png\" alt=\"代价函数\"></p>\n<p><strong>Gradient Descent(梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-梯度下降.png\" alt=\"梯度下降\"></p>\n<p>重复执行，直至收敛</p>\n<p><strong>Gradient Descent for Linear Regression(针对线性回归的梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-线性梯度下降.png\" alt=\"梯度下降1\"></p>\n<h2 id=\"2-多参数-LinearRegression-线性回归\"><a href=\"#2-多参数-LinearRegression-线性回归\" class=\"headerlink\" title=\"2.多参数-LinearRegression(线性回归)\"></a>2.多参数-LinearRegression(线性回归)</h2><p><strong>Hypothesis Function(假设函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数.png\" alt=\"假设函数\"></p>\n<p>向量化表示:</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png\" alt=\"假设函数向量化\"></p>\n<p>多训练集下：</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png\" alt=\"多训练集\"></p>\n<p>对应的假设函数:</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png\" alt=\"假设函数\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-代价函数.png\" alt=\"代价函数\"></p>\n<p><strong>Gradient Descent for Multiple Linear Regression(针对多参数线性回归的梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-梯度下降.png\" alt=\"梯度下降\"></p>\n<p><strong>Normal Equation(正规方程):</strong></p>\n<p>正规方程是从最小二乘法(矩阵形式)推导过来的，其本质是对代价函数求导，让导数等于0即可求极值，得到最优参数。</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-正规方程.png\" alt=\"正规方程\"></p>\n<h2 id=\"3-参数估计算法概述\"><a href=\"#3-参数估计算法概述\" class=\"headerlink\" title=\"3.参数估计算法概述\"></a>3.参数估计算法概述</h2><p>参数估计是指在已知系统模型结构时，用系统的输入和输出数据计算系统模型参数的过程。18世纪末德国数学家C.F.高斯首先提出参数估计的方法，他用最小二乘法计算天体运行的轨道。20世纪60年代，随着电子计算机的普及，参数估计有了飞速的发展。参数估计有多种方法，有矩估计、极大似然法、一致最小方差无偏估计、最小风险估计、同变估计、最小二乘法、贝叶斯估计、极大验后法、最小风险法和极小化极大熵法等。最基本的方法是最小二乘法和极大似然法。</p>\n<p>最小二乘法的目标：求误差的最小平方和，对应有两种：线性和非线性。线性最小二乘的解是closed-form即，而非线性最小二乘没有closed-form，通常用迭代法求解。</p>\n<p>迭代法，即在每一步update未知量逐渐逼近解，可以用于各种各样的问题（包括最小二乘），比如求的不是误差的最小平方和而是最小立方和。梯度下降是迭代法的一种，可以用于求解最小二乘问题（线性和非线性都可以）。高斯-牛顿法是另一种经常用于求解非线性最小二乘的迭代法（一定程度上可视为标准非线性最小二乘求解方法）。</p>\n<p>还有一种叫做Levenberg-Marquardt的迭代法用于求解非线性最小二乘问题，就结合了梯度下降和高斯-牛顿法。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>回归分析（regression analysis)是确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法。运用十分广泛，回归分析按照涉及的变量的多少，分为一元回归和多元回归分析；在线性回归中，按照因变量的多少，可分为简单回归分析和多重回归分析；按照自变量和因变量之间的关系类型，可分为线性回归分析和非线性回归分析。如果在回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且自变量之间存在线性相关，则称为多元线性回归分析。</p>\n<p>在统计学中，线性回归(Linear Regression)是利用称为线性回归方程的最小平方函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析。这种函数是一个或多个称为回归系数的模型参数的线性组合。只有一个自变量的情况称为简单回归,大于一个自变量情况的叫做多元回归。线性回归的主要问题是参数估计。<br>","more":"</p>\n<h2 id=\"1-单参数-LinearRegression-线性回归\"><a href=\"#1-单参数-LinearRegression-线性回归\" class=\"headerlink\" title=\"1.单参数-LinearRegression(线性回归)\"></a>1.单参数-LinearRegression(线性回归)</h2><p><strong>Hypothesis Function(假设函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-假设函数.png\" alt=\"假设函数\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-代价函数.png\" alt=\"代价函数\"></p>\n<p><strong>Gradient Descent(梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-梯度下降.png\" alt=\"梯度下降\"></p>\n<p>重复执行，直至收敛</p>\n<p><strong>Gradient Descent for Linear Regression(针对线性回归的梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/单参数-线性-线性梯度下降.png\" alt=\"梯度下降1\"></p>\n<h2 id=\"2-多参数-LinearRegression-线性回归\"><a href=\"#2-多参数-LinearRegression-线性回归\" class=\"headerlink\" title=\"2.多参数-LinearRegression(线性回归)\"></a>2.多参数-LinearRegression(线性回归)</h2><p><strong>Hypothesis Function(假设函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数.png\" alt=\"假设函数\"></p>\n<p>向量化表示:</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化.png\" alt=\"假设函数向量化\"></p>\n<p>多训练集下：</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练.png\" alt=\"多训练集\"></p>\n<p>对应的假设函数:</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-假设函数-向量化-多训练-假设函数.png\" alt=\"假设函数\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-代价函数.png\" alt=\"代价函数\"></p>\n<p><strong>Gradient Descent for Multiple Linear Regression(针对多参数线性回归的梯度下降算法):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-梯度下降.png\" alt=\"梯度下降\"></p>\n<p><strong>Normal Equation(正规方程):</strong></p>\n<p>正规方程是从最小二乘法(矩阵形式)推导过来的，其本质是对代价函数求导，让导数等于0即可求极值，得到最优参数。</p>\n<p><img src=\"/images/算法/逻辑回归/多参数-线性-正规方程.png\" alt=\"正规方程\"></p>\n<h2 id=\"3-参数估计算法概述\"><a href=\"#3-参数估计算法概述\" class=\"headerlink\" title=\"3.参数估计算法概述\"></a>3.参数估计算法概述</h2><p>参数估计是指在已知系统模型结构时，用系统的输入和输出数据计算系统模型参数的过程。18世纪末德国数学家C.F.高斯首先提出参数估计的方法，他用最小二乘法计算天体运行的轨道。20世纪60年代，随着电子计算机的普及，参数估计有了飞速的发展。参数估计有多种方法，有矩估计、极大似然法、一致最小方差无偏估计、最小风险估计、同变估计、最小二乘法、贝叶斯估计、极大验后法、最小风险法和极小化极大熵法等。最基本的方法是最小二乘法和极大似然法。</p>\n<p>最小二乘法的目标：求误差的最小平方和，对应有两种：线性和非线性。线性最小二乘的解是closed-form即，而非线性最小二乘没有closed-form，通常用迭代法求解。</p>\n<p>迭代法，即在每一步update未知量逐渐逼近解，可以用于各种各样的问题（包括最小二乘），比如求的不是误差的最小平方和而是最小立方和。梯度下降是迭代法的一种，可以用于求解最小二乘问题（线性和非线性都可以）。高斯-牛顿法是另一种经常用于求解非线性最小二乘的迭代法（一定程度上可视为标准非线性最小二乘求解方法）。</p>\n<p>还有一种叫做Levenberg-Marquardt的迭代法用于求解非线性最小二乘问题，就结合了梯度下降和高斯-牛顿法。</p>"},{"layout":"lay_post","title":"机器学习算法-分类-LogisticRegression(逻辑回归)","date":"2016-11-22T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n监督学习问题分为“回归”(regression)和“分类”(classification)问题。LinearRegression(线性回归)属于\"回归\"问题，而LogisticRegression(逻辑回归)属于\"分类\"问题。\n<!-- more -->\n\n## 1.LogisticRegression(逻辑回归)\n\n现在我们正在从回归问题切换到分类问题。不要被“逻辑回归”的名字混淆，它被命名为历史原因的方法，实际上是一种分类问题的方法，而不是回归问题。\n\n**Sigmoid Function(S函数):**\n\n![S函数](/images/算法/逻辑回归/S函数.png)\n\n我们的假设应该满足：\n\n![函数范围](/images/算法/逻辑回归/函数范围.png)\n\n逻辑回归的假设函数：\n\n![逻辑回归函数](/images/算法/逻辑回归/逻辑回归函数.png)\n\n针对分类问题，当假设函数预测的值达到一定概率后就判定为指定类别，预测值为:\n\n![预测函数概率](/images/算法/逻辑回归/预测函数概率.png)\n\n**Decision Boundary(决策边界):**\n\n决策边界控制分类的界限，当预测函数值大于0.5就分类为1，当预测函数的值小于0.5就分类为0。针对S函数，当S函数中的X大于0是S函数就结果就大于0.5，相反则小于0.5。\n0.5就是决策边界，改变这个边界将影响到分类的结果。\n\n当边界为0.5时，在逻辑函数里面就是假设函数为0的情况。\n\n![预测分类](/images/算法/逻辑回归/预测分类.png)\n\n**Cost Function(代价函数):**\n\n![逻辑回归代价函数](/images/算法/逻辑回归/逻辑回归代价函数.png)\n\n对数函数模型:\n\n![对数函数](/images/算法/逻辑回归/对数函数.png)\n\n代价函数分析:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数1.png)\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数.png)\n\n精简版代价函数:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数2.png)\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数3.png)\n\n向量化:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数向量化.png)\n\n**Gradient Descent(梯度下降):**\n\n![逻辑回归-梯度下降](/images/算法/逻辑回归/逻辑回归-梯度下降.png)\n\n**多分类:One-vs-all**\n\n![逻辑回归-多分类](/images/算法/逻辑回归/逻辑回归-多分类.png)\n\n我们先是选择一类，然后将所有的其它分到一个单一的二类。我们这样做是反复的，对每一种情况下应用二元逻辑回归，然后使用返回的最高值作为我们的预测的假设\n\n## 2.Regularization(正则化)\n\n正则化是设计来解决过度拟合的问题。\n\n**正则化线性回归-梯度下降**\n\n![逻辑回归-正则化代价函数](/images/算法/逻辑回归/逻辑回归-正则化代价函数.png)\n\n![逻辑回归-正则化代价函数1](/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png)\n\n**正则化逻辑回归-代价函数**\n\n![逻辑回归-正则化代价函数2](/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png)\n\n**正则化逻辑回归-梯度下降**\n\n![逻辑回归-正则化梯度下降](/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png)\n\n## 3.广义线性模型\n\n逻辑回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。\n\n这一家族中的模型形式基本上都差不多，不同的就是因变量不同。\n\n1.如果是连续的，就是多重线性回归；\n\n2.如果是二项分布，就是Logistic回归；\n\n3.如果是Poisson分布，就是Poisson回归；\n\n4.如果是负二项分布，就是负二项回归。\n\nLogistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。\n\nLogistic回归的主要用途：\n\n寻找危险因素：寻找某一疾病的危险因素等；\n\n预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；\n\n判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。\n\nLogistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。","source":"_posts/2016-11-23-机器学习算法-分类-LogisticRegression(逻辑回归).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-分类-LogisticRegression(逻辑回归)\"\ndate: 2016-11-23\ncategories: 分类算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n监督学习问题分为“回归”(regression)和“分类”(classification)问题。LinearRegression(线性回归)属于\"回归\"问题，而LogisticRegression(逻辑回归)属于\"分类\"问题。\n<!-- more -->\n\n## 1.LogisticRegression(逻辑回归)\n\n现在我们正在从回归问题切换到分类问题。不要被“逻辑回归”的名字混淆，它被命名为历史原因的方法，实际上是一种分类问题的方法，而不是回归问题。\n\n**Sigmoid Function(S函数):**\n\n![S函数](/images/算法/逻辑回归/S函数.png)\n\n我们的假设应该满足：\n\n![函数范围](/images/算法/逻辑回归/函数范围.png)\n\n逻辑回归的假设函数：\n\n![逻辑回归函数](/images/算法/逻辑回归/逻辑回归函数.png)\n\n针对分类问题，当假设函数预测的值达到一定概率后就判定为指定类别，预测值为:\n\n![预测函数概率](/images/算法/逻辑回归/预测函数概率.png)\n\n**Decision Boundary(决策边界):**\n\n决策边界控制分类的界限，当预测函数值大于0.5就分类为1，当预测函数的值小于0.5就分类为0。针对S函数，当S函数中的X大于0是S函数就结果就大于0.5，相反则小于0.5。\n0.5就是决策边界，改变这个边界将影响到分类的结果。\n\n当边界为0.5时，在逻辑函数里面就是假设函数为0的情况。\n\n![预测分类](/images/算法/逻辑回归/预测分类.png)\n\n**Cost Function(代价函数):**\n\n![逻辑回归代价函数](/images/算法/逻辑回归/逻辑回归代价函数.png)\n\n对数函数模型:\n\n![对数函数](/images/算法/逻辑回归/对数函数.png)\n\n代价函数分析:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数1.png)\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数.png)\n\n精简版代价函数:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数2.png)\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数3.png)\n\n向量化:\n\n![逻辑回归-代价函数](/images/算法/逻辑回归/逻辑回归-代价函数向量化.png)\n\n**Gradient Descent(梯度下降):**\n\n![逻辑回归-梯度下降](/images/算法/逻辑回归/逻辑回归-梯度下降.png)\n\n**多分类:One-vs-all**\n\n![逻辑回归-多分类](/images/算法/逻辑回归/逻辑回归-多分类.png)\n\n我们先是选择一类，然后将所有的其它分到一个单一的二类。我们这样做是反复的，对每一种情况下应用二元逻辑回归，然后使用返回的最高值作为我们的预测的假设\n\n## 2.Regularization(正则化)\n\n正则化是设计来解决过度拟合的问题。\n\n**正则化线性回归-梯度下降**\n\n![逻辑回归-正则化代价函数](/images/算法/逻辑回归/逻辑回归-正则化代价函数.png)\n\n![逻辑回归-正则化代价函数1](/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png)\n\n**正则化逻辑回归-代价函数**\n\n![逻辑回归-正则化代价函数2](/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png)\n\n**正则化逻辑回归-梯度下降**\n\n![逻辑回归-正则化梯度下降](/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png)\n\n## 3.广义线性模型\n\n逻辑回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。\n\n这一家族中的模型形式基本上都差不多，不同的就是因变量不同。\n\n1.如果是连续的，就是多重线性回归；\n\n2.如果是二项分布，就是Logistic回归；\n\n3.如果是Poisson分布，就是Poisson回归；\n\n4.如果是负二项分布，就是负二项回归。\n\nLogistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。\n\nLogistic回归的主要用途：\n\n寻找危险因素：寻找某一疾病的危险因素等；\n\n预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；\n\n判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。\n\nLogistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。","slug":"2016-11-23-机器学习算法-分类-LogisticRegression(逻辑回归)","published":1,"updated":"2018-11-29T12:51:24.949Z","comments":1,"photos":[],"link":"","_id":"cjskffo8k00384glmw7cfxccz","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>监督学习问题分为“回归”(regression)和“分类”(classification)问题。LinearRegression(线性回归)属于”回归”问题，而LogisticRegression(逻辑回归)属于”分类”问题。<br><a id=\"more\"></a></p>\n<h2 id=\"1-LogisticRegression-逻辑回归\"><a href=\"#1-LogisticRegression-逻辑回归\" class=\"headerlink\" title=\"1.LogisticRegression(逻辑回归)\"></a>1.LogisticRegression(逻辑回归)</h2><p>现在我们正在从回归问题切换到分类问题。不要被“逻辑回归”的名字混淆，它被命名为历史原因的方法，实际上是一种分类问题的方法，而不是回归问题。</p>\n<p><strong>Sigmoid Function(S函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/S函数.png\" alt=\"S函数\"></p>\n<p>我们的假设应该满足：</p>\n<p><img src=\"/images/算法/逻辑回归/函数范围.png\" alt=\"函数范围\"></p>\n<p>逻辑回归的假设函数：</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归函数.png\" alt=\"逻辑回归函数\"></p>\n<p>针对分类问题，当假设函数预测的值达到一定概率后就判定为指定类别，预测值为:</p>\n<p><img src=\"/images/算法/逻辑回归/预测函数概率.png\" alt=\"预测函数概率\"></p>\n<p><strong>Decision Boundary(决策边界):</strong></p>\n<p>决策边界控制分类的界限，当预测函数值大于0.5就分类为1，当预测函数的值小于0.5就分类为0。针对S函数，当S函数中的X大于0是S函数就结果就大于0.5，相反则小于0.5。<br>0.5就是决策边界，改变这个边界将影响到分类的结果。</p>\n<p>当边界为0.5时，在逻辑函数里面就是假设函数为0的情况。</p>\n<p><img src=\"/images/算法/逻辑回归/预测分类.png\" alt=\"预测分类\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归代价函数.png\" alt=\"逻辑回归代价函数\"></p>\n<p>对数函数模型:</p>\n<p><img src=\"/images/算法/逻辑回归/对数函数.png\" alt=\"对数函数\"></p>\n<p>代价函数分析:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数1.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数.png\" alt=\"逻辑回归-代价函数\"></p>\n<p>精简版代价函数:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数2.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数3.png\" alt=\"逻辑回归-代价函数\"></p>\n<p>向量化:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数向量化.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><strong>Gradient Descent(梯度下降):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-梯度下降.png\" alt=\"逻辑回归-梯度下降\"></p>\n<p><strong>多分类:One-vs-all</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-多分类.png\" alt=\"逻辑回归-多分类\"></p>\n<p>我们先是选择一类，然后将所有的其它分到一个单一的二类。我们这样做是反复的，对每一种情况下应用二元逻辑回归，然后使用返回的最高值作为我们的预测的假设</p>\n<h2 id=\"2-Regularization-正则化\"><a href=\"#2-Regularization-正则化\" class=\"headerlink\" title=\"2.Regularization(正则化)\"></a>2.Regularization(正则化)</h2><p>正则化是设计来解决过度拟合的问题。</p>\n<p><strong>正则化线性回归-梯度下降</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数.png\" alt=\"逻辑回归-正则化代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png\" alt=\"逻辑回归-正则化代价函数1\"></p>\n<p><strong>正则化逻辑回归-代价函数</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png\" alt=\"逻辑回归-正则化代价函数2\"></p>\n<p><strong>正则化逻辑回归-梯度下降</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png\" alt=\"逻辑回归-正则化梯度下降\"></p>\n<h2 id=\"3-广义线性模型\"><a href=\"#3-广义线性模型\" class=\"headerlink\" title=\"3.广义线性模型\"></a>3.广义线性模型</h2><p>逻辑回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。</p>\n<p>这一家族中的模型形式基本上都差不多，不同的就是因变量不同。</p>\n<p>1.如果是连续的，就是多重线性回归；</p>\n<p>2.如果是二项分布，就是Logistic回归；</p>\n<p>3.如果是Poisson分布，就是Poisson回归；</p>\n<p>4.如果是负二项分布，就是负二项回归。</p>\n<p>Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。</p>\n<p>Logistic回归的主要用途：</p>\n<p>寻找危险因素：寻找某一疾病的危险因素等；</p>\n<p>预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；</p>\n<p>判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。</p>\n<p>Logistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>监督学习问题分为“回归”(regression)和“分类”(classification)问题。LinearRegression(线性回归)属于”回归”问题，而LogisticRegression(逻辑回归)属于”分类”问题。<br>","more":"</p>\n<h2 id=\"1-LogisticRegression-逻辑回归\"><a href=\"#1-LogisticRegression-逻辑回归\" class=\"headerlink\" title=\"1.LogisticRegression(逻辑回归)\"></a>1.LogisticRegression(逻辑回归)</h2><p>现在我们正在从回归问题切换到分类问题。不要被“逻辑回归”的名字混淆，它被命名为历史原因的方法，实际上是一种分类问题的方法，而不是回归问题。</p>\n<p><strong>Sigmoid Function(S函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/S函数.png\" alt=\"S函数\"></p>\n<p>我们的假设应该满足：</p>\n<p><img src=\"/images/算法/逻辑回归/函数范围.png\" alt=\"函数范围\"></p>\n<p>逻辑回归的假设函数：</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归函数.png\" alt=\"逻辑回归函数\"></p>\n<p>针对分类问题，当假设函数预测的值达到一定概率后就判定为指定类别，预测值为:</p>\n<p><img src=\"/images/算法/逻辑回归/预测函数概率.png\" alt=\"预测函数概率\"></p>\n<p><strong>Decision Boundary(决策边界):</strong></p>\n<p>决策边界控制分类的界限，当预测函数值大于0.5就分类为1，当预测函数的值小于0.5就分类为0。针对S函数，当S函数中的X大于0是S函数就结果就大于0.5，相反则小于0.5。<br>0.5就是决策边界，改变这个边界将影响到分类的结果。</p>\n<p>当边界为0.5时，在逻辑函数里面就是假设函数为0的情况。</p>\n<p><img src=\"/images/算法/逻辑回归/预测分类.png\" alt=\"预测分类\"></p>\n<p><strong>Cost Function(代价函数):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归代价函数.png\" alt=\"逻辑回归代价函数\"></p>\n<p>对数函数模型:</p>\n<p><img src=\"/images/算法/逻辑回归/对数函数.png\" alt=\"对数函数\"></p>\n<p>代价函数分析:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数1.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数.png\" alt=\"逻辑回归-代价函数\"></p>\n<p>精简版代价函数:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数2.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数3.png\" alt=\"逻辑回归-代价函数\"></p>\n<p>向量化:</p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-代价函数向量化.png\" alt=\"逻辑回归-代价函数\"></p>\n<p><strong>Gradient Descent(梯度下降):</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-梯度下降.png\" alt=\"逻辑回归-梯度下降\"></p>\n<p><strong>多分类:One-vs-all</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-多分类.png\" alt=\"逻辑回归-多分类\"></p>\n<p>我们先是选择一类，然后将所有的其它分到一个单一的二类。我们这样做是反复的，对每一种情况下应用二元逻辑回归，然后使用返回的最高值作为我们的预测的假设</p>\n<h2 id=\"2-Regularization-正则化\"><a href=\"#2-Regularization-正则化\" class=\"headerlink\" title=\"2.Regularization(正则化)\"></a>2.Regularization(正则化)</h2><p>正则化是设计来解决过度拟合的问题。</p>\n<p><strong>正则化线性回归-梯度下降</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数.png\" alt=\"逻辑回归-正则化代价函数\"></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数1.png\" alt=\"逻辑回归-正则化代价函数1\"></p>\n<p><strong>正则化逻辑回归-代价函数</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化代价函数2.png\" alt=\"逻辑回归-正则化代价函数2\"></p>\n<p><strong>正则化逻辑回归-梯度下降</strong></p>\n<p><img src=\"/images/算法/逻辑回归/逻辑回归-正则化梯度下降.png\" alt=\"逻辑回归-正则化梯度下降\"></p>\n<h2 id=\"3-广义线性模型\"><a href=\"#3-广义线性模型\" class=\"headerlink\" title=\"3.广义线性模型\"></a>3.广义线性模型</h2><p>逻辑回归与多重线性回归实际上有很多相同之处，最大的区别就在于它们的因变量不同，其他的基本都差不多。正是因为如此，这两种回归可以归于同一个家族，即广义线性模型（generalizedlinear model）。</p>\n<p>这一家族中的模型形式基本上都差不多，不同的就是因变量不同。</p>\n<p>1.如果是连续的，就是多重线性回归；</p>\n<p>2.如果是二项分布，就是Logistic回归；</p>\n<p>3.如果是Poisson分布，就是Poisson回归；</p>\n<p>4.如果是负二项分布，就是负二项回归。</p>\n<p>Logistic回归的因变量可以是二分类的，也可以是多分类的，但是二分类的更为常用，也更加容易解释。所以实际中最常用的就是二分类的Logistic回归。</p>\n<p>Logistic回归的主要用途：</p>\n<p>寻找危险因素：寻找某一疾病的危险因素等；</p>\n<p>预测：根据模型，预测在不同的自变量情况下，发生某病或某种情况的概率有多大；</p>\n<p>判别：实际上跟预测有些类似，也是根据模型，判断某人属于某病或属于某种情况的概率有多大，也就是看一下这个人有多大的可能性是属于某病。</p>\n<p>Logistic回归主要在流行病学中应用较多，比较常用的情形是探索某疾病的危险因素，根据危险因素预测某疾病发生的概率，等等。例如，想探讨胃癌发生的危险因素，可以选择两组人群，一组是胃癌组，一组是非胃癌组，两组人群肯定有不同的体征和生活方式等。这里的因变量就是是否胃癌，即“是”或“否”，自变量就可以包括很多了，例如年龄、性别、饮食习惯、幽门螺杆菌感染等。自变量既可以是连续的，也可以是分类的。</p>"},{"layout":"lay_post","title":"机器学习算法-分类-NeuralNetwork(神经网络)","date":"2016-11-23T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n当我们面对一个有许多特征和复杂假设函数的问题时，神经网络提供了一种替代的方式来执行机器学习。例如，对拥有大量像素的图片进行分类识别时，大量的特征值(每个像素)和复杂的假设函数(特征值的N次方组合)使其它监督学习算法执行效率和表现上都不太良好,神经网络能够提供一个高效的学习模型。\n<!-- more -->\n\n## 1.假设函数\n\n![假设函数](/images/算法/神经网络/hfunction.png)\n\n![假设函数-向量化](/images/算法/神经网络/vector.png)\n\n![多分类](/images/算法/神经网络/multi-class.png)\n\n## 2.代价函数\n\n![代价函数](/images/算法/神经网络/costfunction.png)\n\n## 3.向后传播\n\n![向后传播](/images/算法/神经网络/backpropagation.png)\n\n## 4.向后传播-实现\n\n![向后传播](/images/算法/神经网络/backpropagation-impl.png)\n\n## 5.向前-向后传播示意图\n\n![向后-向前](/images/算法/神经网络/backpropagation-pic.png)\n\n## 6.其他\n\n![other](/images/算法/神经网络/other.png)","source":"_posts/2016-11-24-机器学习算法-分类-NeuralNetwork(神经网络).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-分类-NeuralNetwork(神经网络)\"\ndate: 2016-11-24\ncategories: 分类算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n当我们面对一个有许多特征和复杂假设函数的问题时，神经网络提供了一种替代的方式来执行机器学习。例如，对拥有大量像素的图片进行分类识别时，大量的特征值(每个像素)和复杂的假设函数(特征值的N次方组合)使其它监督学习算法执行效率和表现上都不太良好,神经网络能够提供一个高效的学习模型。\n<!-- more -->\n\n## 1.假设函数\n\n![假设函数](/images/算法/神经网络/hfunction.png)\n\n![假设函数-向量化](/images/算法/神经网络/vector.png)\n\n![多分类](/images/算法/神经网络/multi-class.png)\n\n## 2.代价函数\n\n![代价函数](/images/算法/神经网络/costfunction.png)\n\n## 3.向后传播\n\n![向后传播](/images/算法/神经网络/backpropagation.png)\n\n## 4.向后传播-实现\n\n![向后传播](/images/算法/神经网络/backpropagation-impl.png)\n\n## 5.向前-向后传播示意图\n\n![向后-向前](/images/算法/神经网络/backpropagation-pic.png)\n\n## 6.其他\n\n![other](/images/算法/神经网络/other.png)","slug":"2016-11-24-机器学习算法-分类-NeuralNetwork(神经网络)","published":1,"updated":"2018-11-29T12:51:24.959Z","comments":1,"photos":[],"link":"","_id":"cjskffo9000394glmc7uodlr6","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>当我们面对一个有许多特征和复杂假设函数的问题时，神经网络提供了一种替代的方式来执行机器学习。例如，对拥有大量像素的图片进行分类识别时，大量的特征值(每个像素)和复杂的假设函数(特征值的N次方组合)使其它监督学习算法执行效率和表现上都不太良好,神经网络能够提供一个高效的学习模型。<br><a id=\"more\"></a></p>\n<h2 id=\"1-假设函数\"><a href=\"#1-假设函数\" class=\"headerlink\" title=\"1.假设函数\"></a>1.假设函数</h2><p><img src=\"/images/算法/神经网络/hfunction.png\" alt=\"假设函数\"></p>\n<p><img src=\"/images/算法/神经网络/vector.png\" alt=\"假设函数-向量化\"></p>\n<p><img src=\"/images/算法/神经网络/multi-class.png\" alt=\"多分类\"></p>\n<h2 id=\"2-代价函数\"><a href=\"#2-代价函数\" class=\"headerlink\" title=\"2.代价函数\"></a>2.代价函数</h2><p><img src=\"/images/算法/神经网络/costfunction.png\" alt=\"代价函数\"></p>\n<h2 id=\"3-向后传播\"><a href=\"#3-向后传播\" class=\"headerlink\" title=\"3.向后传播\"></a>3.向后传播</h2><p><img src=\"/images/算法/神经网络/backpropagation.png\" alt=\"向后传播\"></p>\n<h2 id=\"4-向后传播-实现\"><a href=\"#4-向后传播-实现\" class=\"headerlink\" title=\"4.向后传播-实现\"></a>4.向后传播-实现</h2><p><img src=\"/images/算法/神经网络/backpropagation-impl.png\" alt=\"向后传播\"></p>\n<h2 id=\"5-向前-向后传播示意图\"><a href=\"#5-向前-向后传播示意图\" class=\"headerlink\" title=\"5.向前-向后传播示意图\"></a>5.向前-向后传播示意图</h2><p><img src=\"/images/算法/神经网络/backpropagation-pic.png\" alt=\"向后-向前\"></p>\n<h2 id=\"6-其他\"><a href=\"#6-其他\" class=\"headerlink\" title=\"6.其他\"></a>6.其他</h2><p><img src=\"/images/算法/神经网络/other.png\" alt=\"other\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>当我们面对一个有许多特征和复杂假设函数的问题时，神经网络提供了一种替代的方式来执行机器学习。例如，对拥有大量像素的图片进行分类识别时，大量的特征值(每个像素)和复杂的假设函数(特征值的N次方组合)使其它监督学习算法执行效率和表现上都不太良好,神经网络能够提供一个高效的学习模型。<br>","more":"</p>\n<h2 id=\"1-假设函数\"><a href=\"#1-假设函数\" class=\"headerlink\" title=\"1.假设函数\"></a>1.假设函数</h2><p><img src=\"/images/算法/神经网络/hfunction.png\" alt=\"假设函数\"></p>\n<p><img src=\"/images/算法/神经网络/vector.png\" alt=\"假设函数-向量化\"></p>\n<p><img src=\"/images/算法/神经网络/multi-class.png\" alt=\"多分类\"></p>\n<h2 id=\"2-代价函数\"><a href=\"#2-代价函数\" class=\"headerlink\" title=\"2.代价函数\"></a>2.代价函数</h2><p><img src=\"/images/算法/神经网络/costfunction.png\" alt=\"代价函数\"></p>\n<h2 id=\"3-向后传播\"><a href=\"#3-向后传播\" class=\"headerlink\" title=\"3.向后传播\"></a>3.向后传播</h2><p><img src=\"/images/算法/神经网络/backpropagation.png\" alt=\"向后传播\"></p>\n<h2 id=\"4-向后传播-实现\"><a href=\"#4-向后传播-实现\" class=\"headerlink\" title=\"4.向后传播-实现\"></a>4.向后传播-实现</h2><p><img src=\"/images/算法/神经网络/backpropagation-impl.png\" alt=\"向后传播\"></p>\n<h2 id=\"5-向前-向后传播示意图\"><a href=\"#5-向前-向后传播示意图\" class=\"headerlink\" title=\"5.向前-向后传播示意图\"></a>5.向前-向后传播示意图</h2><p><img src=\"/images/算法/神经网络/backpropagation-pic.png\" alt=\"向后-向前\"></p>\n<h2 id=\"6-其他\"><a href=\"#6-其他\" class=\"headerlink\" title=\"6.其他\"></a>6.其他</h2><p><img src=\"/images/算法/神经网络/other.png\" alt=\"other\"></p>"},{"layout":"lay_post","title":"机器学习算法-分类-SVM(支持向量机)","date":"2016-11-24T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nSVM(支持向量机)是另一种监督机器学习算法。它有时更清洁，更强大。\n<!-- more -->\n\n## 1.逻辑回归和SVM对比\n\n![逻辑回归](/images/算法/SVM/逻辑回归.png)\n\n![SVM](/images/算法/SVM/svm.png)\n\n![costfunction](/images/算法/SVM/costfunction.png)\n\n## 2.大边距分类器(Large Margin Classifiers)\n\n![costfunction](/images/算法/SVM/largemargin.png)\n\n## 3.核(Kernels)\n\n![kernel](/images/算法/SVM/kernel.png)\n\n![kernel-simila](/images/算法/SVM/kernel-simila.png)\n\n## 4.参数选择和多分类\n\n![other](/images/算法/SVM/other.png)\n\n## 5.SVM和LogisticRegression选择对比\n\n![vs](/images/算法/SVM/vs.png)","source":"_posts/2016-11-25-机器学习算法-分类-SVM(支持向量机).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-分类-SVM(支持向量机)\"\ndate: 2016-11-25\ncategories: 分类算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\nSVM(支持向量机)是另一种监督机器学习算法。它有时更清洁，更强大。\n<!-- more -->\n\n## 1.逻辑回归和SVM对比\n\n![逻辑回归](/images/算法/SVM/逻辑回归.png)\n\n![SVM](/images/算法/SVM/svm.png)\n\n![costfunction](/images/算法/SVM/costfunction.png)\n\n## 2.大边距分类器(Large Margin Classifiers)\n\n![costfunction](/images/算法/SVM/largemargin.png)\n\n## 3.核(Kernels)\n\n![kernel](/images/算法/SVM/kernel.png)\n\n![kernel-simila](/images/算法/SVM/kernel-simila.png)\n\n## 4.参数选择和多分类\n\n![other](/images/算法/SVM/other.png)\n\n## 5.SVM和LogisticRegression选择对比\n\n![vs](/images/算法/SVM/vs.png)","slug":"2016-11-25-机器学习算法-分类-SVM(支持向量机)","published":1,"updated":"2018-11-29T12:51:24.963Z","comments":1,"photos":[],"link":"","_id":"cjskffo90003e4glmhoby23j3","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>SVM(支持向量机)是另一种监督机器学习算法。它有时更清洁，更强大。<br><a id=\"more\"></a></p>\n<h2 id=\"1-逻辑回归和SVM对比\"><a href=\"#1-逻辑回归和SVM对比\" class=\"headerlink\" title=\"1.逻辑回归和SVM对比\"></a>1.逻辑回归和SVM对比</h2><p><img src=\"/images/算法/SVM/逻辑回归.png\" alt=\"逻辑回归\"></p>\n<p><img src=\"/images/算法/SVM/svm.png\" alt=\"SVM\"></p>\n<p><img src=\"/images/算法/SVM/costfunction.png\" alt=\"costfunction\"></p>\n<h2 id=\"2-大边距分类器-Large-Margin-Classifiers\"><a href=\"#2-大边距分类器-Large-Margin-Classifiers\" class=\"headerlink\" title=\"2.大边距分类器(Large Margin Classifiers)\"></a>2.大边距分类器(Large Margin Classifiers)</h2><p><img src=\"/images/算法/SVM/largemargin.png\" alt=\"costfunction\"></p>\n<h2 id=\"3-核-Kernels\"><a href=\"#3-核-Kernels\" class=\"headerlink\" title=\"3.核(Kernels)\"></a>3.核(Kernels)</h2><p><img src=\"/images/算法/SVM/kernel.png\" alt=\"kernel\"></p>\n<p><img src=\"/images/算法/SVM/kernel-simila.png\" alt=\"kernel-simila\"></p>\n<h2 id=\"4-参数选择和多分类\"><a href=\"#4-参数选择和多分类\" class=\"headerlink\" title=\"4.参数选择和多分类\"></a>4.参数选择和多分类</h2><p><img src=\"/images/算法/SVM/other.png\" alt=\"other\"></p>\n<h2 id=\"5-SVM和LogisticRegression选择对比\"><a href=\"#5-SVM和LogisticRegression选择对比\" class=\"headerlink\" title=\"5.SVM和LogisticRegression选择对比\"></a>5.SVM和LogisticRegression选择对比</h2><p><img src=\"/images/算法/SVM/vs.png\" alt=\"vs\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>SVM(支持向量机)是另一种监督机器学习算法。它有时更清洁，更强大。<br>","more":"</p>\n<h2 id=\"1-逻辑回归和SVM对比\"><a href=\"#1-逻辑回归和SVM对比\" class=\"headerlink\" title=\"1.逻辑回归和SVM对比\"></a>1.逻辑回归和SVM对比</h2><p><img src=\"/images/算法/SVM/逻辑回归.png\" alt=\"逻辑回归\"></p>\n<p><img src=\"/images/算法/SVM/svm.png\" alt=\"SVM\"></p>\n<p><img src=\"/images/算法/SVM/costfunction.png\" alt=\"costfunction\"></p>\n<h2 id=\"2-大边距分类器-Large-Margin-Classifiers\"><a href=\"#2-大边距分类器-Large-Margin-Classifiers\" class=\"headerlink\" title=\"2.大边距分类器(Large Margin Classifiers)\"></a>2.大边距分类器(Large Margin Classifiers)</h2><p><img src=\"/images/算法/SVM/largemargin.png\" alt=\"costfunction\"></p>\n<h2 id=\"3-核-Kernels\"><a href=\"#3-核-Kernels\" class=\"headerlink\" title=\"3.核(Kernels)\"></a>3.核(Kernels)</h2><p><img src=\"/images/算法/SVM/kernel.png\" alt=\"kernel\"></p>\n<p><img src=\"/images/算法/SVM/kernel-simila.png\" alt=\"kernel-simila\"></p>\n<h2 id=\"4-参数选择和多分类\"><a href=\"#4-参数选择和多分类\" class=\"headerlink\" title=\"4.参数选择和多分类\"></a>4.参数选择和多分类</h2><p><img src=\"/images/算法/SVM/other.png\" alt=\"other\"></p>\n<h2 id=\"5-SVM和LogisticRegression选择对比\"><a href=\"#5-SVM和LogisticRegression选择对比\" class=\"headerlink\" title=\"5.SVM和LogisticRegression选择对比\"></a>5.SVM和LogisticRegression选择对比</h2><p><img src=\"/images/算法/SVM/vs.png\" alt=\"vs\"></p>"},{"layout":"lay_post","title":"机器学习算法-聚类-K-Means(K均值)","date":"2016-11-26T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n无监督学习和监督学习的区别是，无监督学习使用一个未标记的训练集，而监督学习使用的是一个标记的训练集。换句话说，我们没有一个预期结果的向量，只有一个可以找到结构的特征数据集。\n<!-- more -->\n\n无监督学习可以适用于以下领域:\n\n1.市场细分\n\n2.社会网络分析\n\n3.组织计算机集群\n\n4.天文数据分析\n\n## 1.K-Means(K-均值)\n\nk-均值算法是自动分组数据到相干子集问题中使用最流行和最广泛的算法。\n\n1.在数据集中随机初始化两个点。(称为聚类中心)。\n\n2.群集分配：根据当前例子距离哪个聚类中心最近，将所有的例子都分配到两个组中的一个。\n\n3.移动聚类中心：计算两个聚类中心组内的所有点的平均值，然后将聚类中心点移动到这些平均值的位置上。\n\n4.重复运行2,3步骤，直到找到我们的聚类。\n\n我们使用的几个主要变量是:\n\n1.K(聚类的数量)\n\n2.训练集(x1,x2,...xm)\n\n3.xi属于实数\n\n注意：我们不使用x0=1这个参数。经过若干次的迭代，算法将会收敛，一旦收敛后，在新的迭代中不会影响现有的集群。\n\n关于非分离聚类的注记：一些数据集没有真正的内分离或自然结构。k-均值仍然可以将您的数据均匀地分割成K个子集，因此在这种情况下仍然有用。\n\n## 2.代价函数\n\n![cost](/images/算法/K-means/costfunction.png)\n\n## 3.初始化和簇的数目\n\n![init](/images/算法/K-means/init.png)\n\n## 4.降维(Dimensionality Reduction)\n\n![dimensionality](/images/算法/K-means/dimensionality.png)\n\n## 5.主成分分析(Principal Component Analysis)问题描述\n\n![principal](/images/算法/K-means/principal.png)\n\n## 6.PCA算法\n\n![pca](/images/算法/K-means/pca.png)\n\n## 7.解压缩数据\n\n![unzip](/images/算法/K-means/unzip.png)\n\n## 8.选择主成分的数量\n\n![pca-num](/images/算法/K-means/pca-num.png)\n\n## 9.使用PCA的建议\n\n![advice](/images/算法/K-means/advice.png)","source":"_posts/2016-11-27-机器学习算法-聚类-K-Means(K均值).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-聚类-K-Means(K均值)\"\ndate: 2016-11-27\ncategories: 聚类算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n无监督学习和监督学习的区别是，无监督学习使用一个未标记的训练集，而监督学习使用的是一个标记的训练集。换句话说，我们没有一个预期结果的向量，只有一个可以找到结构的特征数据集。\n<!-- more -->\n\n无监督学习可以适用于以下领域:\n\n1.市场细分\n\n2.社会网络分析\n\n3.组织计算机集群\n\n4.天文数据分析\n\n## 1.K-Means(K-均值)\n\nk-均值算法是自动分组数据到相干子集问题中使用最流行和最广泛的算法。\n\n1.在数据集中随机初始化两个点。(称为聚类中心)。\n\n2.群集分配：根据当前例子距离哪个聚类中心最近，将所有的例子都分配到两个组中的一个。\n\n3.移动聚类中心：计算两个聚类中心组内的所有点的平均值，然后将聚类中心点移动到这些平均值的位置上。\n\n4.重复运行2,3步骤，直到找到我们的聚类。\n\n我们使用的几个主要变量是:\n\n1.K(聚类的数量)\n\n2.训练集(x1,x2,...xm)\n\n3.xi属于实数\n\n注意：我们不使用x0=1这个参数。经过若干次的迭代，算法将会收敛，一旦收敛后，在新的迭代中不会影响现有的集群。\n\n关于非分离聚类的注记：一些数据集没有真正的内分离或自然结构。k-均值仍然可以将您的数据均匀地分割成K个子集，因此在这种情况下仍然有用。\n\n## 2.代价函数\n\n![cost](/images/算法/K-means/costfunction.png)\n\n## 3.初始化和簇的数目\n\n![init](/images/算法/K-means/init.png)\n\n## 4.降维(Dimensionality Reduction)\n\n![dimensionality](/images/算法/K-means/dimensionality.png)\n\n## 5.主成分分析(Principal Component Analysis)问题描述\n\n![principal](/images/算法/K-means/principal.png)\n\n## 6.PCA算法\n\n![pca](/images/算法/K-means/pca.png)\n\n## 7.解压缩数据\n\n![unzip](/images/算法/K-means/unzip.png)\n\n## 8.选择主成分的数量\n\n![pca-num](/images/算法/K-means/pca-num.png)\n\n## 9.使用PCA的建议\n\n![advice](/images/算法/K-means/advice.png)","slug":"2016-11-27-机器学习算法-聚类-K-Means(K均值)","published":1,"updated":"2018-11-29T12:51:24.968Z","comments":1,"photos":[],"link":"","_id":"cjskffo90003g4glmb4eljxl4","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>无监督学习和监督学习的区别是，无监督学习使用一个未标记的训练集，而监督学习使用的是一个标记的训练集。换句话说，我们没有一个预期结果的向量，只有一个可以找到结构的特征数据集。<br><a id=\"more\"></a></p>\n<p>无监督学习可以适用于以下领域:</p>\n<p>1.市场细分</p>\n<p>2.社会网络分析</p>\n<p>3.组织计算机集群</p>\n<p>4.天文数据分析</p>\n<h2 id=\"1-K-Means-K-均值\"><a href=\"#1-K-Means-K-均值\" class=\"headerlink\" title=\"1.K-Means(K-均值)\"></a>1.K-Means(K-均值)</h2><p>k-均值算法是自动分组数据到相干子集问题中使用最流行和最广泛的算法。</p>\n<p>1.在数据集中随机初始化两个点。(称为聚类中心)。</p>\n<p>2.群集分配：根据当前例子距离哪个聚类中心最近，将所有的例子都分配到两个组中的一个。</p>\n<p>3.移动聚类中心：计算两个聚类中心组内的所有点的平均值，然后将聚类中心点移动到这些平均值的位置上。</p>\n<p>4.重复运行2,3步骤，直到找到我们的聚类。</p>\n<p>我们使用的几个主要变量是:</p>\n<p>1.K(聚类的数量)</p>\n<p>2.训练集(x1,x2,…xm)</p>\n<p>3.xi属于实数</p>\n<p>注意：我们不使用x0=1这个参数。经过若干次的迭代，算法将会收敛，一旦收敛后，在新的迭代中不会影响现有的集群。</p>\n<p>关于非分离聚类的注记：一些数据集没有真正的内分离或自然结构。k-均值仍然可以将您的数据均匀地分割成K个子集，因此在这种情况下仍然有用。</p>\n<h2 id=\"2-代价函数\"><a href=\"#2-代价函数\" class=\"headerlink\" title=\"2.代价函数\"></a>2.代价函数</h2><p><img src=\"/images/算法/K-means/costfunction.png\" alt=\"cost\"></p>\n<h2 id=\"3-初始化和簇的数目\"><a href=\"#3-初始化和簇的数目\" class=\"headerlink\" title=\"3.初始化和簇的数目\"></a>3.初始化和簇的数目</h2><p><img src=\"/images/算法/K-means/init.png\" alt=\"init\"></p>\n<h2 id=\"4-降维-Dimensionality-Reduction\"><a href=\"#4-降维-Dimensionality-Reduction\" class=\"headerlink\" title=\"4.降维(Dimensionality Reduction)\"></a>4.降维(Dimensionality Reduction)</h2><p><img src=\"/images/算法/K-means/dimensionality.png\" alt=\"dimensionality\"></p>\n<h2 id=\"5-主成分分析-Principal-Component-Analysis-问题描述\"><a href=\"#5-主成分分析-Principal-Component-Analysis-问题描述\" class=\"headerlink\" title=\"5.主成分分析(Principal Component Analysis)问题描述\"></a>5.主成分分析(Principal Component Analysis)问题描述</h2><p><img src=\"/images/算法/K-means/principal.png\" alt=\"principal\"></p>\n<h2 id=\"6-PCA算法\"><a href=\"#6-PCA算法\" class=\"headerlink\" title=\"6.PCA算法\"></a>6.PCA算法</h2><p><img src=\"/images/算法/K-means/pca.png\" alt=\"pca\"></p>\n<h2 id=\"7-解压缩数据\"><a href=\"#7-解压缩数据\" class=\"headerlink\" title=\"7.解压缩数据\"></a>7.解压缩数据</h2><p><img src=\"/images/算法/K-means/unzip.png\" alt=\"unzip\"></p>\n<h2 id=\"8-选择主成分的数量\"><a href=\"#8-选择主成分的数量\" class=\"headerlink\" title=\"8.选择主成分的数量\"></a>8.选择主成分的数量</h2><p><img src=\"/images/算法/K-means/pca-num.png\" alt=\"pca-num\"></p>\n<h2 id=\"9-使用PCA的建议\"><a href=\"#9-使用PCA的建议\" class=\"headerlink\" title=\"9.使用PCA的建议\"></a>9.使用PCA的建议</h2><p><img src=\"/images/算法/K-means/advice.png\" alt=\"advice\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>无监督学习和监督学习的区别是，无监督学习使用一个未标记的训练集，而监督学习使用的是一个标记的训练集。换句话说，我们没有一个预期结果的向量，只有一个可以找到结构的特征数据集。<br>","more":"</p>\n<p>无监督学习可以适用于以下领域:</p>\n<p>1.市场细分</p>\n<p>2.社会网络分析</p>\n<p>3.组织计算机集群</p>\n<p>4.天文数据分析</p>\n<h2 id=\"1-K-Means-K-均值\"><a href=\"#1-K-Means-K-均值\" class=\"headerlink\" title=\"1.K-Means(K-均值)\"></a>1.K-Means(K-均值)</h2><p>k-均值算法是自动分组数据到相干子集问题中使用最流行和最广泛的算法。</p>\n<p>1.在数据集中随机初始化两个点。(称为聚类中心)。</p>\n<p>2.群集分配：根据当前例子距离哪个聚类中心最近，将所有的例子都分配到两个组中的一个。</p>\n<p>3.移动聚类中心：计算两个聚类中心组内的所有点的平均值，然后将聚类中心点移动到这些平均值的位置上。</p>\n<p>4.重复运行2,3步骤，直到找到我们的聚类。</p>\n<p>我们使用的几个主要变量是:</p>\n<p>1.K(聚类的数量)</p>\n<p>2.训练集(x1,x2,…xm)</p>\n<p>3.xi属于实数</p>\n<p>注意：我们不使用x0=1这个参数。经过若干次的迭代，算法将会收敛，一旦收敛后，在新的迭代中不会影响现有的集群。</p>\n<p>关于非分离聚类的注记：一些数据集没有真正的内分离或自然结构。k-均值仍然可以将您的数据均匀地分割成K个子集，因此在这种情况下仍然有用。</p>\n<h2 id=\"2-代价函数\"><a href=\"#2-代价函数\" class=\"headerlink\" title=\"2.代价函数\"></a>2.代价函数</h2><p><img src=\"/images/算法/K-means/costfunction.png\" alt=\"cost\"></p>\n<h2 id=\"3-初始化和簇的数目\"><a href=\"#3-初始化和簇的数目\" class=\"headerlink\" title=\"3.初始化和簇的数目\"></a>3.初始化和簇的数目</h2><p><img src=\"/images/算法/K-means/init.png\" alt=\"init\"></p>\n<h2 id=\"4-降维-Dimensionality-Reduction\"><a href=\"#4-降维-Dimensionality-Reduction\" class=\"headerlink\" title=\"4.降维(Dimensionality Reduction)\"></a>4.降维(Dimensionality Reduction)</h2><p><img src=\"/images/算法/K-means/dimensionality.png\" alt=\"dimensionality\"></p>\n<h2 id=\"5-主成分分析-Principal-Component-Analysis-问题描述\"><a href=\"#5-主成分分析-Principal-Component-Analysis-问题描述\" class=\"headerlink\" title=\"5.主成分分析(Principal Component Analysis)问题描述\"></a>5.主成分分析(Principal Component Analysis)问题描述</h2><p><img src=\"/images/算法/K-means/principal.png\" alt=\"principal\"></p>\n<h2 id=\"6-PCA算法\"><a href=\"#6-PCA算法\" class=\"headerlink\" title=\"6.PCA算法\"></a>6.PCA算法</h2><p><img src=\"/images/算法/K-means/pca.png\" alt=\"pca\"></p>\n<h2 id=\"7-解压缩数据\"><a href=\"#7-解压缩数据\" class=\"headerlink\" title=\"7.解压缩数据\"></a>7.解压缩数据</h2><p><img src=\"/images/算法/K-means/unzip.png\" alt=\"unzip\"></p>\n<h2 id=\"8-选择主成分的数量\"><a href=\"#8-选择主成分的数量\" class=\"headerlink\" title=\"8.选择主成分的数量\"></a>8.选择主成分的数量</h2><p><img src=\"/images/算法/K-means/pca-num.png\" alt=\"pca-num\"></p>\n<h2 id=\"9-使用PCA的建议\"><a href=\"#9-使用PCA的建议\" class=\"headerlink\" title=\"9.使用PCA的建议\"></a>9.使用PCA的建议</h2><p><img src=\"/images/算法/K-means/advice.png\" alt=\"advice\"></p>"},{"layout":"lay_post","title":"机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离)","date":"2016-11-27T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n距离计算中，非常常用的是欧几里得距离，和欧几里得距离相似的还有曼哈顿距离，切比雪夫距离，这些算法都是从闵可夫斯基距离演变出来的。\n<!-- more -->\n\n## 1.闵可夫斯基距离计算公式\n\n![计算公式](/images/算法/闵可夫斯基/计算公式.png)\n\n## 2.图形化展示\n\n![图形展示](/images/算法/闵可夫斯基/图形展示.png)\n\n## 3.闵可夫斯基距离的缺点\n\n![缺点](/images/算法/闵可夫斯基/缺点.png)\n\n## 4.欧式距离公式推导\n\n![公式推导](/images/算法/闵可夫斯基/公式推导.png)\n\n## 5.二维平面中闵可夫斯基图像展示\n\n![公式](/images/算法/闵可夫斯基/公式.png)\n\n![p1](/images/算法/闵可夫斯基/p25.png)\n\n![p1](/images/算法/闵可夫斯基/p1.png)\n\n![p2](/images/算法/闵可夫斯基/p2.png)\n\n![p4](/images/算法/闵可夫斯基/p4.png)\n\n![plong](/images/算法/闵可夫斯基/plong.png)","source":"_posts/2016-11-28-机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离)\"\ndate: 2016-11-28\ncategories: 相似度算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n距离计算中，非常常用的是欧几里得距离，和欧几里得距离相似的还有曼哈顿距离，切比雪夫距离，这些算法都是从闵可夫斯基距离演变出来的。\n<!-- more -->\n\n## 1.闵可夫斯基距离计算公式\n\n![计算公式](/images/算法/闵可夫斯基/计算公式.png)\n\n## 2.图形化展示\n\n![图形展示](/images/算法/闵可夫斯基/图形展示.png)\n\n## 3.闵可夫斯基距离的缺点\n\n![缺点](/images/算法/闵可夫斯基/缺点.png)\n\n## 4.欧式距离公式推导\n\n![公式推导](/images/算法/闵可夫斯基/公式推导.png)\n\n## 5.二维平面中闵可夫斯基图像展示\n\n![公式](/images/算法/闵可夫斯基/公式.png)\n\n![p1](/images/算法/闵可夫斯基/p25.png)\n\n![p1](/images/算法/闵可夫斯基/p1.png)\n\n![p2](/images/算法/闵可夫斯基/p2.png)\n\n![p4](/images/算法/闵可夫斯基/p4.png)\n\n![plong](/images/算法/闵可夫斯基/plong.png)","slug":"2016-11-28-机器学习算法-相似度-MinkowskiDistance(闵可夫斯基距离)","published":1,"updated":"2018-11-29T12:51:24.976Z","comments":1,"photos":[],"link":"","_id":"cjskffo9g003k4glm4cs8h9zt","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>距离计算中，非常常用的是欧几里得距离，和欧几里得距离相似的还有曼哈顿距离，切比雪夫距离，这些算法都是从闵可夫斯基距离演变出来的。<br><a id=\"more\"></a></p>\n<h2 id=\"1-闵可夫斯基距离计算公式\"><a href=\"#1-闵可夫斯基距离计算公式\" class=\"headerlink\" title=\"1.闵可夫斯基距离计算公式\"></a>1.闵可夫斯基距离计算公式</h2><p><img src=\"/images/算法/闵可夫斯基/计算公式.png\" alt=\"计算公式\"></p>\n<h2 id=\"2-图形化展示\"><a href=\"#2-图形化展示\" class=\"headerlink\" title=\"2.图形化展示\"></a>2.图形化展示</h2><p><img src=\"/images/算法/闵可夫斯基/图形展示.png\" alt=\"图形展示\"></p>\n<h2 id=\"3-闵可夫斯基距离的缺点\"><a href=\"#3-闵可夫斯基距离的缺点\" class=\"headerlink\" title=\"3.闵可夫斯基距离的缺点\"></a>3.闵可夫斯基距离的缺点</h2><p><img src=\"/images/算法/闵可夫斯基/缺点.png\" alt=\"缺点\"></p>\n<h2 id=\"4-欧式距离公式推导\"><a href=\"#4-欧式距离公式推导\" class=\"headerlink\" title=\"4.欧式距离公式推导\"></a>4.欧式距离公式推导</h2><p><img src=\"/images/算法/闵可夫斯基/公式推导.png\" alt=\"公式推导\"></p>\n<h2 id=\"5-二维平面中闵可夫斯基图像展示\"><a href=\"#5-二维平面中闵可夫斯基图像展示\" class=\"headerlink\" title=\"5.二维平面中闵可夫斯基图像展示\"></a>5.二维平面中闵可夫斯基图像展示</h2><p><img src=\"/images/算法/闵可夫斯基/公式.png\" alt=\"公式\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p25.png\" alt=\"p1\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p1.png\" alt=\"p1\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p2.png\" alt=\"p2\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p4.png\" alt=\"p4\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/plong.png\" alt=\"plong\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>距离计算中，非常常用的是欧几里得距离，和欧几里得距离相似的还有曼哈顿距离，切比雪夫距离，这些算法都是从闵可夫斯基距离演变出来的。<br>","more":"</p>\n<h2 id=\"1-闵可夫斯基距离计算公式\"><a href=\"#1-闵可夫斯基距离计算公式\" class=\"headerlink\" title=\"1.闵可夫斯基距离计算公式\"></a>1.闵可夫斯基距离计算公式</h2><p><img src=\"/images/算法/闵可夫斯基/计算公式.png\" alt=\"计算公式\"></p>\n<h2 id=\"2-图形化展示\"><a href=\"#2-图形化展示\" class=\"headerlink\" title=\"2.图形化展示\"></a>2.图形化展示</h2><p><img src=\"/images/算法/闵可夫斯基/图形展示.png\" alt=\"图形展示\"></p>\n<h2 id=\"3-闵可夫斯基距离的缺点\"><a href=\"#3-闵可夫斯基距离的缺点\" class=\"headerlink\" title=\"3.闵可夫斯基距离的缺点\"></a>3.闵可夫斯基距离的缺点</h2><p><img src=\"/images/算法/闵可夫斯基/缺点.png\" alt=\"缺点\"></p>\n<h2 id=\"4-欧式距离公式推导\"><a href=\"#4-欧式距离公式推导\" class=\"headerlink\" title=\"4.欧式距离公式推导\"></a>4.欧式距离公式推导</h2><p><img src=\"/images/算法/闵可夫斯基/公式推导.png\" alt=\"公式推导\"></p>\n<h2 id=\"5-二维平面中闵可夫斯基图像展示\"><a href=\"#5-二维平面中闵可夫斯基图像展示\" class=\"headerlink\" title=\"5.二维平面中闵可夫斯基图像展示\"></a>5.二维平面中闵可夫斯基图像展示</h2><p><img src=\"/images/算法/闵可夫斯基/公式.png\" alt=\"公式\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p25.png\" alt=\"p1\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p1.png\" alt=\"p1\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p2.png\" alt=\"p2\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/p4.png\" alt=\"p4\"></p>\n<p><img src=\"/images/算法/闵可夫斯基/plong.png\" alt=\"plong\"></p>"},{"layout":"lay_post","title":"机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度)","date":"2016-11-28T16:00:00.000Z","author":"bornhe","_content":"\n## 0.概述\n\n它不关心用户对物品的具体评分值是多少，它在关心用户与物品之间是否存在关联关系。Tanimoto Coefficient依赖于用户和物品之间的这种Boolean关系作为输入。\n<!-- more -->\n\n## 1.谷本系数描述\n\nTanimoto Coefficient主要用于计算符号度量或布尔值度量的个体间的相似度，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Tanimoto Coefficient只关心个体间共同具有的特征是否一致这个问题。Tanimoto Coefficient又被叫做Jaccard Coefficient，其值等于两个用户共同关联（不管喜欢还是不喜欢）的物品数量除于两个用户分别关联的所有物品数量。\n\n![公式](/images/算法/谷本系数/公式.png)\n\n其值介于[0, 1]之间，如果两个用户关联的物品完全相同，交集等于并集，值为1；如果没有任何关联，交集为空，值为0。\n","source":"_posts/2016-11-29-机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度)\"\ndate: 2016-11-29\ncategories: 相似度算法\ntags: 机器学习\nauthor: bornhe\n---\n\n## 0.概述\n\n它不关心用户对物品的具体评分值是多少，它在关心用户与物品之间是否存在关联关系。Tanimoto Coefficient依赖于用户和物品之间的这种Boolean关系作为输入。\n<!-- more -->\n\n## 1.谷本系数描述\n\nTanimoto Coefficient主要用于计算符号度量或布尔值度量的个体间的相似度，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Tanimoto Coefficient只关心个体间共同具有的特征是否一致这个问题。Tanimoto Coefficient又被叫做Jaccard Coefficient，其值等于两个用户共同关联（不管喜欢还是不喜欢）的物品数量除于两个用户分别关联的所有物品数量。\n\n![公式](/images/算法/谷本系数/公式.png)\n\n其值介于[0, 1]之间，如果两个用户关联的物品完全相同，交集等于并集，值为1；如果没有任何关联，交集为空，值为0。\n","slug":"2016-11-29-机器学习算法-相似度-TanimotoCoefficientSimilarity(谷本系数相似度)","published":1,"updated":"2018-11-29T12:51:24.983Z","comments":1,"photos":[],"link":"","_id":"cjskffo9g003m4glm2eyl949r","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>它不关心用户对物品的具体评分值是多少，它在关心用户与物品之间是否存在关联关系。Tanimoto Coefficient依赖于用户和物品之间的这种Boolean关系作为输入。<br><a id=\"more\"></a></p>\n<h2 id=\"1-谷本系数描述\"><a href=\"#1-谷本系数描述\" class=\"headerlink\" title=\"1.谷本系数描述\"></a>1.谷本系数描述</h2><p>Tanimoto Coefficient主要用于计算符号度量或布尔值度量的个体间的相似度，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Tanimoto Coefficient只关心个体间共同具有的特征是否一致这个问题。Tanimoto Coefficient又被叫做Jaccard Coefficient，其值等于两个用户共同关联（不管喜欢还是不喜欢）的物品数量除于两个用户分别关联的所有物品数量。</p>\n<p><img src=\"/images/算法/谷本系数/公式.png\" alt=\"公式\"></p>\n<p>其值介于[0, 1]之间，如果两个用户关联的物品完全相同，交集等于并集，值为1；如果没有任何关联，交集为空，值为0。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>它不关心用户对物品的具体评分值是多少，它在关心用户与物品之间是否存在关联关系。Tanimoto Coefficient依赖于用户和物品之间的这种Boolean关系作为输入。<br>","more":"</p>\n<h2 id=\"1-谷本系数描述\"><a href=\"#1-谷本系数描述\" class=\"headerlink\" title=\"1.谷本系数描述\"></a>1.谷本系数描述</h2><p>Tanimoto Coefficient主要用于计算符号度量或布尔值度量的个体间的相似度，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以Tanimoto Coefficient只关心个体间共同具有的特征是否一致这个问题。Tanimoto Coefficient又被叫做Jaccard Coefficient，其值等于两个用户共同关联（不管喜欢还是不喜欢）的物品数量除于两个用户分别关联的所有物品数量。</p>\n<p><img src=\"/images/算法/谷本系数/公式.png\" alt=\"公式\"></p>\n<p>其值介于[0, 1]之间，如果两个用户关联的物品完全相同，交集等于并集，值为1；如果没有任何关联，交集为空，值为0。</p>"},{"layout":"lay_post","title":"机器学习算法-相似度-CosineSimilarity(余弦相似度)","date":"2016-11-29T16:00:00.000Z","author":"bornhe","_content":"\n## 0.概述\n\n余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。\n<!-- more -->\n\n## 1.余弦相似度描述\n\n![公式](/images/算法/余弦相似度/公式.png)\n\n与欧几里德距离类似，基于余弦相似度的计算方法也是把用户的喜好作为n-维坐标系中的一个点，通过连接这个点与坐标系的原点构成一条直线（向量），两个用户之间的相似度值就是两条直线（向量）间夹角的余弦值。因为连接代表用户评分的点与原点的直线都会相交于原点，夹角越小代表两个用户越相似，夹角越大代表两个用户的相似度越小。同时在三角系数中，角的余弦值是在[-1, 1]之间的，0度角的余弦值是1，180角的余弦值是-1。\n\n## 2.欧氏距离和余弦相似度的区别\n\n![图例](/images/算法/余弦相似度/图例.png)\n\n从图上可以看出距离度量衡量的是空间各点间的绝对距离，跟各个点所在的位置坐标（即个体特征维度的数值）直接相关；而余弦相似度衡量的是空间向量的夹角，更加的是体现在方向上的差异，而不是位置。如果保持A点的位置不变，B点朝原方向远离坐标轴原点，那么这个时候余弦相似度cosθ是保持不变的，因为夹角不变，而A、B两点的距离显然在发生改变，这就是欧氏距离和余弦相似度的不同之处。\n\n根据欧氏距离和余弦相似度各自的计算方式和衡量特征，分别适用于不同的数据分析模型：欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析，如使用用户行为指标分析用户价值的相似度或差异；而余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感，更多的用于使用用户对内容评分来区分用户兴趣的相似度和差异，同时修正了用户间可能存在的度量标准不统一的问题（因为余弦相似度对绝对数值不敏感）。\n\n## 3.调整余弦相似度——AdjustedCosineSimilarity\n\n在余弦相似度的介绍中说到：余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感。因此没法衡量每个维数值的差异，会导致这样一个情况：比如用户对内容评分，5分制，X和Y两个用户对两个内容的评分分别为(1,2)和(4,5)，使用余弦相似度得出的结果是0.98，两者极为相似，但从评分上看X似乎不喜欢这2个内容，而Y比较喜欢，余弦相似度对数值的不敏感导致了结果的误差，需要修正这种不合理性，就出现了调整余弦相似度，即所有维度上的数值都减去一个均值，比如X和Y的评分均值都是3，那么调整后为(-2,-1)和(1,2)，再用余弦相似度计算，得到-0.8，相似度为负值并且差异不小，但显然更加符合现实。","source":"_posts/2016-11-30-机器学习算法-相似度-CosineSimilarity(余弦相似度).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-CosineSimilarity(余弦相似度)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: bornhe\n---\n\n## 0.概述\n\n余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。\n<!-- more -->\n\n## 1.余弦相似度描述\n\n![公式](/images/算法/余弦相似度/公式.png)\n\n与欧几里德距离类似，基于余弦相似度的计算方法也是把用户的喜好作为n-维坐标系中的一个点，通过连接这个点与坐标系的原点构成一条直线（向量），两个用户之间的相似度值就是两条直线（向量）间夹角的余弦值。因为连接代表用户评分的点与原点的直线都会相交于原点，夹角越小代表两个用户越相似，夹角越大代表两个用户的相似度越小。同时在三角系数中，角的余弦值是在[-1, 1]之间的，0度角的余弦值是1，180角的余弦值是-1。\n\n## 2.欧氏距离和余弦相似度的区别\n\n![图例](/images/算法/余弦相似度/图例.png)\n\n从图上可以看出距离度量衡量的是空间各点间的绝对距离，跟各个点所在的位置坐标（即个体特征维度的数值）直接相关；而余弦相似度衡量的是空间向量的夹角，更加的是体现在方向上的差异，而不是位置。如果保持A点的位置不变，B点朝原方向远离坐标轴原点，那么这个时候余弦相似度cosθ是保持不变的，因为夹角不变，而A、B两点的距离显然在发生改变，这就是欧氏距离和余弦相似度的不同之处。\n\n根据欧氏距离和余弦相似度各自的计算方式和衡量特征，分别适用于不同的数据分析模型：欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析，如使用用户行为指标分析用户价值的相似度或差异；而余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感，更多的用于使用用户对内容评分来区分用户兴趣的相似度和差异，同时修正了用户间可能存在的度量标准不统一的问题（因为余弦相似度对绝对数值不敏感）。\n\n## 3.调整余弦相似度——AdjustedCosineSimilarity\n\n在余弦相似度的介绍中说到：余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感。因此没法衡量每个维数值的差异，会导致这样一个情况：比如用户对内容评分，5分制，X和Y两个用户对两个内容的评分分别为(1,2)和(4,5)，使用余弦相似度得出的结果是0.98，两者极为相似，但从评分上看X似乎不喜欢这2个内容，而Y比较喜欢，余弦相似度对数值的不敏感导致了结果的误差，需要修正这种不合理性，就出现了调整余弦相似度，即所有维度上的数值都减去一个均值，比如X和Y的评分均值都是3，那么调整后为(-2,-1)和(1,2)，再用余弦相似度计算，得到-0.8，相似度为负值并且差异不小，但显然更加符合现实。","slug":"2016-11-30-机器学习算法-相似度-CosineSimilarity(余弦相似度)","published":1,"updated":"2018-11-29T12:51:24.990Z","comments":1,"photos":[],"link":"","_id":"cjskffo9g003q4glmztj4zd9j","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。<br><a id=\"more\"></a></p>\n<h2 id=\"1-余弦相似度描述\"><a href=\"#1-余弦相似度描述\" class=\"headerlink\" title=\"1.余弦相似度描述\"></a>1.余弦相似度描述</h2><p><img src=\"/images/算法/余弦相似度/公式.png\" alt=\"公式\"></p>\n<p>与欧几里德距离类似，基于余弦相似度的计算方法也是把用户的喜好作为n-维坐标系中的一个点，通过连接这个点与坐标系的原点构成一条直线（向量），两个用户之间的相似度值就是两条直线（向量）间夹角的余弦值。因为连接代表用户评分的点与原点的直线都会相交于原点，夹角越小代表两个用户越相似，夹角越大代表两个用户的相似度越小。同时在三角系数中，角的余弦值是在[-1, 1]之间的，0度角的余弦值是1，180角的余弦值是-1。</p>\n<h2 id=\"2-欧氏距离和余弦相似度的区别\"><a href=\"#2-欧氏距离和余弦相似度的区别\" class=\"headerlink\" title=\"2.欧氏距离和余弦相似度的区别\"></a>2.欧氏距离和余弦相似度的区别</h2><p><img src=\"/images/算法/余弦相似度/图例.png\" alt=\"图例\"></p>\n<p>从图上可以看出距离度量衡量的是空间各点间的绝对距离，跟各个点所在的位置坐标（即个体特征维度的数值）直接相关；而余弦相似度衡量的是空间向量的夹角，更加的是体现在方向上的差异，而不是位置。如果保持A点的位置不变，B点朝原方向远离坐标轴原点，那么这个时候余弦相似度cosθ是保持不变的，因为夹角不变，而A、B两点的距离显然在发生改变，这就是欧氏距离和余弦相似度的不同之处。</p>\n<p>根据欧氏距离和余弦相似度各自的计算方式和衡量特征，分别适用于不同的数据分析模型：欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析，如使用用户行为指标分析用户价值的相似度或差异；而余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感，更多的用于使用用户对内容评分来区分用户兴趣的相似度和差异，同时修正了用户间可能存在的度量标准不统一的问题（因为余弦相似度对绝对数值不敏感）。</p>\n<h2 id=\"3-调整余弦相似度——AdjustedCosineSimilarity\"><a href=\"#3-调整余弦相似度——AdjustedCosineSimilarity\" class=\"headerlink\" title=\"3.调整余弦相似度——AdjustedCosineSimilarity\"></a>3.调整余弦相似度——AdjustedCosineSimilarity</h2><p>在余弦相似度的介绍中说到：余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感。因此没法衡量每个维数值的差异，会导致这样一个情况：比如用户对内容评分，5分制，X和Y两个用户对两个内容的评分分别为(1,2)和(4,5)，使用余弦相似度得出的结果是0.98，两者极为相似，但从评分上看X似乎不喜欢这2个内容，而Y比较喜欢，余弦相似度对数值的不敏感导致了结果的误差，需要修正这种不合理性，就出现了调整余弦相似度，即所有维度上的数值都减去一个均值，比如X和Y的评分均值都是3，那么调整后为(-2,-1)和(1,2)，再用余弦相似度计算，得到-0.8，相似度为负值并且差异不小，但显然更加符合现实。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。<br>","more":"</p>\n<h2 id=\"1-余弦相似度描述\"><a href=\"#1-余弦相似度描述\" class=\"headerlink\" title=\"1.余弦相似度描述\"></a>1.余弦相似度描述</h2><p><img src=\"/images/算法/余弦相似度/公式.png\" alt=\"公式\"></p>\n<p>与欧几里德距离类似，基于余弦相似度的计算方法也是把用户的喜好作为n-维坐标系中的一个点，通过连接这个点与坐标系的原点构成一条直线（向量），两个用户之间的相似度值就是两条直线（向量）间夹角的余弦值。因为连接代表用户评分的点与原点的直线都会相交于原点，夹角越小代表两个用户越相似，夹角越大代表两个用户的相似度越小。同时在三角系数中，角的余弦值是在[-1, 1]之间的，0度角的余弦值是1，180角的余弦值是-1。</p>\n<h2 id=\"2-欧氏距离和余弦相似度的区别\"><a href=\"#2-欧氏距离和余弦相似度的区别\" class=\"headerlink\" title=\"2.欧氏距离和余弦相似度的区别\"></a>2.欧氏距离和余弦相似度的区别</h2><p><img src=\"/images/算法/余弦相似度/图例.png\" alt=\"图例\"></p>\n<p>从图上可以看出距离度量衡量的是空间各点间的绝对距离，跟各个点所在的位置坐标（即个体特征维度的数值）直接相关；而余弦相似度衡量的是空间向量的夹角，更加的是体现在方向上的差异，而不是位置。如果保持A点的位置不变，B点朝原方向远离坐标轴原点，那么这个时候余弦相似度cosθ是保持不变的，因为夹角不变，而A、B两点的距离显然在发生改变，这就是欧氏距离和余弦相似度的不同之处。</p>\n<p>根据欧氏距离和余弦相似度各自的计算方式和衡量特征，分别适用于不同的数据分析模型：欧氏距离能够体现个体数值特征的绝对差异，所以更多的用于需要从维度的数值大小中体现差异的分析，如使用用户行为指标分析用户价值的相似度或差异；而余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感，更多的用于使用用户对内容评分来区分用户兴趣的相似度和差异，同时修正了用户间可能存在的度量标准不统一的问题（因为余弦相似度对绝对数值不敏感）。</p>\n<h2 id=\"3-调整余弦相似度——AdjustedCosineSimilarity\"><a href=\"#3-调整余弦相似度——AdjustedCosineSimilarity\" class=\"headerlink\" title=\"3.调整余弦相似度——AdjustedCosineSimilarity\"></a>3.调整余弦相似度——AdjustedCosineSimilarity</h2><p>在余弦相似度的介绍中说到：余弦相似度更多的是从方向上区分差异，而对绝对的数值不敏感。因此没法衡量每个维数值的差异，会导致这样一个情况：比如用户对内容评分，5分制，X和Y两个用户对两个内容的评分分别为(1,2)和(4,5)，使用余弦相似度得出的结果是0.98，两者极为相似，但从评分上看X似乎不喜欢这2个内容，而Y比较喜欢，余弦相似度对数值的不敏感导致了结果的误差，需要修正这种不合理性，就出现了调整余弦相似度，即所有维度上的数值都减去一个均值，比如X和Y的评分均值都是3，那么调整后为(-2,-1)和(1,2)，再用余弦相似度计算，得到-0.8，相似度为负值并且差异不小，但显然更加符合现实。</p>"},{"layout":"lay_post","title":"机器学习算法-相似度-HammingDistance(汉明距离)","date":"2016-11-29T16:00:00.000Z","author":"cnblogs","_content":"\n## 0.概述\n\n两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。\n<!-- more -->\n\n## 1.应用场景\n\n信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。\n\n![公式](/images/算法/汉明距离/公式.png)\n\n## 2.Octave实例\n\n![octave](/images/算法/汉明距离/octave.png)\n\n![octave_result](/images/算法/汉明距离/octave_result.png)","source":"_posts/2016-11-30-机器学习算法-相似度-HammingDistance(汉明距离).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-HammingDistance(汉明距离)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: cnblogs\n---\n\n## 0.概述\n\n两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。\n<!-- more -->\n\n## 1.应用场景\n\n信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。\n\n![公式](/images/算法/汉明距离/公式.png)\n\n## 2.Octave实例\n\n![octave](/images/算法/汉明距离/octave.png)\n\n![octave_result](/images/算法/汉明距离/octave_result.png)","slug":"2016-11-30-机器学习算法-相似度-HammingDistance(汉明距离)","published":1,"updated":"2018-11-29T12:51:24.997Z","comments":1,"photos":[],"link":"","_id":"cjskffo9v003s4glm6e2fvws0","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。<br><a id=\"more\"></a></p>\n<h2 id=\"1-应用场景\"><a href=\"#1-应用场景\" class=\"headerlink\" title=\"1.应用场景\"></a>1.应用场景</h2><p>信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。</p>\n<p><img src=\"/images/算法/汉明距离/公式.png\" alt=\"公式\"></p>\n<h2 id=\"2-Octave实例\"><a href=\"#2-Octave实例\" class=\"headerlink\" title=\"2.Octave实例\"></a>2.Octave实例</h2><p><img src=\"/images/算法/汉明距离/octave.png\" alt=\"octave\"></p>\n<p><img src=\"/images/算法/汉明距离/octave_result.png\" alt=\"octave_result\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>两个等长字符串s1与s2之间的汉明距离定义为将其中一个变为另外一个所需要作的最小替换次数。例如字符串“1111”与“1001”之间的汉明距离为2。<br>","more":"</p>\n<h2 id=\"1-应用场景\"><a href=\"#1-应用场景\" class=\"headerlink\" title=\"1.应用场景\"></a>1.应用场景</h2><p>信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。</p>\n<p><img src=\"/images/算法/汉明距离/公式.png\" alt=\"公式\"></p>\n<h2 id=\"2-Octave实例\"><a href=\"#2-Octave实例\" class=\"headerlink\" title=\"2.Octave实例\"></a>2.Octave实例</h2><p><img src=\"/images/算法/汉明距离/octave.png\" alt=\"octave\"></p>\n<p><img src=\"/images/算法/汉明距离/octave_result.png\" alt=\"octave_result\"></p>"},{"layout":"lay_post","title":"机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数)","date":"2016-11-29T16:00:00.000Z","author":"cnblog","_content":"\n## 0.概述\n\n两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。杰卡德相似系数是衡量两个集合的相似度一种指标。与杰卡德相似系数相反的概念是杰卡德距离(Jaccard distance)。杰卡德距离可用如下公式表示：1-J(A,B)\n<!-- more -->\n\n## 1.公式\n\n![公式](/images/算法/杰卡德相似系数/公式.png)\n\n## 2.Octave实例\n\n![octave](/images/算法/杰卡德相似系数/octave.png)\n\n![octave_result](/images/算法/杰卡德相似系数/octave_result.png)","source":"_posts/2016-11-30-机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: cnblog\n---\n\n## 0.概述\n\n两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。杰卡德相似系数是衡量两个集合的相似度一种指标。与杰卡德相似系数相反的概念是杰卡德距离(Jaccard distance)。杰卡德距离可用如下公式表示：1-J(A,B)\n<!-- more -->\n\n## 1.公式\n\n![公式](/images/算法/杰卡德相似系数/公式.png)\n\n## 2.Octave实例\n\n![octave](/images/算法/杰卡德相似系数/octave.png)\n\n![octave_result](/images/算法/杰卡德相似系数/octave_result.png)","slug":"2016-11-30-机器学习算法-相似度-JaccardSimilarityCoefficient(杰卡德相似系数)","published":1,"updated":"2018-11-29T12:51:25.008Z","comments":1,"photos":[],"link":"","_id":"cjskffo9v003w4glmc2wcgmjb","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。杰卡德相似系数是衡量两个集合的相似度一种指标。与杰卡德相似系数相反的概念是杰卡德距离(Jaccard distance)。杰卡德距离可用如下公式表示：1-J(A,B)<br><a id=\"more\"></a></p>\n<h2 id=\"1-公式\"><a href=\"#1-公式\" class=\"headerlink\" title=\"1.公式\"></a>1.公式</h2><p><img src=\"/images/算法/杰卡德相似系数/公式.png\" alt=\"公式\"></p>\n<h2 id=\"2-Octave实例\"><a href=\"#2-Octave实例\" class=\"headerlink\" title=\"2.Octave实例\"></a>2.Octave实例</h2><p><img src=\"/images/算法/杰卡德相似系数/octave.png\" alt=\"octave\"></p>\n<p><img src=\"/images/算法/杰卡德相似系数/octave_result.png\" alt=\"octave_result\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。杰卡德相似系数是衡量两个集合的相似度一种指标。与杰卡德相似系数相反的概念是杰卡德距离(Jaccard distance)。杰卡德距离可用如下公式表示：1-J(A,B)<br>","more":"</p>\n<h2 id=\"1-公式\"><a href=\"#1-公式\" class=\"headerlink\" title=\"1.公式\"></a>1.公式</h2><p><img src=\"/images/算法/杰卡德相似系数/公式.png\" alt=\"公式\"></p>\n<h2 id=\"2-Octave实例\"><a href=\"#2-Octave实例\" class=\"headerlink\" title=\"2.Octave实例\"></a>2.Octave实例</h2><p><img src=\"/images/算法/杰卡德相似系数/octave.png\" alt=\"octave\"></p>\n<p><img src=\"/images/算法/杰卡德相似系数/octave_result.png\" alt=\"octave_result\"></p>"},{"layout":"lay_post","title":"机器学习算法-相似度-MahalanobisDistance(马氏距离)","date":"2016-11-29T16:00:00.000Z","author":"cnblog","_content":"\n## 0.概述\n\n马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特征之间的联系，即独立于测量尺度。\n<!-- more -->\n\n## 1.马氏距离公式\n\n设总体G为m维总体(考察m个指标),均值向量为μ，协方差矩阵为S,则样品X=(x1,x2,...xm)'与总体G的马氏距离定义为:\n\n![公式](/images/算法/马氏距离/公式.png)\n\n向量Xi与Xj之间的马氏距离定义为：\n\n![公式1](/images/算法/马氏距离/公式1.png)\n\n若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了：\n\n![公式2](/images/算法/马氏距离/公式2.png)\n\n若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。\n\n## 2.马氏距离可视化\n\n![图例](/images/算法/马氏距离/图例.png)\n\n## 3.优缺点\n\n马氏距离和量纲(尺寸)无关，排除变量之间的相关性干扰。\n\n\n","source":"_posts/2016-11-30-机器学习算法-相似度-MahalanobisDistance(马氏距离).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-MahalanobisDistance(马氏距离)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: cnblog\n---\n\n## 0.概述\n\n马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特征之间的联系，即独立于测量尺度。\n<!-- more -->\n\n## 1.马氏距离公式\n\n设总体G为m维总体(考察m个指标),均值向量为μ，协方差矩阵为S,则样品X=(x1,x2,...xm)'与总体G的马氏距离定义为:\n\n![公式](/images/算法/马氏距离/公式.png)\n\n向量Xi与Xj之间的马氏距离定义为：\n\n![公式1](/images/算法/马氏距离/公式1.png)\n\n若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了：\n\n![公式2](/images/算法/马氏距离/公式2.png)\n\n若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。\n\n## 2.马氏距离可视化\n\n![图例](/images/算法/马氏距离/图例.png)\n\n## 3.优缺点\n\n马氏距离和量纲(尺寸)无关，排除变量之间的相关性干扰。\n\n\n","slug":"2016-11-30-机器学习算法-相似度-MahalanobisDistance(马氏距离)","published":1,"updated":"2018-11-29T12:51:25.019Z","comments":1,"photos":[],"link":"","_id":"cjskffoab003z4glmrlszcfx7","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特征之间的联系，即独立于测量尺度。<br><a id=\"more\"></a></p>\n<h2 id=\"1-马氏距离公式\"><a href=\"#1-马氏距离公式\" class=\"headerlink\" title=\"1.马氏距离公式\"></a>1.马氏距离公式</h2><p>设总体G为m维总体(考察m个指标),均值向量为μ，协方差矩阵为S,则样品X=(x1,x2,…xm)’与总体G的马氏距离定义为:</p>\n<p><img src=\"/images/算法/马氏距离/公式.png\" alt=\"公式\"></p>\n<p>向量Xi与Xj之间的马氏距离定义为：</p>\n<p><img src=\"/images/算法/马氏距离/公式1.png\" alt=\"公式1\"></p>\n<p>若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了：</p>\n<p><img src=\"/images/算法/马氏距离/公式2.png\" alt=\"公式2\"></p>\n<p>若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。</p>\n<h2 id=\"2-马氏距离可视化\"><a href=\"#2-马氏距离可视化\" class=\"headerlink\" title=\"2.马氏距离可视化\"></a>2.马氏距离可视化</h2><p><img src=\"/images/算法/马氏距离/图例.png\" alt=\"图例\"></p>\n<h2 id=\"3-优缺点\"><a href=\"#3-优缺点\" class=\"headerlink\" title=\"3.优缺点\"></a>3.优缺点</h2><p>马氏距离和量纲(尺寸)无关，排除变量之间的相关性干扰。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特征之间的联系，即独立于测量尺度。<br>","more":"</p>\n<h2 id=\"1-马氏距离公式\"><a href=\"#1-马氏距离公式\" class=\"headerlink\" title=\"1.马氏距离公式\"></a>1.马氏距离公式</h2><p>设总体G为m维总体(考察m个指标),均值向量为μ，协方差矩阵为S,则样品X=(x1,x2,…xm)’与总体G的马氏距离定义为:</p>\n<p><img src=\"/images/算法/马氏距离/公式.png\" alt=\"公式\"></p>\n<p>向量Xi与Xj之间的马氏距离定义为：</p>\n<p><img src=\"/images/算法/马氏距离/公式1.png\" alt=\"公式1\"></p>\n<p>若协方差矩阵是单位矩阵（各个样本向量之间独立同分布）,则公式就成了：</p>\n<p><img src=\"/images/算法/马氏距离/公式2.png\" alt=\"公式2\"></p>\n<p>若协方差矩阵是对角矩阵，公式变成了标准化欧氏距离。</p>\n<h2 id=\"2-马氏距离可视化\"><a href=\"#2-马氏距离可视化\" class=\"headerlink\" title=\"2.马氏距离可视化\"></a>2.马氏距离可视化</h2><p><img src=\"/images/算法/马氏距离/图例.png\" alt=\"图例\"></p>\n<h2 id=\"3-优缺点\"><a href=\"#3-优缺点\" class=\"headerlink\" title=\"3.优缺点\"></a>3.优缺点</h2><p>马氏距离和量纲(尺寸)无关，排除变量之间的相关性干扰。</p>"},{"layout":"lay_post","title":"机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)","date":"2016-11-29T16:00:00.000Z","author":"bornhe","_content":"\n## 0.概述\n\n皮尔斯曼相关度的计算舍弃了一些重要信息，即真实的评分值。但它保留了用户喜好值的本质特性——排序（ordering），它是建立在排序（或等级，Rank）的基础上计算的。\n<!-- more -->\n\n## 1.皮尔斯曼相关性描述\n\n皮尔斯曼相关性可以理解为是排列后（Rank）用户喜好值之间的Pearson相关度。《Mahout in Action》中有这样的解释：假设对于每个用户，我们找到他最不喜欢的物品，重写他的评分值为“1”；然后找到下一个最不喜欢的物品，重写评分值为“2”，以此类推。然后我们对这些转换后的值求Pearson相关系数，这就是Spearman相关系数。\n\n## 2.举例\n\nUser1～5对Item101～103的喜好（评分）值，通过斯皮尔曼相关系数计算出的相似度为：\n\n![例子](/images/算法/皮尔斯曼/例子.png)\n\n我们发现，计算出来的相似度值要么是1，要么是-1，因为这依赖于用户的喜好值和User1的喜好值是否趋于“一致变化”还是呈“相反趋势变化\"。\n\nMahout对斯皮尔曼相关系数给出了实现，具体可参考SpearmanCorrelationSimilarity，它的执行效率不是非常高，因为斯皮尔曼相关性的计算需要花时间计算并存储喜好值的一个排序（Ranks），具体时间取决于数据的数量级大小。正因为这样，斯皮尔曼相关系数一般用于学术研究或者是小规模的计算。\n\n代码：\n\n![代码](/images/算法/皮尔斯曼/代码.png)\n\n考虑到Spearman Correlation的效率，可以把SpearmanCorrelationSimilarity包装一层Cache，具体做法为：\n\nUserSimilarity similarity2 = new CachingUserSimilarity(new SpearmanCorrelationSimilarity(model), model);\n\n这样，每次计算的结果会直接放入Cache，下一次计算的时候可以立即得到结果，而不是重新再计算一次。","source":"_posts/2016-11-30-机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: bornhe\n---\n\n## 0.概述\n\n皮尔斯曼相关度的计算舍弃了一些重要信息，即真实的评分值。但它保留了用户喜好值的本质特性——排序（ordering），它是建立在排序（或等级，Rank）的基础上计算的。\n<!-- more -->\n\n## 1.皮尔斯曼相关性描述\n\n皮尔斯曼相关性可以理解为是排列后（Rank）用户喜好值之间的Pearson相关度。《Mahout in Action》中有这样的解释：假设对于每个用户，我们找到他最不喜欢的物品，重写他的评分值为“1”；然后找到下一个最不喜欢的物品，重写评分值为“2”，以此类推。然后我们对这些转换后的值求Pearson相关系数，这就是Spearman相关系数。\n\n## 2.举例\n\nUser1～5对Item101～103的喜好（评分）值，通过斯皮尔曼相关系数计算出的相似度为：\n\n![例子](/images/算法/皮尔斯曼/例子.png)\n\n我们发现，计算出来的相似度值要么是1，要么是-1，因为这依赖于用户的喜好值和User1的喜好值是否趋于“一致变化”还是呈“相反趋势变化\"。\n\nMahout对斯皮尔曼相关系数给出了实现，具体可参考SpearmanCorrelationSimilarity，它的执行效率不是非常高，因为斯皮尔曼相关性的计算需要花时间计算并存储喜好值的一个排序（Ranks），具体时间取决于数据的数量级大小。正因为这样，斯皮尔曼相关系数一般用于学术研究或者是小规模的计算。\n\n代码：\n\n![代码](/images/算法/皮尔斯曼/代码.png)\n\n考虑到Spearman Correlation的效率，可以把SpearmanCorrelationSimilarity包装一层Cache，具体做法为：\n\nUserSimilarity similarity2 = new CachingUserSimilarity(new SpearmanCorrelationSimilarity(model), model);\n\n这样，每次计算的结果会直接放入Cache，下一次计算的时候可以立即得到结果，而不是重新再计算一次。","slug":"2016-11-30-机器学习算法-相似度-SpearmanCorrelationSimilarity(皮尔斯曼相关系数相似度)","published":1,"updated":"2018-11-29T12:51:25.036Z","comments":1,"photos":[],"link":"","_id":"cjskffoab00414glm4v1u4afz","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>皮尔斯曼相关度的计算舍弃了一些重要信息，即真实的评分值。但它保留了用户喜好值的本质特性——排序（ordering），它是建立在排序（或等级，Rank）的基础上计算的。<br><a id=\"more\"></a></p>\n<h2 id=\"1-皮尔斯曼相关性描述\"><a href=\"#1-皮尔斯曼相关性描述\" class=\"headerlink\" title=\"1.皮尔斯曼相关性描述\"></a>1.皮尔斯曼相关性描述</h2><p>皮尔斯曼相关性可以理解为是排列后（Rank）用户喜好值之间的Pearson相关度。《Mahout in Action》中有这样的解释：假设对于每个用户，我们找到他最不喜欢的物品，重写他的评分值为“1”；然后找到下一个最不喜欢的物品，重写评分值为“2”，以此类推。然后我们对这些转换后的值求Pearson相关系数，这就是Spearman相关系数。</p>\n<h2 id=\"2-举例\"><a href=\"#2-举例\" class=\"headerlink\" title=\"2.举例\"></a>2.举例</h2><p>User1～5对Item101～103的喜好（评分）值，通过斯皮尔曼相关系数计算出的相似度为：</p>\n<p><img src=\"/images/算法/皮尔斯曼/例子.png\" alt=\"例子\"></p>\n<p>我们发现，计算出来的相似度值要么是1，要么是-1，因为这依赖于用户的喜好值和User1的喜好值是否趋于“一致变化”还是呈“相反趋势变化”。</p>\n<p>Mahout对斯皮尔曼相关系数给出了实现，具体可参考SpearmanCorrelationSimilarity，它的执行效率不是非常高，因为斯皮尔曼相关性的计算需要花时间计算并存储喜好值的一个排序（Ranks），具体时间取决于数据的数量级大小。正因为这样，斯皮尔曼相关系数一般用于学术研究或者是小规模的计算。</p>\n<p>代码：</p>\n<p><img src=\"/images/算法/皮尔斯曼/代码.png\" alt=\"代码\"></p>\n<p>考虑到Spearman Correlation的效率，可以把SpearmanCorrelationSimilarity包装一层Cache，具体做法为：</p>\n<p>UserSimilarity similarity2 = new CachingUserSimilarity(new SpearmanCorrelationSimilarity(model), model);</p>\n<p>这样，每次计算的结果会直接放入Cache，下一次计算的时候可以立即得到结果，而不是重新再计算一次。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>皮尔斯曼相关度的计算舍弃了一些重要信息，即真实的评分值。但它保留了用户喜好值的本质特性——排序（ordering），它是建立在排序（或等级，Rank）的基础上计算的。<br>","more":"</p>\n<h2 id=\"1-皮尔斯曼相关性描述\"><a href=\"#1-皮尔斯曼相关性描述\" class=\"headerlink\" title=\"1.皮尔斯曼相关性描述\"></a>1.皮尔斯曼相关性描述</h2><p>皮尔斯曼相关性可以理解为是排列后（Rank）用户喜好值之间的Pearson相关度。《Mahout in Action》中有这样的解释：假设对于每个用户，我们找到他最不喜欢的物品，重写他的评分值为“1”；然后找到下一个最不喜欢的物品，重写评分值为“2”，以此类推。然后我们对这些转换后的值求Pearson相关系数，这就是Spearman相关系数。</p>\n<h2 id=\"2-举例\"><a href=\"#2-举例\" class=\"headerlink\" title=\"2.举例\"></a>2.举例</h2><p>User1～5对Item101～103的喜好（评分）值，通过斯皮尔曼相关系数计算出的相似度为：</p>\n<p><img src=\"/images/算法/皮尔斯曼/例子.png\" alt=\"例子\"></p>\n<p>我们发现，计算出来的相似度值要么是1，要么是-1，因为这依赖于用户的喜好值和User1的喜好值是否趋于“一致变化”还是呈“相反趋势变化”。</p>\n<p>Mahout对斯皮尔曼相关系数给出了实现，具体可参考SpearmanCorrelationSimilarity，它的执行效率不是非常高，因为斯皮尔曼相关性的计算需要花时间计算并存储喜好值的一个排序（Ranks），具体时间取决于数据的数量级大小。正因为这样，斯皮尔曼相关系数一般用于学术研究或者是小规模的计算。</p>\n<p>代码：</p>\n<p><img src=\"/images/算法/皮尔斯曼/代码.png\" alt=\"代码\"></p>\n<p>考虑到Spearman Correlation的效率，可以把SpearmanCorrelationSimilarity包装一层Cache，具体做法为：</p>\n<p>UserSimilarity similarity2 = new CachingUserSimilarity(new SpearmanCorrelationSimilarity(model), model);</p>\n<p>这样，每次计算的结果会直接放入Cache，下一次计算的时候可以立即得到结果，而不是重新再计算一次。</p>"},{"layout":"lay_post","title":"Web架构基础-四部件","date":"2016-12-16T16:00:00.000Z","author":"cnblogs","_content":"\n## 0.概述\n\n架构基础知识是需要对Web的运行周期有一个完整的掌握，才能在此基础上做技术上的架构设计。\n<!-- more -->\n\n## 1.Web底层学习资料\n\nservlet/filter/listener/interceptor区别与联系\n\nhttp://www.cnblogs.com/doit8791/p/4209442.html\n\nSpring中ApplicationContext加载机制和配置初始化\n\nhttp://zhangzhenting.iteye.com/blog/1827777\n\nSpring MVC之MultiActionController\n\nhttp://blog.csdn.net/q3498233/article/details/6703101\n\nSpringMVC 4.2.2 - Web.xml,Dispatcher-Servlet及ApplicationContext配置笔记\n\nhttp://blog.csdn.net/chendev1/article/details/50294381\n\nApplicationContext\n\nhttp://blog.csdn.net/sinodragon21/article/details/25842667\n\nSpring 的监听事件 ApplicationListener 和 ApplicationEvent 用法\n\nhttp://blog.csdn.net/ilovejava_2010/article/details/7953419","source":"_posts/2016-12-17-Web架构基础-四部件.md","raw":"---\nlayout: lay_post\ntitle: \"Web架构基础-四部件\"\ndate: 2016-12-17\ncategories: 架构\ntags: Servlet3.0\nauthor: cnblogs\n---\n\n## 0.概述\n\n架构基础知识是需要对Web的运行周期有一个完整的掌握，才能在此基础上做技术上的架构设计。\n<!-- more -->\n\n## 1.Web底层学习资料\n\nservlet/filter/listener/interceptor区别与联系\n\nhttp://www.cnblogs.com/doit8791/p/4209442.html\n\nSpring中ApplicationContext加载机制和配置初始化\n\nhttp://zhangzhenting.iteye.com/blog/1827777\n\nSpring MVC之MultiActionController\n\nhttp://blog.csdn.net/q3498233/article/details/6703101\n\nSpringMVC 4.2.2 - Web.xml,Dispatcher-Servlet及ApplicationContext配置笔记\n\nhttp://blog.csdn.net/chendev1/article/details/50294381\n\nApplicationContext\n\nhttp://blog.csdn.net/sinodragon21/article/details/25842667\n\nSpring 的监听事件 ApplicationListener 和 ApplicationEvent 用法\n\nhttp://blog.csdn.net/ilovejava_2010/article/details/7953419","slug":"2016-12-17-Web架构基础-四部件","published":1,"updated":"2018-11-29T12:51:25.048Z","comments":1,"photos":[],"link":"","_id":"cjskffoab00464glmnvxmdcz4","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>架构基础知识是需要对Web的运行周期有一个完整的掌握，才能在此基础上做技术上的架构设计。<br><a id=\"more\"></a></p>\n<h2 id=\"1-Web底层学习资料\"><a href=\"#1-Web底层学习资料\" class=\"headerlink\" title=\"1.Web底层学习资料\"></a>1.Web底层学习资料</h2><p>servlet/filter/listener/interceptor区别与联系</p>\n<p><a href=\"http://www.cnblogs.com/doit8791/p/4209442.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/doit8791/p/4209442.html</a></p>\n<p>Spring中ApplicationContext加载机制和配置初始化</p>\n<p><a href=\"http://zhangzhenting.iteye.com/blog/1827777\" target=\"_blank\" rel=\"noopener\">http://zhangzhenting.iteye.com/blog/1827777</a></p>\n<p>Spring MVC之MultiActionController</p>\n<p><a href=\"http://blog.csdn.net/q3498233/article/details/6703101\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/q3498233/article/details/6703101</a></p>\n<p>SpringMVC 4.2.2 - Web.xml,Dispatcher-Servlet及ApplicationContext配置笔记</p>\n<p><a href=\"http://blog.csdn.net/chendev1/article/details/50294381\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chendev1/article/details/50294381</a></p>\n<p>ApplicationContext</p>\n<p><a href=\"http://blog.csdn.net/sinodragon21/article/details/25842667\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/sinodragon21/article/details/25842667</a></p>\n<p>Spring 的监听事件 ApplicationListener 和 ApplicationEvent 用法</p>\n<p><a href=\"http://blog.csdn.net/ilovejava_2010/article/details/7953419\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/ilovejava_2010/article/details/7953419</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>架构基础知识是需要对Web的运行周期有一个完整的掌握，才能在此基础上做技术上的架构设计。<br>","more":"</p>\n<h2 id=\"1-Web底层学习资料\"><a href=\"#1-Web底层学习资料\" class=\"headerlink\" title=\"1.Web底层学习资料\"></a>1.Web底层学习资料</h2><p>servlet/filter/listener/interceptor区别与联系</p>\n<p><a href=\"http://www.cnblogs.com/doit8791/p/4209442.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/doit8791/p/4209442.html</a></p>\n<p>Spring中ApplicationContext加载机制和配置初始化</p>\n<p><a href=\"http://zhangzhenting.iteye.com/blog/1827777\" target=\"_blank\" rel=\"noopener\">http://zhangzhenting.iteye.com/blog/1827777</a></p>\n<p>Spring MVC之MultiActionController</p>\n<p><a href=\"http://blog.csdn.net/q3498233/article/details/6703101\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/q3498233/article/details/6703101</a></p>\n<p>SpringMVC 4.2.2 - Web.xml,Dispatcher-Servlet及ApplicationContext配置笔记</p>\n<p><a href=\"http://blog.csdn.net/chendev1/article/details/50294381\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/chendev1/article/details/50294381</a></p>\n<p>ApplicationContext</p>\n<p><a href=\"http://blog.csdn.net/sinodragon21/article/details/25842667\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/sinodragon21/article/details/25842667</a></p>\n<p>Spring 的监听事件 ApplicationListener 和 ApplicationEvent 用法</p>\n<p><a href=\"http://blog.csdn.net/ilovejava_2010/article/details/7953419\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/ilovejava_2010/article/details/7953419</a></p>"},{"layout":"lay_post","title":"Duke-快速的相似数据过滤引擎","date":"2016-12-19T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nDuke是一个基于JAVA的快速灵活的重复数据过滤引擎。\n<!-- more -->\n\n## 1.实例\n\n假设我们正在处理一个客户资料数据库，并试图识别重复的客户记录。数据记录中有这样的三行数据：\n\n| ID | NAME               | ADDRESS         | ZIP   | EMAIL             |\n|:--:|:------------------:|:---------------:|:-----:|:-----------------:|\n| 1  | J. Random Hacker   | Main St 101     | 21231 |                   |\t\n| 2  | John Random Hacker | Mian Street 101 | 21231 | hack@gmail.com    |\n| 3  | Jacob Hacker       | Main Street 201 | 38122 | jacob@hotmail.com | \n\n首先，Duke先从数据库中读取每条数据，并将数据记录转换为Duke记录对象。该过程中数据将被清洗。清洗后，数据如下：\n\n| ID | NAME               | ADDRESS         | ZIP   | EMAIL             |\n|:--:|:------------------:|:---------------:|:-----:|:-----------------:|\n| 1  | j. random hacker   | main street 101 | 21231 |                   |\t\n| 2  | john random hacker | mian street 101 | 21231 | hack@gmail.com    |\n| 3  | jacob hacker       | main street 201 | 38122 | jacob@hotmail.com | \n\n然后，Duke将对记录做详细的比较，看看他们代表同一客户的可能性是多少？。我们使用以下配置：\n\n```xml\n  <schema>\n    <threshold>0.732</threshold>\n\n    <property type=\"id\">\n      <name>ID</name>\n    </property>\n    <property>\n      <name>NAME</name> \n      <comparator>no.priv.garshol.duke.comparators.QGramComparator</comparator>\n      <low>0.35</low>\n      <high>0.88</high>\n    </property>    \n    <property>\n      <name>ADDRESS1</name> \n      <comparator>address-comp</comparator>\n      <low>0.25</low>\n      <high>0.65</high>\n    </property>    \n    <property>\n      <name>EMAIL</name> \n      <comparator>no.priv.garshol.duke.comparators.ExactComparator</comparator>\n      <low>0.4</low>\n      <high>0.8</high>\n    </property>    \n    <property>\n      <name>ZIP</name> \n      <comparator>no.priv.garshol.duke.comparators.ExactComparator</comparator>\n      <low>0.45</low>\n      <high>0.6</high>\n    </property>    \n  </schema>  \n```\n\n注意这个address-comp比较器，这是一个对象引用，通常，你可以用以下方式创建对象引用。然后在需要使用的地方引用就可以了。\n\n```xml\n  <object class=\"no.priv.garshol.duke.comparators.WeightedLevenshtein$DefaultWeightEstimator\"\n          name=\"estimator\">\n    <param name=\"digit-weight\" value=\"10.0\"/>\n  </object>\n  <object class=\"no.priv.garshol.duke.comparators.WeightedLevenshtein\"\n          name=\"address-comp\">\n    <param name=\"estimator\" value=\"estimator\"/>\n  </object>\n```\n在上面的schema代码中，threshold(阀值)参数表示只有当概率为0.732(73.2%)或者更高时候，才能代表两个记录为同一事物。否则就认为这是两个不同的实物。含有忽略参数的属性将被忽略。\n\n记录1和记录2的比较结果如下：\n\n```ruby\n---ADDRESS1\n'main street 101' ~ 'mian street 101': 0.867 (prob 0.6127)\nResult: 0.5 -> 0.6127\n\n---NAME\n'j. random hacker' ~ 'john random hacker': 0.8 (prob 0.78542)\nResult: 0.6127 -> 0.8527\n\n---ZIP\n'21231' ~ '21231': 1.0 (prob 0.6)\nResult: 0.8527 -> 0.8967\n\nOverall: 0.8967\n```\n如果我们比较记录1和3，结果是不同的：\n\n```ruby\n---ADDRESS1\n'main street 101' ~ 'main street 201': 0.73 (prob 0.58)\nResult: 0.5 -> 0.58\n\n---NAME\n'j. random hacker' ~ 'jacob hacker': 0.6 (prob 0.64)\nResult: 0.58 -> 0.71\n\n---ZIP\n'21231' ~ '38122': 0.0 (prob 0.45)\nResult: 0.71 -> 0.67\n\nOverall: 0.67\n```\n我希望这有助于说明Duke如何权衡来自不同领域的证据，并利用它来达成裁决。\n\n参考地址:https://github.com/larsga/Duke/wiki","source":"_posts/2016-12-20-Duke-快速的相似数据过滤引擎.md","raw":"---\nlayout: lay_post\ntitle: \"Duke-快速的相似数据过滤引擎\"\ndate: 2016-12-20\ncategories: Duke\ntags: 其他\nauthor: lvyafei\n---\n\n## 0.概述\n\nDuke是一个基于JAVA的快速灵活的重复数据过滤引擎。\n<!-- more -->\n\n## 1.实例\n\n假设我们正在处理一个客户资料数据库，并试图识别重复的客户记录。数据记录中有这样的三行数据：\n\n| ID | NAME               | ADDRESS         | ZIP   | EMAIL             |\n|:--:|:------------------:|:---------------:|:-----:|:-----------------:|\n| 1  | J. Random Hacker   | Main St 101     | 21231 |                   |\t\n| 2  | John Random Hacker | Mian Street 101 | 21231 | hack@gmail.com    |\n| 3  | Jacob Hacker       | Main Street 201 | 38122 | jacob@hotmail.com | \n\n首先，Duke先从数据库中读取每条数据，并将数据记录转换为Duke记录对象。该过程中数据将被清洗。清洗后，数据如下：\n\n| ID | NAME               | ADDRESS         | ZIP   | EMAIL             |\n|:--:|:------------------:|:---------------:|:-----:|:-----------------:|\n| 1  | j. random hacker   | main street 101 | 21231 |                   |\t\n| 2  | john random hacker | mian street 101 | 21231 | hack@gmail.com    |\n| 3  | jacob hacker       | main street 201 | 38122 | jacob@hotmail.com | \n\n然后，Duke将对记录做详细的比较，看看他们代表同一客户的可能性是多少？。我们使用以下配置：\n\n```xml\n  <schema>\n    <threshold>0.732</threshold>\n\n    <property type=\"id\">\n      <name>ID</name>\n    </property>\n    <property>\n      <name>NAME</name> \n      <comparator>no.priv.garshol.duke.comparators.QGramComparator</comparator>\n      <low>0.35</low>\n      <high>0.88</high>\n    </property>    \n    <property>\n      <name>ADDRESS1</name> \n      <comparator>address-comp</comparator>\n      <low>0.25</low>\n      <high>0.65</high>\n    </property>    \n    <property>\n      <name>EMAIL</name> \n      <comparator>no.priv.garshol.duke.comparators.ExactComparator</comparator>\n      <low>0.4</low>\n      <high>0.8</high>\n    </property>    \n    <property>\n      <name>ZIP</name> \n      <comparator>no.priv.garshol.duke.comparators.ExactComparator</comparator>\n      <low>0.45</low>\n      <high>0.6</high>\n    </property>    \n  </schema>  \n```\n\n注意这个address-comp比较器，这是一个对象引用，通常，你可以用以下方式创建对象引用。然后在需要使用的地方引用就可以了。\n\n```xml\n  <object class=\"no.priv.garshol.duke.comparators.WeightedLevenshtein$DefaultWeightEstimator\"\n          name=\"estimator\">\n    <param name=\"digit-weight\" value=\"10.0\"/>\n  </object>\n  <object class=\"no.priv.garshol.duke.comparators.WeightedLevenshtein\"\n          name=\"address-comp\">\n    <param name=\"estimator\" value=\"estimator\"/>\n  </object>\n```\n在上面的schema代码中，threshold(阀值)参数表示只有当概率为0.732(73.2%)或者更高时候，才能代表两个记录为同一事物。否则就认为这是两个不同的实物。含有忽略参数的属性将被忽略。\n\n记录1和记录2的比较结果如下：\n\n```ruby\n---ADDRESS1\n'main street 101' ~ 'mian street 101': 0.867 (prob 0.6127)\nResult: 0.5 -> 0.6127\n\n---NAME\n'j. random hacker' ~ 'john random hacker': 0.8 (prob 0.78542)\nResult: 0.6127 -> 0.8527\n\n---ZIP\n'21231' ~ '21231': 1.0 (prob 0.6)\nResult: 0.8527 -> 0.8967\n\nOverall: 0.8967\n```\n如果我们比较记录1和3，结果是不同的：\n\n```ruby\n---ADDRESS1\n'main street 101' ~ 'main street 201': 0.73 (prob 0.58)\nResult: 0.5 -> 0.58\n\n---NAME\n'j. random hacker' ~ 'jacob hacker': 0.6 (prob 0.64)\nResult: 0.58 -> 0.71\n\n---ZIP\n'21231' ~ '38122': 0.0 (prob 0.45)\nResult: 0.71 -> 0.67\n\nOverall: 0.67\n```\n我希望这有助于说明Duke如何权衡来自不同领域的证据，并利用它来达成裁决。\n\n参考地址:https://github.com/larsga/Duke/wiki","slug":"2016-12-20-Duke-快速的相似数据过滤引擎","published":1,"updated":"2018-11-29T12:51:25.062Z","comments":1,"photos":[],"link":"","_id":"cjskffoaq00484glmw41oopfp","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Duke是一个基于JAVA的快速灵活的重复数据过滤引擎。<br><a id=\"more\"></a></p>\n<h2 id=\"1-实例\"><a href=\"#1-实例\" class=\"headerlink\" title=\"1.实例\"></a>1.实例</h2><p>假设我们正在处理一个客户资料数据库，并试图识别重复的客户记录。数据记录中有这样的三行数据：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ID</th>\n<th style=\"text-align:center\">NAME</th>\n<th style=\"text-align:center\">ADDRESS</th>\n<th style=\"text-align:center\">ZIP</th>\n<th style=\"text-align:center\">EMAIL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">J. Random Hacker</td>\n<td style=\"text-align:center\">Main St 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">John Random Hacker</td>\n<td style=\"text-align:center\">Mian Street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"><a href=\"mailto:hack@gmail.com\" target=\"_blank\" rel=\"noopener\">hack@gmail.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">Jacob Hacker</td>\n<td style=\"text-align:center\">Main Street 201</td>\n<td style=\"text-align:center\">38122</td>\n<td style=\"text-align:center\"><a href=\"mailto:jacob@hotmail.com\" target=\"_blank\" rel=\"noopener\">jacob@hotmail.com</a></td>\n</tr>\n</tbody>\n</table>\n<p>首先，Duke先从数据库中读取每条数据，并将数据记录转换为Duke记录对象。该过程中数据将被清洗。清洗后，数据如下：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ID</th>\n<th style=\"text-align:center\">NAME</th>\n<th style=\"text-align:center\">ADDRESS</th>\n<th style=\"text-align:center\">ZIP</th>\n<th style=\"text-align:center\">EMAIL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">j. random hacker</td>\n<td style=\"text-align:center\">main street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">john random hacker</td>\n<td style=\"text-align:center\">mian street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"><a href=\"mailto:hack@gmail.com\" target=\"_blank\" rel=\"noopener\">hack@gmail.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">jacob hacker</td>\n<td style=\"text-align:center\">main street 201</td>\n<td style=\"text-align:center\">38122</td>\n<td style=\"text-align:center\"><a href=\"mailto:jacob@hotmail.com\" target=\"_blank\" rel=\"noopener\">jacob@hotmail.com</a></td>\n</tr>\n</tbody>\n</table>\n<p>然后，Duke将对记录做详细的比较，看看他们代表同一客户的可能性是多少？。我们使用以下配置：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">threshold</span>&gt;</span>0.732<span class=\"tag\">&lt;/<span class=\"name\">threshold</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">type</span>=<span class=\"string\">\"id\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ID<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>NAME<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.QGramComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.35<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.88<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ADDRESS1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>address-comp<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.25<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.65<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>EMAIL<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.ExactComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.4<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.8<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ZIP<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.ExactComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.45<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.6<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>注意这个address-comp比较器，这是一个对象引用，通常，你可以用以下方式创建对象引用。然后在需要使用的地方引用就可以了。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">object</span> <span class=\"attr\">class</span>=<span class=\"string\">\"no.priv.garshol.duke.comparators.WeightedLevenshtein$DefaultWeightEstimator\"</span></span></span><br><span class=\"line\"><span class=\"tag\">        <span class=\"attr\">name</span>=<span class=\"string\">\"estimator\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">name</span>=<span class=\"string\">\"digit-weight\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"10.0\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">object</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">object</span> <span class=\"attr\">class</span>=<span class=\"string\">\"no.priv.garshol.duke.comparators.WeightedLevenshtein\"</span></span></span><br><span class=\"line\"><span class=\"tag\">        <span class=\"attr\">name</span>=<span class=\"string\">\"address-comp\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">name</span>=<span class=\"string\">\"estimator\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"estimator\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">object</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>在上面的schema代码中，threshold(阀值)参数表示只有当概率为0.732(73.2%)或者更高时候，才能代表两个记录为同一事物。否则就认为这是两个不同的实物。含有忽略参数的属性将被忽略。</p>\n<p>记录1和记录2的比较结果如下：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---ADDRESS1</span><br><span class=\"line\"><span class=\"string\">'main street 101'</span> ~ <span class=\"string\">'mian street 101'</span>: <span class=\"number\">0</span>.<span class=\"number\">867</span> (prob <span class=\"number\">0</span>.<span class=\"number\">6127</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">5</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">6127</span></span><br><span class=\"line\"></span><br><span class=\"line\">---NAME</span><br><span class=\"line\"><span class=\"string\">'j. random hacker'</span> ~ <span class=\"string\">'john random hacker'</span>: <span class=\"number\">0</span>.<span class=\"number\">8</span> (prob <span class=\"number\">0</span>.<span class=\"number\">78542</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">6127</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">8527</span></span><br><span class=\"line\"></span><br><span class=\"line\">---ZIP</span><br><span class=\"line\"><span class=\"string\">'21231'</span> ~ <span class=\"string\">'21231'</span>: <span class=\"number\">1.0</span> (prob <span class=\"number\">0</span>.<span class=\"number\">6</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">8527</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">8967</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"symbol\">Overall:</span> <span class=\"number\">0</span>.<span class=\"number\">8967</span></span><br></pre></td></tr></table></figure>\n<p>如果我们比较记录1和3，结果是不同的：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---ADDRESS1</span><br><span class=\"line\"><span class=\"string\">'main street 101'</span> ~ <span class=\"string\">'main street 201'</span>: <span class=\"number\">0</span>.<span class=\"number\">73</span> (prob <span class=\"number\">0</span>.<span class=\"number\">58</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">5</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">58</span></span><br><span class=\"line\"></span><br><span class=\"line\">---NAME</span><br><span class=\"line\"><span class=\"string\">'j. random hacker'</span> ~ <span class=\"string\">'jacob hacker'</span>: <span class=\"number\">0</span>.<span class=\"number\">6</span> (prob <span class=\"number\">0</span>.<span class=\"number\">64</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">58</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">71</span></span><br><span class=\"line\"></span><br><span class=\"line\">---ZIP</span><br><span class=\"line\"><span class=\"string\">'21231'</span> ~ <span class=\"string\">'38122'</span>: <span class=\"number\">0</span>.<span class=\"number\">0</span> (prob <span class=\"number\">0</span>.<span class=\"number\">45</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">71</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">67</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"symbol\">Overall:</span> <span class=\"number\">0</span>.<span class=\"number\">67</span></span><br></pre></td></tr></table></figure>\n<p>我希望这有助于说明Duke如何权衡来自不同领域的证据，并利用它来达成裁决。</p>\n<p>参考地址:<a href=\"https://github.com/larsga/Duke/wiki\" target=\"_blank\" rel=\"noopener\">https://github.com/larsga/Duke/wiki</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Duke是一个基于JAVA的快速灵活的重复数据过滤引擎。<br>","more":"</p>\n<h2 id=\"1-实例\"><a href=\"#1-实例\" class=\"headerlink\" title=\"1.实例\"></a>1.实例</h2><p>假设我们正在处理一个客户资料数据库，并试图识别重复的客户记录。数据记录中有这样的三行数据：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ID</th>\n<th style=\"text-align:center\">NAME</th>\n<th style=\"text-align:center\">ADDRESS</th>\n<th style=\"text-align:center\">ZIP</th>\n<th style=\"text-align:center\">EMAIL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">J. Random Hacker</td>\n<td style=\"text-align:center\">Main St 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">John Random Hacker</td>\n<td style=\"text-align:center\">Mian Street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"><a href=\"mailto:hack@gmail.com\" target=\"_blank\" rel=\"noopener\">hack@gmail.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">Jacob Hacker</td>\n<td style=\"text-align:center\">Main Street 201</td>\n<td style=\"text-align:center\">38122</td>\n<td style=\"text-align:center\"><a href=\"mailto:jacob@hotmail.com\" target=\"_blank\" rel=\"noopener\">jacob@hotmail.com</a></td>\n</tr>\n</tbody>\n</table>\n<p>首先，Duke先从数据库中读取每条数据，并将数据记录转换为Duke记录对象。该过程中数据将被清洗。清洗后，数据如下：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">ID</th>\n<th style=\"text-align:center\">NAME</th>\n<th style=\"text-align:center\">ADDRESS</th>\n<th style=\"text-align:center\">ZIP</th>\n<th style=\"text-align:center\">EMAIL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">j. random hacker</td>\n<td style=\"text-align:center\">main street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">john random hacker</td>\n<td style=\"text-align:center\">mian street 101</td>\n<td style=\"text-align:center\">21231</td>\n<td style=\"text-align:center\"><a href=\"mailto:hack@gmail.com\" target=\"_blank\" rel=\"noopener\">hack@gmail.com</a></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">jacob hacker</td>\n<td style=\"text-align:center\">main street 201</td>\n<td style=\"text-align:center\">38122</td>\n<td style=\"text-align:center\"><a href=\"mailto:jacob@hotmail.com\" target=\"_blank\" rel=\"noopener\">jacob@hotmail.com</a></td>\n</tr>\n</tbody>\n</table>\n<p>然后，Duke将对记录做详细的比较，看看他们代表同一客户的可能性是多少？。我们使用以下配置：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">threshold</span>&gt;</span>0.732<span class=\"tag\">&lt;/<span class=\"name\">threshold</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">type</span>=<span class=\"string\">\"id\"</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ID<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>NAME<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.QGramComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.35<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.88<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ADDRESS1<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>address-comp<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.25<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.65<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>EMAIL<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.ExactComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.4<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.8<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>ZIP<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">comparator</span>&gt;</span>no.priv.garshol.duke.comparators.ExactComparator<span class=\"tag\">&lt;/<span class=\"name\">comparator</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">low</span>&gt;</span>0.45<span class=\"tag\">&lt;/<span class=\"name\">low</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">high</span>&gt;</span>0.6<span class=\"tag\">&lt;/<span class=\"name\">high</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span>    </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>注意这个address-comp比较器，这是一个对象引用，通常，你可以用以下方式创建对象引用。然后在需要使用的地方引用就可以了。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">object</span> <span class=\"attr\">class</span>=<span class=\"string\">\"no.priv.garshol.duke.comparators.WeightedLevenshtein$DefaultWeightEstimator\"</span></span></span><br><span class=\"line\"><span class=\"tag\">        <span class=\"attr\">name</span>=<span class=\"string\">\"estimator\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">name</span>=<span class=\"string\">\"digit-weight\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"10.0\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">object</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">object</span> <span class=\"attr\">class</span>=<span class=\"string\">\"no.priv.garshol.duke.comparators.WeightedLevenshtein\"</span></span></span><br><span class=\"line\"><span class=\"tag\">        <span class=\"attr\">name</span>=<span class=\"string\">\"address-comp\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">param</span> <span class=\"attr\">name</span>=<span class=\"string\">\"estimator\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"estimator\"</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">object</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>在上面的schema代码中，threshold(阀值)参数表示只有当概率为0.732(73.2%)或者更高时候，才能代表两个记录为同一事物。否则就认为这是两个不同的实物。含有忽略参数的属性将被忽略。</p>\n<p>记录1和记录2的比较结果如下：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---ADDRESS1</span><br><span class=\"line\"><span class=\"string\">'main street 101'</span> ~ <span class=\"string\">'mian street 101'</span>: <span class=\"number\">0</span>.<span class=\"number\">867</span> (prob <span class=\"number\">0</span>.<span class=\"number\">6127</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">5</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">6127</span></span><br><span class=\"line\"></span><br><span class=\"line\">---NAME</span><br><span class=\"line\"><span class=\"string\">'j. random hacker'</span> ~ <span class=\"string\">'john random hacker'</span>: <span class=\"number\">0</span>.<span class=\"number\">8</span> (prob <span class=\"number\">0</span>.<span class=\"number\">78542</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">6127</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">8527</span></span><br><span class=\"line\"></span><br><span class=\"line\">---ZIP</span><br><span class=\"line\"><span class=\"string\">'21231'</span> ~ <span class=\"string\">'21231'</span>: <span class=\"number\">1.0</span> (prob <span class=\"number\">0</span>.<span class=\"number\">6</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">8527</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">8967</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"symbol\">Overall:</span> <span class=\"number\">0</span>.<span class=\"number\">8967</span></span><br></pre></td></tr></table></figure>\n<p>如果我们比较记录1和3，结果是不同的：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">---ADDRESS1</span><br><span class=\"line\"><span class=\"string\">'main street 101'</span> ~ <span class=\"string\">'main street 201'</span>: <span class=\"number\">0</span>.<span class=\"number\">73</span> (prob <span class=\"number\">0</span>.<span class=\"number\">58</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">5</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">58</span></span><br><span class=\"line\"></span><br><span class=\"line\">---NAME</span><br><span class=\"line\"><span class=\"string\">'j. random hacker'</span> ~ <span class=\"string\">'jacob hacker'</span>: <span class=\"number\">0</span>.<span class=\"number\">6</span> (prob <span class=\"number\">0</span>.<span class=\"number\">64</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">58</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">71</span></span><br><span class=\"line\"></span><br><span class=\"line\">---ZIP</span><br><span class=\"line\"><span class=\"string\">'21231'</span> ~ <span class=\"string\">'38122'</span>: <span class=\"number\">0</span>.<span class=\"number\">0</span> (prob <span class=\"number\">0</span>.<span class=\"number\">45</span>)</span><br><span class=\"line\"><span class=\"symbol\">Result:</span> <span class=\"number\">0</span>.<span class=\"number\">71</span> -&gt; <span class=\"number\">0</span>.<span class=\"number\">67</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"symbol\">Overall:</span> <span class=\"number\">0</span>.<span class=\"number\">67</span></span><br></pre></td></tr></table></figure>\n<p>我希望这有助于说明Duke如何权衡来自不同领域的证据，并利用它来达成裁决。</p>\n<p>参考地址:<a href=\"https://github.com/larsga/Duke/wiki\" target=\"_blank\" rel=\"noopener\">https://github.com/larsga/Duke/wiki</a></p>"},{"layout":"lay_post","title":"推荐系统比较-阿里RecEng、Amazon和开源EasyRrec","date":"2016-12-22T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n研究了下阿里的RecEng、Amazon和开源EasyRec推荐系统，孰优孰劣,针对一个通用的推荐系统设计的方法是什么。\n<!-- more -->\n\n## 1.阿里推荐RecEng架构\n\n![例子](/images/推荐/receng.png)\n\n离线计算的数据类型分为:接入数据、中间数据和输出数据三类。接入数据指客户离线提供的用户、物品、日志等数据，中间数据是在离线算法流程中产生的各种中间性质的结果数据表，输出数据是指推荐结果数据表，该结果最终将会被导入到在线存储中，供在线计算模块使用。\n\n近线计算主要处理用户行为发生变化、推荐物品发生更新时，对离线推荐结果进行更新。近线程序的输入数据可以来自多个数据源，如在线的表格存储（原OTS），以及用户的API请求，又或者是程序中的变量；输出可以是程序变量，或者写回在线存储，或者返回给用户。\n\n在线计算负责的任务是推荐API接收到API请求时，实时对离线和近线修正产生的推荐结果进行过滤、排重、补足等处理。\n\n## 2.阿里推荐RecEng引擎流程\n\n![例子](/images/推荐/引擎流程.png)\n\n## 3.阿里推荐RecEng优缺点\n\n缺点：每个配置流程都很慢，依赖平台型太强。系统支持的推荐算法没有清晰的内部实现过程说明。\n\n优点：配置度比较灵活，可以自定义模板和算法(但是成本太高，扩展性不太清楚,自定义算法手册没有找到)。和Amazon的架构有很多的相似处。架构理念正确。\n\n## 4.Amazon推荐系统架构\n\n![例子](/images/推荐/amazon.png)\n\n系统被分为3部分， online，nearLine和离线部分(offLine)。Online和nearLine部分一起认为是实时部分。\n\n离线部分就是传统的个性化推荐系统的主体，定期将大量存储的数据拿出来进行批处理运算，然后对模型进行建立与更新，这里就不详细介绍了。\n\nnearLine部分，是将用户产生的事件，利用流式计算得到一些中间结果，这些中间结果一方面发送给online部分用于实时更新推荐模型，另一方面将中间结果存储起来，例如存储在MemCached、Cassandra、MySQL等可以快速查询的存储中作为备份。在NetFlix的系统中，他们的流式计算是通过一个叫做NetFlix.Manhattan来实现的，它是一个类似于Storm的实时流式计算框架，只是针对他们自己的应用有一定的特异性，不是通用的实时计算框架。\n\n然后是online部分。这一部分利用离线部分的主体模型并考虑nearLine部分的实时数据对模型进行增量更新，然后可以得到一个实时的推荐模型，进而根据用户的行为来对用户进行实时推荐。\n\n## 5.阿里RecEng和开源EasyRec的对比\n\n开源EasyRec是一个比较完整的推荐系统，内置已经实现的管理规则算法，插件话的开发模式，支持自定义插件和算法。但是属于半成品，itemitem,cf,svg等经典的推荐算法都没有完整实现，目前版本更新停止，整个系统是针对离线推荐做的，对在线推荐场景支持不到位，整个架构没有考虑到在线推荐的场景。但模块比较完整，报表，API等比较齐全。对企业自主研发推荐系统有很多借鉴的地方。架构方面可以和Amazon的做一个结合，在通用性方面已经比较完整。\n\n个性化推荐系统架构的关键问题，就是如何以无缝方式实现在线和离线计算过程，说到底，也是算法的设计，如何将算法的计算步骤合理分配到各个部分，使得得到的模型既可以非常准确，又可以快速计算出来以满足实时性的要求。","source":"_posts/2016-12-23-推荐系统比较-阿里RecEng、Amazon和开源EasyRrec.md","raw":"---\nlayout: lay_post\ntitle: \"推荐系统比较-阿里RecEng、Amazon和开源EasyRrec\"\ndate: 2016-12-23\ncategories: 系统架构\ntags: 推荐系统\nauthor: lvyafei\n---\n\n## 0.概述\n\n研究了下阿里的RecEng、Amazon和开源EasyRec推荐系统，孰优孰劣,针对一个通用的推荐系统设计的方法是什么。\n<!-- more -->\n\n## 1.阿里推荐RecEng架构\n\n![例子](/images/推荐/receng.png)\n\n离线计算的数据类型分为:接入数据、中间数据和输出数据三类。接入数据指客户离线提供的用户、物品、日志等数据，中间数据是在离线算法流程中产生的各种中间性质的结果数据表，输出数据是指推荐结果数据表，该结果最终将会被导入到在线存储中，供在线计算模块使用。\n\n近线计算主要处理用户行为发生变化、推荐物品发生更新时，对离线推荐结果进行更新。近线程序的输入数据可以来自多个数据源，如在线的表格存储（原OTS），以及用户的API请求，又或者是程序中的变量；输出可以是程序变量，或者写回在线存储，或者返回给用户。\n\n在线计算负责的任务是推荐API接收到API请求时，实时对离线和近线修正产生的推荐结果进行过滤、排重、补足等处理。\n\n## 2.阿里推荐RecEng引擎流程\n\n![例子](/images/推荐/引擎流程.png)\n\n## 3.阿里推荐RecEng优缺点\n\n缺点：每个配置流程都很慢，依赖平台型太强。系统支持的推荐算法没有清晰的内部实现过程说明。\n\n优点：配置度比较灵活，可以自定义模板和算法(但是成本太高，扩展性不太清楚,自定义算法手册没有找到)。和Amazon的架构有很多的相似处。架构理念正确。\n\n## 4.Amazon推荐系统架构\n\n![例子](/images/推荐/amazon.png)\n\n系统被分为3部分， online，nearLine和离线部分(offLine)。Online和nearLine部分一起认为是实时部分。\n\n离线部分就是传统的个性化推荐系统的主体，定期将大量存储的数据拿出来进行批处理运算，然后对模型进行建立与更新，这里就不详细介绍了。\n\nnearLine部分，是将用户产生的事件，利用流式计算得到一些中间结果，这些中间结果一方面发送给online部分用于实时更新推荐模型，另一方面将中间结果存储起来，例如存储在MemCached、Cassandra、MySQL等可以快速查询的存储中作为备份。在NetFlix的系统中，他们的流式计算是通过一个叫做NetFlix.Manhattan来实现的，它是一个类似于Storm的实时流式计算框架，只是针对他们自己的应用有一定的特异性，不是通用的实时计算框架。\n\n然后是online部分。这一部分利用离线部分的主体模型并考虑nearLine部分的实时数据对模型进行增量更新，然后可以得到一个实时的推荐模型，进而根据用户的行为来对用户进行实时推荐。\n\n## 5.阿里RecEng和开源EasyRec的对比\n\n开源EasyRec是一个比较完整的推荐系统，内置已经实现的管理规则算法，插件话的开发模式，支持自定义插件和算法。但是属于半成品，itemitem,cf,svg等经典的推荐算法都没有完整实现，目前版本更新停止，整个系统是针对离线推荐做的，对在线推荐场景支持不到位，整个架构没有考虑到在线推荐的场景。但模块比较完整，报表，API等比较齐全。对企业自主研发推荐系统有很多借鉴的地方。架构方面可以和Amazon的做一个结合，在通用性方面已经比较完整。\n\n个性化推荐系统架构的关键问题，就是如何以无缝方式实现在线和离线计算过程，说到底，也是算法的设计，如何将算法的计算步骤合理分配到各个部分，使得得到的模型既可以非常准确，又可以快速计算出来以满足实时性的要求。","slug":"2016-12-23-推荐系统比较-阿里RecEng、Amazon和开源EasyRrec","published":1,"updated":"2018-11-29T12:51:25.143Z","comments":1,"photos":[],"link":"","_id":"cjskffoaq004d4glm7nev95rh","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>研究了下阿里的RecEng、Amazon和开源EasyRec推荐系统，孰优孰劣,针对一个通用的推荐系统设计的方法是什么。<br><a id=\"more\"></a></p>\n<h2 id=\"1-阿里推荐RecEng架构\"><a href=\"#1-阿里推荐RecEng架构\" class=\"headerlink\" title=\"1.阿里推荐RecEng架构\"></a>1.阿里推荐RecEng架构</h2><p><img src=\"/images/推荐/receng.png\" alt=\"例子\"></p>\n<p>离线计算的数据类型分为:接入数据、中间数据和输出数据三类。接入数据指客户离线提供的用户、物品、日志等数据，中间数据是在离线算法流程中产生的各种中间性质的结果数据表，输出数据是指推荐结果数据表，该结果最终将会被导入到在线存储中，供在线计算模块使用。</p>\n<p>近线计算主要处理用户行为发生变化、推荐物品发生更新时，对离线推荐结果进行更新。近线程序的输入数据可以来自多个数据源，如在线的表格存储（原OTS），以及用户的API请求，又或者是程序中的变量；输出可以是程序变量，或者写回在线存储，或者返回给用户。</p>\n<p>在线计算负责的任务是推荐API接收到API请求时，实时对离线和近线修正产生的推荐结果进行过滤、排重、补足等处理。</p>\n<h2 id=\"2-阿里推荐RecEng引擎流程\"><a href=\"#2-阿里推荐RecEng引擎流程\" class=\"headerlink\" title=\"2.阿里推荐RecEng引擎流程\"></a>2.阿里推荐RecEng引擎流程</h2><p><img src=\"/images/推荐/引擎流程.png\" alt=\"例子\"></p>\n<h2 id=\"3-阿里推荐RecEng优缺点\"><a href=\"#3-阿里推荐RecEng优缺点\" class=\"headerlink\" title=\"3.阿里推荐RecEng优缺点\"></a>3.阿里推荐RecEng优缺点</h2><p>缺点：每个配置流程都很慢，依赖平台型太强。系统支持的推荐算法没有清晰的内部实现过程说明。</p>\n<p>优点：配置度比较灵活，可以自定义模板和算法(但是成本太高，扩展性不太清楚,自定义算法手册没有找到)。和Amazon的架构有很多的相似处。架构理念正确。</p>\n<h2 id=\"4-Amazon推荐系统架构\"><a href=\"#4-Amazon推荐系统架构\" class=\"headerlink\" title=\"4.Amazon推荐系统架构\"></a>4.Amazon推荐系统架构</h2><p><img src=\"/images/推荐/amazon.png\" alt=\"例子\"></p>\n<p>系统被分为3部分， online，nearLine和离线部分(offLine)。Online和nearLine部分一起认为是实时部分。</p>\n<p>离线部分就是传统的个性化推荐系统的主体，定期将大量存储的数据拿出来进行批处理运算，然后对模型进行建立与更新，这里就不详细介绍了。</p>\n<p>nearLine部分，是将用户产生的事件，利用流式计算得到一些中间结果，这些中间结果一方面发送给online部分用于实时更新推荐模型，另一方面将中间结果存储起来，例如存储在MemCached、Cassandra、MySQL等可以快速查询的存储中作为备份。在NetFlix的系统中，他们的流式计算是通过一个叫做NetFlix.Manhattan来实现的，它是一个类似于Storm的实时流式计算框架，只是针对他们自己的应用有一定的特异性，不是通用的实时计算框架。</p>\n<p>然后是online部分。这一部分利用离线部分的主体模型并考虑nearLine部分的实时数据对模型进行增量更新，然后可以得到一个实时的推荐模型，进而根据用户的行为来对用户进行实时推荐。</p>\n<h2 id=\"5-阿里RecEng和开源EasyRec的对比\"><a href=\"#5-阿里RecEng和开源EasyRec的对比\" class=\"headerlink\" title=\"5.阿里RecEng和开源EasyRec的对比\"></a>5.阿里RecEng和开源EasyRec的对比</h2><p>开源EasyRec是一个比较完整的推荐系统，内置已经实现的管理规则算法，插件话的开发模式，支持自定义插件和算法。但是属于半成品，itemitem,cf,svg等经典的推荐算法都没有完整实现，目前版本更新停止，整个系统是针对离线推荐做的，对在线推荐场景支持不到位，整个架构没有考虑到在线推荐的场景。但模块比较完整，报表，API等比较齐全。对企业自主研发推荐系统有很多借鉴的地方。架构方面可以和Amazon的做一个结合，在通用性方面已经比较完整。</p>\n<p>个性化推荐系统架构的关键问题，就是如何以无缝方式实现在线和离线计算过程，说到底，也是算法的设计，如何将算法的计算步骤合理分配到各个部分，使得得到的模型既可以非常准确，又可以快速计算出来以满足实时性的要求。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>研究了下阿里的RecEng、Amazon和开源EasyRec推荐系统，孰优孰劣,针对一个通用的推荐系统设计的方法是什么。<br>","more":"</p>\n<h2 id=\"1-阿里推荐RecEng架构\"><a href=\"#1-阿里推荐RecEng架构\" class=\"headerlink\" title=\"1.阿里推荐RecEng架构\"></a>1.阿里推荐RecEng架构</h2><p><img src=\"/images/推荐/receng.png\" alt=\"例子\"></p>\n<p>离线计算的数据类型分为:接入数据、中间数据和输出数据三类。接入数据指客户离线提供的用户、物品、日志等数据，中间数据是在离线算法流程中产生的各种中间性质的结果数据表，输出数据是指推荐结果数据表，该结果最终将会被导入到在线存储中，供在线计算模块使用。</p>\n<p>近线计算主要处理用户行为发生变化、推荐物品发生更新时，对离线推荐结果进行更新。近线程序的输入数据可以来自多个数据源，如在线的表格存储（原OTS），以及用户的API请求，又或者是程序中的变量；输出可以是程序变量，或者写回在线存储，或者返回给用户。</p>\n<p>在线计算负责的任务是推荐API接收到API请求时，实时对离线和近线修正产生的推荐结果进行过滤、排重、补足等处理。</p>\n<h2 id=\"2-阿里推荐RecEng引擎流程\"><a href=\"#2-阿里推荐RecEng引擎流程\" class=\"headerlink\" title=\"2.阿里推荐RecEng引擎流程\"></a>2.阿里推荐RecEng引擎流程</h2><p><img src=\"/images/推荐/引擎流程.png\" alt=\"例子\"></p>\n<h2 id=\"3-阿里推荐RecEng优缺点\"><a href=\"#3-阿里推荐RecEng优缺点\" class=\"headerlink\" title=\"3.阿里推荐RecEng优缺点\"></a>3.阿里推荐RecEng优缺点</h2><p>缺点：每个配置流程都很慢，依赖平台型太强。系统支持的推荐算法没有清晰的内部实现过程说明。</p>\n<p>优点：配置度比较灵活，可以自定义模板和算法(但是成本太高，扩展性不太清楚,自定义算法手册没有找到)。和Amazon的架构有很多的相似处。架构理念正确。</p>\n<h2 id=\"4-Amazon推荐系统架构\"><a href=\"#4-Amazon推荐系统架构\" class=\"headerlink\" title=\"4.Amazon推荐系统架构\"></a>4.Amazon推荐系统架构</h2><p><img src=\"/images/推荐/amazon.png\" alt=\"例子\"></p>\n<p>系统被分为3部分， online，nearLine和离线部分(offLine)。Online和nearLine部分一起认为是实时部分。</p>\n<p>离线部分就是传统的个性化推荐系统的主体，定期将大量存储的数据拿出来进行批处理运算，然后对模型进行建立与更新，这里就不详细介绍了。</p>\n<p>nearLine部分，是将用户产生的事件，利用流式计算得到一些中间结果，这些中间结果一方面发送给online部分用于实时更新推荐模型，另一方面将中间结果存储起来，例如存储在MemCached、Cassandra、MySQL等可以快速查询的存储中作为备份。在NetFlix的系统中，他们的流式计算是通过一个叫做NetFlix.Manhattan来实现的，它是一个类似于Storm的实时流式计算框架，只是针对他们自己的应用有一定的特异性，不是通用的实时计算框架。</p>\n<p>然后是online部分。这一部分利用离线部分的主体模型并考虑nearLine部分的实时数据对模型进行增量更新，然后可以得到一个实时的推荐模型，进而根据用户的行为来对用户进行实时推荐。</p>\n<h2 id=\"5-阿里RecEng和开源EasyRec的对比\"><a href=\"#5-阿里RecEng和开源EasyRec的对比\" class=\"headerlink\" title=\"5.阿里RecEng和开源EasyRec的对比\"></a>5.阿里RecEng和开源EasyRec的对比</h2><p>开源EasyRec是一个比较完整的推荐系统，内置已经实现的管理规则算法，插件话的开发模式，支持自定义插件和算法。但是属于半成品，itemitem,cf,svg等经典的推荐算法都没有完整实现，目前版本更新停止，整个系统是针对离线推荐做的，对在线推荐场景支持不到位，整个架构没有考虑到在线推荐的场景。但模块比较完整，报表，API等比较齐全。对企业自主研发推荐系统有很多借鉴的地方。架构方面可以和Amazon的做一个结合，在通用性方面已经比较完整。</p>\n<p>个性化推荐系统架构的关键问题，就是如何以无缝方式实现在线和离线计算过程，说到底，也是算法的设计，如何将算法的计算步骤合理分配到各个部分，使得得到的模型既可以非常准确，又可以快速计算出来以满足实时性的要求。</p>"},{"layout":"lay_post","title":"推荐系统比较重要的期刊和学术会议","date":"2016-12-24T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n关注最前沿的研究成果，是做好推荐系统的重要条件。\n<!-- more -->\n\n## 1.计算机国际学术会议和期刊目录\n\n[中国计算机学会推荐国际学术会议和期刊目录](http://www.ccf.org.cn/sites/ccf/paiming.jsp)\n\nCCF是中国计算机学会推荐的比较好的会议和期刊目录，可以作为研究计算机领域问题比较好的参考资源列表。\n\n[dblp](http://dblp.uni-trier.de/)\n\nDBLP是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。DBLP所收录的期刊和会议论文质量较高，DBLP的文献更新速度很快，很好地反应了国外学术研究的前沿方向。\n\n这个项目是德国特里尔大学的Michael Ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，DBLP并没有使用数据库而是使用XML存储元数据。\n\n国内类似的权威期刊及重要会议论文集成检索系统有[C-DBLP](http://c-dblp.cn/)\n\n**文档下载**:文档可以在dblp对应的view中链接的网址查看和下载论文，若给出的地址不能免费查看和下载可以使用百度学术来检索免费下载资源。\n\n## 2.推荐系统相关的学术会议和重要论文\n\n**paper**：论文，**journal**：期刊，**conference**：会议。\n\nRecSys是ACM主办的推荐系统旗舰会议，其征文范畴包含推荐系统的各个领域，包括算法设计、系统实现、理论推导和评估测试等。RecSys是推荐系统领域最好的专门会议，另外KDD、WWW和ICML跟推荐系统相关的track也属A+级别。\n\n但是这个会议目前为止录用的论文质量参差不齐，除少数有影响力的论文之外，其它质量较一般，会议的reputation(声誉)和KDD、SIGIR、WWW，ICDM，甚至WSDM这些比肯定是差较多的，从参会的人就能看出来。另外目前CCF没有把它纳入推荐名单，这也是国内在这个会议上出现较少的原因吧。\n\n重要论文：\n\n1.综述：\n\n1.Adomavicius G, Tuzhilin A. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions[J]. Knowledge and Data Engineering, IEEE Transactions on, 2005, 17(6): 734-749. 2005年的state-of-the-art的推荐综述，按照content-based, CF, Hybrid的分类方法进行组织，并介绍了推荐引擎设计时需要关注的特性指标，内容非常全。\n\n2.Marlin B. Collaborative filtering: A machine learning perspective[D]. University of Toronto, 2004. 从传统机器学习的分类角度来介绍推荐算法，有一定机器学习背景的人来看该文章的话， 会觉得写得通俗易懂\n\n3.Koren Y, Bell R. Advances in collaborative filtering[M]//Recommender Systems Handbook. Springer US, 2011: 145-186.  RSs Handbook中专门讲述协同过滤的一章，其中对近年协同过滤的一些重要突破进行了介绍，包括因式分解，时间相关推荐，基于近邻的推荐以及多种方法的融合，内部不多，但其中引用的论文值得细看\n\n4.Su X, Khoshgoftaar T M. A survey of collaborative filtering techniques[J]. Advances in artificial intelligence, 2009, 2009: 4. 协同过滤的篇survey， 按照memory-base, model-based, hybrid分类方法介绍各种协同过滤方法及评价标准，并在其中给出基于netflix数据进行评估的效果对比\n\n5.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.  主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了\n\n6.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构\n\n2.Content-based方面的论文\n\ncontent-based方法非常依赖于特定领域item的特征提取及处理，例如音乐推荐或是关键词推荐中很多细节内容信息处理过程都是不一样的，故这里仅列了content-based综述类的几篇文章。\n\n1.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构\n\n2.Lops P, de Gemmis M, Semeraro G. Content-based recommender systems: State of the art and trends[M]//Recommender Systems Handbook. Springer US, 2011: 73-105. RS Handbook中专门介绍content-based 算法的章节\n\n3.Jannach D, Zanker M, Felfernig A, et al. Content-based recommendation   [M] Charpter 3 Recommender systems: an introduction[M]. Cambridge University Press, 2010.\n\n3.Collaborative Filtering方面的论文\n\n**Neighbourhood Based Methods**\n\n1.Sarwar B, Karypis G, Konstan J, et al. Item-based collaborative filtering recommendation algorithms[C]//Proceedings of the 10th international conference on World Wide Web. ACM, 2001: 285-295. KNN进行item-based推荐的经典文章，其中也介绍了多种相似度度量标准\n\n2.Linden G, Smith B, York J. Amazon. com recommendations: Item-to-item collaborative filtering[J]. Internet Computing, IEEE, 2003, 7(1): 76-80. 经典的亚马逊item-based算法的文章\n\n3.Gionis A, Indyk P, Motwani R. Similarity search in high dimensions via hashing[C]//VLDB. 1999, 99: 518-529.  LSH\n\n4.Bell R M, Koren Y. Scalable collaborative filtering with jointly derived neighborhood interpolation weights[C]//Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 2007: 43-52.\n\n5.Indyk P, Motwani R. Approximate nearest neighbors: towards removing the curse of dimensionality[C]//Proceedings of the thirtieth annual ACM symposium on Theory of computing. ACM, 1998: 604-613. LSH\n\n6.Buhler J. Efficient large-scale sequence comparison by locality-sensitive hashing[J]. Bioinformatics, 2001, 17(5): 419-428. LSH应用\n\n7.Chen T, Zheng Z, Lu Q, et al. Feature-based matrix factorization[J]. arXiv preprint arXiv:1109.2271, 2011.上交Apex实验室开发的svdfeature工具背后的原理。 优点是可以对照着代码学习\n\n**Model Based Methods**\n\n1.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了\n\n2.Singh A P, Gordon G J. A unified view of matrix factorization models[M]//Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2008: 358-373.\n\n**Hybrid Methods**\n\n1.Koren Y. Factorization meets the neighborhood: a multifaceted collaborative filtering model[C]//Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008: 426-434. 因式分解与Neighbour-based方法融合\n\n2.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370.\n\n3.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370. 介绍了多种推荐算法进行融合的框架\n\n## 3.参考内容\n\n[Dustinsea](http://semocean.com/)","source":"_posts/2016-12-25-推荐系统比较重要的期刊和学术会议.md","raw":"---\nlayout: lay_post\ntitle: \"推荐系统比较重要的期刊和学术会议\"\ndate: 2016-12-25\ncategories: 学术会议\ntags: 推荐系统\nauthor: lvyafei\n---\n\n## 0.概述\n\n关注最前沿的研究成果，是做好推荐系统的重要条件。\n<!-- more -->\n\n## 1.计算机国际学术会议和期刊目录\n\n[中国计算机学会推荐国际学术会议和期刊目录](http://www.ccf.org.cn/sites/ccf/paiming.jsp)\n\nCCF是中国计算机学会推荐的比较好的会议和期刊目录，可以作为研究计算机领域问题比较好的参考资源列表。\n\n[dblp](http://dblp.uni-trier.de/)\n\nDBLP是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。DBLP所收录的期刊和会议论文质量较高，DBLP的文献更新速度很快，很好地反应了国外学术研究的前沿方向。\n\n这个项目是德国特里尔大学的Michael Ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，DBLP并没有使用数据库而是使用XML存储元数据。\n\n国内类似的权威期刊及重要会议论文集成检索系统有[C-DBLP](http://c-dblp.cn/)\n\n**文档下载**:文档可以在dblp对应的view中链接的网址查看和下载论文，若给出的地址不能免费查看和下载可以使用百度学术来检索免费下载资源。\n\n## 2.推荐系统相关的学术会议和重要论文\n\n**paper**：论文，**journal**：期刊，**conference**：会议。\n\nRecSys是ACM主办的推荐系统旗舰会议，其征文范畴包含推荐系统的各个领域，包括算法设计、系统实现、理论推导和评估测试等。RecSys是推荐系统领域最好的专门会议，另外KDD、WWW和ICML跟推荐系统相关的track也属A+级别。\n\n但是这个会议目前为止录用的论文质量参差不齐，除少数有影响力的论文之外，其它质量较一般，会议的reputation(声誉)和KDD、SIGIR、WWW，ICDM，甚至WSDM这些比肯定是差较多的，从参会的人就能看出来。另外目前CCF没有把它纳入推荐名单，这也是国内在这个会议上出现较少的原因吧。\n\n重要论文：\n\n1.综述：\n\n1.Adomavicius G, Tuzhilin A. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions[J]. Knowledge and Data Engineering, IEEE Transactions on, 2005, 17(6): 734-749. 2005年的state-of-the-art的推荐综述，按照content-based, CF, Hybrid的分类方法进行组织，并介绍了推荐引擎设计时需要关注的特性指标，内容非常全。\n\n2.Marlin B. Collaborative filtering: A machine learning perspective[D]. University of Toronto, 2004. 从传统机器学习的分类角度来介绍推荐算法，有一定机器学习背景的人来看该文章的话， 会觉得写得通俗易懂\n\n3.Koren Y, Bell R. Advances in collaborative filtering[M]//Recommender Systems Handbook. Springer US, 2011: 145-186.  RSs Handbook中专门讲述协同过滤的一章，其中对近年协同过滤的一些重要突破进行了介绍，包括因式分解，时间相关推荐，基于近邻的推荐以及多种方法的融合，内部不多，但其中引用的论文值得细看\n\n4.Su X, Khoshgoftaar T M. A survey of collaborative filtering techniques[J]. Advances in artificial intelligence, 2009, 2009: 4. 协同过滤的篇survey， 按照memory-base, model-based, hybrid分类方法介绍各种协同过滤方法及评价标准，并在其中给出基于netflix数据进行评估的效果对比\n\n5.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.  主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了\n\n6.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构\n\n2.Content-based方面的论文\n\ncontent-based方法非常依赖于特定领域item的特征提取及处理，例如音乐推荐或是关键词推荐中很多细节内容信息处理过程都是不一样的，故这里仅列了content-based综述类的几篇文章。\n\n1.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构\n\n2.Lops P, de Gemmis M, Semeraro G. Content-based recommender systems: State of the art and trends[M]//Recommender Systems Handbook. Springer US, 2011: 73-105. RS Handbook中专门介绍content-based 算法的章节\n\n3.Jannach D, Zanker M, Felfernig A, et al. Content-based recommendation   [M] Charpter 3 Recommender systems: an introduction[M]. Cambridge University Press, 2010.\n\n3.Collaborative Filtering方面的论文\n\n**Neighbourhood Based Methods**\n\n1.Sarwar B, Karypis G, Konstan J, et al. Item-based collaborative filtering recommendation algorithms[C]//Proceedings of the 10th international conference on World Wide Web. ACM, 2001: 285-295. KNN进行item-based推荐的经典文章，其中也介绍了多种相似度度量标准\n\n2.Linden G, Smith B, York J. Amazon. com recommendations: Item-to-item collaborative filtering[J]. Internet Computing, IEEE, 2003, 7(1): 76-80. 经典的亚马逊item-based算法的文章\n\n3.Gionis A, Indyk P, Motwani R. Similarity search in high dimensions via hashing[C]//VLDB. 1999, 99: 518-529.  LSH\n\n4.Bell R M, Koren Y. Scalable collaborative filtering with jointly derived neighborhood interpolation weights[C]//Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 2007: 43-52.\n\n5.Indyk P, Motwani R. Approximate nearest neighbors: towards removing the curse of dimensionality[C]//Proceedings of the thirtieth annual ACM symposium on Theory of computing. ACM, 1998: 604-613. LSH\n\n6.Buhler J. Efficient large-scale sequence comparison by locality-sensitive hashing[J]. Bioinformatics, 2001, 17(5): 419-428. LSH应用\n\n7.Chen T, Zheng Z, Lu Q, et al. Feature-based matrix factorization[J]. arXiv preprint arXiv:1109.2271, 2011.上交Apex实验室开发的svdfeature工具背后的原理。 优点是可以对照着代码学习\n\n**Model Based Methods**\n\n1.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了\n\n2.Singh A P, Gordon G J. A unified view of matrix factorization models[M]//Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2008: 358-373.\n\n**Hybrid Methods**\n\n1.Koren Y. Factorization meets the neighborhood: a multifaceted collaborative filtering model[C]//Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008: 426-434. 因式分解与Neighbour-based方法融合\n\n2.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370.\n\n3.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370. 介绍了多种推荐算法进行融合的框架\n\n## 3.参考内容\n\n[Dustinsea](http://semocean.com/)","slug":"2016-12-25-推荐系统比较重要的期刊和学术会议","published":1,"updated":"2018-11-29T12:51:25.154Z","comments":1,"photos":[],"link":"","_id":"cjskffoaq004g4glmp5e5nl3t","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>关注最前沿的研究成果，是做好推荐系统的重要条件。<br><a id=\"more\"></a></p>\n<h2 id=\"1-计算机国际学术会议和期刊目录\"><a href=\"#1-计算机国际学术会议和期刊目录\" class=\"headerlink\" title=\"1.计算机国际学术会议和期刊目录\"></a>1.计算机国际学术会议和期刊目录</h2><p><a href=\"http://www.ccf.org.cn/sites/ccf/paiming.jsp\" target=\"_blank\" rel=\"noopener\">中国计算机学会推荐国际学术会议和期刊目录</a></p>\n<p>CCF是中国计算机学会推荐的比较好的会议和期刊目录，可以作为研究计算机领域问题比较好的参考资源列表。</p>\n<p><a href=\"http://dblp.uni-trier.de/\" target=\"_blank\" rel=\"noopener\">dblp</a></p>\n<p>DBLP是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。DBLP所收录的期刊和会议论文质量较高，DBLP的文献更新速度很快，很好地反应了国外学术研究的前沿方向。</p>\n<p>这个项目是德国特里尔大学的Michael Ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，DBLP并没有使用数据库而是使用XML存储元数据。</p>\n<p>国内类似的权威期刊及重要会议论文集成检索系统有<a href=\"http://c-dblp.cn/\" target=\"_blank\" rel=\"noopener\">C-DBLP</a></p>\n<p><strong>文档下载</strong>:文档可以在dblp对应的view中链接的网址查看和下载论文，若给出的地址不能免费查看和下载可以使用百度学术来检索免费下载资源。</p>\n<h2 id=\"2-推荐系统相关的学术会议和重要论文\"><a href=\"#2-推荐系统相关的学术会议和重要论文\" class=\"headerlink\" title=\"2.推荐系统相关的学术会议和重要论文\"></a>2.推荐系统相关的学术会议和重要论文</h2><p><strong>paper</strong>：论文，<strong>journal</strong>：期刊，<strong>conference</strong>：会议。</p>\n<p>RecSys是ACM主办的推荐系统旗舰会议，其征文范畴包含推荐系统的各个领域，包括算法设计、系统实现、理论推导和评估测试等。RecSys是推荐系统领域最好的专门会议，另外KDD、WWW和ICML跟推荐系统相关的track也属A+级别。</p>\n<p>但是这个会议目前为止录用的论文质量参差不齐，除少数有影响力的论文之外，其它质量较一般，会议的reputation(声誉)和KDD、SIGIR、WWW，ICDM，甚至WSDM这些比肯定是差较多的，从参会的人就能看出来。另外目前CCF没有把它纳入推荐名单，这也是国内在这个会议上出现较少的原因吧。</p>\n<p>重要论文：</p>\n<p>1.综述：</p>\n<p>1.Adomavicius G, Tuzhilin A. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions[J]. Knowledge and Data Engineering, IEEE Transactions on, 2005, 17(6): 734-749. 2005年的state-of-the-art的推荐综述，按照content-based, CF, Hybrid的分类方法进行组织，并介绍了推荐引擎设计时需要关注的特性指标，内容非常全。</p>\n<p>2.Marlin B. Collaborative filtering: A machine learning perspective[D]. University of Toronto, 2004. 从传统机器学习的分类角度来介绍推荐算法，有一定机器学习背景的人来看该文章的话， 会觉得写得通俗易懂</p>\n<p>3.Koren Y, Bell R. Advances in collaborative filtering[M]//Recommender Systems Handbook. Springer US, 2011: 145-186.  RSs Handbook中专门讲述协同过滤的一章，其中对近年协同过滤的一些重要突破进行了介绍，包括因式分解，时间相关推荐，基于近邻的推荐以及多种方法的融合，内部不多，但其中引用的论文值得细看</p>\n<p>4.Su X, Khoshgoftaar T M. A survey of collaborative filtering techniques[J]. Advances in artificial intelligence, 2009, 2009: 4. 协同过滤的篇survey， 按照memory-base, model-based, hybrid分类方法介绍各种协同过滤方法及评价标准，并在其中给出基于netflix数据进行评估的效果对比</p>\n<p>5.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.  主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了</p>\n<p>6.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构</p>\n<p>2.Content-based方面的论文</p>\n<p>content-based方法非常依赖于特定领域item的特征提取及处理，例如音乐推荐或是关键词推荐中很多细节内容信息处理过程都是不一样的，故这里仅列了content-based综述类的几篇文章。</p>\n<p>1.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构</p>\n<p>2.Lops P, de Gemmis M, Semeraro G. Content-based recommender systems: State of the art and trends[M]//Recommender Systems Handbook. Springer US, 2011: 73-105. RS Handbook中专门介绍content-based 算法的章节</p>\n<p>3.Jannach D, Zanker M, Felfernig A, et al. Content-based recommendation   [M] Charpter 3 Recommender systems: an introduction[M]. Cambridge University Press, 2010.</p>\n<p>3.Collaborative Filtering方面的论文</p>\n<p><strong>Neighbourhood Based Methods</strong></p>\n<p>1.Sarwar B, Karypis G, Konstan J, et al. Item-based collaborative filtering recommendation algorithms[C]//Proceedings of the 10th international conference on World Wide Web. ACM, 2001: 285-295. KNN进行item-based推荐的经典文章，其中也介绍了多种相似度度量标准</p>\n<p>2.Linden G, Smith B, York J. Amazon. com recommendations: Item-to-item collaborative filtering[J]. Internet Computing, IEEE, 2003, 7(1): 76-80. 经典的亚马逊item-based算法的文章</p>\n<p>3.Gionis A, Indyk P, Motwani R. Similarity search in high dimensions via hashing[C]//VLDB. 1999, 99: 518-529.  LSH</p>\n<p>4.Bell R M, Koren Y. Scalable collaborative filtering with jointly derived neighborhood interpolation weights[C]//Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 2007: 43-52.</p>\n<p>5.Indyk P, Motwani R. Approximate nearest neighbors: towards removing the curse of dimensionality[C]//Proceedings of the thirtieth annual ACM symposium on Theory of computing. ACM, 1998: 604-613. LSH</p>\n<p>6.Buhler J. Efficient large-scale sequence comparison by locality-sensitive hashing[J]. Bioinformatics, 2001, 17(5): 419-428. LSH应用</p>\n<p>7.Chen T, Zheng Z, Lu Q, et al. Feature-based matrix factorization[J]. arXiv preprint arXiv:1109.2271, 2011.上交Apex实验室开发的svdfeature工具背后的原理。 优点是可以对照着代码学习</p>\n<p><strong>Model Based Methods</strong></p>\n<p>1.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了</p>\n<p>2.Singh A P, Gordon G J. A unified view of matrix factorization models[M]//Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2008: 358-373.</p>\n<p><strong>Hybrid Methods</strong></p>\n<p>1.Koren Y. Factorization meets the neighborhood: a multifaceted collaborative filtering model[C]//Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008: 426-434. 因式分解与Neighbour-based方法融合</p>\n<p>2.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370.</p>\n<p>3.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370. 介绍了多种推荐算法进行融合的框架</p>\n<h2 id=\"3-参考内容\"><a href=\"#3-参考内容\" class=\"headerlink\" title=\"3.参考内容\"></a>3.参考内容</h2><p><a href=\"http://semocean.com/\" target=\"_blank\" rel=\"noopener\">Dustinsea</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>关注最前沿的研究成果，是做好推荐系统的重要条件。<br>","more":"</p>\n<h2 id=\"1-计算机国际学术会议和期刊目录\"><a href=\"#1-计算机国际学术会议和期刊目录\" class=\"headerlink\" title=\"1.计算机国际学术会议和期刊目录\"></a>1.计算机国际学术会议和期刊目录</h2><p><a href=\"http://www.ccf.org.cn/sites/ccf/paiming.jsp\" target=\"_blank\" rel=\"noopener\">中国计算机学会推荐国际学术会议和期刊目录</a></p>\n<p>CCF是中国计算机学会推荐的比较好的会议和期刊目录，可以作为研究计算机领域问题比较好的参考资源列表。</p>\n<p><a href=\"http://dblp.uni-trier.de/\" target=\"_blank\" rel=\"noopener\">dblp</a></p>\n<p>DBLP是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。DBLP所收录的期刊和会议论文质量较高，DBLP的文献更新速度很快，很好地反应了国外学术研究的前沿方向。</p>\n<p>这个项目是德国特里尔大学的Michael Ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，DBLP并没有使用数据库而是使用XML存储元数据。</p>\n<p>国内类似的权威期刊及重要会议论文集成检索系统有<a href=\"http://c-dblp.cn/\" target=\"_blank\" rel=\"noopener\">C-DBLP</a></p>\n<p><strong>文档下载</strong>:文档可以在dblp对应的view中链接的网址查看和下载论文，若给出的地址不能免费查看和下载可以使用百度学术来检索免费下载资源。</p>\n<h2 id=\"2-推荐系统相关的学术会议和重要论文\"><a href=\"#2-推荐系统相关的学术会议和重要论文\" class=\"headerlink\" title=\"2.推荐系统相关的学术会议和重要论文\"></a>2.推荐系统相关的学术会议和重要论文</h2><p><strong>paper</strong>：论文，<strong>journal</strong>：期刊，<strong>conference</strong>：会议。</p>\n<p>RecSys是ACM主办的推荐系统旗舰会议，其征文范畴包含推荐系统的各个领域，包括算法设计、系统实现、理论推导和评估测试等。RecSys是推荐系统领域最好的专门会议，另外KDD、WWW和ICML跟推荐系统相关的track也属A+级别。</p>\n<p>但是这个会议目前为止录用的论文质量参差不齐，除少数有影响力的论文之外，其它质量较一般，会议的reputation(声誉)和KDD、SIGIR、WWW，ICDM，甚至WSDM这些比肯定是差较多的，从参会的人就能看出来。另外目前CCF没有把它纳入推荐名单，这也是国内在这个会议上出现较少的原因吧。</p>\n<p>重要论文：</p>\n<p>1.综述：</p>\n<p>1.Adomavicius G, Tuzhilin A. Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions[J]. Knowledge and Data Engineering, IEEE Transactions on, 2005, 17(6): 734-749. 2005年的state-of-the-art的推荐综述，按照content-based, CF, Hybrid的分类方法进行组织，并介绍了推荐引擎设计时需要关注的特性指标，内容非常全。</p>\n<p>2.Marlin B. Collaborative filtering: A machine learning perspective[D]. University of Toronto, 2004. 从传统机器学习的分类角度来介绍推荐算法，有一定机器学习背景的人来看该文章的话， 会觉得写得通俗易懂</p>\n<p>3.Koren Y, Bell R. Advances in collaborative filtering[M]//Recommender Systems Handbook. Springer US, 2011: 145-186.  RSs Handbook中专门讲述协同过滤的一章，其中对近年协同过滤的一些重要突破进行了介绍，包括因式分解，时间相关推荐，基于近邻的推荐以及多种方法的融合，内部不多，但其中引用的论文值得细看</p>\n<p>4.Su X, Khoshgoftaar T M. A survey of collaborative filtering techniques[J]. Advances in artificial intelligence, 2009, 2009: 4. 协同过滤的篇survey， 按照memory-base, model-based, hybrid分类方法介绍各种协同过滤方法及评价标准，并在其中给出基于netflix数据进行评估的效果对比</p>\n<p>5.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.  主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了</p>\n<p>6.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构</p>\n<p>2.Content-based方面的论文</p>\n<p>content-based方法非常依赖于特定领域item的特征提取及处理，例如音乐推荐或是关键词推荐中很多细节内容信息处理过程都是不一样的，故这里仅列了content-based综述类的几篇文章。</p>\n<p>1.Pazzani M J, Billsus D. Content-based recommendation systems[M]//The adaptive web. Springer Berlin Heidelberg, 2007: 325-341.从宏观上介绍content-based的策略架构</p>\n<p>2.Lops P, de Gemmis M, Semeraro G. Content-based recommender systems: State of the art and trends[M]//Recommender Systems Handbook. Springer US, 2011: 73-105. RS Handbook中专门介绍content-based 算法的章节</p>\n<p>3.Jannach D, Zanker M, Felfernig A, et al. Content-based recommendation   [M] Charpter 3 Recommender systems: an introduction[M]. Cambridge University Press, 2010.</p>\n<p>3.Collaborative Filtering方面的论文</p>\n<p><strong>Neighbourhood Based Methods</strong></p>\n<p>1.Sarwar B, Karypis G, Konstan J, et al. Item-based collaborative filtering recommendation algorithms[C]//Proceedings of the 10th international conference on World Wide Web. ACM, 2001: 285-295. KNN进行item-based推荐的经典文章，其中也介绍了多种相似度度量标准</p>\n<p>2.Linden G, Smith B, York J. Amazon. com recommendations: Item-to-item collaborative filtering[J]. Internet Computing, IEEE, 2003, 7(1): 76-80. 经典的亚马逊item-based算法的文章</p>\n<p>3.Gionis A, Indyk P, Motwani R. Similarity search in high dimensions via hashing[C]//VLDB. 1999, 99: 518-529.  LSH</p>\n<p>4.Bell R M, Koren Y. Scalable collaborative filtering with jointly derived neighborhood interpolation weights[C]//Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on. IEEE, 2007: 43-52.</p>\n<p>5.Indyk P, Motwani R. Approximate nearest neighbors: towards removing the curse of dimensionality[C]//Proceedings of the thirtieth annual ACM symposium on Theory of computing. ACM, 1998: 604-613. LSH</p>\n<p>6.Buhler J. Efficient large-scale sequence comparison by locality-sensitive hashing[J]. Bioinformatics, 2001, 17(5): 419-428. LSH应用</p>\n<p>7.Chen T, Zheng Z, Lu Q, et al. Feature-based matrix factorization[J]. arXiv preprint arXiv:1109.2271, 2011.上交Apex实验室开发的svdfeature工具背后的原理。 优点是可以对照着代码学习</p>\n<p><strong>Model Based Methods</strong></p>\n<p>1.Koren Y, Bell R, Volinsky C. Matrix factorization techniques for recommender systems[J]. Computer, 2009, 42(8): 30-37.主要集中在因式分解实现协同过滤方法，如果看完Advances in collaborative filtering[M]//Recommender Systems Handbook的话，这篇文章就没有必要再看了</p>\n<p>2.Singh A P, Gordon G J. A unified view of matrix factorization models[M]//Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2008: 358-373.</p>\n<p><strong>Hybrid Methods</strong></p>\n<p>1.Koren Y. Factorization meets the neighborhood: a multifaceted collaborative filtering model[C]//Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2008: 426-434. 因式分解与Neighbour-based方法融合</p>\n<p>2.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370.</p>\n<p>3.Burke R. Hybrid recommender systems: Survey and experiments[J]. User modeling and user-adapted interaction, 2002, 12(4): 331-370. 介绍了多种推荐算法进行融合的框架</p>\n<h2 id=\"3-参考内容\"><a href=\"#3-参考内容\" class=\"headerlink\" title=\"3.参考内容\"></a>3.参考内容</h2><p><a href=\"http://semocean.com/\" target=\"_blank\" rel=\"noopener\">Dustinsea</a></p>"},{"layout":"lay_post","title":"数据挖掘导论-读书笔记","date":"2016-12-27T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n数据挖掘导论涉及到的知识比较丰富,梳理下内容，为后面推荐系统设计做铺垫。\n<!-- more -->\n\n## 1.什么是数据挖掘\n\n数据挖掘是在大型数据存储库中，自动发现有用信息的过程。数据挖掘技术用来探测大型数据库，发现先前未知的有用模式。\n数据挖掘还可以预测未来观测结果，例如预测一位新的顾客是否会在一家百货公司消费100美元以上。\n\n数据挖掘是数据库中知识发现(KDD)不可缺少的一部分，而KDD是将未加工的数据转换为有用信息的整个过程。\n\n![知识发现](/images/数据挖掘/知识发现.png)\n\n## 2.数据挖掘要解决的问题\n\n数据可伸缩，数据的高维性，异种数据和复杂数据，数据的所有权与分布，非传统的分析。\n\n## 3.数据挖掘和其他领域之间的联系\n\n![领域知识](/images/数据挖掘/领域知识.png)\n\n## 4.数据挖掘任务\n\n1.预测任务。目标是根据其他属性的值，预测特定属性的值。被预测的属性一般称目标变量，而用来做预测的属性称说明变量。\n\n2.描述任务。目标是导出概况数据中潜在联系的模式(相关、趋势、聚类、轨迹和异常)。\n\n![挖掘任务](/images/数据挖掘/挖掘任务.png)\n\n预测建模(predictive modeling):涉及以说明变量函数的方式为目标变量建立模型。有两类预测建模任务：分类(classification),用于预测离散的目标变量;回归(regression),用于预测连续的目标变量。\n\n关联分析(association analysis):用来发现描述数据中强关联特征的模式。\n\n聚类分析(cluster analysis):旨在发现紧密相关的观测值组群。\n\n异常检测(anomaly detection):识别其特征显著不同于其他数据的观测值。这样的观测值称为异常点(anomaly)或离群点(outlier)。异常检测算法的目标是发现真正的异常点，而避免错误地将正常的对象标注为异常点。\n\n## 5.分类\n\n分类法包括：决策树归纳，基于规则分类，最近邻分类，神经网络，支持向量机，朴素贝叶斯分类。\n\n## 6.关联分析\n\napriori算法,FP增长算法\n\n## 7.聚类分析\n\n聚类类型：层次的与划分的，互斥的、重叠的与模糊的，完全的与部分的。\n\n簇类型：明显分离的，基于原型的，基于图的，基于密度的，共同性质的(概念簇)\n\n![聚类分析](/images/数据挖掘/聚类分析.png)\n\n基于原型的算法：K均值，自组织映射(SOM)，期望最大化(EM),\n\n基于密度的算法：DBSCAN,CLIQUE,DENCLUE\n\n基于图的算法：MST(最小生成树)算法,Opossum算法,Chameleon算法,Jarvis-Patrick算法\n\n凝聚的层次聚类:分两种产生层次聚类的方法：凝聚的，分裂的。\n\n可伸缩的聚类:BIRCH,CURE\n\n## 8.异常检测\n\n异常检测方法:基于模型的技术，基于临近度的技术，基于密度的技术，基于聚类的技术","source":"_posts/2016-12-28-数据挖掘导论-读书笔记.md","raw":"---\nlayout: lay_post\ntitle: \"数据挖掘导论-读书笔记\"\ndate: 2016-12-28\ncategories: 读书笔记\ntags: 数据挖掘\nauthor: lvyafei\n---\n\n## 0.概述\n\n数据挖掘导论涉及到的知识比较丰富,梳理下内容，为后面推荐系统设计做铺垫。\n<!-- more -->\n\n## 1.什么是数据挖掘\n\n数据挖掘是在大型数据存储库中，自动发现有用信息的过程。数据挖掘技术用来探测大型数据库，发现先前未知的有用模式。\n数据挖掘还可以预测未来观测结果，例如预测一位新的顾客是否会在一家百货公司消费100美元以上。\n\n数据挖掘是数据库中知识发现(KDD)不可缺少的一部分，而KDD是将未加工的数据转换为有用信息的整个过程。\n\n![知识发现](/images/数据挖掘/知识发现.png)\n\n## 2.数据挖掘要解决的问题\n\n数据可伸缩，数据的高维性，异种数据和复杂数据，数据的所有权与分布，非传统的分析。\n\n## 3.数据挖掘和其他领域之间的联系\n\n![领域知识](/images/数据挖掘/领域知识.png)\n\n## 4.数据挖掘任务\n\n1.预测任务。目标是根据其他属性的值，预测特定属性的值。被预测的属性一般称目标变量，而用来做预测的属性称说明变量。\n\n2.描述任务。目标是导出概况数据中潜在联系的模式(相关、趋势、聚类、轨迹和异常)。\n\n![挖掘任务](/images/数据挖掘/挖掘任务.png)\n\n预测建模(predictive modeling):涉及以说明变量函数的方式为目标变量建立模型。有两类预测建模任务：分类(classification),用于预测离散的目标变量;回归(regression),用于预测连续的目标变量。\n\n关联分析(association analysis):用来发现描述数据中强关联特征的模式。\n\n聚类分析(cluster analysis):旨在发现紧密相关的观测值组群。\n\n异常检测(anomaly detection):识别其特征显著不同于其他数据的观测值。这样的观测值称为异常点(anomaly)或离群点(outlier)。异常检测算法的目标是发现真正的异常点，而避免错误地将正常的对象标注为异常点。\n\n## 5.分类\n\n分类法包括：决策树归纳，基于规则分类，最近邻分类，神经网络，支持向量机，朴素贝叶斯分类。\n\n## 6.关联分析\n\napriori算法,FP增长算法\n\n## 7.聚类分析\n\n聚类类型：层次的与划分的，互斥的、重叠的与模糊的，完全的与部分的。\n\n簇类型：明显分离的，基于原型的，基于图的，基于密度的，共同性质的(概念簇)\n\n![聚类分析](/images/数据挖掘/聚类分析.png)\n\n基于原型的算法：K均值，自组织映射(SOM)，期望最大化(EM),\n\n基于密度的算法：DBSCAN,CLIQUE,DENCLUE\n\n基于图的算法：MST(最小生成树)算法,Opossum算法,Chameleon算法,Jarvis-Patrick算法\n\n凝聚的层次聚类:分两种产生层次聚类的方法：凝聚的，分裂的。\n\n可伸缩的聚类:BIRCH,CURE\n\n## 8.异常检测\n\n异常检测方法:基于模型的技术，基于临近度的技术，基于密度的技术，基于聚类的技术","slug":"2016-12-28-数据挖掘导论-读书笔记","published":1,"updated":"2018-11-29T12:51:25.182Z","comments":1,"photos":[],"link":"","_id":"cjskffob6004l4glmqm30j57m","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>数据挖掘导论涉及到的知识比较丰富,梳理下内容，为后面推荐系统设计做铺垫。<br><a id=\"more\"></a></p>\n<h2 id=\"1-什么是数据挖掘\"><a href=\"#1-什么是数据挖掘\" class=\"headerlink\" title=\"1.什么是数据挖掘\"></a>1.什么是数据挖掘</h2><p>数据挖掘是在大型数据存储库中，自动发现有用信息的过程。数据挖掘技术用来探测大型数据库，发现先前未知的有用模式。<br>数据挖掘还可以预测未来观测结果，例如预测一位新的顾客是否会在一家百货公司消费100美元以上。</p>\n<p>数据挖掘是数据库中知识发现(KDD)不可缺少的一部分，而KDD是将未加工的数据转换为有用信息的整个过程。</p>\n<p><img src=\"/images/数据挖掘/知识发现.png\" alt=\"知识发现\"></p>\n<h2 id=\"2-数据挖掘要解决的问题\"><a href=\"#2-数据挖掘要解决的问题\" class=\"headerlink\" title=\"2.数据挖掘要解决的问题\"></a>2.数据挖掘要解决的问题</h2><p>数据可伸缩，数据的高维性，异种数据和复杂数据，数据的所有权与分布，非传统的分析。</p>\n<h2 id=\"3-数据挖掘和其他领域之间的联系\"><a href=\"#3-数据挖掘和其他领域之间的联系\" class=\"headerlink\" title=\"3.数据挖掘和其他领域之间的联系\"></a>3.数据挖掘和其他领域之间的联系</h2><p><img src=\"/images/数据挖掘/领域知识.png\" alt=\"领域知识\"></p>\n<h2 id=\"4-数据挖掘任务\"><a href=\"#4-数据挖掘任务\" class=\"headerlink\" title=\"4.数据挖掘任务\"></a>4.数据挖掘任务</h2><p>1.预测任务。目标是根据其他属性的值，预测特定属性的值。被预测的属性一般称目标变量，而用来做预测的属性称说明变量。</p>\n<p>2.描述任务。目标是导出概况数据中潜在联系的模式(相关、趋势、聚类、轨迹和异常)。</p>\n<p><img src=\"/images/数据挖掘/挖掘任务.png\" alt=\"挖掘任务\"></p>\n<p>预测建模(predictive modeling):涉及以说明变量函数的方式为目标变量建立模型。有两类预测建模任务：分类(classification),用于预测离散的目标变量;回归(regression),用于预测连续的目标变量。</p>\n<p>关联分析(association analysis):用来发现描述数据中强关联特征的模式。</p>\n<p>聚类分析(cluster analysis):旨在发现紧密相关的观测值组群。</p>\n<p>异常检测(anomaly detection):识别其特征显著不同于其他数据的观测值。这样的观测值称为异常点(anomaly)或离群点(outlier)。异常检测算法的目标是发现真正的异常点，而避免错误地将正常的对象标注为异常点。</p>\n<h2 id=\"5-分类\"><a href=\"#5-分类\" class=\"headerlink\" title=\"5.分类\"></a>5.分类</h2><p>分类法包括：决策树归纳，基于规则分类，最近邻分类，神经网络，支持向量机，朴素贝叶斯分类。</p>\n<h2 id=\"6-关联分析\"><a href=\"#6-关联分析\" class=\"headerlink\" title=\"6.关联分析\"></a>6.关联分析</h2><p>apriori算法,FP增长算法</p>\n<h2 id=\"7-聚类分析\"><a href=\"#7-聚类分析\" class=\"headerlink\" title=\"7.聚类分析\"></a>7.聚类分析</h2><p>聚类类型：层次的与划分的，互斥的、重叠的与模糊的，完全的与部分的。</p>\n<p>簇类型：明显分离的，基于原型的，基于图的，基于密度的，共同性质的(概念簇)</p>\n<p><img src=\"/images/数据挖掘/聚类分析.png\" alt=\"聚类分析\"></p>\n<p>基于原型的算法：K均值，自组织映射(SOM)，期望最大化(EM),</p>\n<p>基于密度的算法：DBSCAN,CLIQUE,DENCLUE</p>\n<p>基于图的算法：MST(最小生成树)算法,Opossum算法,Chameleon算法,Jarvis-Patrick算法</p>\n<p>凝聚的层次聚类:分两种产生层次聚类的方法：凝聚的，分裂的。</p>\n<p>可伸缩的聚类:BIRCH,CURE</p>\n<h2 id=\"8-异常检测\"><a href=\"#8-异常检测\" class=\"headerlink\" title=\"8.异常检测\"></a>8.异常检测</h2><p>异常检测方法:基于模型的技术，基于临近度的技术，基于密度的技术，基于聚类的技术</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>数据挖掘导论涉及到的知识比较丰富,梳理下内容，为后面推荐系统设计做铺垫。<br>","more":"</p>\n<h2 id=\"1-什么是数据挖掘\"><a href=\"#1-什么是数据挖掘\" class=\"headerlink\" title=\"1.什么是数据挖掘\"></a>1.什么是数据挖掘</h2><p>数据挖掘是在大型数据存储库中，自动发现有用信息的过程。数据挖掘技术用来探测大型数据库，发现先前未知的有用模式。<br>数据挖掘还可以预测未来观测结果，例如预测一位新的顾客是否会在一家百货公司消费100美元以上。</p>\n<p>数据挖掘是数据库中知识发现(KDD)不可缺少的一部分，而KDD是将未加工的数据转换为有用信息的整个过程。</p>\n<p><img src=\"/images/数据挖掘/知识发现.png\" alt=\"知识发现\"></p>\n<h2 id=\"2-数据挖掘要解决的问题\"><a href=\"#2-数据挖掘要解决的问题\" class=\"headerlink\" title=\"2.数据挖掘要解决的问题\"></a>2.数据挖掘要解决的问题</h2><p>数据可伸缩，数据的高维性，异种数据和复杂数据，数据的所有权与分布，非传统的分析。</p>\n<h2 id=\"3-数据挖掘和其他领域之间的联系\"><a href=\"#3-数据挖掘和其他领域之间的联系\" class=\"headerlink\" title=\"3.数据挖掘和其他领域之间的联系\"></a>3.数据挖掘和其他领域之间的联系</h2><p><img src=\"/images/数据挖掘/领域知识.png\" alt=\"领域知识\"></p>\n<h2 id=\"4-数据挖掘任务\"><a href=\"#4-数据挖掘任务\" class=\"headerlink\" title=\"4.数据挖掘任务\"></a>4.数据挖掘任务</h2><p>1.预测任务。目标是根据其他属性的值，预测特定属性的值。被预测的属性一般称目标变量，而用来做预测的属性称说明变量。</p>\n<p>2.描述任务。目标是导出概况数据中潜在联系的模式(相关、趋势、聚类、轨迹和异常)。</p>\n<p><img src=\"/images/数据挖掘/挖掘任务.png\" alt=\"挖掘任务\"></p>\n<p>预测建模(predictive modeling):涉及以说明变量函数的方式为目标变量建立模型。有两类预测建模任务：分类(classification),用于预测离散的目标变量;回归(regression),用于预测连续的目标变量。</p>\n<p>关联分析(association analysis):用来发现描述数据中强关联特征的模式。</p>\n<p>聚类分析(cluster analysis):旨在发现紧密相关的观测值组群。</p>\n<p>异常检测(anomaly detection):识别其特征显著不同于其他数据的观测值。这样的观测值称为异常点(anomaly)或离群点(outlier)。异常检测算法的目标是发现真正的异常点，而避免错误地将正常的对象标注为异常点。</p>\n<h2 id=\"5-分类\"><a href=\"#5-分类\" class=\"headerlink\" title=\"5.分类\"></a>5.分类</h2><p>分类法包括：决策树归纳，基于规则分类，最近邻分类，神经网络，支持向量机，朴素贝叶斯分类。</p>\n<h2 id=\"6-关联分析\"><a href=\"#6-关联分析\" class=\"headerlink\" title=\"6.关联分析\"></a>6.关联分析</h2><p>apriori算法,FP增长算法</p>\n<h2 id=\"7-聚类分析\"><a href=\"#7-聚类分析\" class=\"headerlink\" title=\"7.聚类分析\"></a>7.聚类分析</h2><p>聚类类型：层次的与划分的，互斥的、重叠的与模糊的，完全的与部分的。</p>\n<p>簇类型：明显分离的，基于原型的，基于图的，基于密度的，共同性质的(概念簇)</p>\n<p><img src=\"/images/数据挖掘/聚类分析.png\" alt=\"聚类分析\"></p>\n<p>基于原型的算法：K均值，自组织映射(SOM)，期望最大化(EM),</p>\n<p>基于密度的算法：DBSCAN,CLIQUE,DENCLUE</p>\n<p>基于图的算法：MST(最小生成树)算法,Opossum算法,Chameleon算法,Jarvis-Patrick算法</p>\n<p>凝聚的层次聚类:分两种产生层次聚类的方法：凝聚的，分裂的。</p>\n<p>可伸缩的聚类:BIRCH,CURE</p>\n<h2 id=\"8-异常检测\"><a href=\"#8-异常检测\" class=\"headerlink\" title=\"8.异常检测\"></a>8.异常检测</h2><p>异常检测方法:基于模型的技术，基于临近度的技术，基于密度的技术，基于聚类的技术</p>"},{"layout":"lay_post","title":"决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法","date":"2016-12-28T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n基于树模型的分类与回归算法。\n<!-- more -->\n\n## 1.决策树(Decision Tree,DT)分类算法\n\n决策树是一种常见的分类与回归模型，主要呈树结构，每一个节点代表一个集合，一条边代表一种属性，而叶子节点则表示对应的类别或值。根据节点分裂规则的不同，主要分为三种方法。\n\n**ID3算法**\n\nID3算法采用的是选择一个特征使得分裂前后样本集合的不确定性降低最大，也就是信息增益最大。\n\n计算方式：g(D,A)=H(D)-H(D/A)。H(D)表示分裂前对应样本集合的经验熵，而H(D/A)表示在A特征划分下的样本经验熵，也就是由特征A进行子集划分后的经验熵之和。\n\nID3算法采用信息增益最大的方式，对于一个节点而言，其对应的样本集合如果所有的类别不是一类，且样本集合不为空，逐个选择特征计算信息增益，选择最大的信息增益，如果其信息增益大于阈值，则按照对应的特征进行样本划分（分裂），然后对每个子节点和样本，循环上述的方法，否则停止。\n\n**C4.5算法**\n\nC4.5算法是ID3算法的改进，由于ID3计算方式会导致选择特征时倾向于选择值较多的特征，C4.5引入了信息增益比的方式。即当前特征下计算的信息增益除以此特征对应的经验熵，基于C4.5的决策树的生产方式与上述类似。\n\n剪枝规则：剪枝的思想就是比较当前节点的下对应的整棵决策树的损失函数，与返回到其父节点上对应的损失函数，当父节点下对应的损失函数比子节点下的损失函数更小时，可以进行剪枝，将父节点变为叶子节点，去掉其子节点。至于决策树的损失函数，是各个叶子节点上的经验熵与节点样本数之积的总和，加上a*T，T为叶子节点数。其中前半部分用于表征决策树的训练误差，而a*T则代表了决策树的复杂程度。根据剃刀准则，只有在训练误差足够下的同时，模型也足够简单，这样的模型才是最好的，能够防止过拟合。\n\n**CART算法**\n\nCART算法也是对分裂规则进行改进，可以用来进行分类与回归，能够处理连续的数据。CART分类规则是选择特征A，使得划分前后基尼系数比的降低最大，也就是划分后左右节点的基尼系数之和最小。\n\n在使用CART树进行回归时，可以采用基于方差的形式，由于回归时标签都是连续值，因此使用方差较为合适。即分别挑选一个特征，基于此特征下，逐个遍历特征值，将样本划分为左右子集（2层循环，第一层为特征数，第二层为某个特征对应的取值），计算左右子集的方差之和，找到所有的特征下特征值对应的方差最小的那个特征和特征值，作为划分特征和阈值，进行节点的分裂。CART树的生成方式是二叉树的形式，与上述两种方法有些微不同。但是大体的步骤相同。\n\n剪枝规则：采用的是分别记录由根节点到各个节点下对应的决策树的损失函数序列，找到在设定值a下决策树对训练数据的预测误差最小对应的树结构。\n\n## 2.随机森林(RandomForests/RandomTrees)\n\n随机森林类似bagging思想，对样本进行多次采用，并以此生成多颗决策树，通过投票获得判别结果。\n\n随机森林中的每棵树与决策树的区别：主要包括3点：\n\n1）.样本随机采样:n=2/3*N;就是说对训练样本而言，每棵树从样本集中采用大约2/3的样本进行决策树的训练；\n\n2）.特征随机抽取：k<<K;对于样本集中的特征，不是逐个遍历所有的特征进行划分，而是在所有的特征中随机选择k个特征，从这k个特征中找到最优的划分特征，以此对节点的样本进行划分，因此用过的特征可能还会出现。\n\n3）.无剪枝：由于随机森林在进行训练样本选择时是随机抽样的，选择划分特征时也是随机的，因此不需要进行剪枝。\n\nOBB无偏估计：一般对于所有的训练样本，抽取2/3的样本数进行决策树的训练，那么大约有1/3的样本没有被抽取到，由limN-∞ (1-1/N)^N求得。这些样本成为袋外样本，利用这些样本对随机森林中的决策树进行预测误差的估计，称为obb无偏估计。\n\n## 3.霍夫森林(HoughForests)\n\n主要用来进行目标检测，也有人用来进行头部姿态估计。它与随机森林相比，往往还需要每个样本到目标中心的距离值，作为额外的输入。\n\n对于分裂规则：对于样本集合，包括特征、标签以及中心距离，首先生成二值测试特征集，对于当前节点的样本集，选择一个二值测试特征集中的一个特征，将样本集划分为两个子集{0,1}，对于0、1子集，分别随机选择类别不确定规则与位置不确定规则（可进行分类或回归，CART规则）计算总误差。遍历所有的二值测试集中的特征，找到最小的总误差对应的二值测试特征，将当前节点的样本集进行左右划分。此外当达到停止条件时就停止分裂。\n\n## 4.Boosting算法\n\nBoosting算法是一种把若干个分类器整合为一个分类器的方法，在boosting算法产生之前，还出现过两种比较重要的将多个分类器整合为一个分类器的方法，即boostrapping方法和bagging方法。boosting算法的思想受到bootstraping思想和bagging想的启发而产生，大致原理是通过训练多个分类器作为一个模型，提升决策能力。我们先简要介绍一下bootstrapping方法和bagging方法。\n\n(1)boosttraping ：是一种样本抽样方式，对一个样本集N，只采样其中的一部分子样本m个，放入模型中去学习，一般是有放回的抽样。跟随机森林中的样本随机选取一样。\n\n主要步骤：\n\ni)重复地从一个样本集合D中采样n个样本\n\nii)针对每次采样的子样本集，进行统计学习，获得假设Hi\n\niii)将若干个假设进行组合，形成最终的假设Hfinal\n\niv)将最终的假设用于具体的分类任务\n\n(2)bagging：其思想是指对一个样本集N，分别抽样m个子集合，每个子集分别对应一个模型进行训练。最后的输出结果为各个模型的结果投票。即对分类问题，各个类别结果相加取最大，对于回归问题，各模型输出的平均值。\n\n主要思路:\n\ni)训练分类器\n\n从整体样本集合中，抽样n* < N个样本 针对抽样的集合训练分类器Ci。\n　\nii)分类器进行投票，最终的结果是分类器投票的优胜结果。\n\n述这两种方法，都只是将分类器进行简单的组合，实际上，并没有发挥出分类器组合的威力来。直到1989年，Yoav Freund与 Robert Schapire提出了一种可行的将弱分类器组合为强分类器的方法。并由此而获得了2003年的哥德尔奖（Godel price）。\n\nSchapire还提出了一种早期的boosting算法，其主要过程如下：\n\ni)从样本整体集合D中，不放回的随机抽样n1 < n 个样本，得到集合 D1\n\n训练弱分类器C1\n\nii)从样本整体集合D中，抽取 n2 < n 个样本，其中合并进一半被 C1 分类错误的样本。得到样本集合 D2\n　\n训练弱分类器C2\n　\niii)抽取D样本集合中，C1 和 C2 分类不一致样本，组成D3\n\n训练弱分类器C3\n　\niv)用三个分类器做投票，得到最后分类结果\n\n到了1995年，Freund and schapire提出了现在的adaboost算法，其主要框架可以描述为：\n\ni)循环迭代多次\n\n更新样本分布\n　\n寻找当前分布下的最优弱分类器\n\n计算弱分类器误差率\n\nii)聚合多次训练的弱分类器\n\n现在，boost算法有了很大的发展，出现了很多的其他boost算法，例如：logitboost算法，gentleboost算法等等。我们将着重介绍adaboost算法的过程和特性。\n\n## 5.Adaboost算法\n\nAdaboost算法能够进行实际应用的boosting算法。\n\n**Adaboost算法主要步骤：**\n\na.初始化样本的权值为1/n。\n\nb.基于样本与权值训练弱分类器；这里的弱分类器就是个二分类器。\n\nc.根据分类器对样本进行判别，如果判别正确，此样本的权值降低，判别错误，降低样本的权值，同时根据识别率计算出此分类器的权值。\n\nd.利用改变权值的样本训练下一个分类器；\n\ne.循环得到N个分类器与其对应的权值；\n\nf.基于加权的分类器组合成为最终的模型。\n\nAdaboost算法模型简单，不容易过拟合，无需调参，优点挺多。但是其实也是需要根据样本类型来使用。\n\n**Adaboost的特点**\n\n1）每次迭代改变的是样本的分布，而不是重复采样（re weight)\n\n2）样本分布的改变取决于样本是否被正确分类\n\n总是分类正确的样本权值低\n\n总是分类错误的样本权值高（通常是边界附近的样本）\n\n3）最终的结果是弱分类器的加权组合\n\n权值表示该弱分类器的性能\n\n**Adaboost的优点:**\n\n1)adaboost是一种有很高精度的分类器\n\n2)可以使用各种方法构建子分类器，adaboost算法提供的是框架\n\n3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单\n\n4)简单，不用做特征筛选\n\n5)不用担心overfitting！\n\n## 6.多分类Adaboost\n\n在日常任务中，我们通常需要去解决多分类的问题。而前面的介绍中，adaboost算法只能适用于二分类的情况。因此，在这一小节中，我们着重介绍如何将adaboost算法调整到适合处理多分类任务的方法。\n\n目前有三种比较常用的将二分类adaboost方法:\n\n1、adaboost M1方法\n\n主要思路： adaboost组合的若干个弱分类器本身就是多分类的分类器。\n\n在训练的时候，样本权重空间的计算方法不变，在解码的时候，选择一个最有可能的分类\n\n2、adaboost MH方法\n\n主要思路： 组合的弱分类器仍然是二分类的分类器，将分类label和分类样例组合，生成N个样本，在这个新的样本空间上训练分类器。\n\n3、对多分类输出进行二进制编码\n\n主要思路：对N个label进行二进制编码，例如用m位二进制数表示一个label。然后训练m个二分类分类器，在解码时生成m位的二进制数。从而对应到一个label上。\n\n最后，我们可以总结下adaboost算法的一些实际可以使用的场景：\n\n1）用于二分类或多分类的应用场景\n\n2）用于做分类任务的baseline\n　\n无脑化，简单，不会overfitting，不用调分类器\n\n3）用于特征选择（feature selection)\n\n4）Boosting框架用于对badcase的修正\n\n只需要增加新的分类器，不需要变动原有分类器\n\n由于adaboost算法是一种实现简单，应用也很简单的算法。Adaboost算法通过组合弱分类器而得到强分类器，同时具有分类错误率上界随着训练增加而稳定下降，不会过拟合等的性质，应该说是一种很适合于在各种分类场景下应用的算法。\n\n## 7.GBD\n\n误差函数的梯度。根据第一个模型可以写出对应的误差函数，通过最小化误差函数得到第一个模型的参数，此时再加入第二个模型，形成新的误差函数，此时模型一的参数已知了，通过最小化新的误差函数，得到第二个模型的参数。在每次得到的误差函数，对每个模型的参数的导数，为误差函数的梯度。\n\n## 8.GBDT\n\nGBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。\n\nGBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage (算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的。\n\n**DT(回归树)**\n\n决策树分为两大类，回归树和分类树。GBDT中的树都是回归树，不是分类树。回归树总体流程也是类似，不过在每个节点（不一定是叶子节点）都会得一个预测值。\n\n以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差--即（每个人的年龄-预测年龄）^2 的总和 / N，或者说是每个人的预测误差平方和 除以 N。\n\n**GB(梯度迭代)**\n\nGBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。\n\n比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义\n\n那么哪里体现了Gradient呢？其实回到第一棵树结束时想一想，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量(-1, 1, -1, 1)都是它的全局最优方向，这就是Gradient。\n\n讲到这里我们已经把GBDT最核心的概念、运算过程讲完了！没错就是这么简单。不过讲到这里很容易发现三个问题：\n\n1）使用回归决策树和GBDT有时最终效果相同，为何还需要GBDT呢？\n\n答案是过拟合。过拟合是指为了让训练集精度更高，学到了很多”仅在训练集上成立的规律“，导致换一个数据集当前规律就不适用了。其实只要允许一棵树的叶子节点足够多，训练集总是能训练到100%准确率的（大不了最后一个叶子上只有一个instance)。在训练精度和实际精度（或测试精度）之间，后者才是我们想要真正得到的。\n\n2）Gradient呢？不是“G”BDT么？\n\n到目前为止，我们的确没有用到求导的Gradient。在当前版本GBDT描述中，的确没有用到Gradient，该版本用残差作为全局最优的绝对方向，并不需要Gradient求解.\n\n3）这不是boosting吧？Adaboost可不是这么定义的。\n\n这是boosting，但不是Adaboost。GBDT不是Adaboost Decistion Tree。就像提到决策树大家会想起C4.5，提到boost多数人也会想到Adaboost。Adaboost是另一种boost方法，它按分类对错，分配不同的weight，计算cost function时使用这些weight，从而让“错分的样本权重越来越大，使它们更被重视”。Bootstrap也有类似思想，它在每一步迭代时不改变模型本身，也不计算残差，而是从N个instance训练集中按一定概率重新抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮。由于数据集变了迭代模型训练结果也不一样，而一个instance被前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。Adaboost的方法被实践证明是一种很好的防止过拟合的方法，但至于为什么则至今没从理论上被证明。GBDT也可以在使用残差的同时引入Bootstrap re-sampling，GBDT多数实现版本中也增加的这个选项，但是否一定使用则有不同看法。re-sampling一个缺点是它的随机性，即同样的数据集合训练两遍结果是不一样的，也就是模型不可稳定复现，这对评估是很大挑战，比如很难说一个模型变好是因为你选用了更好的feature，还是由于这次sample的随机因素。\n\n**Shrinkage(缩减)**\n\nShrinkage的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight，但和Gradient并没有关系。这个weight就是step。就像Adaboost一样，Shrinkage能减少过拟合发生也是经验证明的，目前还没有看到从理论的证明。\n\n## 9.GBDT的适用范围\n\n该版本GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。\n\n参考：\n\nhttp://baidutech.blog.51cto.com/4114344/743809/\n\nhttp://blog.csdn.net/tianxiaguixin002/article/details/47701881\n\nhttp://blog.csdn.net/w28971023/article/details/8240756","source":"_posts/2016-12-29-决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法.md","raw":"---\nlayout: lay_post\ntitle: \"决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法\"\ndate: 2016-12-29\ncategories: 分类算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n基于树模型的分类与回归算法。\n<!-- more -->\n\n## 1.决策树(Decision Tree,DT)分类算法\n\n决策树是一种常见的分类与回归模型，主要呈树结构，每一个节点代表一个集合，一条边代表一种属性，而叶子节点则表示对应的类别或值。根据节点分裂规则的不同，主要分为三种方法。\n\n**ID3算法**\n\nID3算法采用的是选择一个特征使得分裂前后样本集合的不确定性降低最大，也就是信息增益最大。\n\n计算方式：g(D,A)=H(D)-H(D/A)。H(D)表示分裂前对应样本集合的经验熵，而H(D/A)表示在A特征划分下的样本经验熵，也就是由特征A进行子集划分后的经验熵之和。\n\nID3算法采用信息增益最大的方式，对于一个节点而言，其对应的样本集合如果所有的类别不是一类，且样本集合不为空，逐个选择特征计算信息增益，选择最大的信息增益，如果其信息增益大于阈值，则按照对应的特征进行样本划分（分裂），然后对每个子节点和样本，循环上述的方法，否则停止。\n\n**C4.5算法**\n\nC4.5算法是ID3算法的改进，由于ID3计算方式会导致选择特征时倾向于选择值较多的特征，C4.5引入了信息增益比的方式。即当前特征下计算的信息增益除以此特征对应的经验熵，基于C4.5的决策树的生产方式与上述类似。\n\n剪枝规则：剪枝的思想就是比较当前节点的下对应的整棵决策树的损失函数，与返回到其父节点上对应的损失函数，当父节点下对应的损失函数比子节点下的损失函数更小时，可以进行剪枝，将父节点变为叶子节点，去掉其子节点。至于决策树的损失函数，是各个叶子节点上的经验熵与节点样本数之积的总和，加上a*T，T为叶子节点数。其中前半部分用于表征决策树的训练误差，而a*T则代表了决策树的复杂程度。根据剃刀准则，只有在训练误差足够下的同时，模型也足够简单，这样的模型才是最好的，能够防止过拟合。\n\n**CART算法**\n\nCART算法也是对分裂规则进行改进，可以用来进行分类与回归，能够处理连续的数据。CART分类规则是选择特征A，使得划分前后基尼系数比的降低最大，也就是划分后左右节点的基尼系数之和最小。\n\n在使用CART树进行回归时，可以采用基于方差的形式，由于回归时标签都是连续值，因此使用方差较为合适。即分别挑选一个特征，基于此特征下，逐个遍历特征值，将样本划分为左右子集（2层循环，第一层为特征数，第二层为某个特征对应的取值），计算左右子集的方差之和，找到所有的特征下特征值对应的方差最小的那个特征和特征值，作为划分特征和阈值，进行节点的分裂。CART树的生成方式是二叉树的形式，与上述两种方法有些微不同。但是大体的步骤相同。\n\n剪枝规则：采用的是分别记录由根节点到各个节点下对应的决策树的损失函数序列，找到在设定值a下决策树对训练数据的预测误差最小对应的树结构。\n\n## 2.随机森林(RandomForests/RandomTrees)\n\n随机森林类似bagging思想，对样本进行多次采用，并以此生成多颗决策树，通过投票获得判别结果。\n\n随机森林中的每棵树与决策树的区别：主要包括3点：\n\n1）.样本随机采样:n=2/3*N;就是说对训练样本而言，每棵树从样本集中采用大约2/3的样本进行决策树的训练；\n\n2）.特征随机抽取：k<<K;对于样本集中的特征，不是逐个遍历所有的特征进行划分，而是在所有的特征中随机选择k个特征，从这k个特征中找到最优的划分特征，以此对节点的样本进行划分，因此用过的特征可能还会出现。\n\n3）.无剪枝：由于随机森林在进行训练样本选择时是随机抽样的，选择划分特征时也是随机的，因此不需要进行剪枝。\n\nOBB无偏估计：一般对于所有的训练样本，抽取2/3的样本数进行决策树的训练，那么大约有1/3的样本没有被抽取到，由limN-∞ (1-1/N)^N求得。这些样本成为袋外样本，利用这些样本对随机森林中的决策树进行预测误差的估计，称为obb无偏估计。\n\n## 3.霍夫森林(HoughForests)\n\n主要用来进行目标检测，也有人用来进行头部姿态估计。它与随机森林相比，往往还需要每个样本到目标中心的距离值，作为额外的输入。\n\n对于分裂规则：对于样本集合，包括特征、标签以及中心距离，首先生成二值测试特征集，对于当前节点的样本集，选择一个二值测试特征集中的一个特征，将样本集划分为两个子集{0,1}，对于0、1子集，分别随机选择类别不确定规则与位置不确定规则（可进行分类或回归，CART规则）计算总误差。遍历所有的二值测试集中的特征，找到最小的总误差对应的二值测试特征，将当前节点的样本集进行左右划分。此外当达到停止条件时就停止分裂。\n\n## 4.Boosting算法\n\nBoosting算法是一种把若干个分类器整合为一个分类器的方法，在boosting算法产生之前，还出现过两种比较重要的将多个分类器整合为一个分类器的方法，即boostrapping方法和bagging方法。boosting算法的思想受到bootstraping思想和bagging想的启发而产生，大致原理是通过训练多个分类器作为一个模型，提升决策能力。我们先简要介绍一下bootstrapping方法和bagging方法。\n\n(1)boosttraping ：是一种样本抽样方式，对一个样本集N，只采样其中的一部分子样本m个，放入模型中去学习，一般是有放回的抽样。跟随机森林中的样本随机选取一样。\n\n主要步骤：\n\ni)重复地从一个样本集合D中采样n个样本\n\nii)针对每次采样的子样本集，进行统计学习，获得假设Hi\n\niii)将若干个假设进行组合，形成最终的假设Hfinal\n\niv)将最终的假设用于具体的分类任务\n\n(2)bagging：其思想是指对一个样本集N，分别抽样m个子集合，每个子集分别对应一个模型进行训练。最后的输出结果为各个模型的结果投票。即对分类问题，各个类别结果相加取最大，对于回归问题，各模型输出的平均值。\n\n主要思路:\n\ni)训练分类器\n\n从整体样本集合中，抽样n* < N个样本 针对抽样的集合训练分类器Ci。\n　\nii)分类器进行投票，最终的结果是分类器投票的优胜结果。\n\n述这两种方法，都只是将分类器进行简单的组合，实际上，并没有发挥出分类器组合的威力来。直到1989年，Yoav Freund与 Robert Schapire提出了一种可行的将弱分类器组合为强分类器的方法。并由此而获得了2003年的哥德尔奖（Godel price）。\n\nSchapire还提出了一种早期的boosting算法，其主要过程如下：\n\ni)从样本整体集合D中，不放回的随机抽样n1 < n 个样本，得到集合 D1\n\n训练弱分类器C1\n\nii)从样本整体集合D中，抽取 n2 < n 个样本，其中合并进一半被 C1 分类错误的样本。得到样本集合 D2\n　\n训练弱分类器C2\n　\niii)抽取D样本集合中，C1 和 C2 分类不一致样本，组成D3\n\n训练弱分类器C3\n　\niv)用三个分类器做投票，得到最后分类结果\n\n到了1995年，Freund and schapire提出了现在的adaboost算法，其主要框架可以描述为：\n\ni)循环迭代多次\n\n更新样本分布\n　\n寻找当前分布下的最优弱分类器\n\n计算弱分类器误差率\n\nii)聚合多次训练的弱分类器\n\n现在，boost算法有了很大的发展，出现了很多的其他boost算法，例如：logitboost算法，gentleboost算法等等。我们将着重介绍adaboost算法的过程和特性。\n\n## 5.Adaboost算法\n\nAdaboost算法能够进行实际应用的boosting算法。\n\n**Adaboost算法主要步骤：**\n\na.初始化样本的权值为1/n。\n\nb.基于样本与权值训练弱分类器；这里的弱分类器就是个二分类器。\n\nc.根据分类器对样本进行判别，如果判别正确，此样本的权值降低，判别错误，降低样本的权值，同时根据识别率计算出此分类器的权值。\n\nd.利用改变权值的样本训练下一个分类器；\n\ne.循环得到N个分类器与其对应的权值；\n\nf.基于加权的分类器组合成为最终的模型。\n\nAdaboost算法模型简单，不容易过拟合，无需调参，优点挺多。但是其实也是需要根据样本类型来使用。\n\n**Adaboost的特点**\n\n1）每次迭代改变的是样本的分布，而不是重复采样（re weight)\n\n2）样本分布的改变取决于样本是否被正确分类\n\n总是分类正确的样本权值低\n\n总是分类错误的样本权值高（通常是边界附近的样本）\n\n3）最终的结果是弱分类器的加权组合\n\n权值表示该弱分类器的性能\n\n**Adaboost的优点:**\n\n1)adaboost是一种有很高精度的分类器\n\n2)可以使用各种方法构建子分类器，adaboost算法提供的是框架\n\n3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单\n\n4)简单，不用做特征筛选\n\n5)不用担心overfitting！\n\n## 6.多分类Adaboost\n\n在日常任务中，我们通常需要去解决多分类的问题。而前面的介绍中，adaboost算法只能适用于二分类的情况。因此，在这一小节中，我们着重介绍如何将adaboost算法调整到适合处理多分类任务的方法。\n\n目前有三种比较常用的将二分类adaboost方法:\n\n1、adaboost M1方法\n\n主要思路： adaboost组合的若干个弱分类器本身就是多分类的分类器。\n\n在训练的时候，样本权重空间的计算方法不变，在解码的时候，选择一个最有可能的分类\n\n2、adaboost MH方法\n\n主要思路： 组合的弱分类器仍然是二分类的分类器，将分类label和分类样例组合，生成N个样本，在这个新的样本空间上训练分类器。\n\n3、对多分类输出进行二进制编码\n\n主要思路：对N个label进行二进制编码，例如用m位二进制数表示一个label。然后训练m个二分类分类器，在解码时生成m位的二进制数。从而对应到一个label上。\n\n最后，我们可以总结下adaboost算法的一些实际可以使用的场景：\n\n1）用于二分类或多分类的应用场景\n\n2）用于做分类任务的baseline\n　\n无脑化，简单，不会overfitting，不用调分类器\n\n3）用于特征选择（feature selection)\n\n4）Boosting框架用于对badcase的修正\n\n只需要增加新的分类器，不需要变动原有分类器\n\n由于adaboost算法是一种实现简单，应用也很简单的算法。Adaboost算法通过组合弱分类器而得到强分类器，同时具有分类错误率上界随着训练增加而稳定下降，不会过拟合等的性质，应该说是一种很适合于在各种分类场景下应用的算法。\n\n## 7.GBD\n\n误差函数的梯度。根据第一个模型可以写出对应的误差函数，通过最小化误差函数得到第一个模型的参数，此时再加入第二个模型，形成新的误差函数，此时模型一的参数已知了，通过最小化新的误差函数，得到第二个模型的参数。在每次得到的误差函数，对每个模型的参数的导数，为误差函数的梯度。\n\n## 8.GBDT\n\nGBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。\n\nGBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage (算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的。\n\n**DT(回归树)**\n\n决策树分为两大类，回归树和分类树。GBDT中的树都是回归树，不是分类树。回归树总体流程也是类似，不过在每个节点（不一定是叶子节点）都会得一个预测值。\n\n以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差--即（每个人的年龄-预测年龄）^2 的总和 / N，或者说是每个人的预测误差平方和 除以 N。\n\n**GB(梯度迭代)**\n\nGBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。\n\n比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义\n\n那么哪里体现了Gradient呢？其实回到第一棵树结束时想一想，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量(-1, 1, -1, 1)都是它的全局最优方向，这就是Gradient。\n\n讲到这里我们已经把GBDT最核心的概念、运算过程讲完了！没错就是这么简单。不过讲到这里很容易发现三个问题：\n\n1）使用回归决策树和GBDT有时最终效果相同，为何还需要GBDT呢？\n\n答案是过拟合。过拟合是指为了让训练集精度更高，学到了很多”仅在训练集上成立的规律“，导致换一个数据集当前规律就不适用了。其实只要允许一棵树的叶子节点足够多，训练集总是能训练到100%准确率的（大不了最后一个叶子上只有一个instance)。在训练精度和实际精度（或测试精度）之间，后者才是我们想要真正得到的。\n\n2）Gradient呢？不是“G”BDT么？\n\n到目前为止，我们的确没有用到求导的Gradient。在当前版本GBDT描述中，的确没有用到Gradient，该版本用残差作为全局最优的绝对方向，并不需要Gradient求解.\n\n3）这不是boosting吧？Adaboost可不是这么定义的。\n\n这是boosting，但不是Adaboost。GBDT不是Adaboost Decistion Tree。就像提到决策树大家会想起C4.5，提到boost多数人也会想到Adaboost。Adaboost是另一种boost方法，它按分类对错，分配不同的weight，计算cost function时使用这些weight，从而让“错分的样本权重越来越大，使它们更被重视”。Bootstrap也有类似思想，它在每一步迭代时不改变模型本身，也不计算残差，而是从N个instance训练集中按一定概率重新抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮。由于数据集变了迭代模型训练结果也不一样，而一个instance被前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。Adaboost的方法被实践证明是一种很好的防止过拟合的方法，但至于为什么则至今没从理论上被证明。GBDT也可以在使用残差的同时引入Bootstrap re-sampling，GBDT多数实现版本中也增加的这个选项，但是否一定使用则有不同看法。re-sampling一个缺点是它的随机性，即同样的数据集合训练两遍结果是不一样的，也就是模型不可稳定复现，这对评估是很大挑战，比如很难说一个模型变好是因为你选用了更好的feature，还是由于这次sample的随机因素。\n\n**Shrinkage(缩减)**\n\nShrinkage的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight，但和Gradient并没有关系。这个weight就是step。就像Adaboost一样，Shrinkage能减少过拟合发生也是经验证明的，目前还没有看到从理论的证明。\n\n## 9.GBDT的适用范围\n\n该版本GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。\n\n参考：\n\nhttp://baidutech.blog.51cto.com/4114344/743809/\n\nhttp://blog.csdn.net/tianxiaguixin002/article/details/47701881\n\nhttp://blog.csdn.net/w28971023/article/details/8240756","slug":"2016-12-29-决策树-随机森林-Boosting-Adaboost-GBDT由决策树衍生的分类算法","published":1,"updated":"2018-11-29T12:51:25.187Z","comments":1,"photos":[],"link":"","_id":"cjskffob6004o4glm0zxyws76","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>基于树模型的分类与回归算法。<br><a id=\"more\"></a></p>\n<h2 id=\"1-决策树-Decision-Tree-DT-分类算法\"><a href=\"#1-决策树-Decision-Tree-DT-分类算法\" class=\"headerlink\" title=\"1.决策树(Decision Tree,DT)分类算法\"></a>1.决策树(Decision Tree,DT)分类算法</h2><p>决策树是一种常见的分类与回归模型，主要呈树结构，每一个节点代表一个集合，一条边代表一种属性，而叶子节点则表示对应的类别或值。根据节点分裂规则的不同，主要分为三种方法。</p>\n<p><strong>ID3算法</strong></p>\n<p>ID3算法采用的是选择一个特征使得分裂前后样本集合的不确定性降低最大，也就是信息增益最大。</p>\n<p>计算方式：g(D,A)=H(D)-H(D/A)。H(D)表示分裂前对应样本集合的经验熵，而H(D/A)表示在A特征划分下的样本经验熵，也就是由特征A进行子集划分后的经验熵之和。</p>\n<p>ID3算法采用信息增益最大的方式，对于一个节点而言，其对应的样本集合如果所有的类别不是一类，且样本集合不为空，逐个选择特征计算信息增益，选择最大的信息增益，如果其信息增益大于阈值，则按照对应的特征进行样本划分（分裂），然后对每个子节点和样本，循环上述的方法，否则停止。</p>\n<p><strong>C4.5算法</strong></p>\n<p>C4.5算法是ID3算法的改进，由于ID3计算方式会导致选择特征时倾向于选择值较多的特征，C4.5引入了信息增益比的方式。即当前特征下计算的信息增益除以此特征对应的经验熵，基于C4.5的决策树的生产方式与上述类似。</p>\n<p>剪枝规则：剪枝的思想就是比较当前节点的下对应的整棵决策树的损失函数，与返回到其父节点上对应的损失函数，当父节点下对应的损失函数比子节点下的损失函数更小时，可以进行剪枝，将父节点变为叶子节点，去掉其子节点。至于决策树的损失函数，是各个叶子节点上的经验熵与节点样本数之积的总和，加上a<em>T，T为叶子节点数。其中前半部分用于表征决策树的训练误差，而a</em>T则代表了决策树的复杂程度。根据剃刀准则，只有在训练误差足够下的同时，模型也足够简单，这样的模型才是最好的，能够防止过拟合。</p>\n<p><strong>CART算法</strong></p>\n<p>CART算法也是对分裂规则进行改进，可以用来进行分类与回归，能够处理连续的数据。CART分类规则是选择特征A，使得划分前后基尼系数比的降低最大，也就是划分后左右节点的基尼系数之和最小。</p>\n<p>在使用CART树进行回归时，可以采用基于方差的形式，由于回归时标签都是连续值，因此使用方差较为合适。即分别挑选一个特征，基于此特征下，逐个遍历特征值，将样本划分为左右子集（2层循环，第一层为特征数，第二层为某个特征对应的取值），计算左右子集的方差之和，找到所有的特征下特征值对应的方差最小的那个特征和特征值，作为划分特征和阈值，进行节点的分裂。CART树的生成方式是二叉树的形式，与上述两种方法有些微不同。但是大体的步骤相同。</p>\n<p>剪枝规则：采用的是分别记录由根节点到各个节点下对应的决策树的损失函数序列，找到在设定值a下决策树对训练数据的预测误差最小对应的树结构。</p>\n<h2 id=\"2-随机森林-RandomForests-RandomTrees\"><a href=\"#2-随机森林-RandomForests-RandomTrees\" class=\"headerlink\" title=\"2.随机森林(RandomForests/RandomTrees)\"></a>2.随机森林(RandomForests/RandomTrees)</h2><p>随机森林类似bagging思想，对样本进行多次采用，并以此生成多颗决策树，通过投票获得判别结果。</p>\n<p>随机森林中的每棵树与决策树的区别：主要包括3点：</p>\n<p>1）.样本随机采样:n=2/3*N;就是说对训练样本而言，每棵树从样本集中采用大约2/3的样本进行决策树的训练；</p>\n<p>2）.特征随机抽取：k&lt;&lt;K;对于样本集中的特征，不是逐个遍历所有的特征进行划分，而是在所有的特征中随机选择k个特征，从这k个特征中找到最优的划分特征，以此对节点的样本进行划分，因此用过的特征可能还会出现。</p>\n<p>3）.无剪枝：由于随机森林在进行训练样本选择时是随机抽样的，选择划分特征时也是随机的，因此不需要进行剪枝。</p>\n<p>OBB无偏估计：一般对于所有的训练样本，抽取2/3的样本数进行决策树的训练，那么大约有1/3的样本没有被抽取到，由limN-∞ (1-1/N)^N求得。这些样本成为袋外样本，利用这些样本对随机森林中的决策树进行预测误差的估计，称为obb无偏估计。</p>\n<h2 id=\"3-霍夫森林-HoughForests\"><a href=\"#3-霍夫森林-HoughForests\" class=\"headerlink\" title=\"3.霍夫森林(HoughForests)\"></a>3.霍夫森林(HoughForests)</h2><p>主要用来进行目标检测，也有人用来进行头部姿态估计。它与随机森林相比，往往还需要每个样本到目标中心的距离值，作为额外的输入。</p>\n<p>对于分裂规则：对于样本集合，包括特征、标签以及中心距离，首先生成二值测试特征集，对于当前节点的样本集，选择一个二值测试特征集中的一个特征，将样本集划分为两个子集{0,1}，对于0、1子集，分别随机选择类别不确定规则与位置不确定规则（可进行分类或回归，CART规则）计算总误差。遍历所有的二值测试集中的特征，找到最小的总误差对应的二值测试特征，将当前节点的样本集进行左右划分。此外当达到停止条件时就停止分裂。</p>\n<h2 id=\"4-Boosting算法\"><a href=\"#4-Boosting算法\" class=\"headerlink\" title=\"4.Boosting算法\"></a>4.Boosting算法</h2><p>Boosting算法是一种把若干个分类器整合为一个分类器的方法，在boosting算法产生之前，还出现过两种比较重要的将多个分类器整合为一个分类器的方法，即boostrapping方法和bagging方法。boosting算法的思想受到bootstraping思想和bagging想的启发而产生，大致原理是通过训练多个分类器作为一个模型，提升决策能力。我们先简要介绍一下bootstrapping方法和bagging方法。</p>\n<p>(1)boosttraping ：是一种样本抽样方式，对一个样本集N，只采样其中的一部分子样本m个，放入模型中去学习，一般是有放回的抽样。跟随机森林中的样本随机选取一样。</p>\n<p>主要步骤：</p>\n<p>i)重复地从一个样本集合D中采样n个样本</p>\n<p>ii)针对每次采样的子样本集，进行统计学习，获得假设Hi</p>\n<p>iii)将若干个假设进行组合，形成最终的假设Hfinal</p>\n<p>iv)将最终的假设用于具体的分类任务</p>\n<p>(2)bagging：其思想是指对一个样本集N，分别抽样m个子集合，每个子集分别对应一个模型进行训练。最后的输出结果为各个模型的结果投票。即对分类问题，各个类别结果相加取最大，对于回归问题，各模型输出的平均值。</p>\n<p>主要思路:</p>\n<p>i)训练分类器</p>\n<p>从整体样本集合中，抽样n* &lt; N个样本 针对抽样的集合训练分类器Ci。<br>　<br>ii)分类器进行投票，最终的结果是分类器投票的优胜结果。</p>\n<p>述这两种方法，都只是将分类器进行简单的组合，实际上，并没有发挥出分类器组合的威力来。直到1989年，Yoav Freund与 Robert Schapire提出了一种可行的将弱分类器组合为强分类器的方法。并由此而获得了2003年的哥德尔奖（Godel price）。</p>\n<p>Schapire还提出了一种早期的boosting算法，其主要过程如下：</p>\n<p>i)从样本整体集合D中，不放回的随机抽样n1 &lt; n 个样本，得到集合 D1</p>\n<p>训练弱分类器C1</p>\n<p>ii)从样本整体集合D中，抽取 n2 &lt; n 个样本，其中合并进一半被 C1 分类错误的样本。得到样本集合 D2<br>　<br>训练弱分类器C2<br>　<br>iii)抽取D样本集合中，C1 和 C2 分类不一致样本，组成D3</p>\n<p>训练弱分类器C3<br>　<br>iv)用三个分类器做投票，得到最后分类结果</p>\n<p>到了1995年，Freund and schapire提出了现在的adaboost算法，其主要框架可以描述为：</p>\n<p>i)循环迭代多次</p>\n<p>更新样本分布<br>　<br>寻找当前分布下的最优弱分类器</p>\n<p>计算弱分类器误差率</p>\n<p>ii)聚合多次训练的弱分类器</p>\n<p>现在，boost算法有了很大的发展，出现了很多的其他boost算法，例如：logitboost算法，gentleboost算法等等。我们将着重介绍adaboost算法的过程和特性。</p>\n<h2 id=\"5-Adaboost算法\"><a href=\"#5-Adaboost算法\" class=\"headerlink\" title=\"5.Adaboost算法\"></a>5.Adaboost算法</h2><p>Adaboost算法能够进行实际应用的boosting算法。</p>\n<p><strong>Adaboost算法主要步骤：</strong></p>\n<p>a.初始化样本的权值为1/n。</p>\n<p>b.基于样本与权值训练弱分类器；这里的弱分类器就是个二分类器。</p>\n<p>c.根据分类器对样本进行判别，如果判别正确，此样本的权值降低，判别错误，降低样本的权值，同时根据识别率计算出此分类器的权值。</p>\n<p>d.利用改变权值的样本训练下一个分类器；</p>\n<p>e.循环得到N个分类器与其对应的权值；</p>\n<p>f.基于加权的分类器组合成为最终的模型。</p>\n<p>Adaboost算法模型简单，不容易过拟合，无需调参，优点挺多。但是其实也是需要根据样本类型来使用。</p>\n<p><strong>Adaboost的特点</strong></p>\n<p>1）每次迭代改变的是样本的分布，而不是重复采样（re weight)</p>\n<p>2）样本分布的改变取决于样本是否被正确分类</p>\n<p>总是分类正确的样本权值低</p>\n<p>总是分类错误的样本权值高（通常是边界附近的样本）</p>\n<p>3）最终的结果是弱分类器的加权组合</p>\n<p>权值表示该弱分类器的性能</p>\n<p><strong>Adaboost的优点:</strong></p>\n<p>1)adaboost是一种有很高精度的分类器</p>\n<p>2)可以使用各种方法构建子分类器，adaboost算法提供的是框架</p>\n<p>3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单</p>\n<p>4)简单，不用做特征筛选</p>\n<p>5)不用担心overfitting！</p>\n<h2 id=\"6-多分类Adaboost\"><a href=\"#6-多分类Adaboost\" class=\"headerlink\" title=\"6.多分类Adaboost\"></a>6.多分类Adaboost</h2><p>在日常任务中，我们通常需要去解决多分类的问题。而前面的介绍中，adaboost算法只能适用于二分类的情况。因此，在这一小节中，我们着重介绍如何将adaboost算法调整到适合处理多分类任务的方法。</p>\n<p>目前有三种比较常用的将二分类adaboost方法:</p>\n<p>1、adaboost M1方法</p>\n<p>主要思路： adaboost组合的若干个弱分类器本身就是多分类的分类器。</p>\n<p>在训练的时候，样本权重空间的计算方法不变，在解码的时候，选择一个最有可能的分类</p>\n<p>2、adaboost MH方法</p>\n<p>主要思路： 组合的弱分类器仍然是二分类的分类器，将分类label和分类样例组合，生成N个样本，在这个新的样本空间上训练分类器。</p>\n<p>3、对多分类输出进行二进制编码</p>\n<p>主要思路：对N个label进行二进制编码，例如用m位二进制数表示一个label。然后训练m个二分类分类器，在解码时生成m位的二进制数。从而对应到一个label上。</p>\n<p>最后，我们可以总结下adaboost算法的一些实际可以使用的场景：</p>\n<p>1）用于二分类或多分类的应用场景</p>\n<p>2）用于做分类任务的baseline<br>　<br>无脑化，简单，不会overfitting，不用调分类器</p>\n<p>3）用于特征选择（feature selection)</p>\n<p>4）Boosting框架用于对badcase的修正</p>\n<p>只需要增加新的分类器，不需要变动原有分类器</p>\n<p>由于adaboost算法是一种实现简单，应用也很简单的算法。Adaboost算法通过组合弱分类器而得到强分类器，同时具有分类错误率上界随着训练增加而稳定下降，不会过拟合等的性质，应该说是一种很适合于在各种分类场景下应用的算法。</p>\n<h2 id=\"7-GBD\"><a href=\"#7-GBD\" class=\"headerlink\" title=\"7.GBD\"></a>7.GBD</h2><p>误差函数的梯度。根据第一个模型可以写出对应的误差函数，通过最小化误差函数得到第一个模型的参数，此时再加入第二个模型，形成新的误差函数，此时模型一的参数已知了，通过最小化新的误差函数，得到第二个模型的参数。在每次得到的误差函数，对每个模型的参数的导数，为误差函数的梯度。</p>\n<h2 id=\"8-GBDT\"><a href=\"#8-GBDT\" class=\"headerlink\" title=\"8.GBDT\"></a>8.GBDT</h2><p>GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。</p>\n<p>GBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage (算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的。</p>\n<p><strong>DT(回归树)</strong></p>\n<p>决策树分为两大类，回归树和分类树。GBDT中的树都是回归树，不是分类树。回归树总体流程也是类似，不过在每个节点（不一定是叶子节点）都会得一个预测值。</p>\n<p>以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差–即（每个人的年龄-预测年龄）^2 的总和 / N，或者说是每个人的预测误差平方和 除以 N。</p>\n<p><strong>GB(梯度迭代)</strong></p>\n<p>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。</p>\n<p>比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义</p>\n<p>那么哪里体现了Gradient呢？其实回到第一棵树结束时想一想，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量(-1, 1, -1, 1)都是它的全局最优方向，这就是Gradient。</p>\n<p>讲到这里我们已经把GBDT最核心的概念、运算过程讲完了！没错就是这么简单。不过讲到这里很容易发现三个问题：</p>\n<p>1）使用回归决策树和GBDT有时最终效果相同，为何还需要GBDT呢？</p>\n<p>答案是过拟合。过拟合是指为了让训练集精度更高，学到了很多”仅在训练集上成立的规律“，导致换一个数据集当前规律就不适用了。其实只要允许一棵树的叶子节点足够多，训练集总是能训练到100%准确率的（大不了最后一个叶子上只有一个instance)。在训练精度和实际精度（或测试精度）之间，后者才是我们想要真正得到的。</p>\n<p>2）Gradient呢？不是“G”BDT么？</p>\n<p>到目前为止，我们的确没有用到求导的Gradient。在当前版本GBDT描述中，的确没有用到Gradient，该版本用残差作为全局最优的绝对方向，并不需要Gradient求解.</p>\n<p>3）这不是boosting吧？Adaboost可不是这么定义的。</p>\n<p>这是boosting，但不是Adaboost。GBDT不是Adaboost Decistion Tree。就像提到决策树大家会想起C4.5，提到boost多数人也会想到Adaboost。Adaboost是另一种boost方法，它按分类对错，分配不同的weight，计算cost function时使用这些weight，从而让“错分的样本权重越来越大，使它们更被重视”。Bootstrap也有类似思想，它在每一步迭代时不改变模型本身，也不计算残差，而是从N个instance训练集中按一定概率重新抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮。由于数据集变了迭代模型训练结果也不一样，而一个instance被前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。Adaboost的方法被实践证明是一种很好的防止过拟合的方法，但至于为什么则至今没从理论上被证明。GBDT也可以在使用残差的同时引入Bootstrap re-sampling，GBDT多数实现版本中也增加的这个选项，但是否一定使用则有不同看法。re-sampling一个缺点是它的随机性，即同样的数据集合训练两遍结果是不一样的，也就是模型不可稳定复现，这对评估是很大挑战，比如很难说一个模型变好是因为你选用了更好的feature，还是由于这次sample的随机因素。</p>\n<p><strong>Shrinkage(缩减)</strong></p>\n<p>Shrinkage的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight，但和Gradient并没有关系。这个weight就是step。就像Adaboost一样，Shrinkage能减少过拟合发生也是经验证明的，目前还没有看到从理论的证明。</p>\n<h2 id=\"9-GBDT的适用范围\"><a href=\"#9-GBDT的适用范围\" class=\"headerlink\" title=\"9.GBDT的适用范围\"></a>9.GBDT的适用范围</h2><p>该版本GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。</p>\n<p>参考：</p>\n<p><a href=\"http://baidutech.blog.51cto.com/4114344/743809/\" target=\"_blank\" rel=\"noopener\">http://baidutech.blog.51cto.com/4114344/743809/</a></p>\n<p><a href=\"http://blog.csdn.net/tianxiaguixin002/article/details/47701881\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tianxiaguixin002/article/details/47701881</a></p>\n<p><a href=\"http://blog.csdn.net/w28971023/article/details/8240756\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/w28971023/article/details/8240756</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>基于树模型的分类与回归算法。<br>","more":"</p>\n<h2 id=\"1-决策树-Decision-Tree-DT-分类算法\"><a href=\"#1-决策树-Decision-Tree-DT-分类算法\" class=\"headerlink\" title=\"1.决策树(Decision Tree,DT)分类算法\"></a>1.决策树(Decision Tree,DT)分类算法</h2><p>决策树是一种常见的分类与回归模型，主要呈树结构，每一个节点代表一个集合，一条边代表一种属性，而叶子节点则表示对应的类别或值。根据节点分裂规则的不同，主要分为三种方法。</p>\n<p><strong>ID3算法</strong></p>\n<p>ID3算法采用的是选择一个特征使得分裂前后样本集合的不确定性降低最大，也就是信息增益最大。</p>\n<p>计算方式：g(D,A)=H(D)-H(D/A)。H(D)表示分裂前对应样本集合的经验熵，而H(D/A)表示在A特征划分下的样本经验熵，也就是由特征A进行子集划分后的经验熵之和。</p>\n<p>ID3算法采用信息增益最大的方式，对于一个节点而言，其对应的样本集合如果所有的类别不是一类，且样本集合不为空，逐个选择特征计算信息增益，选择最大的信息增益，如果其信息增益大于阈值，则按照对应的特征进行样本划分（分裂），然后对每个子节点和样本，循环上述的方法，否则停止。</p>\n<p><strong>C4.5算法</strong></p>\n<p>C4.5算法是ID3算法的改进，由于ID3计算方式会导致选择特征时倾向于选择值较多的特征，C4.5引入了信息增益比的方式。即当前特征下计算的信息增益除以此特征对应的经验熵，基于C4.5的决策树的生产方式与上述类似。</p>\n<p>剪枝规则：剪枝的思想就是比较当前节点的下对应的整棵决策树的损失函数，与返回到其父节点上对应的损失函数，当父节点下对应的损失函数比子节点下的损失函数更小时，可以进行剪枝，将父节点变为叶子节点，去掉其子节点。至于决策树的损失函数，是各个叶子节点上的经验熵与节点样本数之积的总和，加上a<em>T，T为叶子节点数。其中前半部分用于表征决策树的训练误差，而a</em>T则代表了决策树的复杂程度。根据剃刀准则，只有在训练误差足够下的同时，模型也足够简单，这样的模型才是最好的，能够防止过拟合。</p>\n<p><strong>CART算法</strong></p>\n<p>CART算法也是对分裂规则进行改进，可以用来进行分类与回归，能够处理连续的数据。CART分类规则是选择特征A，使得划分前后基尼系数比的降低最大，也就是划分后左右节点的基尼系数之和最小。</p>\n<p>在使用CART树进行回归时，可以采用基于方差的形式，由于回归时标签都是连续值，因此使用方差较为合适。即分别挑选一个特征，基于此特征下，逐个遍历特征值，将样本划分为左右子集（2层循环，第一层为特征数，第二层为某个特征对应的取值），计算左右子集的方差之和，找到所有的特征下特征值对应的方差最小的那个特征和特征值，作为划分特征和阈值，进行节点的分裂。CART树的生成方式是二叉树的形式，与上述两种方法有些微不同。但是大体的步骤相同。</p>\n<p>剪枝规则：采用的是分别记录由根节点到各个节点下对应的决策树的损失函数序列，找到在设定值a下决策树对训练数据的预测误差最小对应的树结构。</p>\n<h2 id=\"2-随机森林-RandomForests-RandomTrees\"><a href=\"#2-随机森林-RandomForests-RandomTrees\" class=\"headerlink\" title=\"2.随机森林(RandomForests/RandomTrees)\"></a>2.随机森林(RandomForests/RandomTrees)</h2><p>随机森林类似bagging思想，对样本进行多次采用，并以此生成多颗决策树，通过投票获得判别结果。</p>\n<p>随机森林中的每棵树与决策树的区别：主要包括3点：</p>\n<p>1）.样本随机采样:n=2/3*N;就是说对训练样本而言，每棵树从样本集中采用大约2/3的样本进行决策树的训练；</p>\n<p>2）.特征随机抽取：k&lt;&lt;K;对于样本集中的特征，不是逐个遍历所有的特征进行划分，而是在所有的特征中随机选择k个特征，从这k个特征中找到最优的划分特征，以此对节点的样本进行划分，因此用过的特征可能还会出现。</p>\n<p>3）.无剪枝：由于随机森林在进行训练样本选择时是随机抽样的，选择划分特征时也是随机的，因此不需要进行剪枝。</p>\n<p>OBB无偏估计：一般对于所有的训练样本，抽取2/3的样本数进行决策树的训练，那么大约有1/3的样本没有被抽取到，由limN-∞ (1-1/N)^N求得。这些样本成为袋外样本，利用这些样本对随机森林中的决策树进行预测误差的估计，称为obb无偏估计。</p>\n<h2 id=\"3-霍夫森林-HoughForests\"><a href=\"#3-霍夫森林-HoughForests\" class=\"headerlink\" title=\"3.霍夫森林(HoughForests)\"></a>3.霍夫森林(HoughForests)</h2><p>主要用来进行目标检测，也有人用来进行头部姿态估计。它与随机森林相比，往往还需要每个样本到目标中心的距离值，作为额外的输入。</p>\n<p>对于分裂规则：对于样本集合，包括特征、标签以及中心距离，首先生成二值测试特征集，对于当前节点的样本集，选择一个二值测试特征集中的一个特征，将样本集划分为两个子集{0,1}，对于0、1子集，分别随机选择类别不确定规则与位置不确定规则（可进行分类或回归，CART规则）计算总误差。遍历所有的二值测试集中的特征，找到最小的总误差对应的二值测试特征，将当前节点的样本集进行左右划分。此外当达到停止条件时就停止分裂。</p>\n<h2 id=\"4-Boosting算法\"><a href=\"#4-Boosting算法\" class=\"headerlink\" title=\"4.Boosting算法\"></a>4.Boosting算法</h2><p>Boosting算法是一种把若干个分类器整合为一个分类器的方法，在boosting算法产生之前，还出现过两种比较重要的将多个分类器整合为一个分类器的方法，即boostrapping方法和bagging方法。boosting算法的思想受到bootstraping思想和bagging想的启发而产生，大致原理是通过训练多个分类器作为一个模型，提升决策能力。我们先简要介绍一下bootstrapping方法和bagging方法。</p>\n<p>(1)boosttraping ：是一种样本抽样方式，对一个样本集N，只采样其中的一部分子样本m个，放入模型中去学习，一般是有放回的抽样。跟随机森林中的样本随机选取一样。</p>\n<p>主要步骤：</p>\n<p>i)重复地从一个样本集合D中采样n个样本</p>\n<p>ii)针对每次采样的子样本集，进行统计学习，获得假设Hi</p>\n<p>iii)将若干个假设进行组合，形成最终的假设Hfinal</p>\n<p>iv)将最终的假设用于具体的分类任务</p>\n<p>(2)bagging：其思想是指对一个样本集N，分别抽样m个子集合，每个子集分别对应一个模型进行训练。最后的输出结果为各个模型的结果投票。即对分类问题，各个类别结果相加取最大，对于回归问题，各模型输出的平均值。</p>\n<p>主要思路:</p>\n<p>i)训练分类器</p>\n<p>从整体样本集合中，抽样n* &lt; N个样本 针对抽样的集合训练分类器Ci。<br>　<br>ii)分类器进行投票，最终的结果是分类器投票的优胜结果。</p>\n<p>述这两种方法，都只是将分类器进行简单的组合，实际上，并没有发挥出分类器组合的威力来。直到1989年，Yoav Freund与 Robert Schapire提出了一种可行的将弱分类器组合为强分类器的方法。并由此而获得了2003年的哥德尔奖（Godel price）。</p>\n<p>Schapire还提出了一种早期的boosting算法，其主要过程如下：</p>\n<p>i)从样本整体集合D中，不放回的随机抽样n1 &lt; n 个样本，得到集合 D1</p>\n<p>训练弱分类器C1</p>\n<p>ii)从样本整体集合D中，抽取 n2 &lt; n 个样本，其中合并进一半被 C1 分类错误的样本。得到样本集合 D2<br>　<br>训练弱分类器C2<br>　<br>iii)抽取D样本集合中，C1 和 C2 分类不一致样本，组成D3</p>\n<p>训练弱分类器C3<br>　<br>iv)用三个分类器做投票，得到最后分类结果</p>\n<p>到了1995年，Freund and schapire提出了现在的adaboost算法，其主要框架可以描述为：</p>\n<p>i)循环迭代多次</p>\n<p>更新样本分布<br>　<br>寻找当前分布下的最优弱分类器</p>\n<p>计算弱分类器误差率</p>\n<p>ii)聚合多次训练的弱分类器</p>\n<p>现在，boost算法有了很大的发展，出现了很多的其他boost算法，例如：logitboost算法，gentleboost算法等等。我们将着重介绍adaboost算法的过程和特性。</p>\n<h2 id=\"5-Adaboost算法\"><a href=\"#5-Adaboost算法\" class=\"headerlink\" title=\"5.Adaboost算法\"></a>5.Adaboost算法</h2><p>Adaboost算法能够进行实际应用的boosting算法。</p>\n<p><strong>Adaboost算法主要步骤：</strong></p>\n<p>a.初始化样本的权值为1/n。</p>\n<p>b.基于样本与权值训练弱分类器；这里的弱分类器就是个二分类器。</p>\n<p>c.根据分类器对样本进行判别，如果判别正确，此样本的权值降低，判别错误，降低样本的权值，同时根据识别率计算出此分类器的权值。</p>\n<p>d.利用改变权值的样本训练下一个分类器；</p>\n<p>e.循环得到N个分类器与其对应的权值；</p>\n<p>f.基于加权的分类器组合成为最终的模型。</p>\n<p>Adaboost算法模型简单，不容易过拟合，无需调参，优点挺多。但是其实也是需要根据样本类型来使用。</p>\n<p><strong>Adaboost的特点</strong></p>\n<p>1）每次迭代改变的是样本的分布，而不是重复采样（re weight)</p>\n<p>2）样本分布的改变取决于样本是否被正确分类</p>\n<p>总是分类正确的样本权值低</p>\n<p>总是分类错误的样本权值高（通常是边界附近的样本）</p>\n<p>3）最终的结果是弱分类器的加权组合</p>\n<p>权值表示该弱分类器的性能</p>\n<p><strong>Adaboost的优点:</strong></p>\n<p>1)adaboost是一种有很高精度的分类器</p>\n<p>2)可以使用各种方法构建子分类器，adaboost算法提供的是框架</p>\n<p>3)当使用简单分类器时，计算出的结果是可以理解的。而且弱分类器构造极其简单</p>\n<p>4)简单，不用做特征筛选</p>\n<p>5)不用担心overfitting！</p>\n<h2 id=\"6-多分类Adaboost\"><a href=\"#6-多分类Adaboost\" class=\"headerlink\" title=\"6.多分类Adaboost\"></a>6.多分类Adaboost</h2><p>在日常任务中，我们通常需要去解决多分类的问题。而前面的介绍中，adaboost算法只能适用于二分类的情况。因此，在这一小节中，我们着重介绍如何将adaboost算法调整到适合处理多分类任务的方法。</p>\n<p>目前有三种比较常用的将二分类adaboost方法:</p>\n<p>1、adaboost M1方法</p>\n<p>主要思路： adaboost组合的若干个弱分类器本身就是多分类的分类器。</p>\n<p>在训练的时候，样本权重空间的计算方法不变，在解码的时候，选择一个最有可能的分类</p>\n<p>2、adaboost MH方法</p>\n<p>主要思路： 组合的弱分类器仍然是二分类的分类器，将分类label和分类样例组合，生成N个样本，在这个新的样本空间上训练分类器。</p>\n<p>3、对多分类输出进行二进制编码</p>\n<p>主要思路：对N个label进行二进制编码，例如用m位二进制数表示一个label。然后训练m个二分类分类器，在解码时生成m位的二进制数。从而对应到一个label上。</p>\n<p>最后，我们可以总结下adaboost算法的一些实际可以使用的场景：</p>\n<p>1）用于二分类或多分类的应用场景</p>\n<p>2）用于做分类任务的baseline<br>　<br>无脑化，简单，不会overfitting，不用调分类器</p>\n<p>3）用于特征选择（feature selection)</p>\n<p>4）Boosting框架用于对badcase的修正</p>\n<p>只需要增加新的分类器，不需要变动原有分类器</p>\n<p>由于adaboost算法是一种实现简单，应用也很简单的算法。Adaboost算法通过组合弱分类器而得到强分类器，同时具有分类错误率上界随着训练增加而稳定下降，不会过拟合等的性质，应该说是一种很适合于在各种分类场景下应用的算法。</p>\n<h2 id=\"7-GBD\"><a href=\"#7-GBD\" class=\"headerlink\" title=\"7.GBD\"></a>7.GBD</h2><p>误差函数的梯度。根据第一个模型可以写出对应的误差函数，通过最小化误差函数得到第一个模型的参数，此时再加入第二个模型，形成新的误差函数，此时模型一的参数已知了，通过最小化新的误差函数，得到第二个模型的参数。在每次得到的误差函数，对每个模型的参数的导数，为误差函数的梯度。</p>\n<h2 id=\"8-GBDT\"><a href=\"#8-GBDT\" class=\"headerlink\" title=\"8.GBDT\"></a>8.GBDT</h2><p>GBDT(Gradient Boosting Decision Tree) 又叫 MART（Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。</p>\n<p>GBDT主要由三个概念组成：Regression Decistion Tree（即DT)，Gradient Boosting（即GB)，Shrinkage (算法的一个重要演进分枝，目前大部分源码都按该版本实现）。搞定这三个概念后就能明白GBDT是如何工作的。</p>\n<p><strong>DT(回归树)</strong></p>\n<p>决策树分为两大类，回归树和分类树。GBDT中的树都是回归树，不是分类树。回归树总体流程也是类似，不过在每个节点（不一定是叶子节点）都会得一个预测值。</p>\n<p>以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化均方差–即（每个人的年龄-预测年龄）^2 的总和 / N，或者说是每个人的预测误差平方和 除以 N。</p>\n<p><strong>GB(梯度迭代)</strong></p>\n<p>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量。</p>\n<p>比如A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。这就是Gradient Boosting在GBDT中的意义</p>\n<p>那么哪里体现了Gradient呢？其实回到第一棵树结束时想一想，无论此时的cost function是什么，是均方差还是均差，只要它以误差作为衡量标准，残差向量(-1, 1, -1, 1)都是它的全局最优方向，这就是Gradient。</p>\n<p>讲到这里我们已经把GBDT最核心的概念、运算过程讲完了！没错就是这么简单。不过讲到这里很容易发现三个问题：</p>\n<p>1）使用回归决策树和GBDT有时最终效果相同，为何还需要GBDT呢？</p>\n<p>答案是过拟合。过拟合是指为了让训练集精度更高，学到了很多”仅在训练集上成立的规律“，导致换一个数据集当前规律就不适用了。其实只要允许一棵树的叶子节点足够多，训练集总是能训练到100%准确率的（大不了最后一个叶子上只有一个instance)。在训练精度和实际精度（或测试精度）之间，后者才是我们想要真正得到的。</p>\n<p>2）Gradient呢？不是“G”BDT么？</p>\n<p>到目前为止，我们的确没有用到求导的Gradient。在当前版本GBDT描述中，的确没有用到Gradient，该版本用残差作为全局最优的绝对方向，并不需要Gradient求解.</p>\n<p>3）这不是boosting吧？Adaboost可不是这么定义的。</p>\n<p>这是boosting，但不是Adaboost。GBDT不是Adaboost Decistion Tree。就像提到决策树大家会想起C4.5，提到boost多数人也会想到Adaboost。Adaboost是另一种boost方法，它按分类对错，分配不同的weight，计算cost function时使用这些weight，从而让“错分的样本权重越来越大，使它们更被重视”。Bootstrap也有类似思想，它在每一步迭代时不改变模型本身，也不计算残差，而是从N个instance训练集中按一定概率重新抽取N个instance出来（单个instance可以被重复sample），对着这N个新的instance再训练一轮。由于数据集变了迭代模型训练结果也不一样，而一个instance被前面分错的越厉害，它的概率就被设的越高，这样就能同样达到逐步关注被分错的instance，逐步完善的效果。Adaboost的方法被实践证明是一种很好的防止过拟合的方法，但至于为什么则至今没从理论上被证明。GBDT也可以在使用残差的同时引入Bootstrap re-sampling，GBDT多数实现版本中也增加的这个选项，但是否一定使用则有不同看法。re-sampling一个缺点是它的随机性，即同样的数据集合训练两遍结果是不一样的，也就是模型不可稳定复现，这对评估是很大挑战，比如很难说一个模型变好是因为你选用了更好的feature，还是由于这次sample的随机因素。</p>\n<p><strong>Shrinkage(缩减)</strong></p>\n<p>Shrinkage的思想认为，每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。本质上，Shrinkage为每棵树设置了一个weight，累加时要乘以这个weight，但和Gradient并没有关系。这个weight就是step。就像Adaboost一样，Shrinkage能减少过拟合发生也是经验证明的，目前还没有看到从理论的证明。</p>\n<h2 id=\"9-GBDT的适用范围\"><a href=\"#9-GBDT的适用范围\" class=\"headerlink\" title=\"9.GBDT的适用范围\"></a>9.GBDT的适用范围</h2><p>该版本GBDT几乎可用于所有回归问题（线性/非线性），相对logistic regression仅能用于线性回归，GBDT的适用面非常广。亦可用于二分类问题（设定阈值，大于阈值为正例，反之为负例）。</p>\n<p>参考：</p>\n<p><a href=\"http://baidutech.blog.51cto.com/4114344/743809/\" target=\"_blank\" rel=\"noopener\">http://baidutech.blog.51cto.com/4114344/743809/</a></p>\n<p><a href=\"http://blog.csdn.net/tianxiaguixin002/article/details/47701881\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/tianxiaguixin002/article/details/47701881</a></p>\n<p><a href=\"http://blog.csdn.net/w28971023/article/details/8240756\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/w28971023/article/details/8240756</a></p>"},{"layout":"lay_post","title":"机器学习算法-回归-最小二乘法(LeastSquare)","date":"2016-12-30T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n对于线性回归的参数求解问题，可以使用迭代法求解，如梯度下降(GD)。也可以使用非迭代法，如正规方程(NormalEquation)。正规方程的本质是最小二乘法的矩阵形式，最小二乘法求解本质是对代价函数求导。\n<!-- more -->\n\n## 1.背景\n\n最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。\n\n《统计学习方法》中提到，回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以用著名的最小二乘法来解决。看来最小二乘法果然是机器学习领域最有名和有效的算法之一。\n\n## 2.最小二乘法(LeastSquare)\n\n我们以最简单的一元线性模型来解释最小二乘法。什么是一元线性模型呢？ 监督学习中，如果预测的变量是离散的，我们称其为分类（如决策树，支持向量机等），如果预测的变量是连续的，我们称其为回归。回归分析中，如果只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。对于二维空间线性是一条直线；对于三维空间线性是一个平面，对于多维空间线性是一个超平面。\n\n对于平面中的这n个点，可以使用无数条曲线来拟合。要求样本回归函数尽可能好地拟合这组值。综合起来看，这条直线处于样本数据的中心位置最合理。 选择最佳拟合曲线的标准可以确定为：使总的拟合误差（即总残差）达到最小。有以下三个标准可以选择：\n\n（1）用“残差和最小”确定直线位置是一个途径。但很快发现计算“残差和”存在相互抵消的问题。\n\n（2）用“残差绝对值和最小”确定直线位置也是一个途径。但绝对值的计算比较麻烦。\n\n（3）最小二乘法的原则是以“残差平方和最小”确定直线位置。用最小二乘法除了计算比较方便外，得到的估计量还具有优良特性。这种方法对异常值非常敏感。\n\n## 3.普通最小二乘法(OrdinaryLeastSquare,OLS)\n\n最常用的是普通最小二乘法(OrdinaryLeastSquare,OLS)：所选择的回归模型应该使所有观察值的残差平方和达到最小。\n\n为了方便讲清楚最小二乘法推导过程这里使用，数据集有1…N个数据组成，每个数据由、构成，x表示特征，y为结果；这里将线性回归模型定义为：\n\n![回归模型](/images/算法/最小二乘法/回归模型.png)\n\n平均损失函数定义有：\n\n![平方损失函数](/images/算法/最小二乘法/平方损失函数.png)\n\n要求得L的最小，其关于c与m的偏导数定为0，所以求偏导数，得出后让导数等于0，并对c与m求解便能得到最小的L此时的c与m便是最匹配该模型的；\n\n**关于c偏导数:**\n\n![c偏导数](/images/算法/最小二乘法/c偏导数.png)\n\n**关于m的偏导数:**\n\n![m偏导数](/images/算法/最小二乘法/m偏导数.png)\n\n**令关于c的偏导数等于0，求解：**\n\n![c偏导数为0](/images/算法/最小二乘法/c偏导数为0.png)\n\n**令关于m的偏导数等于0，求解：**\n\n![m偏导数为0](/images/算法/最小二乘法/m偏导数为0.png)\n\n## 4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式\n\n**模型变换**\n\n![模型变换](/images/算法/最小二乘法/模型变换.png)\n\n**代价函数**\n\n![代价函数](/images/算法/最小二乘法/代价函数.png)\n\n根据矩阵乘积转置规则损失函数可以进一步化简为：\n\n![转置-代价函数](/images/算法/最小二乘法/转置-代价函数.png)\n\n**偏导数**\n\n![偏导数](/images/算法/最小二乘法/偏导数.png)\n\n## 5.最小二乘法与梯度下降法比较\n\n最小二乘法跟梯度下降法都是通过求导来求损失函数的最小值，那它们有什么区别呢。\n\n**相同**\n\n1.本质相同：两种方法都是在给定已知数据（independent & dependent variables）的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。\n\n2.目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方），估算值与实际值的总平方差的公式为：\n\n![平方差](/images/算法/最小二乘法/平方差.png)\n\n其中x(i) 为第i组数据的independent variable，y(i) 为第i组数据的dependent variable，B 为系数向量。\n\n**不同**\n\n1.实现方法和结果不同：最小二乘法是直接对△求导找出全局最小，是非迭代法。而梯度下降法是一种迭代法，先给定一个B ，然后向△下降最快的方向调整B ，在若干次迭代之后找到局部最小。梯度下降法的缺点是到最小点的时候收敛速度变慢，并且对初始点的选择极为敏感，其改进大多是在这两方面下功夫。\n\n参考资料:http://www.cnblogs.com/softlin/p/5815531.html","source":"_posts/2016-12-31-机器学习算法-回归-最小二乘法.md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-回归-最小二乘法(LeastSquare)\"\ndate: 2016-12-31\ncategories: 回归算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n对于线性回归的参数求解问题，可以使用迭代法求解，如梯度下降(GD)。也可以使用非迭代法，如正规方程(NormalEquation)。正规方程的本质是最小二乘法的矩阵形式，最小二乘法求解本质是对代价函数求导。\n<!-- more -->\n\n## 1.背景\n\n最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。\n\n《统计学习方法》中提到，回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以用著名的最小二乘法来解决。看来最小二乘法果然是机器学习领域最有名和有效的算法之一。\n\n## 2.最小二乘法(LeastSquare)\n\n我们以最简单的一元线性模型来解释最小二乘法。什么是一元线性模型呢？ 监督学习中，如果预测的变量是离散的，我们称其为分类（如决策树，支持向量机等），如果预测的变量是连续的，我们称其为回归。回归分析中，如果只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。对于二维空间线性是一条直线；对于三维空间线性是一个平面，对于多维空间线性是一个超平面。\n\n对于平面中的这n个点，可以使用无数条曲线来拟合。要求样本回归函数尽可能好地拟合这组值。综合起来看，这条直线处于样本数据的中心位置最合理。 选择最佳拟合曲线的标准可以确定为：使总的拟合误差（即总残差）达到最小。有以下三个标准可以选择：\n\n（1）用“残差和最小”确定直线位置是一个途径。但很快发现计算“残差和”存在相互抵消的问题。\n\n（2）用“残差绝对值和最小”确定直线位置也是一个途径。但绝对值的计算比较麻烦。\n\n（3）最小二乘法的原则是以“残差平方和最小”确定直线位置。用最小二乘法除了计算比较方便外，得到的估计量还具有优良特性。这种方法对异常值非常敏感。\n\n## 3.普通最小二乘法(OrdinaryLeastSquare,OLS)\n\n最常用的是普通最小二乘法(OrdinaryLeastSquare,OLS)：所选择的回归模型应该使所有观察值的残差平方和达到最小。\n\n为了方便讲清楚最小二乘法推导过程这里使用，数据集有1…N个数据组成，每个数据由、构成，x表示特征，y为结果；这里将线性回归模型定义为：\n\n![回归模型](/images/算法/最小二乘法/回归模型.png)\n\n平均损失函数定义有：\n\n![平方损失函数](/images/算法/最小二乘法/平方损失函数.png)\n\n要求得L的最小，其关于c与m的偏导数定为0，所以求偏导数，得出后让导数等于0，并对c与m求解便能得到最小的L此时的c与m便是最匹配该模型的；\n\n**关于c偏导数:**\n\n![c偏导数](/images/算法/最小二乘法/c偏导数.png)\n\n**关于m的偏导数:**\n\n![m偏导数](/images/算法/最小二乘法/m偏导数.png)\n\n**令关于c的偏导数等于0，求解：**\n\n![c偏导数为0](/images/算法/最小二乘法/c偏导数为0.png)\n\n**令关于m的偏导数等于0，求解：**\n\n![m偏导数为0](/images/算法/最小二乘法/m偏导数为0.png)\n\n## 4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式\n\n**模型变换**\n\n![模型变换](/images/算法/最小二乘法/模型变换.png)\n\n**代价函数**\n\n![代价函数](/images/算法/最小二乘法/代价函数.png)\n\n根据矩阵乘积转置规则损失函数可以进一步化简为：\n\n![转置-代价函数](/images/算法/最小二乘法/转置-代价函数.png)\n\n**偏导数**\n\n![偏导数](/images/算法/最小二乘法/偏导数.png)\n\n## 5.最小二乘法与梯度下降法比较\n\n最小二乘法跟梯度下降法都是通过求导来求损失函数的最小值，那它们有什么区别呢。\n\n**相同**\n\n1.本质相同：两种方法都是在给定已知数据（independent & dependent variables）的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。\n\n2.目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方），估算值与实际值的总平方差的公式为：\n\n![平方差](/images/算法/最小二乘法/平方差.png)\n\n其中x(i) 为第i组数据的independent variable，y(i) 为第i组数据的dependent variable，B 为系数向量。\n\n**不同**\n\n1.实现方法和结果不同：最小二乘法是直接对△求导找出全局最小，是非迭代法。而梯度下降法是一种迭代法，先给定一个B ，然后向△下降最快的方向调整B ，在若干次迭代之后找到局部最小。梯度下降法的缺点是到最小点的时候收敛速度变慢，并且对初始点的选择极为敏感，其改进大多是在这两方面下功夫。\n\n参考资料:http://www.cnblogs.com/softlin/p/5815531.html","slug":"2016-12-31-机器学习算法-回归-最小二乘法","published":1,"updated":"2018-11-29T12:51:25.190Z","comments":1,"photos":[],"link":"","_id":"cjskffobm004t4glmwx1lxu2a","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对于线性回归的参数求解问题，可以使用迭代法求解，如梯度下降(GD)。也可以使用非迭代法，如正规方程(NormalEquation)。正规方程的本质是最小二乘法的矩阵形式，最小二乘法求解本质是对代价函数求导。<br><a id=\"more\"></a></p>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1.背景\"></a>1.背景</h2><p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。</p>\n<p>《统计学习方法》中提到，回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以用著名的最小二乘法来解决。看来最小二乘法果然是机器学习领域最有名和有效的算法之一。</p>\n<h2 id=\"2-最小二乘法-LeastSquare\"><a href=\"#2-最小二乘法-LeastSquare\" class=\"headerlink\" title=\"2.最小二乘法(LeastSquare)\"></a>2.最小二乘法(LeastSquare)</h2><p>我们以最简单的一元线性模型来解释最小二乘法。什么是一元线性模型呢？ 监督学习中，如果预测的变量是离散的，我们称其为分类（如决策树，支持向量机等），如果预测的变量是连续的，我们称其为回归。回归分析中，如果只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。对于二维空间线性是一条直线；对于三维空间线性是一个平面，对于多维空间线性是一个超平面。</p>\n<p>对于平面中的这n个点，可以使用无数条曲线来拟合。要求样本回归函数尽可能好地拟合这组值。综合起来看，这条直线处于样本数据的中心位置最合理。 选择最佳拟合曲线的标准可以确定为：使总的拟合误差（即总残差）达到最小。有以下三个标准可以选择：</p>\n<p>（1）用“残差和最小”确定直线位置是一个途径。但很快发现计算“残差和”存在相互抵消的问题。</p>\n<p>（2）用“残差绝对值和最小”确定直线位置也是一个途径。但绝对值的计算比较麻烦。</p>\n<p>（3）最小二乘法的原则是以“残差平方和最小”确定直线位置。用最小二乘法除了计算比较方便外，得到的估计量还具有优良特性。这种方法对异常值非常敏感。</p>\n<h2 id=\"3-普通最小二乘法-OrdinaryLeastSquare-OLS\"><a href=\"#3-普通最小二乘法-OrdinaryLeastSquare-OLS\" class=\"headerlink\" title=\"3.普通最小二乘法(OrdinaryLeastSquare,OLS)\"></a>3.普通最小二乘法(OrdinaryLeastSquare,OLS)</h2><p>最常用的是普通最小二乘法(OrdinaryLeastSquare,OLS)：所选择的回归模型应该使所有观察值的残差平方和达到最小。</p>\n<p>为了方便讲清楚最小二乘法推导过程这里使用，数据集有1…N个数据组成，每个数据由、构成，x表示特征，y为结果；这里将线性回归模型定义为：</p>\n<p><img src=\"/images/算法/最小二乘法/回归模型.png\" alt=\"回归模型\"></p>\n<p>平均损失函数定义有：</p>\n<p><img src=\"/images/算法/最小二乘法/平方损失函数.png\" alt=\"平方损失函数\"></p>\n<p>要求得L的最小，其关于c与m的偏导数定为0，所以求偏导数，得出后让导数等于0，并对c与m求解便能得到最小的L此时的c与m便是最匹配该模型的；</p>\n<p><strong>关于c偏导数:</strong></p>\n<p><img src=\"/images/算法/最小二乘法/c偏导数.png\" alt=\"c偏导数\"></p>\n<p><strong>关于m的偏导数:</strong></p>\n<p><img src=\"/images/算法/最小二乘法/m偏导数.png\" alt=\"m偏导数\"></p>\n<p><strong>令关于c的偏导数等于0，求解：</strong></p>\n<p><img src=\"/images/算法/最小二乘法/c偏导数为0.png\" alt=\"c偏导数为0\"></p>\n<p><strong>令关于m的偏导数等于0，求解：</strong></p>\n<p><img src=\"/images/算法/最小二乘法/m偏导数为0.png\" alt=\"m偏导数为0\"></p>\n<h2 id=\"4-普通最小二乘法-OrdinaryLeastSquare-OLS-矩阵形式\"><a href=\"#4-普通最小二乘法-OrdinaryLeastSquare-OLS-矩阵形式\" class=\"headerlink\" title=\"4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式\"></a>4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式</h2><p><strong>模型变换</strong></p>\n<p><img src=\"/images/算法/最小二乘法/模型变换.png\" alt=\"模型变换\"></p>\n<p><strong>代价函数</strong></p>\n<p><img src=\"/images/算法/最小二乘法/代价函数.png\" alt=\"代价函数\"></p>\n<p>根据矩阵乘积转置规则损失函数可以进一步化简为：</p>\n<p><img src=\"/images/算法/最小二乘法/转置-代价函数.png\" alt=\"转置-代价函数\"></p>\n<p><strong>偏导数</strong></p>\n<p><img src=\"/images/算法/最小二乘法/偏导数.png\" alt=\"偏导数\"></p>\n<h2 id=\"5-最小二乘法与梯度下降法比较\"><a href=\"#5-最小二乘法与梯度下降法比较\" class=\"headerlink\" title=\"5.最小二乘法与梯度下降法比较\"></a>5.最小二乘法与梯度下降法比较</h2><p>最小二乘法跟梯度下降法都是通过求导来求损失函数的最小值，那它们有什么区别呢。</p>\n<p><strong>相同</strong></p>\n<p>1.本质相同：两种方法都是在给定已知数据（independent &amp; dependent variables）的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。</p>\n<p>2.目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方），估算值与实际值的总平方差的公式为：</p>\n<p><img src=\"/images/算法/最小二乘法/平方差.png\" alt=\"平方差\"></p>\n<p>其中x(i) 为第i组数据的independent variable，y(i) 为第i组数据的dependent variable，B 为系数向量。</p>\n<p><strong>不同</strong></p>\n<p>1.实现方法和结果不同：最小二乘法是直接对△求导找出全局最小，是非迭代法。而梯度下降法是一种迭代法，先给定一个B ，然后向△下降最快的方向调整B ，在若干次迭代之后找到局部最小。梯度下降法的缺点是到最小点的时候收敛速度变慢，并且对初始点的选择极为敏感，其改进大多是在这两方面下功夫。</p>\n<p>参考资料:<a href=\"http://www.cnblogs.com/softlin/p/5815531.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/softlin/p/5815531.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对于线性回归的参数求解问题，可以使用迭代法求解，如梯度下降(GD)。也可以使用非迭代法，如正规方程(NormalEquation)。正规方程的本质是最小二乘法的矩阵形式，最小二乘法求解本质是对代价函数求导。<br>","more":"</p>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1.背景\"></a>1.背景</h2><p>最小二乘法（又称最小平方法）是一种数学优化技术。它通过最小化误差的平方和寻找数据的最佳函数匹配。利用最小二乘法可以简便地求得未知的数据，并使得这些求得的数据与实际数据之间误差的平方和为最小。最小二乘法还可用于曲线拟合。其他一些优化问题也可通过最小化能量或最大化熵用最小二乘法来表达。</p>\n<p>《统计学习方法》中提到，回归学习最常用的损失函数是平方损失函数，在此情况下，回归问题可以用著名的最小二乘法来解决。看来最小二乘法果然是机器学习领域最有名和有效的算法之一。</p>\n<h2 id=\"2-最小二乘法-LeastSquare\"><a href=\"#2-最小二乘法-LeastSquare\" class=\"headerlink\" title=\"2.最小二乘法(LeastSquare)\"></a>2.最小二乘法(LeastSquare)</h2><p>我们以最简单的一元线性模型来解释最小二乘法。什么是一元线性模型呢？ 监督学习中，如果预测的变量是离散的，我们称其为分类（如决策树，支持向量机等），如果预测的变量是连续的，我们称其为回归。回归分析中，如果只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。对于二维空间线性是一条直线；对于三维空间线性是一个平面，对于多维空间线性是一个超平面。</p>\n<p>对于平面中的这n个点，可以使用无数条曲线来拟合。要求样本回归函数尽可能好地拟合这组值。综合起来看，这条直线处于样本数据的中心位置最合理。 选择最佳拟合曲线的标准可以确定为：使总的拟合误差（即总残差）达到最小。有以下三个标准可以选择：</p>\n<p>（1）用“残差和最小”确定直线位置是一个途径。但很快发现计算“残差和”存在相互抵消的问题。</p>\n<p>（2）用“残差绝对值和最小”确定直线位置也是一个途径。但绝对值的计算比较麻烦。</p>\n<p>（3）最小二乘法的原则是以“残差平方和最小”确定直线位置。用最小二乘法除了计算比较方便外，得到的估计量还具有优良特性。这种方法对异常值非常敏感。</p>\n<h2 id=\"3-普通最小二乘法-OrdinaryLeastSquare-OLS\"><a href=\"#3-普通最小二乘法-OrdinaryLeastSquare-OLS\" class=\"headerlink\" title=\"3.普通最小二乘法(OrdinaryLeastSquare,OLS)\"></a>3.普通最小二乘法(OrdinaryLeastSquare,OLS)</h2><p>最常用的是普通最小二乘法(OrdinaryLeastSquare,OLS)：所选择的回归模型应该使所有观察值的残差平方和达到最小。</p>\n<p>为了方便讲清楚最小二乘法推导过程这里使用，数据集有1…N个数据组成，每个数据由、构成，x表示特征，y为结果；这里将线性回归模型定义为：</p>\n<p><img src=\"/images/算法/最小二乘法/回归模型.png\" alt=\"回归模型\"></p>\n<p>平均损失函数定义有：</p>\n<p><img src=\"/images/算法/最小二乘法/平方损失函数.png\" alt=\"平方损失函数\"></p>\n<p>要求得L的最小，其关于c与m的偏导数定为0，所以求偏导数，得出后让导数等于0，并对c与m求解便能得到最小的L此时的c与m便是最匹配该模型的；</p>\n<p><strong>关于c偏导数:</strong></p>\n<p><img src=\"/images/算法/最小二乘法/c偏导数.png\" alt=\"c偏导数\"></p>\n<p><strong>关于m的偏导数:</strong></p>\n<p><img src=\"/images/算法/最小二乘法/m偏导数.png\" alt=\"m偏导数\"></p>\n<p><strong>令关于c的偏导数等于0，求解：</strong></p>\n<p><img src=\"/images/算法/最小二乘法/c偏导数为0.png\" alt=\"c偏导数为0\"></p>\n<p><strong>令关于m的偏导数等于0，求解：</strong></p>\n<p><img src=\"/images/算法/最小二乘法/m偏导数为0.png\" alt=\"m偏导数为0\"></p>\n<h2 id=\"4-普通最小二乘法-OrdinaryLeastSquare-OLS-矩阵形式\"><a href=\"#4-普通最小二乘法-OrdinaryLeastSquare-OLS-矩阵形式\" class=\"headerlink\" title=\"4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式\"></a>4.普通最小二乘法(OrdinaryLeastSquare,OLS)-矩阵形式</h2><p><strong>模型变换</strong></p>\n<p><img src=\"/images/算法/最小二乘法/模型变换.png\" alt=\"模型变换\"></p>\n<p><strong>代价函数</strong></p>\n<p><img src=\"/images/算法/最小二乘法/代价函数.png\" alt=\"代价函数\"></p>\n<p>根据矩阵乘积转置规则损失函数可以进一步化简为：</p>\n<p><img src=\"/images/算法/最小二乘法/转置-代价函数.png\" alt=\"转置-代价函数\"></p>\n<p><strong>偏导数</strong></p>\n<p><img src=\"/images/算法/最小二乘法/偏导数.png\" alt=\"偏导数\"></p>\n<h2 id=\"5-最小二乘法与梯度下降法比较\"><a href=\"#5-最小二乘法与梯度下降法比较\" class=\"headerlink\" title=\"5.最小二乘法与梯度下降法比较\"></a>5.最小二乘法与梯度下降法比较</h2><p>最小二乘法跟梯度下降法都是通过求导来求损失函数的最小值，那它们有什么区别呢。</p>\n<p><strong>相同</strong></p>\n<p>1.本质相同：两种方法都是在给定已知数据（independent &amp; dependent variables）的前提下对dependent variables算出出一个一般性的估值函数。然后对给定新数据的dependent variables进行估算。</p>\n<p>2.目标相同：都是在已知数据的框架内，使得估算值与实际值的总平方差尽量更小（事实上未必一定要使用平方），估算值与实际值的总平方差的公式为：</p>\n<p><img src=\"/images/算法/最小二乘法/平方差.png\" alt=\"平方差\"></p>\n<p>其中x(i) 为第i组数据的independent variable，y(i) 为第i组数据的dependent variable，B 为系数向量。</p>\n<p><strong>不同</strong></p>\n<p>1.实现方法和结果不同：最小二乘法是直接对△求导找出全局最小，是非迭代法。而梯度下降法是一种迭代法，先给定一个B ，然后向△下降最快的方向调整B ，在若干次迭代之后找到局部最小。梯度下降法的缺点是到最小点的时候收敛速度变慢，并且对初始点的选择极为敏感，其改进大多是在这两方面下功夫。</p>\n<p>参考资料:<a href=\"http://www.cnblogs.com/softlin/p/5815531.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/softlin/p/5815531.html</a></p>"},{"layout":"lay_post","title":"机器学习算法-回归-最大似然函数","date":"2017-01-02T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n似然函数与概率非常类似但又有根本的区别，概率为在某种条件（参数）下预测某事件发生的可能性；而似然函数与之相反为已知该事件的情况下推测出该事件发生时的条件（参数）；所以似然估计也称为参数估计，为参数估计中的一种算法。\n<!-- more -->\n\n## 1.抛硬币的似然函数\n\n假如有一枚硬币我们现在不知道它是否为正常硬币（正反面出现概率各位50%），所以想通过抛10次然后通过硬币正反面出现的概率分布判断该硬币是否正常；当抛完10次时出现5次正面向上、5次反面向上，正反面出现的概率符合正常硬币的预期，这时我们可以判断该硬币是正常的；\n\n![二项分布](/images/算法/最大似然/二项分布.png)\n\n**二项分布解析:**\n\n![二项分布解析](/images/算法/最大似然/二项分布解析.png)\n\n## 2.使用最大似然法求硬币问题\n\n似然函数为知道了结果求条件，概率问题为知道了条件求概率，在这个问题中就是知道了硬币是正常的，求正反面出现的比例w为何值时该结果最靠谱；所以似然函数等于：\n\n![似然函数](/images/算法/最大似然/似然函数.png)\n\n函数左边的值并非条件概率中的条件而是该函数的依赖值，似然函数L为在给定结果y的情况下参数w的取值情况，概率函数L为知道了参数w求得y的取值；有了抛硬币情况的概率分布这里就可以给出似然函数：\n\n![抛硬币似然函数](/images/算法/最大似然/抛硬币似然函数.png)\n\n![对数似然](/images/算法/最大似然/对数似然.png)\n\n下面对该似然对数进行求关于w的偏导数：\n\n![偏导数](/images/算法/最大似然/偏导数.png)\n\n通过求L关于w的偏导数求得w=0.5，于我们上面概率中的w时一致的，也就是说当w=0.5时y正面出现的次数等于5的可能性是最高的。\n\n## 3.线性回归\n\n通过前面几篇文章我们知道了线性回归的模型为：\n\n![线性回归模型](/images/算法/最大似然/线性回归模型.png)\n\n![概率密度函数](/images/算法/最大似然/概率密度函数.png)\n\n按照惯例直接求解似然函数比较麻烦所以求解对数似然函数：\n\n![对数似然函数](/images/算法/最大似然/对数似然函数.png)\n\n然后求L关于w的偏导数，令其等于0求拐点\n\n![偏导数为0](/images/算法/最大似然/偏导数为0.png)\n\n到这一步我们已经求得到了W，这与前面我们通过最小二乘法求得的矩阵方程一样，所以w也一定是我们这里求得的w正确解。\n\n**使用最大似然法求解问题的步骤为：**\n\n一、确定问题的随机变量类型是离散随机变量还是连续随机变量\n\n二、得出问题的概率分布\n\n三、概率函数转为似然函数\n\n四、似然函数取对数\n\n五、求关于某变量的偏导数\n\n六、解似然方程\n\n## 4.总结\n\n最大似然和最小二乘法是求解回归问题的不同方法，结果都和正规方程一样，但求解的思路不一样。\n\n参考资料:http://www.cnblogs.com/softlin/p/6219372.html","source":"_posts/2017-01-03-机器学习算法-回归-最大似然函数.md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-回归-最大似然函数\"\ndate: 2017-01-03\ncategories: 回归算法\ntags: 机器学习\nauthor: lvyafei\n---\n\n## 0.概述\n\n似然函数与概率非常类似但又有根本的区别，概率为在某种条件（参数）下预测某事件发生的可能性；而似然函数与之相反为已知该事件的情况下推测出该事件发生时的条件（参数）；所以似然估计也称为参数估计，为参数估计中的一种算法。\n<!-- more -->\n\n## 1.抛硬币的似然函数\n\n假如有一枚硬币我们现在不知道它是否为正常硬币（正反面出现概率各位50%），所以想通过抛10次然后通过硬币正反面出现的概率分布判断该硬币是否正常；当抛完10次时出现5次正面向上、5次反面向上，正反面出现的概率符合正常硬币的预期，这时我们可以判断该硬币是正常的；\n\n![二项分布](/images/算法/最大似然/二项分布.png)\n\n**二项分布解析:**\n\n![二项分布解析](/images/算法/最大似然/二项分布解析.png)\n\n## 2.使用最大似然法求硬币问题\n\n似然函数为知道了结果求条件，概率问题为知道了条件求概率，在这个问题中就是知道了硬币是正常的，求正反面出现的比例w为何值时该结果最靠谱；所以似然函数等于：\n\n![似然函数](/images/算法/最大似然/似然函数.png)\n\n函数左边的值并非条件概率中的条件而是该函数的依赖值，似然函数L为在给定结果y的情况下参数w的取值情况，概率函数L为知道了参数w求得y的取值；有了抛硬币情况的概率分布这里就可以给出似然函数：\n\n![抛硬币似然函数](/images/算法/最大似然/抛硬币似然函数.png)\n\n![对数似然](/images/算法/最大似然/对数似然.png)\n\n下面对该似然对数进行求关于w的偏导数：\n\n![偏导数](/images/算法/最大似然/偏导数.png)\n\n通过求L关于w的偏导数求得w=0.5，于我们上面概率中的w时一致的，也就是说当w=0.5时y正面出现的次数等于5的可能性是最高的。\n\n## 3.线性回归\n\n通过前面几篇文章我们知道了线性回归的模型为：\n\n![线性回归模型](/images/算法/最大似然/线性回归模型.png)\n\n![概率密度函数](/images/算法/最大似然/概率密度函数.png)\n\n按照惯例直接求解似然函数比较麻烦所以求解对数似然函数：\n\n![对数似然函数](/images/算法/最大似然/对数似然函数.png)\n\n然后求L关于w的偏导数，令其等于0求拐点\n\n![偏导数为0](/images/算法/最大似然/偏导数为0.png)\n\n到这一步我们已经求得到了W，这与前面我们通过最小二乘法求得的矩阵方程一样，所以w也一定是我们这里求得的w正确解。\n\n**使用最大似然法求解问题的步骤为：**\n\n一、确定问题的随机变量类型是离散随机变量还是连续随机变量\n\n二、得出问题的概率分布\n\n三、概率函数转为似然函数\n\n四、似然函数取对数\n\n五、求关于某变量的偏导数\n\n六、解似然方程\n\n## 4.总结\n\n最大似然和最小二乘法是求解回归问题的不同方法，结果都和正规方程一样，但求解的思路不一样。\n\n参考资料:http://www.cnblogs.com/softlin/p/6219372.html","slug":"2017-01-03-机器学习算法-回归-最大似然函数","published":1,"updated":"2018-11-29T12:51:25.194Z","comments":1,"photos":[],"link":"","_id":"cjskffoc1004w4glmaboxrmk3","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>似然函数与概率非常类似但又有根本的区别，概率为在某种条件（参数）下预测某事件发生的可能性；而似然函数与之相反为已知该事件的情况下推测出该事件发生时的条件（参数）；所以似然估计也称为参数估计，为参数估计中的一种算法。<br><a id=\"more\"></a></p>\n<h2 id=\"1-抛硬币的似然函数\"><a href=\"#1-抛硬币的似然函数\" class=\"headerlink\" title=\"1.抛硬币的似然函数\"></a>1.抛硬币的似然函数</h2><p>假如有一枚硬币我们现在不知道它是否为正常硬币（正反面出现概率各位50%），所以想通过抛10次然后通过硬币正反面出现的概率分布判断该硬币是否正常；当抛完10次时出现5次正面向上、5次反面向上，正反面出现的概率符合正常硬币的预期，这时我们可以判断该硬币是正常的；</p>\n<p><img src=\"/images/算法/最大似然/二项分布.png\" alt=\"二项分布\"></p>\n<p><strong>二项分布解析:</strong></p>\n<p><img src=\"/images/算法/最大似然/二项分布解析.png\" alt=\"二项分布解析\"></p>\n<h2 id=\"2-使用最大似然法求硬币问题\"><a href=\"#2-使用最大似然法求硬币问题\" class=\"headerlink\" title=\"2.使用最大似然法求硬币问题\"></a>2.使用最大似然法求硬币问题</h2><p>似然函数为知道了结果求条件，概率问题为知道了条件求概率，在这个问题中就是知道了硬币是正常的，求正反面出现的比例w为何值时该结果最靠谱；所以似然函数等于：</p>\n<p><img src=\"/images/算法/最大似然/似然函数.png\" alt=\"似然函数\"></p>\n<p>函数左边的值并非条件概率中的条件而是该函数的依赖值，似然函数L为在给定结果y的情况下参数w的取值情况，概率函数L为知道了参数w求得y的取值；有了抛硬币情况的概率分布这里就可以给出似然函数：</p>\n<p><img src=\"/images/算法/最大似然/抛硬币似然函数.png\" alt=\"抛硬币似然函数\"></p>\n<p><img src=\"/images/算法/最大似然/对数似然.png\" alt=\"对数似然\"></p>\n<p>下面对该似然对数进行求关于w的偏导数：</p>\n<p><img src=\"/images/算法/最大似然/偏导数.png\" alt=\"偏导数\"></p>\n<p>通过求L关于w的偏导数求得w=0.5，于我们上面概率中的w时一致的，也就是说当w=0.5时y正面出现的次数等于5的可能性是最高的。</p>\n<h2 id=\"3-线性回归\"><a href=\"#3-线性回归\" class=\"headerlink\" title=\"3.线性回归\"></a>3.线性回归</h2><p>通过前面几篇文章我们知道了线性回归的模型为：</p>\n<p><img src=\"/images/算法/最大似然/线性回归模型.png\" alt=\"线性回归模型\"></p>\n<p><img src=\"/images/算法/最大似然/概率密度函数.png\" alt=\"概率密度函数\"></p>\n<p>按照惯例直接求解似然函数比较麻烦所以求解对数似然函数：</p>\n<p><img src=\"/images/算法/最大似然/对数似然函数.png\" alt=\"对数似然函数\"></p>\n<p>然后求L关于w的偏导数，令其等于0求拐点</p>\n<p><img src=\"/images/算法/最大似然/偏导数为0.png\" alt=\"偏导数为0\"></p>\n<p>到这一步我们已经求得到了W，这与前面我们通过最小二乘法求得的矩阵方程一样，所以w也一定是我们这里求得的w正确解。</p>\n<p><strong>使用最大似然法求解问题的步骤为：</strong></p>\n<p>一、确定问题的随机变量类型是离散随机变量还是连续随机变量</p>\n<p>二、得出问题的概率分布</p>\n<p>三、概率函数转为似然函数</p>\n<p>四、似然函数取对数</p>\n<p>五、求关于某变量的偏导数</p>\n<p>六、解似然方程</p>\n<h2 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4.总结\"></a>4.总结</h2><p>最大似然和最小二乘法是求解回归问题的不同方法，结果都和正规方程一样，但求解的思路不一样。</p>\n<p>参考资料:<a href=\"http://www.cnblogs.com/softlin/p/6219372.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/softlin/p/6219372.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>似然函数与概率非常类似但又有根本的区别，概率为在某种条件（参数）下预测某事件发生的可能性；而似然函数与之相反为已知该事件的情况下推测出该事件发生时的条件（参数）；所以似然估计也称为参数估计，为参数估计中的一种算法。<br>","more":"</p>\n<h2 id=\"1-抛硬币的似然函数\"><a href=\"#1-抛硬币的似然函数\" class=\"headerlink\" title=\"1.抛硬币的似然函数\"></a>1.抛硬币的似然函数</h2><p>假如有一枚硬币我们现在不知道它是否为正常硬币（正反面出现概率各位50%），所以想通过抛10次然后通过硬币正反面出现的概率分布判断该硬币是否正常；当抛完10次时出现5次正面向上、5次反面向上，正反面出现的概率符合正常硬币的预期，这时我们可以判断该硬币是正常的；</p>\n<p><img src=\"/images/算法/最大似然/二项分布.png\" alt=\"二项分布\"></p>\n<p><strong>二项分布解析:</strong></p>\n<p><img src=\"/images/算法/最大似然/二项分布解析.png\" alt=\"二项分布解析\"></p>\n<h2 id=\"2-使用最大似然法求硬币问题\"><a href=\"#2-使用最大似然法求硬币问题\" class=\"headerlink\" title=\"2.使用最大似然法求硬币问题\"></a>2.使用最大似然法求硬币问题</h2><p>似然函数为知道了结果求条件，概率问题为知道了条件求概率，在这个问题中就是知道了硬币是正常的，求正反面出现的比例w为何值时该结果最靠谱；所以似然函数等于：</p>\n<p><img src=\"/images/算法/最大似然/似然函数.png\" alt=\"似然函数\"></p>\n<p>函数左边的值并非条件概率中的条件而是该函数的依赖值，似然函数L为在给定结果y的情况下参数w的取值情况，概率函数L为知道了参数w求得y的取值；有了抛硬币情况的概率分布这里就可以给出似然函数：</p>\n<p><img src=\"/images/算法/最大似然/抛硬币似然函数.png\" alt=\"抛硬币似然函数\"></p>\n<p><img src=\"/images/算法/最大似然/对数似然.png\" alt=\"对数似然\"></p>\n<p>下面对该似然对数进行求关于w的偏导数：</p>\n<p><img src=\"/images/算法/最大似然/偏导数.png\" alt=\"偏导数\"></p>\n<p>通过求L关于w的偏导数求得w=0.5，于我们上面概率中的w时一致的，也就是说当w=0.5时y正面出现的次数等于5的可能性是最高的。</p>\n<h2 id=\"3-线性回归\"><a href=\"#3-线性回归\" class=\"headerlink\" title=\"3.线性回归\"></a>3.线性回归</h2><p>通过前面几篇文章我们知道了线性回归的模型为：</p>\n<p><img src=\"/images/算法/最大似然/线性回归模型.png\" alt=\"线性回归模型\"></p>\n<p><img src=\"/images/算法/最大似然/概率密度函数.png\" alt=\"概率密度函数\"></p>\n<p>按照惯例直接求解似然函数比较麻烦所以求解对数似然函数：</p>\n<p><img src=\"/images/算法/最大似然/对数似然函数.png\" alt=\"对数似然函数\"></p>\n<p>然后求L关于w的偏导数，令其等于0求拐点</p>\n<p><img src=\"/images/算法/最大似然/偏导数为0.png\" alt=\"偏导数为0\"></p>\n<p>到这一步我们已经求得到了W，这与前面我们通过最小二乘法求得的矩阵方程一样，所以w也一定是我们这里求得的w正确解。</p>\n<p><strong>使用最大似然法求解问题的步骤为：</strong></p>\n<p>一、确定问题的随机变量类型是离散随机变量还是连续随机变量</p>\n<p>二、得出问题的概率分布</p>\n<p>三、概率函数转为似然函数</p>\n<p>四、似然函数取对数</p>\n<p>五、求关于某变量的偏导数</p>\n<p>六、解似然方程</p>\n<h2 id=\"4-总结\"><a href=\"#4-总结\" class=\"headerlink\" title=\"4.总结\"></a>4.总结</h2><p>最大似然和最小二乘法是求解回归问题的不同方法，结果都和正规方程一样，但求解的思路不一样。</p>\n<p>参考资料:<a href=\"http://www.cnblogs.com/softlin/p/6219372.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/softlin/p/6219372.html</a></p>"},{"layout":"lay_post","title":"Maven-配置-插件","date":"2017-07-26T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nmaven的配置以及插件管理\n<!-- more -->\n\n## 1.pom.xml中plugins插件配置\n\n```xml\n<build>\n    <plugins>\n        .....\n    </plugins>\n</build>\n```\n\n## 2.plugin-项目编译配置\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-compiler-plugin</artifactId>\n```\n\n说明:\n\n如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话，它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题，以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本，那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现，在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-compiler-plugin</artifactId>\n    <version>3.1</version>\n    <configuration>\n        <source>1.6</source> <!-- 源代码使用的开发版本 -->\n        <target>1.6</target> <!-- 需要生成的目标class文件的编译版本 -->\n        <!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中需要没有使用低版本jdk中不支持的语法)，会存在target不同于source的情况 -->\n    \n        <!-- 这下面的是可选项 -->\n        <meminitial>128m</meminitial>\n        <maxmem>512m</maxmem>\n        <fork>true</fork> <!-- fork is enable,用于明确表示编译版本配置的可用 --> \n        <compilerVersion>1.3</compilerVersion>\n        \n        <!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 -->\n        <compilerArgument>-verbose -bootclasspath ${java.home}\\lib\\rt.jar</compilerArgument>\n        \n    </configuration>\n</plugin>\n```\n\n## 3.plugin-项目打包\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-assembly-plugin</artifactId>\n```\n\n说明:\n\nmaven-assembly-plugin的用途是制作项目分发包，该分发包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。maven-assembly-plugin支持各种主流的格式如zip、tar.gz、jar和war等，具体打包哪些文件是高度可控的，例如用户可以按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly-plugin要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的single目标可以直接在命令行调用，也可以被绑定至生命周期。\n\n实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <configuration>\n        <!-- not append assembly id in release file name -->\n        <appendAssemblyId>false</appendAssemblyId>\n        <descriptors>\n            <descriptor>package.xml</descriptor>\n        </descriptors>\n    </configuration>\n    <executions>\n        <execution>\n            <id>make-deploy-zip</id>\n            <phase>package</phase><!-- 绑定到package生命周期阶段上 -->\n            <goals>\n                <goal>single</goal><!-- 只运行一次 -->\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 4.plugin-打包文件配置\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-jar-plugin</artifactId>\n```\n\n说明：\n\n打包文件配置:可执行jar的入口方法,如果需要把依赖的jar包一起打包,需要使用 maven-assembly-plugin\n\n实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n\t<artifactId>maven-jar-plugin</artifactId>\n\t<configuration>\n\t\t<archive>\n\t\t\t<manifest>\n\t\t\t\t<addClasspath>true</addClasspath>\n\t\t\t\t<classpathPrefix>lib/</classpathPrefix>\n\t\t\t\t<useUniqueVersions>false</useUniqueVersions>\n\t\t\t\t<mainClass>hbec.forum.recsys.etl.BootStrap</mainClass>\n\t\t\t</manifest>\n\t\t\t<manifestEntries>\n\t\t\t\t<Class-Path>configs/</Class-Path>\n\t\t\t</manifestEntries>\n\t\t</archive>\n\t\t<excludes>\n\t\t\t<exclude>*.xml</exclude>\n\t\t\t<exclude>**/*.xml</exclude>\n\t\t\t<exclude>*.json</exclude>\n\t\t\t<exclude>*.properties</exclude>\n\t\t\t<exclude>*.cfg</exclude>\n\t\t</excludes>\n\t</configuration>\n</plugin>\n```\n\n## 5.plugin-项目依赖管理\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-dependency-plugin</artifactId>\n```\n\n说明:\n\nmaven-dependency-plugin最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地Maven仓库复制到某个特定的文件夹下面。\n\n实例:\n\n```xml\n<plugin>  \n    <groupId>org.apache.maven.plugins</groupId>  \n    <artifactId>maven-dependency-plugin</artifactId>  \n    <executions>  \n        <execution>  \n            <id>copy</id>  \n            <phase>package</phase>  \n            <goals>  \n                <goal>copy-dependencies</goal>  \n            </goals>  \n            <configuration>  \n                <outputDirectory>  \n                    ${project.build.directory}/lib  \n                </outputDirectory>  \n            </configuration>  \n        </execution>  \n    </executions>  \n</plugin>\n```\n\n## 6.plugin-项目版本发布\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-release-plugin</artifactId>\n```\n\n说明:\n\nmaven-release-plugin的用途是帮助自动化项目版本发布，它依赖于POM中的SCM信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有SNAPSHOT依赖、升级项目的SNAPSHOT版本至RELEASE版本、为项目打标签等等。release:perform则是签出标签中的RELEASE源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一些细节，maven-release-plugin让该工作变得非常快速简便，不易出错。maven-release-plugin的各种目标通常直接在命令行调用，因为版本发布显然不是日常构建生命周期的一部分.\t  \n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.4.2</version>\n    <configuration>\n        <tagBase>${svn.url}/${project.artifactId}/tags/</tagBase>\n        <branchBase>${svn.url}/${project.artifactId}/branches/</branchBase>\n    </configuration>\n</plugin>\n```\n\n## 7.plugin-资源文件处理\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-resources-plugin</artifactId>\n```\n\n说明:\n\n为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。\n        \n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-resources-plugin</artifactId>\n    <version>2.6</version>\n    <configuration>\n        <encoding>GBK</encoding>\n    </configuration>\n    <executions>\n        <execution>\n            <id>copy-xmls</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.xml</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <execution>\n            <id>copy-properties</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.properties</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <execution>\n            <id>copy-dic</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.dic</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <!-- 打包配置文件 start -->\n        <execution>\n            <id>copy-dev</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/config/dev</directory>\n                        <includes>\n                            <include>**/*.*</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <!-- 打包配置文件 end -->\n    </executions>\n</plugin>\n```\n\n## 8.plugin-Maven中运行ant任务\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-antrun-plugin</artifactId>\n```\n\n说明:\n\nmaven-antrun-plugin能让用户在Maven项目中运行Ant任务。用户可以直接在该插件的配置以Ant的方式编写Target，然后交给该插件的run目标去执行。在一些由Ant往Maven迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉得Maven不够灵活时，也可以以Ant的方式实现之。maven-antrun-plugin的run目标通常与生命周期绑定运行。\n\n使用实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-antrun-plugin</artifactId>\n    <version>1.7</version>\n    <executions>\n        <execution>\n            <phase>package</phase>\n            <configuration>\n                <tasks>\n                    <copy todir=\"target\">\n                        <fileset dir=\"target/${project.artifactId}-${project.version}\"></fileset>\n                    </copy>\n                </tasks>\n            </configuration>\n            <goals>\n                <goal>run</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 9.plugin-生成项目源码包\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-source-plugin</artifactId>\n```\n\n说明:\n\n打包项目源文件到jar包中\n\n实例:      \n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-source-plugin</artifactId>\n    <version>2.2.1</version>\n    <executions>\n        <execution>\n            <id>attach-sources</id>\n            <phase>package</phase>\n            <goals>\n                <goal>jar-no-fork</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 10.plugin-生成项目javadoc文档\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-javadoc-plugin</artifactId>         \n```\n\n说明:\n\n生成项目javadoc文档\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-javadoc-plugin</artifactId>\n    <version>2.9</version>\n    <configuration>\n        <encoding>GBK</encoding>\n    </configuration>\n</plugin>\n```\n\n## 11.plugin-生成项目HTML说明文件\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-site-plugin</artifactId>\n```\n\n说明:\n\n使用maven 的site 插件 生成一个 可以在 浏览器中 查看项目的站点\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-site-plugin</artifactId>\n    <version>3.3</version>\n    <configuration>\n        <outputEncoding>GBK</outputEncoding>\n    </configuration>\n</plugin>\n```\n\n## 12.plugin-执行单元测试\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-surefire-plugin</artifactId>\n```\n\n说明:\n\n可能是由于历史的原因，Maven 2/3中用于执行测试的插件不是maven-test-plugin，而是maven-surefire-plugin。其实大部分时间内，只要你的测试类遵循通用的命令约定（以Test结尾、以TestCase结尾、或者以Test开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些测试类、或者使用一些TestNG特性的时候，了解maven-surefire-plugin的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行FooTest测试类，这是通过控制maven-surefire-plugin的test参数实现的。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-surefire-plugin</artifactId>\n    <version>2.9</version>\n    <configuration>\n        <skip>true</skip> <!-- 跳过测试阶段 -->\n        <testFailureIgnore>true</testFailureIgnore>  <!-- 忽略测试失败 -->\n    </configuration>\n</plugin>\n```\n\n## 13.plugin-自动配合SVN进行版本发布\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-scm-plugin</artifactId>\n```\n\n说明:\n\nMaven中为我们集成了软件配置管理的（SCM：Software Configuration Management）功能，他可以支持我们常用SVN、CVS等，到现在我使用的1.8.1版本，共支持18个命令\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-scm-plugin</artifactId>\n    <version>1.8.1</version>\n</plugin>\n```\n\n## 14.plugin-jetty运行插件\n\n```xml\n<groupId>org.mortbay.jetty</groupId>\n<artifactId>maven-jetty-plugin</artifactId>\n```\n\n说明:\n\n在进行Web开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成war文件，然后部署到Web容器中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin应运而生，它完全兼容 Maven项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的Jetty Web容器中。做一些基本配置后（例如Web应用的contextPath和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在IDE中修改代码，代码经IDE自动编译后产生变更，再由jetty-maven-plugin侦测到后更新至Jetty容器，这时你就可以直接测试Web页面了。需要注意的是，jetty-maven-plugin并不是宿主于Apache或Codehaus的官方插件，因此使用的时候需要额外的配置settings.xml的pluginGroups元素，将org.mortbay.jetty这个pluginGroup加入。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.mortbay.jetty</groupId>\n    <artifactId>maven-jetty-plugin</artifactId>\n    <version>6.1.10</version>\n    <configuration>\n            <scanIntervalSeconds>10</scanIntervalSeconds>\n            <stopKey>foo</stopKey>\n            <stopPort>9999</stopPort>\n    </configuration>\n    <executions>\n        <execution>\n            <id>start-jetty</id>\n            <phase>pre-integration-test</phase>\n            <goals>\n                <goal>run</goal>\n            </goals>\n            <configuration>\n                <scanIntervalSeconds>0</scanIntervalSeconds>\n                <daemon>true</daemon>\n            </configuration>\n        </execution>\n        <execution>\n            <id>stop-jetty</id>\n            <phase>post-integration-test</phase>\n            <goals>\n                <goal>stop</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n开始：mvn jetty:start  关闭：mvn jetty:stop\n\n## 15.plugin-在tomcat中运行项目\n\n```xml\n<groupId>org.apache.tomcat.maven</groupId>\n<artifactId>tomcat7-maven-plugin</artifactId>\n```\n\n说明:\n\n使用maven将web项目运行在tomcat中\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.tomcat.maven</groupId>\n    <artifactId>tomcat7-maven-plugin</artifactId>\n    <version>2.2</version>\n    <configuration>\n        <port>8889</port>\n        <path>/</path>\n        <uriEncoding>utf-8</uriEncoding>\n    </configuration>\n</plugin>\n```\n\n## 16.plugin-生成简单的项目骨架\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-archetype-plugin</artifactId>\n```\n\n说明:\n\nArchtype指项目的骨架，Maven初学者最开始执行的Maven命令可能就是mvn archetype:generate，这实际上就是让maven-archetype-plugin生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create，但实际上create目标已经被弃用了，取而代之的是generate目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。maven-archetype-plugin还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为他们提供一个Archtype，帮助他们快速上手。\n\n## 17.plugin-创建强制规则\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-enforcer-plugin</artifactId>\n```\n\n说明:\n\n在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的SNAPSHOT依赖而导致构建不稳定，使用了一个与大家不一致的Maven版本而经常抱怨构建出现诡异问题。maven-enforcer-plugin能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定Java版本、设定Maven版本、禁止某些依赖、禁止SNAPSHOT依赖。只要在一个父POM配置规则，然后让大家继承，当规则遭到破坏的时候，Maven就会报错。除了标准的规则之外，你还可以扩展该插件，编写自己的规则。maven-enforcer-plugin的enforce目标负责检查规则，它默认绑定到生命周期的validate阶段。\n\n## 18.plugin-帮助工具\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-help-plugin</artifactId>\n```\n\n说明:\n\nmaven-help-plugin是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和Java系统属性。help:effective-pom和help:effective-settings最为有用，它们分别打印项目的有效POM和有效settings，有效POM是指合并了所有父POM（包括Super POM）后的XML，当你不确定POM的某些信息从何而来时，就可以查看有效POM。有效settings同理，特别是当你发现自己配置的settings.xml没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin的describe目标可以帮助你描述任何一个Maven插件的信息，还有all-profiles目标和active-profiles目标帮助查看项目的Profile。\n\n## 19.plugin-其它\n\n```xml\n<groupId>com.thoughtworks.paranamer</groupId>\n<artifactId>paranamer-maven-plugin</artifactId>\n```\n\n说明:\n\n暂无\n\n实例:\n\n```xml\n<plugin>\n    <groupId>com.thoughtworks.paranamer</groupId>\n    <artifactId>paranamer-maven-plugin</artifactId>\n    <version>2.6</version>\n    <executions>\n        <execution>\n            <id>run</id>\n            <configuration>\n                <sourceDirectory>${project.build.sourceDirectory}</sourceDirectory>\n                <outputDirectory>${project.build.outputDirectory}</outputDirectory>\n            </configuration>\n            <goals>\n                <goal>generate</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 20.plugin插件本地位置\n\n在Maven中,仓库就是存放依赖和插件的地方。插件的远端、本地地址和仓库的远端、本地地址相同。\n\n在pom.xml中通过plugin引入的插件本地默认在\"C:\\Users\\Administrator\\.m2\\repository\\org\\apache\\maven\\plugins\"中。\n\n## 21.打包类型设置\n\n```xml\n<packaging>war</packaging>\n```\n\n## 21.仓库地址配置\n\n```xml\n<repositories>\n    <repository>\n        <id>public</id>\n        <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n        <releases>\n            <enabled>true</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\n## 22.Maven-settings.xml配置\n\n结构:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/POM/4.0.0\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                    http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n\n<!-- 1.【servers】:nexus仓库deploy账号设置,id分为:releases,snapshots-->\n<servers>\n\t<server>\n\t\t<id></id>\n\t\t<username></username>\n\t\t<password></password>\n\t</server>\n</servers>\n<!-- 2.【profiles】:环境配置,仓库配置-->\n<profiles>\n\t<profile>\n\t\t<id></id>\n\t\t<properties></properties>\n\t\t<repositories></repositories>\n\t\t<pluginRepositories></pluginRepositories>\n\t\t<dependencies></dependencies>\n\t\t<plugins></plugins>\n\t\t<dependencyManagement></dependencyManagement>\n\t\t<distributionManagement></distributionManagement>\n\t\t<build></build>\n\t\t<activation></activation> <!-- 激活条件:默认激活,激活条件.或者单独用activeProfiles设置 -->\n\t</profile>\n</profiles>\n<!-- 3.【activeProfiles】:激活配置设置 -->\n<activeProfiles>\n\t<activeProfile></activeProfile>\n</activeProfiles>\n<!-- 4.【mirrors】:镜像设置 -->\n<mirrors/>\n<!-- 5.【localRepository】:本地仓库设置-->\n<localRepository></localRepository>\n</settings>\n```\n\n实例1:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/POM/4.0.0\"\n\t\t  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n\t\t  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n<profiles>\n\t<profile>\n\t\t<id>Repositories</id>\n\t\t<repositories>\n\t\t\t<repository>\n\t\t\t\t<id>public</id>\n\t\t\t\t<url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n\t\t\t\t<releases>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t</releases>\n\t\t\t\t<snapshots>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t</snapshots>\n\t\t\t</repository>\n\t\t</repositories>\n\t</profile>\n</profiles>\n<activeProfiles>\n\t<activeProfile>Repositories</activeProfile>\n</activeProfiles>\n<servers>\n\t<server>\n\t\t<id>releases</id>\n\t\t<username>admin</username>\n\t\t<password>admin123</password>\n\t</server>\n\t<server>\n\t\t<id>snapshots</id>\n\t\t<username>admin</username>\n\t\t<password>admin123</password>\n\t</server>\n</servers>\n</settings>\n```\n\n实例2:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <pluginGroups></pluginGroups>\n  <proxies></proxies>\n  <!--nexus account releases帐号为nexus发布正式版本帐号发布帐号,请找部门负责人获取-->\n  <servers>\n    <server>\n      <id>releases</id>\n      <username>***</username>\n      <password>***</password>\n    </server>\n    <server>\n      <id>snapshots</id>\n    <username>deploy</username>\n      <password>deploy</password>\n    </server>\n  </servers>\n  <profiles> \n    <profile>\n    <!--maven中心库的地址\n    <repositories>\n       <repository>\n            <id>thinkive_public</id>\n            <url>http://192.168.1.99:8081/nexus/content/groups/public</url>       \n       </repository>\n    </repositories>\n    -->\n    <repositories>\n       <repository>\n            <id>thinkive_public</id>\n            <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>       \n       </repository>\n    </repositories>\n    <!--maven插件库的地址\n    <pluginRepositories>  \n      <pluginRepository>\n        <id>thinkive_plugin_public</id>\n        <url>http://192.168.1.99:8081/nexus/content/groups/public</url>\n      </pluginRepository>\n    </pluginRepositories>  \n    -->\n    <pluginRepositories>  \n      <pluginRepository>\n        <id>thinkive_plugin_public</id>\n        <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n      </pluginRepository>\n    </pluginRepositories>  \n    <activation>  \n          <activeByDefault>true</activeByDefault>  \n      </activation>  \n   </profile>\n   <profile>\n      <id>dev</id>\n      <activation>  \n          <activeByDefault>true</activeByDefault>  \n      </activation>  \n      <properties>\n        <configPath>/src/config/dev</configPath>\n      </properties>\n   </profile>\n   <profile>\n    <id>uat</id>  \n      <properties>\n        <configPath>/src/config/uat</configPath>\n      </properties>\n    </profile>\n  <profile>\n    <id>pdt</id>  \n      <properties>\n        <configPath>/src/config/pdt</configPath>\n      </properties>\n    </profile>\n  </profiles>\n  <mirrors/>\n  <localRepository>E:\\mysoft\\thinkive-repository</localRepository>\n</settings>\n```\n\n## 23.pom.xml中dependency的scope配置\n\n依赖范围控制哪些依赖在哪些classpath 中可用，哪些依赖包含在一个应用中。让我们详细看一下每一种范围：\n\ncompile （编译范围）\ncompile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。\n\nprovided （已提供范围）\nprovided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。\n\nruntime （运行时范围）\nruntime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC\n驱动实现。\ntest （测试范围）\ntest范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。\n\nsystem （系统范围）\nsystem范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。","source":"_posts/2017-07-27-Maven-配置-插件.md","raw":"---\nlayout: lay_post\ntitle: \"Maven-配置-插件\"\ndate: 2017-07-27\ncategories: 项目构建\ntags: WEB技术\nauthor: lvyafei\n---\n\n## 0.概述\n\nmaven的配置以及插件管理\n<!-- more -->\n\n## 1.pom.xml中plugins插件配置\n\n```xml\n<build>\n    <plugins>\n        .....\n    </plugins>\n</build>\n```\n\n## 2.plugin-项目编译配置\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-compiler-plugin</artifactId>\n```\n\n说明:\n\n如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话，它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题，以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本，那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现，在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-compiler-plugin</artifactId>\n    <version>3.1</version>\n    <configuration>\n        <source>1.6</source> <!-- 源代码使用的开发版本 -->\n        <target>1.6</target> <!-- 需要生成的目标class文件的编译版本 -->\n        <!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中需要没有使用低版本jdk中不支持的语法)，会存在target不同于source的情况 -->\n    \n        <!-- 这下面的是可选项 -->\n        <meminitial>128m</meminitial>\n        <maxmem>512m</maxmem>\n        <fork>true</fork> <!-- fork is enable,用于明确表示编译版本配置的可用 --> \n        <compilerVersion>1.3</compilerVersion>\n        \n        <!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 -->\n        <compilerArgument>-verbose -bootclasspath ${java.home}\\lib\\rt.jar</compilerArgument>\n        \n    </configuration>\n</plugin>\n```\n\n## 3.plugin-项目打包\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-assembly-plugin</artifactId>\n```\n\n说明:\n\nmaven-assembly-plugin的用途是制作项目分发包，该分发包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。maven-assembly-plugin支持各种主流的格式如zip、tar.gz、jar和war等，具体打包哪些文件是高度可控的，例如用户可以按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly-plugin要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的single目标可以直接在命令行调用，也可以被绑定至生命周期。\n\n实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-assembly-plugin</artifactId>\n    <configuration>\n        <!-- not append assembly id in release file name -->\n        <appendAssemblyId>false</appendAssemblyId>\n        <descriptors>\n            <descriptor>package.xml</descriptor>\n        </descriptors>\n    </configuration>\n    <executions>\n        <execution>\n            <id>make-deploy-zip</id>\n            <phase>package</phase><!-- 绑定到package生命周期阶段上 -->\n            <goals>\n                <goal>single</goal><!-- 只运行一次 -->\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 4.plugin-打包文件配置\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-jar-plugin</artifactId>\n```\n\n说明：\n\n打包文件配置:可执行jar的入口方法,如果需要把依赖的jar包一起打包,需要使用 maven-assembly-plugin\n\n实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n\t<artifactId>maven-jar-plugin</artifactId>\n\t<configuration>\n\t\t<archive>\n\t\t\t<manifest>\n\t\t\t\t<addClasspath>true</addClasspath>\n\t\t\t\t<classpathPrefix>lib/</classpathPrefix>\n\t\t\t\t<useUniqueVersions>false</useUniqueVersions>\n\t\t\t\t<mainClass>hbec.forum.recsys.etl.BootStrap</mainClass>\n\t\t\t</manifest>\n\t\t\t<manifestEntries>\n\t\t\t\t<Class-Path>configs/</Class-Path>\n\t\t\t</manifestEntries>\n\t\t</archive>\n\t\t<excludes>\n\t\t\t<exclude>*.xml</exclude>\n\t\t\t<exclude>**/*.xml</exclude>\n\t\t\t<exclude>*.json</exclude>\n\t\t\t<exclude>*.properties</exclude>\n\t\t\t<exclude>*.cfg</exclude>\n\t\t</excludes>\n\t</configuration>\n</plugin>\n```\n\n## 5.plugin-项目依赖管理\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-dependency-plugin</artifactId>\n```\n\n说明:\n\nmaven-dependency-plugin最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地Maven仓库复制到某个特定的文件夹下面。\n\n实例:\n\n```xml\n<plugin>  \n    <groupId>org.apache.maven.plugins</groupId>  \n    <artifactId>maven-dependency-plugin</artifactId>  \n    <executions>  \n        <execution>  \n            <id>copy</id>  \n            <phase>package</phase>  \n            <goals>  \n                <goal>copy-dependencies</goal>  \n            </goals>  \n            <configuration>  \n                <outputDirectory>  \n                    ${project.build.directory}/lib  \n                </outputDirectory>  \n            </configuration>  \n        </execution>  \n    </executions>  \n</plugin>\n```\n\n## 6.plugin-项目版本发布\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-release-plugin</artifactId>\n```\n\n说明:\n\nmaven-release-plugin的用途是帮助自动化项目版本发布，它依赖于POM中的SCM信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有SNAPSHOT依赖、升级项目的SNAPSHOT版本至RELEASE版本、为项目打标签等等。release:perform则是签出标签中的RELEASE源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一些细节，maven-release-plugin让该工作变得非常快速简便，不易出错。maven-release-plugin的各种目标通常直接在命令行调用，因为版本发布显然不是日常构建生命周期的一部分.\t  \n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.4.2</version>\n    <configuration>\n        <tagBase>${svn.url}/${project.artifactId}/tags/</tagBase>\n        <branchBase>${svn.url}/${project.artifactId}/branches/</branchBase>\n    </configuration>\n</plugin>\n```\n\n## 7.plugin-资源文件处理\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-resources-plugin</artifactId>\n```\n\n说明:\n\n为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。\n        \n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-resources-plugin</artifactId>\n    <version>2.6</version>\n    <configuration>\n        <encoding>GBK</encoding>\n    </configuration>\n    <executions>\n        <execution>\n            <id>copy-xmls</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.xml</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <execution>\n            <id>copy-properties</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.properties</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <execution>\n            <id>copy-dic</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/main/java</directory>\n                        <includes>\n                            <include>**/*.dic</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <!-- 打包配置文件 start -->\n        <execution>\n            <id>copy-dev</id>\n            <phase>process-sources</phase>\n            <goals>\n                <goal>copy-resources</goal>\n            </goals>\n            <configuration>\n                <outputDirectory>${basedir}/target/classes</outputDirectory>\n                <resources>\n                    <resource>\n                        <directory>${basedir}/src/config/dev</directory>\n                        <includes>\n                            <include>**/*.*</include>\n                        </includes>\n                    </resource>\n                </resources>\n            </configuration>\n        </execution>\n        <!-- 打包配置文件 end -->\n    </executions>\n</plugin>\n```\n\n## 8.plugin-Maven中运行ant任务\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-antrun-plugin</artifactId>\n```\n\n说明:\n\nmaven-antrun-plugin能让用户在Maven项目中运行Ant任务。用户可以直接在该插件的配置以Ant的方式编写Target，然后交给该插件的run目标去执行。在一些由Ant往Maven迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉得Maven不够灵活时，也可以以Ant的方式实现之。maven-antrun-plugin的run目标通常与生命周期绑定运行。\n\n使用实例:\n\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-antrun-plugin</artifactId>\n    <version>1.7</version>\n    <executions>\n        <execution>\n            <phase>package</phase>\n            <configuration>\n                <tasks>\n                    <copy todir=\"target\">\n                        <fileset dir=\"target/${project.artifactId}-${project.version}\"></fileset>\n                    </copy>\n                </tasks>\n            </configuration>\n            <goals>\n                <goal>run</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 9.plugin-生成项目源码包\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-source-plugin</artifactId>\n```\n\n说明:\n\n打包项目源文件到jar包中\n\n实例:      \n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-source-plugin</artifactId>\n    <version>2.2.1</version>\n    <executions>\n        <execution>\n            <id>attach-sources</id>\n            <phase>package</phase>\n            <goals>\n                <goal>jar-no-fork</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 10.plugin-生成项目javadoc文档\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-javadoc-plugin</artifactId>         \n```\n\n说明:\n\n生成项目javadoc文档\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-javadoc-plugin</artifactId>\n    <version>2.9</version>\n    <configuration>\n        <encoding>GBK</encoding>\n    </configuration>\n</plugin>\n```\n\n## 11.plugin-生成项目HTML说明文件\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-site-plugin</artifactId>\n```\n\n说明:\n\n使用maven 的site 插件 生成一个 可以在 浏览器中 查看项目的站点\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-site-plugin</artifactId>\n    <version>3.3</version>\n    <configuration>\n        <outputEncoding>GBK</outputEncoding>\n    </configuration>\n</plugin>\n```\n\n## 12.plugin-执行单元测试\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-surefire-plugin</artifactId>\n```\n\n说明:\n\n可能是由于历史的原因，Maven 2/3中用于执行测试的插件不是maven-test-plugin，而是maven-surefire-plugin。其实大部分时间内，只要你的测试类遵循通用的命令约定（以Test结尾、以TestCase结尾、或者以Test开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些测试类、或者使用一些TestNG特性的时候，了解maven-surefire-plugin的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行FooTest测试类，这是通过控制maven-surefire-plugin的test参数实现的。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-surefire-plugin</artifactId>\n    <version>2.9</version>\n    <configuration>\n        <skip>true</skip> <!-- 跳过测试阶段 -->\n        <testFailureIgnore>true</testFailureIgnore>  <!-- 忽略测试失败 -->\n    </configuration>\n</plugin>\n```\n\n## 13.plugin-自动配合SVN进行版本发布\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-scm-plugin</artifactId>\n```\n\n说明:\n\nMaven中为我们集成了软件配置管理的（SCM：Software Configuration Management）功能，他可以支持我们常用SVN、CVS等，到现在我使用的1.8.1版本，共支持18个命令\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-scm-plugin</artifactId>\n    <version>1.8.1</version>\n</plugin>\n```\n\n## 14.plugin-jetty运行插件\n\n```xml\n<groupId>org.mortbay.jetty</groupId>\n<artifactId>maven-jetty-plugin</artifactId>\n```\n\n说明:\n\n在进行Web开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成war文件，然后部署到Web容器中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin应运而生，它完全兼容 Maven项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的Jetty Web容器中。做一些基本配置后（例如Web应用的contextPath和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在IDE中修改代码，代码经IDE自动编译后产生变更，再由jetty-maven-plugin侦测到后更新至Jetty容器，这时你就可以直接测试Web页面了。需要注意的是，jetty-maven-plugin并不是宿主于Apache或Codehaus的官方插件，因此使用的时候需要额外的配置settings.xml的pluginGroups元素，将org.mortbay.jetty这个pluginGroup加入。\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.mortbay.jetty</groupId>\n    <artifactId>maven-jetty-plugin</artifactId>\n    <version>6.1.10</version>\n    <configuration>\n            <scanIntervalSeconds>10</scanIntervalSeconds>\n            <stopKey>foo</stopKey>\n            <stopPort>9999</stopPort>\n    </configuration>\n    <executions>\n        <execution>\n            <id>start-jetty</id>\n            <phase>pre-integration-test</phase>\n            <goals>\n                <goal>run</goal>\n            </goals>\n            <configuration>\n                <scanIntervalSeconds>0</scanIntervalSeconds>\n                <daemon>true</daemon>\n            </configuration>\n        </execution>\n        <execution>\n            <id>stop-jetty</id>\n            <phase>post-integration-test</phase>\n            <goals>\n                <goal>stop</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n开始：mvn jetty:start  关闭：mvn jetty:stop\n\n## 15.plugin-在tomcat中运行项目\n\n```xml\n<groupId>org.apache.tomcat.maven</groupId>\n<artifactId>tomcat7-maven-plugin</artifactId>\n```\n\n说明:\n\n使用maven将web项目运行在tomcat中\n\n实例:\n\n```xml\n<plugin>\n    <groupId>org.apache.tomcat.maven</groupId>\n    <artifactId>tomcat7-maven-plugin</artifactId>\n    <version>2.2</version>\n    <configuration>\n        <port>8889</port>\n        <path>/</path>\n        <uriEncoding>utf-8</uriEncoding>\n    </configuration>\n</plugin>\n```\n\n## 16.plugin-生成简单的项目骨架\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-archetype-plugin</artifactId>\n```\n\n说明:\n\nArchtype指项目的骨架，Maven初学者最开始执行的Maven命令可能就是mvn archetype:generate，这实际上就是让maven-archetype-plugin生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create，但实际上create目标已经被弃用了，取而代之的是generate目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。maven-archetype-plugin还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为他们提供一个Archtype，帮助他们快速上手。\n\n## 17.plugin-创建强制规则\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-enforcer-plugin</artifactId>\n```\n\n说明:\n\n在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的SNAPSHOT依赖而导致构建不稳定，使用了一个与大家不一致的Maven版本而经常抱怨构建出现诡异问题。maven-enforcer-plugin能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定Java版本、设定Maven版本、禁止某些依赖、禁止SNAPSHOT依赖。只要在一个父POM配置规则，然后让大家继承，当规则遭到破坏的时候，Maven就会报错。除了标准的规则之外，你还可以扩展该插件，编写自己的规则。maven-enforcer-plugin的enforce目标负责检查规则，它默认绑定到生命周期的validate阶段。\n\n## 18.plugin-帮助工具\n\n```xml\n<groupId>org.apache.maven.plugins</groupId>\n<artifactId>maven-help-plugin</artifactId>\n```\n\n说明:\n\nmaven-help-plugin是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和Java系统属性。help:effective-pom和help:effective-settings最为有用，它们分别打印项目的有效POM和有效settings，有效POM是指合并了所有父POM（包括Super POM）后的XML，当你不确定POM的某些信息从何而来时，就可以查看有效POM。有效settings同理，特别是当你发现自己配置的settings.xml没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin的describe目标可以帮助你描述任何一个Maven插件的信息，还有all-profiles目标和active-profiles目标帮助查看项目的Profile。\n\n## 19.plugin-其它\n\n```xml\n<groupId>com.thoughtworks.paranamer</groupId>\n<artifactId>paranamer-maven-plugin</artifactId>\n```\n\n说明:\n\n暂无\n\n实例:\n\n```xml\n<plugin>\n    <groupId>com.thoughtworks.paranamer</groupId>\n    <artifactId>paranamer-maven-plugin</artifactId>\n    <version>2.6</version>\n    <executions>\n        <execution>\n            <id>run</id>\n            <configuration>\n                <sourceDirectory>${project.build.sourceDirectory}</sourceDirectory>\n                <outputDirectory>${project.build.outputDirectory}</outputDirectory>\n            </configuration>\n            <goals>\n                <goal>generate</goal>\n            </goals>\n        </execution>\n    </executions>\n</plugin>\n```\n\n## 20.plugin插件本地位置\n\n在Maven中,仓库就是存放依赖和插件的地方。插件的远端、本地地址和仓库的远端、本地地址相同。\n\n在pom.xml中通过plugin引入的插件本地默认在\"C:\\Users\\Administrator\\.m2\\repository\\org\\apache\\maven\\plugins\"中。\n\n## 21.打包类型设置\n\n```xml\n<packaging>war</packaging>\n```\n\n## 21.仓库地址配置\n\n```xml\n<repositories>\n    <repository>\n        <id>public</id>\n        <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n        <releases>\n            <enabled>true</enabled>\n        </releases>\n        <snapshots>\n            <enabled>true</enabled>\n        </snapshots>\n    </repository>\n</repositories>\n```\n\n## 22.Maven-settings.xml配置\n\n结构:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/POM/4.0.0\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0\n                    http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n\n<!-- 1.【servers】:nexus仓库deploy账号设置,id分为:releases,snapshots-->\n<servers>\n\t<server>\n\t\t<id></id>\n\t\t<username></username>\n\t\t<password></password>\n\t</server>\n</servers>\n<!-- 2.【profiles】:环境配置,仓库配置-->\n<profiles>\n\t<profile>\n\t\t<id></id>\n\t\t<properties></properties>\n\t\t<repositories></repositories>\n\t\t<pluginRepositories></pluginRepositories>\n\t\t<dependencies></dependencies>\n\t\t<plugins></plugins>\n\t\t<dependencyManagement></dependencyManagement>\n\t\t<distributionManagement></distributionManagement>\n\t\t<build></build>\n\t\t<activation></activation> <!-- 激活条件:默认激活,激活条件.或者单独用activeProfiles设置 -->\n\t</profile>\n</profiles>\n<!-- 3.【activeProfiles】:激活配置设置 -->\n<activeProfiles>\n\t<activeProfile></activeProfile>\n</activeProfiles>\n<!-- 4.【mirrors】:镜像设置 -->\n<mirrors/>\n<!-- 5.【localRepository】:本地仓库设置-->\n<localRepository></localRepository>\n</settings>\n```\n\n实例1:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/POM/4.0.0\"\n\t\t  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n\t\t  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n<profiles>\n\t<profile>\n\t\t<id>Repositories</id>\n\t\t<repositories>\n\t\t\t<repository>\n\t\t\t\t<id>public</id>\n\t\t\t\t<url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n\t\t\t\t<releases>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t</releases>\n\t\t\t\t<snapshots>\n\t\t\t\t\t<enabled>true</enabled>\n\t\t\t\t</snapshots>\n\t\t\t</repository>\n\t\t</repositories>\n\t</profile>\n</profiles>\n<activeProfiles>\n\t<activeProfile>Repositories</activeProfile>\n</activeProfiles>\n<servers>\n\t<server>\n\t\t<id>releases</id>\n\t\t<username>admin</username>\n\t\t<password>admin123</password>\n\t</server>\n\t<server>\n\t\t<id>snapshots</id>\n\t\t<username>admin</username>\n\t\t<password>admin123</password>\n\t</server>\n</servers>\n</settings>\n```\n\n实例2:\n\n```xml\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <pluginGroups></pluginGroups>\n  <proxies></proxies>\n  <!--nexus account releases帐号为nexus发布正式版本帐号发布帐号,请找部门负责人获取-->\n  <servers>\n    <server>\n      <id>releases</id>\n      <username>***</username>\n      <password>***</password>\n    </server>\n    <server>\n      <id>snapshots</id>\n    <username>deploy</username>\n      <password>deploy</password>\n    </server>\n  </servers>\n  <profiles> \n    <profile>\n    <!--maven中心库的地址\n    <repositories>\n       <repository>\n            <id>thinkive_public</id>\n            <url>http://192.168.1.99:8081/nexus/content/groups/public</url>       \n       </repository>\n    </repositories>\n    -->\n    <repositories>\n       <repository>\n            <id>thinkive_public</id>\n            <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>       \n       </repository>\n    </repositories>\n    <!--maven插件库的地址\n    <pluginRepositories>  \n      <pluginRepository>\n        <id>thinkive_plugin_public</id>\n        <url>http://192.168.1.99:8081/nexus/content/groups/public</url>\n      </pluginRepository>\n    </pluginRepositories>  \n    -->\n    <pluginRepositories>  \n      <pluginRepository>\n        <id>thinkive_plugin_public</id>\n        <url>http://10.0.30.78:8080/nexus/content/groups/public/</url>\n      </pluginRepository>\n    </pluginRepositories>  \n    <activation>  \n          <activeByDefault>true</activeByDefault>  \n      </activation>  \n   </profile>\n   <profile>\n      <id>dev</id>\n      <activation>  \n          <activeByDefault>true</activeByDefault>  \n      </activation>  \n      <properties>\n        <configPath>/src/config/dev</configPath>\n      </properties>\n   </profile>\n   <profile>\n    <id>uat</id>  \n      <properties>\n        <configPath>/src/config/uat</configPath>\n      </properties>\n    </profile>\n  <profile>\n    <id>pdt</id>  \n      <properties>\n        <configPath>/src/config/pdt</configPath>\n      </properties>\n    </profile>\n  </profiles>\n  <mirrors/>\n  <localRepository>E:\\mysoft\\thinkive-repository</localRepository>\n</settings>\n```\n\n## 23.pom.xml中dependency的scope配置\n\n依赖范围控制哪些依赖在哪些classpath 中可用，哪些依赖包含在一个应用中。让我们详细看一下每一种范围：\n\ncompile （编译范围）\ncompile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。\n\nprovided （已提供范围）\nprovided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。\n\nruntime （运行时范围）\nruntime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC\n驱动实现。\ntest （测试范围）\ntest范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。\n\nsystem （系统范围）\nsystem范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。","slug":"2017-07-27-Maven-配置-插件","published":1,"updated":"2018-11-29T12:51:25.290Z","comments":1,"photos":[],"link":"","_id":"cjskffoch00514glm4f9jv6s9","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>maven的配置以及插件管理<br><a id=\"more\"></a></p>\n<h2 id=\"1-pom-xml中plugins插件配置\"><a href=\"#1-pom-xml中plugins插件配置\" class=\"headerlink\" title=\"1.pom.xml中plugins插件配置\"></a>1.pom.xml中plugins插件配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">        .....</span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-plugin-项目编译配置\"><a href=\"#2-plugin-项目编译配置\" class=\"headerlink\" title=\"2.plugin-项目编译配置\"></a>2.plugin-项目编译配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话，它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题，以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本，那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现，在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>1.6<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span> <span class=\"comment\">&lt;!-- 源代码使用的开发版本 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">target</span>&gt;</span>1.6<span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span> <span class=\"comment\">&lt;!-- 需要生成的目标class文件的编译版本 --&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中需要没有使用低版本jdk中不支持的语法)，会存在target不同于source的情况 --&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 这下面的是可选项 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">meminitial</span>&gt;</span>128m<span class=\"tag\">&lt;/<span class=\"name\">meminitial</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxmem</span>&gt;</span>512m<span class=\"tag\">&lt;/<span class=\"name\">maxmem</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fork</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">fork</span>&gt;</span> <span class=\"comment\">&lt;!-- fork is enable,用于明确表示编译版本配置的可用 --&gt;</span> </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">compilerVersion</span>&gt;</span>1.3<span class=\"tag\">&lt;/<span class=\"name\">compilerVersion</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">compilerArgument</span>&gt;</span>-verbose -bootclasspath $&#123;java.home&#125;\\lib\\rt.jar<span class=\"tag\">&lt;/<span class=\"name\">compilerArgument</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-plugin-项目打包\"><a href=\"#3-plugin-项目打包\" class=\"headerlink\" title=\"3.plugin-项目打包\"></a>3.plugin-项目打包</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-assembly-plugin的用途是制作项目分发包，该分发包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。maven-assembly-plugin支持各种主流的格式如zip、tar.gz、jar和war等，具体打包哪些文件是高度可控的，例如用户可以按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly-plugin要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的single目标可以直接在命令行调用，也可以被绑定至生命周期。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- not append assembly id in release file name --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">appendAssemblyId</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">appendAssemblyId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>package.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>make-deploy-zip<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span><span class=\"comment\">&lt;!-- 绑定到package生命周期阶段上 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>single<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span><span class=\"comment\">&lt;!-- 只运行一次 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-plugin-打包文件配置\"><a href=\"#4-plugin-打包文件配置\" class=\"headerlink\" title=\"4.plugin-打包文件配置\"></a>4.plugin-打包文件配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jar-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明：</p>\n<p>打包文件配置:可执行jar的入口方法,如果需要把依赖的jar包一起打包,需要使用 maven-assembly-plugin</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jar-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">archive</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">manifest</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">addClasspath</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">addClasspath</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">classpathPrefix</span>&gt;</span>lib/<span class=\"tag\">&lt;/<span class=\"name\">classpathPrefix</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">useUniqueVersions</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">useUniqueVersions</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">mainClass</span>&gt;</span>hbec.forum.recsys.etl.BootStrap<span class=\"tag\">&lt;/<span class=\"name\">mainClass</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">manifest</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">manifestEntries</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">Class-Path</span>&gt;</span>configs/<span class=\"tag\">&lt;/<span class=\"name\">Class-Path</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">manifestEntries</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">archive</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.xml<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.json<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.properties<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.cfg<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"5-plugin-项目依赖管理\"><a href=\"#5-plugin-项目依赖管理\" class=\"headerlink\" title=\"5.plugin-项目依赖管理\"></a>5.plugin-项目依赖管理</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-dependency-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-dependency-plugin最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地Maven仓库复制到某个特定的文件夹下面。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-dependency-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span>  </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span>  </span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-dependencies<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span>  </span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>  </span><br><span class=\"line\">                    $&#123;project.build.directory&#125;/lib  </span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span>  </span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span>  </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-plugin-项目版本发布\"><a href=\"#6-plugin-项目版本发布\" class=\"headerlink\" title=\"6.plugin-项目版本发布\"></a>6.plugin-项目版本发布</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-release-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-release-plugin的用途是帮助自动化项目版本发布，它依赖于POM中的SCM信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有SNAPSHOT依赖、升级项目的SNAPSHOT版本至RELEASE版本、为项目打标签等等。release:perform则是签出标签中的RELEASE源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一些细节，maven-release-plugin让该工作变得非常快速简便，不易出错。maven-release-plugin的各种目标通常直接在命令行调用，因为版本发布显然不是日常构建生命周期的一部分.      </p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-release-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.4.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">tagBase</span>&gt;</span>$&#123;svn.url&#125;/$&#123;project.artifactId&#125;/tags/<span class=\"tag\">&lt;/<span class=\"name\">tagBase</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">branchBase</span>&gt;</span>$&#123;svn.url&#125;/$&#123;project.artifactId&#125;/branches/<span class=\"tag\">&lt;/<span class=\"name\">branchBase</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"7-plugin-资源文件处理\"><a href=\"#7-plugin-资源文件处理\" class=\"headerlink\" title=\"7.plugin-资源文件处理\"></a>7.plugin-资源文件处理</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-resources-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-resources-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.6<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">encoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">encoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-xmls<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-properties<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.properties<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-dic<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.dic<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包配置文件 start --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-dev<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/config/dev<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.*<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包配置文件 end --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"8-plugin-Maven中运行ant任务\"><a href=\"#8-plugin-Maven中运行ant任务\" class=\"headerlink\" title=\"8.plugin-Maven中运行ant任务\"></a>8.plugin-Maven中运行ant任务</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-antrun-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-antrun-plugin能让用户在Maven项目中运行Ant任务。用户可以直接在该插件的配置以Ant的方式编写Target，然后交给该插件的run目标去执行。在一些由Ant往Maven迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉得Maven不够灵活时，也可以以Ant的方式实现之。maven-antrun-plugin的run目标通常与生命周期绑定运行。</p>\n<p>使用实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-antrun-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.7<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">tasks</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"target\"</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"target/$&#123;project.artifactId&#125;-$&#123;project.version&#125;\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">tasks</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"9-plugin-生成项目源码包\"><a href=\"#9-plugin-生成项目源码包\" class=\"headerlink\" title=\"9.plugin-生成项目源码包\"></a>9.plugin-生成项目源码包</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-source-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>打包项目源文件到jar包中</p>\n<p>实例:      </p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-source-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.2.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>attach-sources<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>jar-no-fork<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"10-plugin-生成项目javadoc文档\"><a href=\"#10-plugin-生成项目javadoc文档\" class=\"headerlink\" title=\"10.plugin-生成项目javadoc文档\"></a>10.plugin-生成项目javadoc文档</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-javadoc-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>生成项目javadoc文档</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-javadoc-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.9<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">encoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">encoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"11-plugin-生成项目HTML说明文件\"><a href=\"#11-plugin-生成项目HTML说明文件\" class=\"headerlink\" title=\"11.plugin-生成项目HTML说明文件\"></a>11.plugin-生成项目HTML说明文件</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-site-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>使用maven 的site 插件 生成一个 可以在 浏览器中 查看项目的站点</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-site-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.3<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">outputEncoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">outputEncoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"12-plugin-执行单元测试\"><a href=\"#12-plugin-执行单元测试\" class=\"headerlink\" title=\"12.plugin-执行单元测试\"></a>12.plugin-执行单元测试</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-surefire-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>可能是由于历史的原因，Maven 2/3中用于执行测试的插件不是maven-test-plugin，而是maven-surefire-plugin。其实大部分时间内，只要你的测试类遵循通用的命令约定（以Test结尾、以TestCase结尾、或者以Test开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些测试类、或者使用一些TestNG特性的时候，了解maven-surefire-plugin的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行FooTest测试类，这是通过控制maven-surefire-plugin的test参数实现的。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-surefire-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.9<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">skip</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">skip</span>&gt;</span> <span class=\"comment\">&lt;!-- 跳过测试阶段 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">testFailureIgnore</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">testFailureIgnore</span>&gt;</span>  <span class=\"comment\">&lt;!-- 忽略测试失败 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"13-plugin-自动配合SVN进行版本发布\"><a href=\"#13-plugin-自动配合SVN进行版本发布\" class=\"headerlink\" title=\"13.plugin-自动配合SVN进行版本发布\"></a>13.plugin-自动配合SVN进行版本发布</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-scm-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>Maven中为我们集成了软件配置管理的（SCM：Software Configuration Management）功能，他可以支持我们常用SVN、CVS等，到现在我使用的1.8.1版本，共支持18个命令</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-scm-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"14-plugin-jetty运行插件\"><a href=\"#14-plugin-jetty运行插件\" class=\"headerlink\" title=\"14.plugin-jetty运行插件\"></a>14.plugin-jetty运行插件</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.mortbay.jetty<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jetty-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>在进行Web开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成war文件，然后部署到Web容器中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin应运而生，它完全兼容 Maven项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的Jetty Web容器中。做一些基本配置后（例如Web应用的contextPath和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在IDE中修改代码，代码经IDE自动编译后产生变更，再由jetty-maven-plugin侦测到后更新至Jetty容器，这时你就可以直接测试Web页面了。需要注意的是，jetty-maven-plugin并不是宿主于Apache或Codehaus的官方插件，因此使用的时候需要额外的配置settings.xml的pluginGroups元素，将org.mortbay.jetty这个pluginGroup加入。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.mortbay.jetty<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jetty-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>6.1.10<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scanIntervalSeconds</span>&gt;</span>10<span class=\"tag\">&lt;/<span class=\"name\">scanIntervalSeconds</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">stopKey</span>&gt;</span>foo<span class=\"tag\">&lt;/<span class=\"name\">stopKey</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">stopPort</span>&gt;</span>9999<span class=\"tag\">&lt;/<span class=\"name\">stopPort</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>start-jetty<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>pre-integration-test<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">scanIntervalSeconds</span>&gt;</span>0<span class=\"tag\">&lt;/<span class=\"name\">scanIntervalSeconds</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">daemon</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">daemon</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>stop-jetty<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>post-integration-test<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>stop<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>开始：mvn jetty:start  关闭：mvn jetty:stop</p>\n<h2 id=\"15-plugin-在tomcat中运行项目\"><a href=\"#15-plugin-在tomcat中运行项目\" class=\"headerlink\" title=\"15.plugin-在tomcat中运行项目\"></a>15.plugin-在tomcat中运行项目</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.tomcat.maven<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>tomcat7-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>使用maven将web项目运行在tomcat中</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.tomcat.maven<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>tomcat7-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">port</span>&gt;</span>8889<span class=\"tag\">&lt;/<span class=\"name\">port</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">uriEncoding</span>&gt;</span>utf-8<span class=\"tag\">&lt;/<span class=\"name\">uriEncoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"16-plugin-生成简单的项目骨架\"><a href=\"#16-plugin-生成简单的项目骨架\" class=\"headerlink\" title=\"16.plugin-生成简单的项目骨架\"></a>16.plugin-生成简单的项目骨架</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-archetype-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>Archtype指项目的骨架，Maven初学者最开始执行的Maven命令可能就是mvn archetype:generate，这实际上就是让maven-archetype-plugin生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create，但实际上create目标已经被弃用了，取而代之的是generate目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。maven-archetype-plugin还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为他们提供一个Archtype，帮助他们快速上手。</p>\n<h2 id=\"17-plugin-创建强制规则\"><a href=\"#17-plugin-创建强制规则\" class=\"headerlink\" title=\"17.plugin-创建强制规则\"></a>17.plugin-创建强制规则</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-enforcer-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的SNAPSHOT依赖而导致构建不稳定，使用了一个与大家不一致的Maven版本而经常抱怨构建出现诡异问题。maven-enforcer-plugin能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定Java版本、设定Maven版本、禁止某些依赖、禁止SNAPSHOT依赖。只要在一个父POM配置规则，然后让大家继承，当规则遭到破坏的时候，Maven就会报错。除了标准的规则之外，你还可以扩展该插件，编写自己的规则。maven-enforcer-plugin的enforce目标负责检查规则，它默认绑定到生命周期的validate阶段。</p>\n<h2 id=\"18-plugin-帮助工具\"><a href=\"#18-plugin-帮助工具\" class=\"headerlink\" title=\"18.plugin-帮助工具\"></a>18.plugin-帮助工具</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-help-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-help-plugin是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和Java系统属性。help:effective-pom和help:effective-settings最为有用，它们分别打印项目的有效POM和有效settings，有效POM是指合并了所有父POM（包括Super POM）后的XML，当你不确定POM的某些信息从何而来时，就可以查看有效POM。有效settings同理，特别是当你发现自己配置的settings.xml没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin的describe目标可以帮助你描述任何一个Maven插件的信息，还有all-profiles目标和active-profiles目标帮助查看项目的Profile。</p>\n<h2 id=\"19-plugin-其它\"><a href=\"#19-plugin-其它\" class=\"headerlink\" title=\"19.plugin-其它\"></a>19.plugin-其它</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.thoughtworks.paranamer<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>paranamer-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>暂无</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.thoughtworks.paranamer<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>paranamer-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.6<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">sourceDirectory</span>&gt;</span>$&#123;project.build.sourceDirectory&#125;<span class=\"tag\">&lt;/<span class=\"name\">sourceDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;project.build.outputDirectory&#125;<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>generate<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"20-plugin插件本地位置\"><a href=\"#20-plugin插件本地位置\" class=\"headerlink\" title=\"20.plugin插件本地位置\"></a>20.plugin插件本地位置</h2><p>在Maven中,仓库就是存放依赖和插件的地方。插件的远端、本地地址和仓库的远端、本地地址相同。</p>\n<p>在pom.xml中通过plugin引入的插件本地默认在”C:\\Users\\Administrator.m2\\repository\\org\\apache\\maven\\plugins”中。</p>\n<h2 id=\"21-打包类型设置\"><a href=\"#21-打包类型设置\" class=\"headerlink\" title=\"21.打包类型设置\"></a>21.打包类型设置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>war<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"21-仓库地址配置\"><a href=\"#21-仓库地址配置\" class=\"headerlink\" title=\"21.仓库地址配置\"></a>21.仓库地址配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"22-Maven-settings-xml配置\"><a href=\"#22-Maven-settings-xml配置\" class=\"headerlink\" title=\"22.Maven-settings.xml配置\"></a>22.Maven-settings.xml配置</h2><p>结构:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                    http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 1.【servers】:nexus仓库deploy账号设置,id分为:releases,snapshots--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 2.【profiles】:环境配置,仓库配置--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">pluginRepositories</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">pluginRepositories</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">dependencyManagement</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">dependencyManagement</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">distributionManagement</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span> <span class=\"comment\">&lt;!-- 激活条件:默认激活,激活条件.或者单独用activeProfiles设置 --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 3.【activeProfiles】:激活配置设置 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">activeProfile</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">activeProfile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 4.【mirrors】:镜像设置 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirrors</span>/&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 5.【localRepository】:本地仓库设置--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">localRepository</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">localRepository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>实例1:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">\t\t  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">\t\t  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>Repositories<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">activeProfile</span>&gt;</span>Repositories<span class=\"tag\">&lt;/<span class=\"name\">activeProfile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>releases<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>admin<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>admin123<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>snapshots<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>admin<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>admin123<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>实例2:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">pluginGroups</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">pluginGroups</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">proxies</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">proxies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"comment\">&lt;!--nexus account releases帐号为nexus发布正式版本帐号发布帐号,请找部门负责人获取--&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>releases<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>***<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>***<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>snapshots<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!--maven中心库的地址</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;repositories&gt;</span></span><br><span class=\"line\"><span class=\"comment\">       &lt;repository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">            &lt;id&gt;thinkive_public&lt;/id&gt;</span></span><br><span class=\"line\"><span class=\"comment\">            &lt;url&gt;http://192.168.1.99:8081/nexus/content/groups/public&lt;/url&gt;       </span></span><br><span class=\"line\"><span class=\"comment\">       &lt;/repository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;/repositories&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>thinkive_public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span>       </span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!--maven插件库的地址</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;pluginRepositories&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">      &lt;pluginRepository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">        &lt;id&gt;thinkive_plugin_public&lt;/id&gt;</span></span><br><span class=\"line\"><span class=\"comment\">        &lt;url&gt;http://192.168.1.99:8081/nexus/content/groups/public&lt;/url&gt;</span></span><br><span class=\"line\"><span class=\"comment\">      &lt;/pluginRepository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;/pluginRepositories&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">pluginRepositories</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">pluginRepository</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>thinkive_plugin_public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">pluginRepository</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">pluginRepositories</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">activeByDefault</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">activeByDefault</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>dev<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">activeByDefault</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">activeByDefault</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/dev<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>uat<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/uat<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>pdt<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/pdt<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">mirrors</span>/&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">localRepository</span>&gt;</span>E:\\mysoft\\thinkive-repository<span class=\"tag\">&lt;/<span class=\"name\">localRepository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"23-pom-xml中dependency的scope配置\"><a href=\"#23-pom-xml中dependency的scope配置\" class=\"headerlink\" title=\"23.pom.xml中dependency的scope配置\"></a>23.pom.xml中dependency的scope配置</h2><p>依赖范围控制哪些依赖在哪些classpath 中可用，哪些依赖包含在一个应用中。让我们详细看一下每一种范围：</p>\n<p>compile （编译范围）<br>compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。</p>\n<p>provided （已提供范围）<br>provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。</p>\n<p>runtime （运行时范围）<br>runtime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC<br>驱动实现。<br>test （测试范围）<br>test范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。</p>\n<p>system （系统范围）<br>system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>maven的配置以及插件管理<br>","more":"</p>\n<h2 id=\"1-pom-xml中plugins插件配置\"><a href=\"#1-pom-xml中plugins插件配置\" class=\"headerlink\" title=\"1.pom.xml中plugins插件配置\"></a>1.pom.xml中plugins插件配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">        .....</span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-plugin-项目编译配置\"><a href=\"#2-plugin-项目编译配置\" class=\"headerlink\" title=\"2.plugin-项目编译配置\"></a>2.plugin-项目编译配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>如果我们不告诉它我们的代码要使用什么样的jdk版本编译的话，它就会用maven-compiler-plugin默认的jdk版本来进行处理，这样就容易出现版本不匹配的问题，以至于可能导致编译不通过的问题。例如代码中要是使用上了jdk1.7的新特性，但是maven在编译的时候使用的是jdk1.6的版本，那这一段代码是完全不可能编译成.class文件的。为了处理这一种情况的出现，在构建maven项目的时候，我习惯性第一步就是配置maven-compiler-plugin插件。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-compiler-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">source</span>&gt;</span>1.6<span class=\"tag\">&lt;/<span class=\"name\">source</span>&gt;</span> <span class=\"comment\">&lt;!-- 源代码使用的开发版本 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">target</span>&gt;</span>1.6<span class=\"tag\">&lt;/<span class=\"name\">target</span>&gt;</span> <span class=\"comment\">&lt;!-- 需要生成的目标class文件的编译版本 --&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 一般而言，target与source是保持一致的，但是，有时候为了让程序能在其他版本的jdk中运行(对于低版本目标jdk，源代码中需要没有使用低版本jdk中不支持的语法)，会存在target不同于source的情况 --&gt;</span></span><br><span class=\"line\">    </span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 这下面的是可选项 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">meminitial</span>&gt;</span>128m<span class=\"tag\">&lt;/<span class=\"name\">meminitial</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">maxmem</span>&gt;</span>512m<span class=\"tag\">&lt;/<span class=\"name\">maxmem</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">fork</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">fork</span>&gt;</span> <span class=\"comment\">&lt;!-- fork is enable,用于明确表示编译版本配置的可用 --&gt;</span> </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">compilerVersion</span>&gt;</span>1.3<span class=\"tag\">&lt;/<span class=\"name\">compilerVersion</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 这个选项用来传递编译器自身不包含但是却支持的参数选项 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">compilerArgument</span>&gt;</span>-verbose -bootclasspath $&#123;java.home&#125;\\lib\\rt.jar<span class=\"tag\">&lt;/<span class=\"name\">compilerArgument</span>&gt;</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"3-plugin-项目打包\"><a href=\"#3-plugin-项目打包\" class=\"headerlink\" title=\"3.plugin-项目打包\"></a>3.plugin-项目打包</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-assembly-plugin的用途是制作项目分发包，该分发包可能包含了项目的可执行文件、源代码、readme、平台脚本等等。maven-assembly-plugin支持各种主流的格式如zip、tar.gz、jar和war等，具体打包哪些文件是高度可控的，例如用户可以按文件级别的粒度、文件集级别的粒度、模块级别的粒度、以及依赖级别的粒度控制打包，此外，包含和排除配置也是支持的。maven-assembly-plugin要求用户使用一个名为assembly.xml的元数据文件来表述打包，它的single目标可以直接在命令行调用，也可以被绑定至生命周期。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-assembly-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- not append assembly id in release file name --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">appendAssemblyId</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">appendAssemblyId</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">descriptor</span>&gt;</span>package.xml<span class=\"tag\">&lt;/<span class=\"name\">descriptor</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">descriptors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>make-deploy-zip<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span><span class=\"comment\">&lt;!-- 绑定到package生命周期阶段上 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>single<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span><span class=\"comment\">&lt;!-- 只运行一次 --&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"4-plugin-打包文件配置\"><a href=\"#4-plugin-打包文件配置\" class=\"headerlink\" title=\"4.plugin-打包文件配置\"></a>4.plugin-打包文件配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jar-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明：</p>\n<p>打包文件配置:可执行jar的入口方法,如果需要把依赖的jar包一起打包,需要使用 maven-assembly-plugin</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jar-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">archive</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">manifest</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">addClasspath</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">addClasspath</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">classpathPrefix</span>&gt;</span>lib/<span class=\"tag\">&lt;/<span class=\"name\">classpathPrefix</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">useUniqueVersions</span>&gt;</span>false<span class=\"tag\">&lt;/<span class=\"name\">useUniqueVersions</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">mainClass</span>&gt;</span>hbec.forum.recsys.etl.BootStrap<span class=\"tag\">&lt;/<span class=\"name\">mainClass</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">manifest</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">manifestEntries</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">Class-Path</span>&gt;</span>configs/<span class=\"tag\">&lt;/<span class=\"name\">Class-Path</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">manifestEntries</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">archive</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.xml<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.json<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.properties<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">exclude</span>&gt;</span>*.cfg<span class=\"tag\">&lt;/<span class=\"name\">exclude</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">excludes</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"5-plugin-项目依赖管理\"><a href=\"#5-plugin-项目依赖管理\" class=\"headerlink\" title=\"5.plugin-项目依赖管理\"></a>5.plugin-项目依赖管理</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-dependency-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-dependency-plugin最大的用途是帮助分析项目依赖，dependency:list能够列出项目最终解析到的依赖列表，dependency:tree能进一步的描绘项目依赖树，dependency:analyze可以告诉你项目依赖潜在的问题，如果你有直接使用到的却未声明的依赖，该目标就会发出警告。maven-dependency-plugin还有很多目标帮助你操作依赖文件，例如dependency:copy-dependencies能将项目依赖从本地Maven仓库复制到某个特定的文件夹下面。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-dependency-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span>  </span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span>  </span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-dependencies<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span>  </span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>  </span><br><span class=\"line\">                    $&#123;project.build.directory&#125;/lib  </span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span>  </span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span>  </span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span>  </span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"6-plugin-项目版本发布\"><a href=\"#6-plugin-项目版本发布\" class=\"headerlink\" title=\"6.plugin-项目版本发布\"></a>6.plugin-项目版本发布</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-release-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-release-plugin的用途是帮助自动化项目版本发布，它依赖于POM中的SCM信息。release:prepare用来准备版本发布，具体的工作包括检查是否有未提交代码、检查是否有SNAPSHOT依赖、升级项目的SNAPSHOT版本至RELEASE版本、为项目打标签等等。release:perform则是签出标签中的RELEASE源码，构建并发布。版本发布是非常琐碎的工作，它涉及了各种检查，而且由于该工作仅仅是偶尔需要，因此手动操作很容易遗漏一些细节，maven-release-plugin让该工作变得非常快速简便，不易出错。maven-release-plugin的各种目标通常直接在命令行调用，因为版本发布显然不是日常构建生命周期的一部分.      </p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-release-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.4.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">tagBase</span>&gt;</span>$&#123;svn.url&#125;/$&#123;project.artifactId&#125;/tags/<span class=\"tag\">&lt;/<span class=\"name\">tagBase</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">branchBase</span>&gt;</span>$&#123;svn.url&#125;/$&#123;project.artifactId&#125;/branches/<span class=\"tag\">&lt;/<span class=\"name\">branchBase</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"7-plugin-资源文件处理\"><a href=\"#7-plugin-资源文件处理\" class=\"headerlink\" title=\"7.plugin-资源文件处理\"></a>7.plugin-资源文件处理</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-resources-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>为了使项目结构更为清晰，Maven区别对待Java代码文件和资源文件，maven-compiler-plugin用来编译Java代码，maven-resources-plugin则用来处理资源文件。默认的主资源文件目录是src/main/resources，很多用户会需要添加额外的资源文件目录，这个时候就可以通过配置maven-resources-plugin来实现。此外，资源文件过滤也是Maven的一大特性，你可以在资源文件中使用${propertyName}形式的Maven属性，然后配置maven-resources-plugin开启对资源文件的过滤，之后就可以针对不同环境通过命令行或者Profile传入属性的值，以实现更为灵活的构建。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-resources-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.6<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">encoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">encoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-xmls<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.xml<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-properties<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.properties<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-dic<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/main/java<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.dic<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包配置文件 start --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>copy-dev<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>process-sources<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>copy-resources<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;basedir&#125;/target/classes<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">directory</span>&gt;</span>$&#123;basedir&#125;/src/config/dev<span class=\"tag\">&lt;/<span class=\"name\">directory</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                            <span class=\"tag\">&lt;<span class=\"name\">include</span>&gt;</span>**/*.*<span class=\"tag\">&lt;/<span class=\"name\">include</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;/<span class=\"name\">includes</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">resource</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">resources</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"comment\">&lt;!-- 打包配置文件 end --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"8-plugin-Maven中运行ant任务\"><a href=\"#8-plugin-Maven中运行ant任务\" class=\"headerlink\" title=\"8.plugin-Maven中运行ant任务\"></a>8.plugin-Maven中运行ant任务</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-antrun-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-antrun-plugin能让用户在Maven项目中运行Ant任务。用户可以直接在该插件的配置以Ant的方式编写Target，然后交给该插件的run目标去执行。在一些由Ant往Maven迁移的项目中，该插件尤其有用。此外当你发现需要编写一些自定义程度很高的任务，同时又觉得Maven不够灵活时，也可以以Ant的方式实现之。maven-antrun-plugin的run目标通常与生命周期绑定运行。</p>\n<p>使用实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-antrun-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.7<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">tasks</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;<span class=\"name\">copy</span> <span class=\"attr\">todir</span>=<span class=\"string\">\"target\"</span>&gt;</span></span><br><span class=\"line\">                        <span class=\"tag\">&lt;<span class=\"name\">fileset</span> <span class=\"attr\">dir</span>=<span class=\"string\">\"target/$&#123;project.artifactId&#125;-$&#123;project.version&#125;\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">fileset</span>&gt;</span></span><br><span class=\"line\">                    <span class=\"tag\">&lt;/<span class=\"name\">copy</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;/<span class=\"name\">tasks</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"9-plugin-生成项目源码包\"><a href=\"#9-plugin-生成项目源码包\" class=\"headerlink\" title=\"9.plugin-生成项目源码包\"></a>9.plugin-生成项目源码包</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-source-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>打包项目源文件到jar包中</p>\n<p>实例:      </p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-source-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.2.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>attach-sources<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>package<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>jar-no-fork<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"10-plugin-生成项目javadoc文档\"><a href=\"#10-plugin-生成项目javadoc文档\" class=\"headerlink\" title=\"10.plugin-生成项目javadoc文档\"></a>10.plugin-生成项目javadoc文档</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-javadoc-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>生成项目javadoc文档</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-javadoc-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.9<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">encoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">encoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"11-plugin-生成项目HTML说明文件\"><a href=\"#11-plugin-生成项目HTML说明文件\" class=\"headerlink\" title=\"11.plugin-生成项目HTML说明文件\"></a>11.plugin-生成项目HTML说明文件</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-site-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>使用maven 的site 插件 生成一个 可以在 浏览器中 查看项目的站点</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-site-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>3.3<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">outputEncoding</span>&gt;</span>GBK<span class=\"tag\">&lt;/<span class=\"name\">outputEncoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"12-plugin-执行单元测试\"><a href=\"#12-plugin-执行单元测试\" class=\"headerlink\" title=\"12.plugin-执行单元测试\"></a>12.plugin-执行单元测试</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-surefire-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>可能是由于历史的原因，Maven 2/3中用于执行测试的插件不是maven-test-plugin，而是maven-surefire-plugin。其实大部分时间内，只要你的测试类遵循通用的命令约定（以Test结尾、以TestCase结尾、或者以Test开头），就几乎不用知晓该插件的存在。然而在当你想要跳过测试、排除某些测试类、或者使用一些TestNG特性的时候，了解maven-surefire-plugin的一些配置选项就很有用了。例如 mvn test -Dtest=FooTest 这样一条命令的效果是仅运行FooTest测试类，这是通过控制maven-surefire-plugin的test参数实现的。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-surefire-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.9<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">skip</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">skip</span>&gt;</span> <span class=\"comment\">&lt;!-- 跳过测试阶段 --&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">testFailureIgnore</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">testFailureIgnore</span>&gt;</span>  <span class=\"comment\">&lt;!-- 忽略测试失败 --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"13-plugin-自动配合SVN进行版本发布\"><a href=\"#13-plugin-自动配合SVN进行版本发布\" class=\"headerlink\" title=\"13.plugin-自动配合SVN进行版本发布\"></a>13.plugin-自动配合SVN进行版本发布</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-scm-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>Maven中为我们集成了软件配置管理的（SCM：Software Configuration Management）功能，他可以支持我们常用SVN、CVS等，到现在我使用的1.8.1版本，共支持18个命令</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-scm-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>1.8.1<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"14-plugin-jetty运行插件\"><a href=\"#14-plugin-jetty运行插件\" class=\"headerlink\" title=\"14.plugin-jetty运行插件\"></a>14.plugin-jetty运行插件</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.mortbay.jetty<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jetty-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>在进行Web开发的时候，打开浏览器对应用进行手动的测试几乎是无法避免的，这种测试方法通常就是将项目打包成war文件，然后部署到Web容器中，再启动容器进行验证，这显然十分耗时。为了帮助开发者节省时间，jetty-maven-plugin应运而生，它完全兼容 Maven项目的目录结构，能够周期性地检查源文件，一旦发现变更后自动更新到内置的Jetty Web容器中。做一些基本配置后（例如Web应用的contextPath和自动扫描变更的时间间隔），你只要执行 mvn jetty:run ，然后在IDE中修改代码，代码经IDE自动编译后产生变更，再由jetty-maven-plugin侦测到后更新至Jetty容器，这时你就可以直接测试Web页面了。需要注意的是，jetty-maven-plugin并不是宿主于Apache或Codehaus的官方插件，因此使用的时候需要额外的配置settings.xml的pluginGroups元素，将org.mortbay.jetty这个pluginGroup加入。</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.mortbay.jetty<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-jetty-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>6.1.10<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">scanIntervalSeconds</span>&gt;</span>10<span class=\"tag\">&lt;/<span class=\"name\">scanIntervalSeconds</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">stopKey</span>&gt;</span>foo<span class=\"tag\">&lt;/<span class=\"name\">stopKey</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">stopPort</span>&gt;</span>9999<span class=\"tag\">&lt;/<span class=\"name\">stopPort</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>start-jetty<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>pre-integration-test<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">scanIntervalSeconds</span>&gt;</span>0<span class=\"tag\">&lt;/<span class=\"name\">scanIntervalSeconds</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">daemon</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">daemon</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>stop-jetty<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">phase</span>&gt;</span>post-integration-test<span class=\"tag\">&lt;/<span class=\"name\">phase</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>stop<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>开始：mvn jetty:start  关闭：mvn jetty:stop</p>\n<h2 id=\"15-plugin-在tomcat中运行项目\"><a href=\"#15-plugin-在tomcat中运行项目\" class=\"headerlink\" title=\"15.plugin-在tomcat中运行项目\"></a>15.plugin-在tomcat中运行项目</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.tomcat.maven<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>tomcat7-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>使用maven将web项目运行在tomcat中</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.tomcat.maven<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>tomcat7-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.2<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">port</span>&gt;</span>8889<span class=\"tag\">&lt;/<span class=\"name\">port</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">path</span>&gt;</span>/<span class=\"tag\">&lt;/<span class=\"name\">path</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">uriEncoding</span>&gt;</span>utf-8<span class=\"tag\">&lt;/<span class=\"name\">uriEncoding</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"16-plugin-生成简单的项目骨架\"><a href=\"#16-plugin-生成简单的项目骨架\" class=\"headerlink\" title=\"16.plugin-生成简单的项目骨架\"></a>16.plugin-生成简单的项目骨架</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-archetype-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>Archtype指项目的骨架，Maven初学者最开始执行的Maven命令可能就是mvn archetype:generate，这实际上就是让maven-archetype-plugin生成一个很简单的项目骨架，帮助开发者快速上手。可能也有人看到一些文档写了mvn archetype:create，但实际上create目标已经被弃用了，取而代之的是generate目标，该目标使用交互式的方式提示用户输入必要的信息以创建项目，体验更好。maven-archetype-plugin还有一些其他目标帮助用户自己定义项目原型，例如你由一个产品需要交付给很多客户进行二次开发，你就可以为他们提供一个Archtype，帮助他们快速上手。</p>\n<h2 id=\"17-plugin-创建强制规则\"><a href=\"#17-plugin-创建强制规则\" class=\"headerlink\" title=\"17.plugin-创建强制规则\"></a>17.plugin-创建强制规则</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-enforcer-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>在一个稍大一点的组织或团队中，你无法保证所有成员都熟悉Maven，那他们做一些比较愚蠢的事情就会变得很正常，例如给项目引入了外部的SNAPSHOT依赖而导致构建不稳定，使用了一个与大家不一致的Maven版本而经常抱怨构建出现诡异问题。maven-enforcer-plugin能够帮助你避免之类问题，它允许你创建一系列规则强制大家遵守，包括设定Java版本、设定Maven版本、禁止某些依赖、禁止SNAPSHOT依赖。只要在一个父POM配置规则，然后让大家继承，当规则遭到破坏的时候，Maven就会报错。除了标准的规则之外，你还可以扩展该插件，编写自己的规则。maven-enforcer-plugin的enforce目标负责检查规则，它默认绑定到生命周期的validate阶段。</p>\n<h2 id=\"18-plugin-帮助工具\"><a href=\"#18-plugin-帮助工具\" class=\"headerlink\" title=\"18.plugin-帮助工具\"></a>18.plugin-帮助工具</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.apache.maven.plugins<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>maven-help-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>maven-help-plugin是一个小巧的辅助工具，最简单的help:system可以打印所有可用的环境变量和Java系统属性。help:effective-pom和help:effective-settings最为有用，它们分别打印项目的有效POM和有效settings，有效POM是指合并了所有父POM（包括Super POM）后的XML，当你不确定POM的某些信息从何而来时，就可以查看有效POM。有效settings同理，特别是当你发现自己配置的settings.xml没有生效时，就可以用help:effective-settings来验证。此外，maven-help-plugin的describe目标可以帮助你描述任何一个Maven插件的信息，还有all-profiles目标和active-profiles目标帮助查看项目的Profile。</p>\n<h2 id=\"19-plugin-其它\"><a href=\"#19-plugin-其它\" class=\"headerlink\" title=\"19.plugin-其它\"></a>19.plugin-其它</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.thoughtworks.paranamer<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>paranamer-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>说明:</p>\n<p>暂无</p>\n<p>实例:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">plugin</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>com.thoughtworks.paranamer<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>paranamer-maven-plugin<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">version</span>&gt;</span>2.6<span class=\"tag\">&lt;/<span class=\"name\">version</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>run<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">sourceDirectory</span>&gt;</span>$&#123;project.build.sourceDirectory&#125;<span class=\"tag\">&lt;/<span class=\"name\">sourceDirectory</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">outputDirectory</span>&gt;</span>$&#123;project.build.outputDirectory&#125;<span class=\"tag\">&lt;/<span class=\"name\">outputDirectory</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">configuration</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">                <span class=\"tag\">&lt;<span class=\"name\">goal</span>&gt;</span>generate<span class=\"tag\">&lt;/<span class=\"name\">goal</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;/<span class=\"name\">goals</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">execution</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">executions</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"20-plugin插件本地位置\"><a href=\"#20-plugin插件本地位置\" class=\"headerlink\" title=\"20.plugin插件本地位置\"></a>20.plugin插件本地位置</h2><p>在Maven中,仓库就是存放依赖和插件的地方。插件的远端、本地地址和仓库的远端、本地地址相同。</p>\n<p>在pom.xml中通过plugin引入的插件本地默认在”C:\\Users\\Administrator.m2\\repository\\org\\apache\\maven\\plugins”中。</p>\n<h2 id=\"21-打包类型设置\"><a href=\"#21-打包类型设置\" class=\"headerlink\" title=\"21.打包类型设置\"></a>21.打包类型设置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">packaging</span>&gt;</span>war<span class=\"tag\">&lt;/<span class=\"name\">packaging</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"21-仓库地址配置\"><a href=\"#21-仓库地址配置\" class=\"headerlink\" title=\"21.仓库地址配置\"></a>21.仓库地址配置</h2><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;/<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"22-Maven-settings-xml配置\"><a href=\"#22-Maven-settings-xml配置\" class=\"headerlink\" title=\"22.Maven-settings.xml配置\"></a>22.Maven-settings.xml配置</h2><p>结构:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0</span></span></span><br><span class=\"line\"><span class=\"tag\"><span class=\"string\">                    http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 1.【servers】:nexus仓库deploy账号设置,id分为:releases,snapshots--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 2.【profiles】:环境配置,仓库配置--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">pluginRepositories</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">pluginRepositories</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">plugins</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">plugins</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">dependencyManagement</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">dependencyManagement</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">distributionManagement</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">distributionManagement</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">build</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">build</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span> <span class=\"comment\">&lt;!-- 激活条件:默认激活,激活条件.或者单独用activeProfiles设置 --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 3.【activeProfiles】:激活配置设置 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">activeProfile</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">activeProfile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 4.【mirrors】:镜像设置 --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirrors</span>/&gt;</span></span><br><span class=\"line\"><span class=\"comment\">&lt;!-- 5.【localRepository】:本地仓库设置--&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">localRepository</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">localRepository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>实例1:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0\"</span></span></span><br><span class=\"line\"><span class=\"tag\">\t\t  <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span></span></span><br><span class=\"line\"><span class=\"tag\">\t\t  <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>Repositories<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">releases</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t\t<span class=\"tag\">&lt;<span class=\"name\">enabled</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">enabled</span>&gt;</span></span><br><span class=\"line\">\t\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">snapshots</span>&gt;</span></span><br><span class=\"line\">\t\t\t<span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">activeProfile</span>&gt;</span>Repositories<span class=\"tag\">&lt;/<span class=\"name\">activeProfile</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">activeProfiles</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>releases<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>admin<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>admin123<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>snapshots<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>admin<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>admin123<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>实例2:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">settings</span> <span class=\"attr\">xmlns</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xmlns:xsi</span>=<span class=\"string\">\"http://www.w3.org/2001/XMLSchema-instance\"</span> </span></span><br><span class=\"line\"><span class=\"tag\">          <span class=\"attr\">xsi:schemaLocation</span>=<span class=\"string\">\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\"</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">pluginGroups</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">pluginGroups</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">proxies</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">proxies</span>&gt;</span></span><br><span class=\"line\">  <span class=\"comment\">&lt;!--nexus account releases帐号为nexus发布正式版本帐号发布帐号,请找部门负责人获取--&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>releases<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>***<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>***<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>snapshots<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">username</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">username</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">password</span>&gt;</span>deploy<span class=\"tag\">&lt;/<span class=\"name\">password</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">server</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">servers</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">profiles</span>&gt;</span> </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!--maven中心库的地址</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;repositories&gt;</span></span><br><span class=\"line\"><span class=\"comment\">       &lt;repository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">            &lt;id&gt;thinkive_public&lt;/id&gt;</span></span><br><span class=\"line\"><span class=\"comment\">            &lt;url&gt;http://192.168.1.99:8081/nexus/content/groups/public&lt;/url&gt;       </span></span><br><span class=\"line\"><span class=\"comment\">       &lt;/repository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;/repositories&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>thinkive_public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">            <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span>       </span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">repository</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">repositories</span>&gt;</span></span><br><span class=\"line\">    <span class=\"comment\">&lt;!--maven插件库的地址</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;pluginRepositories&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">      &lt;pluginRepository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">        &lt;id&gt;thinkive_plugin_public&lt;/id&gt;</span></span><br><span class=\"line\"><span class=\"comment\">        &lt;url&gt;http://192.168.1.99:8081/nexus/content/groups/public&lt;/url&gt;</span></span><br><span class=\"line\"><span class=\"comment\">      &lt;/pluginRepository&gt;</span></span><br><span class=\"line\"><span class=\"comment\">    &lt;/pluginRepositories&gt;  </span></span><br><span class=\"line\"><span class=\"comment\">    --&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">pluginRepositories</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">pluginRepository</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>thinkive_plugin_public<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://10.0.30.78:8080/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">pluginRepository</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">pluginRepositories</span>&gt;</span>  </span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">activeByDefault</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">activeByDefault</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>dev<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">activeByDefault</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">activeByDefault</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">activation</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/dev<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>uat<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/uat<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>pdt<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span>  </span><br><span class=\"line\">      <span class=\"tag\">&lt;<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">        <span class=\"tag\">&lt;<span class=\"name\">configPath</span>&gt;</span>/src/config/pdt<span class=\"tag\">&lt;/<span class=\"name\">configPath</span>&gt;</span></span><br><span class=\"line\">      <span class=\"tag\">&lt;/<span class=\"name\">properties</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">profile</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;/<span class=\"name\">profiles</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">mirrors</span>/&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">localRepository</span>&gt;</span>E:\\mysoft\\thinkive-repository<span class=\"tag\">&lt;/<span class=\"name\">localRepository</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">settings</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"23-pom-xml中dependency的scope配置\"><a href=\"#23-pom-xml中dependency的scope配置\" class=\"headerlink\" title=\"23.pom.xml中dependency的scope配置\"></a>23.pom.xml中dependency的scope配置</h2><p>依赖范围控制哪些依赖在哪些classpath 中可用，哪些依赖包含在一个应用中。让我们详细看一下每一种范围：</p>\n<p>compile （编译范围）<br>compile是默认的范围；如果没有提供一个范围，那该依赖的范围就是编译范围。编译范围依赖在所有的classpath 中可用，同时它们也会被打包。</p>\n<p>provided （已提供范围）<br>provided 依赖只有在当JDK 或者一个容器已提供该依赖之后才使用。例如， 如果你开发了一个web 应用，你可能在编译 classpath 中需要可用的Servlet API 来编译一个servlet，但是你不会想要在打包好的WAR 中包含这个Servlet API；这个Servlet API JAR 由你的应用服务器或者servlet 容器提供。已提供范围的依赖在编译classpath （不是运行时）可用。它们不是传递性的，也不会被打包。</p>\n<p>runtime （运行时范围）<br>runtime 依赖在运行和测试系统的时候需要，但在编译的时候不需要。比如，你可能在编译的时候只需要JDBC API JAR，而只有在运行的时候才需要JDBC<br>驱动实现。<br>test （测试范围）<br>test范围依赖 在一般的编译和运行时都不需要，它们只有在测试编译和测试运行阶段可用。</p>\n<p>system （系统范围）<br>system范围依赖与provided 类似，但是你必须显式的提供一个对于本地系统中JAR 文件的路径。这么做是为了允许基于本地对象编译，而这些对象是系统类库的一部分。这样的构件应该是一直可用的，Maven 也不会在仓库中去寻找它。如果你将一个依赖范围设置成系统范围，你必须同时提供一个 systemPath 元素。注意该范围是不推荐使用的（你应该一直尽量去从公共或定制的 Maven 仓库中引用依赖）。</p>"},{"layout":"lay_post","title":"C&C++开源框架大全","date":"2017-07-26T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nC/C++优秀的开源框架列表，以后慢慢研究。\n<!-- more -->\n\n参考地址：\n\nhttp://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419\n\n## 1.Tinyhttpd\n\ntinyhttpd是一个超轻量型Http Server，使用C语言开发，全部代码只有502行(包括注释)，附带一个简单的Client，可以通过阅读这段代码理解一个 Http Server 的本质。\n\n下载链接：http://sourceforge.net/projects/tinyhttpd/\n\n## 2.Libev\n\nlibev是一个开源的事件驱动库，基于epoll，kqueue等OS提供的基础设施。其以高效出名，它可以将IO事件，定时器，和信号统一起来，统一放在事件处理这一套框架下处理。基于Reactor模式，效率较高，并且代码精简（4.15版本8000多行），是学习事件驱动编程的很好的资源。\n\n下载链接：http://software.schmorp.de/pkg/libev.html\n\n## 3.SQLite\n\nSQLite是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。足够小，大致3万行C代码，250K。\n\n下载地址：http://www.sqlite.org/ 。\n\n## 4.异步事件循环\n\nBoost.Asio：用于网络和底层I/O编程的跨平台的C++库。\n\nLibev ：功能齐全，高性能的时间循环，轻微地仿效libevent，但是不再像libevent一样有局限性，也修复了它的一些bug。\n\nLibevent ：事件通知库\n\nLibuv ：跨平台异步I/O。\n\n## 5.网络\n\nBoost.Asio：用于网络和底层I/O编程的跨平台的C++库\n\nOnion :C语言HTTP服务器库，其设计为轻量级，易使用。\n\nMuduo ：用于Linux多线程服务器的C++非阻塞网络库\n\nZeroMQ ：高速，模块化的异步通信库\n\n## 6.Web应用框架\n\nKore :使用C语言开发的用于web应用程序的超快速和灵活的web服务器/框架。\n\nlibOnion：轻量级的库，帮助你使用C编程语言创建web服务器。\n\nCrow ：一个C++微型web框架（灵感来自于Python Flask）","source":"_posts/2017-09-22-C&C++开源框架大全.md","raw":"---\nlayout: lay_post\ntitle: \"C&C++开源框架大全\"\ndate: 2017-07-27\ncategories: 开源框架\ntags: C/C++\nauthor: lvyafei\n---\n\n## 0.概述\n\nC/C++优秀的开源框架列表，以后慢慢研究。\n<!-- more -->\n\n参考地址：\n\nhttp://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419\n\n## 1.Tinyhttpd\n\ntinyhttpd是一个超轻量型Http Server，使用C语言开发，全部代码只有502行(包括注释)，附带一个简单的Client，可以通过阅读这段代码理解一个 Http Server 的本质。\n\n下载链接：http://sourceforge.net/projects/tinyhttpd/\n\n## 2.Libev\n\nlibev是一个开源的事件驱动库，基于epoll，kqueue等OS提供的基础设施。其以高效出名，它可以将IO事件，定时器，和信号统一起来，统一放在事件处理这一套框架下处理。基于Reactor模式，效率较高，并且代码精简（4.15版本8000多行），是学习事件驱动编程的很好的资源。\n\n下载链接：http://software.schmorp.de/pkg/libev.html\n\n## 3.SQLite\n\nSQLite是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。足够小，大致3万行C代码，250K。\n\n下载地址：http://www.sqlite.org/ 。\n\n## 4.异步事件循环\n\nBoost.Asio：用于网络和底层I/O编程的跨平台的C++库。\n\nLibev ：功能齐全，高性能的时间循环，轻微地仿效libevent，但是不再像libevent一样有局限性，也修复了它的一些bug。\n\nLibevent ：事件通知库\n\nLibuv ：跨平台异步I/O。\n\n## 5.网络\n\nBoost.Asio：用于网络和底层I/O编程的跨平台的C++库\n\nOnion :C语言HTTP服务器库，其设计为轻量级，易使用。\n\nMuduo ：用于Linux多线程服务器的C++非阻塞网络库\n\nZeroMQ ：高速，模块化的异步通信库\n\n## 6.Web应用框架\n\nKore :使用C语言开发的用于web应用程序的超快速和灵活的web服务器/框架。\n\nlibOnion：轻量级的库，帮助你使用C编程语言创建web服务器。\n\nCrow ：一个C++微型web框架（灵感来自于Python Flask）","slug":"2017-09-22-C&C++开源框架大全","published":1,"updated":"2018-11-29T12:51:25.292Z","comments":1,"photos":[],"link":"","_id":"cjskffoch00544glm7d4mdooe","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>C/C++优秀的开源框架列表，以后慢慢研究。<br><a id=\"more\"></a></p>\n<p>参考地址：</p>\n<p><a href=\"http://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419</a></p>\n<h2 id=\"1-Tinyhttpd\"><a href=\"#1-Tinyhttpd\" class=\"headerlink\" title=\"1.Tinyhttpd\"></a>1.Tinyhttpd</h2><p>tinyhttpd是一个超轻量型Http Server，使用C语言开发，全部代码只有502行(包括注释)，附带一个简单的Client，可以通过阅读这段代码理解一个 Http Server 的本质。</p>\n<p>下载链接：<a href=\"http://sourceforge.net/projects/tinyhttpd/\" target=\"_blank\" rel=\"noopener\">http://sourceforge.net/projects/tinyhttpd/</a></p>\n<h2 id=\"2-Libev\"><a href=\"#2-Libev\" class=\"headerlink\" title=\"2.Libev\"></a>2.Libev</h2><p>libev是一个开源的事件驱动库，基于epoll，kqueue等OS提供的基础设施。其以高效出名，它可以将IO事件，定时器，和信号统一起来，统一放在事件处理这一套框架下处理。基于Reactor模式，效率较高，并且代码精简（4.15版本8000多行），是学习事件驱动编程的很好的资源。</p>\n<p>下载链接：<a href=\"http://software.schmorp.de/pkg/libev.html\" target=\"_blank\" rel=\"noopener\">http://software.schmorp.de/pkg/libev.html</a></p>\n<h2 id=\"3-SQLite\"><a href=\"#3-SQLite\" class=\"headerlink\" title=\"3.SQLite\"></a>3.SQLite</h2><p>SQLite是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。足够小，大致3万行C代码，250K。</p>\n<p>下载地址：<a href=\"http://www.sqlite.org/\" target=\"_blank\" rel=\"noopener\">http://www.sqlite.org/</a> 。</p>\n<h2 id=\"4-异步事件循环\"><a href=\"#4-异步事件循环\" class=\"headerlink\" title=\"4.异步事件循环\"></a>4.异步事件循环</h2><p>Boost.Asio：用于网络和底层I/O编程的跨平台的C++库。</p>\n<p>Libev ：功能齐全，高性能的时间循环，轻微地仿效libevent，但是不再像libevent一样有局限性，也修复了它的一些bug。</p>\n<p>Libevent ：事件通知库</p>\n<p>Libuv ：跨平台异步I/O。</p>\n<h2 id=\"5-网络\"><a href=\"#5-网络\" class=\"headerlink\" title=\"5.网络\"></a>5.网络</h2><p>Boost.Asio：用于网络和底层I/O编程的跨平台的C++库</p>\n<p>Onion :C语言HTTP服务器库，其设计为轻量级，易使用。</p>\n<p>Muduo ：用于Linux多线程服务器的C++非阻塞网络库</p>\n<p>ZeroMQ ：高速，模块化的异步通信库</p>\n<h2 id=\"6-Web应用框架\"><a href=\"#6-Web应用框架\" class=\"headerlink\" title=\"6.Web应用框架\"></a>6.Web应用框架</h2><p>Kore :使用C语言开发的用于web应用程序的超快速和灵活的web服务器/框架。</p>\n<p>libOnion：轻量级的库，帮助你使用C编程语言创建web服务器。</p>\n<p>Crow ：一个C++微型web框架（灵感来自于Python Flask）</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>C/C++优秀的开源框架列表，以后慢慢研究。<br>","more":"</p>\n<p>参考地址：</p>\n<p><a href=\"http://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419\" target=\"_blank\" rel=\"noopener\">http://blog.csdn.net/xiaoxiaoyeyaya/article/details/42541419</a></p>\n<h2 id=\"1-Tinyhttpd\"><a href=\"#1-Tinyhttpd\" class=\"headerlink\" title=\"1.Tinyhttpd\"></a>1.Tinyhttpd</h2><p>tinyhttpd是一个超轻量型Http Server，使用C语言开发，全部代码只有502行(包括注释)，附带一个简单的Client，可以通过阅读这段代码理解一个 Http Server 的本质。</p>\n<p>下载链接：<a href=\"http://sourceforge.net/projects/tinyhttpd/\" target=\"_blank\" rel=\"noopener\">http://sourceforge.net/projects/tinyhttpd/</a></p>\n<h2 id=\"2-Libev\"><a href=\"#2-Libev\" class=\"headerlink\" title=\"2.Libev\"></a>2.Libev</h2><p>libev是一个开源的事件驱动库，基于epoll，kqueue等OS提供的基础设施。其以高效出名，它可以将IO事件，定时器，和信号统一起来，统一放在事件处理这一套框架下处理。基于Reactor模式，效率较高，并且代码精简（4.15版本8000多行），是学习事件驱动编程的很好的资源。</p>\n<p>下载链接：<a href=\"http://software.schmorp.de/pkg/libev.html\" target=\"_blank\" rel=\"noopener\">http://software.schmorp.de/pkg/libev.html</a></p>\n<h2 id=\"3-SQLite\"><a href=\"#3-SQLite\" class=\"headerlink\" title=\"3.SQLite\"></a>3.SQLite</h2><p>SQLite是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。足够小，大致3万行C代码，250K。</p>\n<p>下载地址：<a href=\"http://www.sqlite.org/\" target=\"_blank\" rel=\"noopener\">http://www.sqlite.org/</a> 。</p>\n<h2 id=\"4-异步事件循环\"><a href=\"#4-异步事件循环\" class=\"headerlink\" title=\"4.异步事件循环\"></a>4.异步事件循环</h2><p>Boost.Asio：用于网络和底层I/O编程的跨平台的C++库。</p>\n<p>Libev ：功能齐全，高性能的时间循环，轻微地仿效libevent，但是不再像libevent一样有局限性，也修复了它的一些bug。</p>\n<p>Libevent ：事件通知库</p>\n<p>Libuv ：跨平台异步I/O。</p>\n<h2 id=\"5-网络\"><a href=\"#5-网络\" class=\"headerlink\" title=\"5.网络\"></a>5.网络</h2><p>Boost.Asio：用于网络和底层I/O编程的跨平台的C++库</p>\n<p>Onion :C语言HTTP服务器库，其设计为轻量级，易使用。</p>\n<p>Muduo ：用于Linux多线程服务器的C++非阻塞网络库</p>\n<p>ZeroMQ ：高速，模块化的异步通信库</p>\n<h2 id=\"6-Web应用框架\"><a href=\"#6-Web应用框架\" class=\"headerlink\" title=\"6.Web应用框架\"></a>6.Web应用框架</h2><p>Kore :使用C语言开发的用于web应用程序的超快速和灵活的web服务器/框架。</p>\n<p>libOnion：轻量级的库，帮助你使用C编程语言创建web服务器。</p>\n<p>Crow ：一个C++微型web框架（灵感来自于Python Flask）</p>"},{"layout":"lay_post","title":"爬虫框架一二三","date":"2017-11-28T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nHeritrix,Nutch,Scrapy三个爬虫框架侧重不同的方面，各有优劣。\n<!-- more -->\n\n## 1.Heritrix\n\n![Heritrix](/images/架构/heritrix.jpg)\n\nHeritrix是一个专门为互联网上的网页进行存档而开发的网页检索器。它使用Java编写并且完全开源。它主要的用户界面可以通过一个web流量器来访问并通过它来控制检索器的行为，另外，它还有一个命令行工具来供用户选择调用。\n\nHeritrix是由互联网档案馆和北欧国家图书馆联合规范化编写于2003年初。第一次正式发布是在2004年1月，并不断的被互联网档案馆和其他感兴趣的第三方改进着。到现在已经成为一个成熟的开源爬虫，并被广泛使用。\n\n官网：https://sourceforge.net/projects/archive-crawler/\n\n参考资料: https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/\n\n## 2.Nutch\n\n![Nutch](/images/架构/nutch.png)\n\nNutch是一个开源的网络爬虫项目，更具体些是一个爬虫软件，可以直接用于抓取网页内容。\n\n现在Nutch分为两个版本，1.x和2.x。1.x最新版本为1.7，2.x最新版本为2.2.1。两个版本的主要区别在于底层的存储不同。\n\n1.x版本是基于Hadoop架构的，底层存储使用的是HDFS，而2.x通过使用Apache Gora，使得Nutch可以访问HBase、Accumulo、Cassandra、MySQL、DataFileAvroStore、AvroStore等NoSQL。\n\n官网：http://nutch.apache.org/\n\n## 3.Scrapy\n\n![Scrapy](/images/架构/scrapy.png)\n\nScrapy是Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。GitHub项目主页：https://github.com/scrapy/scrapy Scrapy 使用了 Twisted 异步网络库来处理网络通讯。\n\n官网：http://www.scrapy.org/","source":"_posts/2017-11-29-爬虫框架一二三.md","raw":"---\nlayout: lay_post\ntitle: \"爬虫框架一二三\"\ndate: 2017-11-29\ncategories: 开源框架\ntags: 爬虫\nauthor: lvyafei\n---\n\n## 0.概述\n\nHeritrix,Nutch,Scrapy三个爬虫框架侧重不同的方面，各有优劣。\n<!-- more -->\n\n## 1.Heritrix\n\n![Heritrix](/images/架构/heritrix.jpg)\n\nHeritrix是一个专门为互联网上的网页进行存档而开发的网页检索器。它使用Java编写并且完全开源。它主要的用户界面可以通过一个web流量器来访问并通过它来控制检索器的行为，另外，它还有一个命令行工具来供用户选择调用。\n\nHeritrix是由互联网档案馆和北欧国家图书馆联合规范化编写于2003年初。第一次正式发布是在2004年1月，并不断的被互联网档案馆和其他感兴趣的第三方改进着。到现在已经成为一个成熟的开源爬虫，并被广泛使用。\n\n官网：https://sourceforge.net/projects/archive-crawler/\n\n参考资料: https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/\n\n## 2.Nutch\n\n![Nutch](/images/架构/nutch.png)\n\nNutch是一个开源的网络爬虫项目，更具体些是一个爬虫软件，可以直接用于抓取网页内容。\n\n现在Nutch分为两个版本，1.x和2.x。1.x最新版本为1.7，2.x最新版本为2.2.1。两个版本的主要区别在于底层的存储不同。\n\n1.x版本是基于Hadoop架构的，底层存储使用的是HDFS，而2.x通过使用Apache Gora，使得Nutch可以访问HBase、Accumulo、Cassandra、MySQL、DataFileAvroStore、AvroStore等NoSQL。\n\n官网：http://nutch.apache.org/\n\n## 3.Scrapy\n\n![Scrapy](/images/架构/scrapy.png)\n\nScrapy是Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。GitHub项目主页：https://github.com/scrapy/scrapy Scrapy 使用了 Twisted 异步网络库来处理网络通讯。\n\n官网：http://www.scrapy.org/","slug":"2017-11-29-爬虫框架一二三","published":1,"updated":"2018-11-29T12:51:25.295Z","comments":1,"photos":[],"link":"","_id":"cjskffoch00594glm4u1p7r1t","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Heritrix,Nutch,Scrapy三个爬虫框架侧重不同的方面，各有优劣。<br><a id=\"more\"></a></p>\n<h2 id=\"1-Heritrix\"><a href=\"#1-Heritrix\" class=\"headerlink\" title=\"1.Heritrix\"></a>1.Heritrix</h2><p><img src=\"/images/架构/heritrix.jpg\" alt=\"Heritrix\"></p>\n<p>Heritrix是一个专门为互联网上的网页进行存档而开发的网页检索器。它使用Java编写并且完全开源。它主要的用户界面可以通过一个web流量器来访问并通过它来控制检索器的行为，另外，它还有一个命令行工具来供用户选择调用。</p>\n<p>Heritrix是由互联网档案馆和北欧国家图书馆联合规范化编写于2003年初。第一次正式发布是在2004年1月，并不断的被互联网档案馆和其他感兴趣的第三方改进着。到现在已经成为一个成熟的开源爬虫，并被广泛使用。</p>\n<p>官网：<a href=\"https://sourceforge.net/projects/archive-crawler/\" target=\"_blank\" rel=\"noopener\">https://sourceforge.net/projects/archive-crawler/</a></p>\n<p>参考资料: <a href=\"https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/</a></p>\n<h2 id=\"2-Nutch\"><a href=\"#2-Nutch\" class=\"headerlink\" title=\"2.Nutch\"></a>2.Nutch</h2><p><img src=\"/images/架构/nutch.png\" alt=\"Nutch\"></p>\n<p>Nutch是一个开源的网络爬虫项目，更具体些是一个爬虫软件，可以直接用于抓取网页内容。</p>\n<p>现在Nutch分为两个版本，1.x和2.x。1.x最新版本为1.7，2.x最新版本为2.2.1。两个版本的主要区别在于底层的存储不同。</p>\n<p>1.x版本是基于Hadoop架构的，底层存储使用的是HDFS，而2.x通过使用Apache Gora，使得Nutch可以访问HBase、Accumulo、Cassandra、MySQL、DataFileAvroStore、AvroStore等NoSQL。</p>\n<p>官网：<a href=\"http://nutch.apache.org/\" target=\"_blank\" rel=\"noopener\">http://nutch.apache.org/</a></p>\n<h2 id=\"3-Scrapy\"><a href=\"#3-Scrapy\" class=\"headerlink\" title=\"3.Scrapy\"></a>3.Scrapy</h2><p><img src=\"/images/架构/scrapy.png\" alt=\"Scrapy\"></p>\n<p>Scrapy是Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。GitHub项目主页：<a href=\"https://github.com/scrapy/scrapy\" target=\"_blank\" rel=\"noopener\">https://github.com/scrapy/scrapy</a> Scrapy 使用了 Twisted 异步网络库来处理网络通讯。</p>\n<p>官网：<a href=\"http://www.scrapy.org/\" target=\"_blank\" rel=\"noopener\">http://www.scrapy.org/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>Heritrix,Nutch,Scrapy三个爬虫框架侧重不同的方面，各有优劣。<br>","more":"</p>\n<h2 id=\"1-Heritrix\"><a href=\"#1-Heritrix\" class=\"headerlink\" title=\"1.Heritrix\"></a>1.Heritrix</h2><p><img src=\"/images/架构/heritrix.jpg\" alt=\"Heritrix\"></p>\n<p>Heritrix是一个专门为互联网上的网页进行存档而开发的网页检索器。它使用Java编写并且完全开源。它主要的用户界面可以通过一个web流量器来访问并通过它来控制检索器的行为，另外，它还有一个命令行工具来供用户选择调用。</p>\n<p>Heritrix是由互联网档案馆和北欧国家图书馆联合规范化编写于2003年初。第一次正式发布是在2004年1月，并不断的被互联网档案馆和其他感兴趣的第三方改进着。到现在已经成为一个成熟的开源爬虫，并被广泛使用。</p>\n<p>官网：<a href=\"https://sourceforge.net/projects/archive-crawler/\" target=\"_blank\" rel=\"noopener\">https://sourceforge.net/projects/archive-crawler/</a></p>\n<p>参考资料: <a href=\"https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/\" target=\"_blank\" rel=\"noopener\">https://www.ibm.com/developerworks/cn/opensource/os-cn-heritrix/</a></p>\n<h2 id=\"2-Nutch\"><a href=\"#2-Nutch\" class=\"headerlink\" title=\"2.Nutch\"></a>2.Nutch</h2><p><img src=\"/images/架构/nutch.png\" alt=\"Nutch\"></p>\n<p>Nutch是一个开源的网络爬虫项目，更具体些是一个爬虫软件，可以直接用于抓取网页内容。</p>\n<p>现在Nutch分为两个版本，1.x和2.x。1.x最新版本为1.7，2.x最新版本为2.2.1。两个版本的主要区别在于底层的存储不同。</p>\n<p>1.x版本是基于Hadoop架构的，底层存储使用的是HDFS，而2.x通过使用Apache Gora，使得Nutch可以访问HBase、Accumulo、Cassandra、MySQL、DataFileAvroStore、AvroStore等NoSQL。</p>\n<p>官网：<a href=\"http://nutch.apache.org/\" target=\"_blank\" rel=\"noopener\">http://nutch.apache.org/</a></p>\n<h2 id=\"3-Scrapy\"><a href=\"#3-Scrapy\" class=\"headerlink\" title=\"3.Scrapy\"></a>3.Scrapy</h2><p><img src=\"/images/架构/scrapy.png\" alt=\"Scrapy\"></p>\n<p>Scrapy是Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。GitHub项目主页：<a href=\"https://github.com/scrapy/scrapy\" target=\"_blank\" rel=\"noopener\">https://github.com/scrapy/scrapy</a> Scrapy 使用了 Twisted 异步网络库来处理网络通讯。</p>\n<p>官网：<a href=\"http://www.scrapy.org/\" target=\"_blank\" rel=\"noopener\">http://www.scrapy.org/</a></p>"},{"layout":"lay_post","title":"机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度)","date":"2016-11-29T16:00:00.000Z","author":"bornhe","_content":"\n## 0.概述\n\n皮尔森相关系数反应了两个变量之间的线性相关程度，它的取值在[-1, 1]之间。当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。\n<!-- more -->\n\n## 1.皮尔森相似度描述\n\n用数学公式表示，皮尔森相关系数等于两个变量的协方差除于两个变量的标准差。\n\n![数学公式](/images/算法/皮尔森相关/数学公式.png)\n\n## 2.协方差(Covariance)\n\n在概率论和统计学中用于衡量两个变量的总体误差。如果两个变量的变化趋于一致，也就是说如果其中一个大于自身的期望值，另一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，则协方差为负值。\n\n![协方差](/images/算法/皮尔森相关/协方差.png)\n\n其中u表示X的期望E(X), v表示Y的期望E(Y)\n\n## 3.标准差(Standard Deviation)\n\n标准差是方差的平方根\n\n![标准差](/images/算法/皮尔森相关/标准差.png)\n\n## 4.方差(Variance)\n\n在概率论和统计学中，一个随机变量的方差表述的是它的离散程度，也就是该变量与期望值的距离。即方差等于误差的平方和的期望\n\n![方差](/images/算法/皮尔森相关/方差.png)\n\n## 5.缺点\n\n基于皮尔森相关系数的相似度有两个缺点：\n\n(1) 没有考虑（take into account）用户间重叠的评分项数量对相似度的影响；\n\n(2) 如果两个用户之间只有一个共同的评分项，相似度也不能被计算\n\n![例子](/images/算法/皮尔森相关/例子.png)\n\n上表中，行表示用户（1～5）对项目（101～103）的一些评分值。直观来看，User1和User5用3个共同的评分项，并且给出的评分走差也不大，按理他们之间的相似度应该比User1和User4之间的相似度要高，可是User1和User4有一个更高的相似度1。\n\n同样的场景在现实生活中也经常发生，比如两个用户共同观看了200部电影，虽然不一定给出相同或完全相近的评分，他们之间的相似度也应该比另一位只观看了2部相同电影的相似度高吧！但事实并不如此，如果对这两部电影，两个用户给出的相似度相同或很相近，通过皮尔森相关性计算出的相似度会明显大于观看了相同的200部电影的用户之间的相似度。\n\nMahout对基于皮尔森相关系数的相似度给出了实现，它依赖一个DataModel作为输入。\n\n![mahout](/images/算法/皮尔森相关/mahout.png)\n\n同时，Mahout还针对缺点(1)进行了优化，只需要在构造PearsonCorrelationSimilarity时多传入一个Weighting.WEIGHTED参数，就能使有更多相同评分项目的用户之间的相似度更趋近于1或-1。\n\nUserSimilarity similarity1 = new PearsonCorrelationSimilarity(model);\n\ndouble value1 = similarity1.userSimilarity(1, 5);\n\nUserSimilarity similarity2 = new PearsonCorrelationSimilarity(model, Weighting.WEIGHTED);\n\ndouble value2 = similarity2.userSimilarity(1, 5);\n\n结果：\n\nSimilarity of User1 and User5: 0.944911182523068\n\nSimilarity of User1 and User5 with weighting: 0.9655694890769175","source":"_posts/2016-11-30-机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度).md","raw":"---\nlayout: lay_post\ntitle: \"机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度)\"\ndate: 2016-11-30\ncategories: 相似度算法\ntags: 机器学习\nauthor: bornhe\n---\n\n## 0.概述\n\n皮尔森相关系数反应了两个变量之间的线性相关程度，它的取值在[-1, 1]之间。当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。\n<!-- more -->\n\n## 1.皮尔森相似度描述\n\n用数学公式表示，皮尔森相关系数等于两个变量的协方差除于两个变量的标准差。\n\n![数学公式](/images/算法/皮尔森相关/数学公式.png)\n\n## 2.协方差(Covariance)\n\n在概率论和统计学中用于衡量两个变量的总体误差。如果两个变量的变化趋于一致，也就是说如果其中一个大于自身的期望值，另一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，则协方差为负值。\n\n![协方差](/images/算法/皮尔森相关/协方差.png)\n\n其中u表示X的期望E(X), v表示Y的期望E(Y)\n\n## 3.标准差(Standard Deviation)\n\n标准差是方差的平方根\n\n![标准差](/images/算法/皮尔森相关/标准差.png)\n\n## 4.方差(Variance)\n\n在概率论和统计学中，一个随机变量的方差表述的是它的离散程度，也就是该变量与期望值的距离。即方差等于误差的平方和的期望\n\n![方差](/images/算法/皮尔森相关/方差.png)\n\n## 5.缺点\n\n基于皮尔森相关系数的相似度有两个缺点：\n\n(1) 没有考虑（take into account）用户间重叠的评分项数量对相似度的影响；\n\n(2) 如果两个用户之间只有一个共同的评分项，相似度也不能被计算\n\n![例子](/images/算法/皮尔森相关/例子.png)\n\n上表中，行表示用户（1～5）对项目（101～103）的一些评分值。直观来看，User1和User5用3个共同的评分项，并且给出的评分走差也不大，按理他们之间的相似度应该比User1和User4之间的相似度要高，可是User1和User4有一个更高的相似度1。\n\n同样的场景在现实生活中也经常发生，比如两个用户共同观看了200部电影，虽然不一定给出相同或完全相近的评分，他们之间的相似度也应该比另一位只观看了2部相同电影的相似度高吧！但事实并不如此，如果对这两部电影，两个用户给出的相似度相同或很相近，通过皮尔森相关性计算出的相似度会明显大于观看了相同的200部电影的用户之间的相似度。\n\nMahout对基于皮尔森相关系数的相似度给出了实现，它依赖一个DataModel作为输入。\n\n![mahout](/images/算法/皮尔森相关/mahout.png)\n\n同时，Mahout还针对缺点(1)进行了优化，只需要在构造PearsonCorrelationSimilarity时多传入一个Weighting.WEIGHTED参数，就能使有更多相同评分项目的用户之间的相似度更趋近于1或-1。\n\nUserSimilarity similarity1 = new PearsonCorrelationSimilarity(model);\n\ndouble value1 = similarity1.userSimilarity(1, 5);\n\nUserSimilarity similarity2 = new PearsonCorrelationSimilarity(model, Weighting.WEIGHTED);\n\ndouble value2 = similarity2.userSimilarity(1, 5);\n\n结果：\n\nSimilarity of User1 and User5: 0.944911182523068\n\nSimilarity of User1 and User5 with weighting: 0.9655694890769175","slug":"2016-11-30-机器学习算法-相似度-PearsonCorrelationSimilarity(皮尔森相似度)","published":1,"updated":"2018-11-29T12:51:25.029Z","comments":1,"photos":[],"link":"","_id":"cjskffocw005c4glm14hwcklm","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>皮尔森相关系数反应了两个变量之间的线性相关程度，它的取值在[-1, 1]之间。当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。<br><a id=\"more\"></a></p>\n<h2 id=\"1-皮尔森相似度描述\"><a href=\"#1-皮尔森相似度描述\" class=\"headerlink\" title=\"1.皮尔森相似度描述\"></a>1.皮尔森相似度描述</h2><p>用数学公式表示，皮尔森相关系数等于两个变量的协方差除于两个变量的标准差。</p>\n<p><img src=\"/images/算法/皮尔森相关/数学公式.png\" alt=\"数学公式\"></p>\n<h2 id=\"2-协方差-Covariance\"><a href=\"#2-协方差-Covariance\" class=\"headerlink\" title=\"2.协方差(Covariance)\"></a>2.协方差(Covariance)</h2><p>在概率论和统计学中用于衡量两个变量的总体误差。如果两个变量的变化趋于一致，也就是说如果其中一个大于自身的期望值，另一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，则协方差为负值。</p>\n<p><img src=\"/images/算法/皮尔森相关/协方差.png\" alt=\"协方差\"></p>\n<p>其中u表示X的期望E(X), v表示Y的期望E(Y)</p>\n<h2 id=\"3-标准差-Standard-Deviation\"><a href=\"#3-标准差-Standard-Deviation\" class=\"headerlink\" title=\"3.标准差(Standard Deviation)\"></a>3.标准差(Standard Deviation)</h2><p>标准差是方差的平方根</p>\n<p><img src=\"/images/算法/皮尔森相关/标准差.png\" alt=\"标准差\"></p>\n<h2 id=\"4-方差-Variance\"><a href=\"#4-方差-Variance\" class=\"headerlink\" title=\"4.方差(Variance)\"></a>4.方差(Variance)</h2><p>在概率论和统计学中，一个随机变量的方差表述的是它的离散程度，也就是该变量与期望值的距离。即方差等于误差的平方和的期望</p>\n<p><img src=\"/images/算法/皮尔森相关/方差.png\" alt=\"方差\"></p>\n<h2 id=\"5-缺点\"><a href=\"#5-缺点\" class=\"headerlink\" title=\"5.缺点\"></a>5.缺点</h2><p>基于皮尔森相关系数的相似度有两个缺点：</p>\n<p>(1) 没有考虑（take into account）用户间重叠的评分项数量对相似度的影响；</p>\n<p>(2) 如果两个用户之间只有一个共同的评分项，相似度也不能被计算</p>\n<p><img src=\"/images/算法/皮尔森相关/例子.png\" alt=\"例子\"></p>\n<p>上表中，行表示用户（1～5）对项目（101～103）的一些评分值。直观来看，User1和User5用3个共同的评分项，并且给出的评分走差也不大，按理他们之间的相似度应该比User1和User4之间的相似度要高，可是User1和User4有一个更高的相似度1。</p>\n<p>同样的场景在现实生活中也经常发生，比如两个用户共同观看了200部电影，虽然不一定给出相同或完全相近的评分，他们之间的相似度也应该比另一位只观看了2部相同电影的相似度高吧！但事实并不如此，如果对这两部电影，两个用户给出的相似度相同或很相近，通过皮尔森相关性计算出的相似度会明显大于观看了相同的200部电影的用户之间的相似度。</p>\n<p>Mahout对基于皮尔森相关系数的相似度给出了实现，它依赖一个DataModel作为输入。</p>\n<p><img src=\"/images/算法/皮尔森相关/mahout.png\" alt=\"mahout\"></p>\n<p>同时，Mahout还针对缺点(1)进行了优化，只需要在构造PearsonCorrelationSimilarity时多传入一个Weighting.WEIGHTED参数，就能使有更多相同评分项目的用户之间的相似度更趋近于1或-1。</p>\n<p>UserSimilarity similarity1 = new PearsonCorrelationSimilarity(model);</p>\n<p>double value1 = similarity1.userSimilarity(1, 5);</p>\n<p>UserSimilarity similarity2 = new PearsonCorrelationSimilarity(model, Weighting.WEIGHTED);</p>\n<p>double value2 = similarity2.userSimilarity(1, 5);</p>\n<p>结果：</p>\n<p>Similarity of User1 and User5: 0.944911182523068</p>\n<p>Similarity of User1 and User5 with weighting: 0.9655694890769175</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>皮尔森相关系数反应了两个变量之间的线性相关程度，它的取值在[-1, 1]之间。当两个变量的线性关系增强时，相关系数趋于1或-1；当一个变量增大，另一个变量也增大时，表明它们之间是正相关的，相关系数大于0；如果一个变量增大，另一个变量却减小，表明它们之间是负相关的，相关系数小于0；如果相关系数等于0，表明它们之间不存在线性相关关系。<br>","more":"</p>\n<h2 id=\"1-皮尔森相似度描述\"><a href=\"#1-皮尔森相似度描述\" class=\"headerlink\" title=\"1.皮尔森相似度描述\"></a>1.皮尔森相似度描述</h2><p>用数学公式表示，皮尔森相关系数等于两个变量的协方差除于两个变量的标准差。</p>\n<p><img src=\"/images/算法/皮尔森相关/数学公式.png\" alt=\"数学公式\"></p>\n<h2 id=\"2-协方差-Covariance\"><a href=\"#2-协方差-Covariance\" class=\"headerlink\" title=\"2.协方差(Covariance)\"></a>2.协方差(Covariance)</h2><p>在概率论和统计学中用于衡量两个变量的总体误差。如果两个变量的变化趋于一致，也就是说如果其中一个大于自身的期望值，另一个也大于自身的期望值，那么两个变量之间的协方差就是正值；如果两个变量的变化趋势相反，则协方差为负值。</p>\n<p><img src=\"/images/算法/皮尔森相关/协方差.png\" alt=\"协方差\"></p>\n<p>其中u表示X的期望E(X), v表示Y的期望E(Y)</p>\n<h2 id=\"3-标准差-Standard-Deviation\"><a href=\"#3-标准差-Standard-Deviation\" class=\"headerlink\" title=\"3.标准差(Standard Deviation)\"></a>3.标准差(Standard Deviation)</h2><p>标准差是方差的平方根</p>\n<p><img src=\"/images/算法/皮尔森相关/标准差.png\" alt=\"标准差\"></p>\n<h2 id=\"4-方差-Variance\"><a href=\"#4-方差-Variance\" class=\"headerlink\" title=\"4.方差(Variance)\"></a>4.方差(Variance)</h2><p>在概率论和统计学中，一个随机变量的方差表述的是它的离散程度，也就是该变量与期望值的距离。即方差等于误差的平方和的期望</p>\n<p><img src=\"/images/算法/皮尔森相关/方差.png\" alt=\"方差\"></p>\n<h2 id=\"5-缺点\"><a href=\"#5-缺点\" class=\"headerlink\" title=\"5.缺点\"></a>5.缺点</h2><p>基于皮尔森相关系数的相似度有两个缺点：</p>\n<p>(1) 没有考虑（take into account）用户间重叠的评分项数量对相似度的影响；</p>\n<p>(2) 如果两个用户之间只有一个共同的评分项，相似度也不能被计算</p>\n<p><img src=\"/images/算法/皮尔森相关/例子.png\" alt=\"例子\"></p>\n<p>上表中，行表示用户（1～5）对项目（101～103）的一些评分值。直观来看，User1和User5用3个共同的评分项，并且给出的评分走差也不大，按理他们之间的相似度应该比User1和User4之间的相似度要高，可是User1和User4有一个更高的相似度1。</p>\n<p>同样的场景在现实生活中也经常发生，比如两个用户共同观看了200部电影，虽然不一定给出相同或完全相近的评分，他们之间的相似度也应该比另一位只观看了2部相同电影的相似度高吧！但事实并不如此，如果对这两部电影，两个用户给出的相似度相同或很相近，通过皮尔森相关性计算出的相似度会明显大于观看了相同的200部电影的用户之间的相似度。</p>\n<p>Mahout对基于皮尔森相关系数的相似度给出了实现，它依赖一个DataModel作为输入。</p>\n<p><img src=\"/images/算法/皮尔森相关/mahout.png\" alt=\"mahout\"></p>\n<p>同时，Mahout还针对缺点(1)进行了优化，只需要在构造PearsonCorrelationSimilarity时多传入一个Weighting.WEIGHTED参数，就能使有更多相同评分项目的用户之间的相似度更趋近于1或-1。</p>\n<p>UserSimilarity similarity1 = new PearsonCorrelationSimilarity(model);</p>\n<p>double value1 = similarity1.userSimilarity(1, 5);</p>\n<p>UserSimilarity similarity2 = new PearsonCorrelationSimilarity(model, Weighting.WEIGHTED);</p>\n<p>double value2 = similarity2.userSimilarity(1, 5);</p>\n<p>结果：</p>\n<p>Similarity of User1 and User5: 0.944911182523068</p>\n<p>Similarity of User1 and User5 with weighting: 0.9655694890769175</p>"},{"layout":"lay_post","title":"mongoDB文档模式设计","date":"2018-11-28T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. mongoDB安装\n\n官方手册：\nhttps://docs.mongodb.com/manual/tutorial/\n\n安装指南:\nhttps://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/\n\nmongoDB可视化工具:\nhttps://studio3t.com/\n<!-- more -->\n\n远程链接需要注意：\n\nmongodb的配置文件中的bind_ip 默认为127.0.0.1，默认只有本机可以连接。  此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。修改mongod配置文件: /etc/mongod.conf\n\n参考文档：\n\nMongoDB 进阶模式设计:\nhttps://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA\n\n## 2.关系模型和文档模型的区别在哪里？\n\n关系模型的功能：单值，多文档事物性，关联。\n\n文档模型的功能：富文档、数组、内嵌，单文档事务性，基本不支持关联\n\n两者的相同功能：动态查询，二级索引，聚合。\n\n### 2.1 文档模型的优点\n\n**读写效率高** -由于文档模型把相关数据集中在一块，在普通机械盘上读数据的时候不用花太多时间去定位磁头，因此在IO性能上有先天独厚的优势；\n\n**可扩展能力强** -关系型数据库很难做分布式的原因就是多节点海量数据关联有巨大的性能问题。如果不考虑关联，数据分区分库，水平扩展就比较简单；\n\n**动态模式** -文档模型支持可变的数据模式，不要求每个文档都具有完全相同的结构。对很多异构数据场景支持非常好；\n\n**模型自然** -文档模型最接近于我们熟悉的对象模型。从内存到存储，无需经过ORM的双向转换，性能上和理解上都很自然易懂。\n\n## 3.MongoDB文档模式设计的基本策略\n\n文档模式设计有2中基本策略：1.内嵌。2.引用\n\n### 3.1 内嵌策略\n\n如果你的对象模型数量不多，关系不是很复杂，可以使用内嵌策略。内嵌是文档模型的特色，可以充分利用MongoDB的富文档功能来享受我们刚才谈到的一些文档模型的性能和扩展性等特性。一般的一对一、一对多关系，比如说一个人多个地址多个电话等等都可以放在一个文档里用内嵌来完成。\n\n单个文档(BSON格式)大小限制为16M。这是一个坑。\n\n这个'坑' 可能会让你花时间都难以发现, 因为这又要牵扯到mongodb的另一个存储机制 ---- 无返回码. 在 < mongodb 权威指南> 一书中, 作者称之为离弦之箭. 什么意思呢？就是mongodb的插入,删除等操作, 客户端向数据库发出请求之后, 是不需要等待数据库返回操作是否成功的返回结果. 这也是mongodb插入,更新等操作速度快的原因. 这就导致, 当单个文件超过16M之后, 程序并不会报错。\n\nGridFS是用于存储和检索超过 BSON文档大小限制为16 MB的文件的规范。GridFS不是将文件存储在单个文档中，而是将文件分成多个部分或块，并将每个块存储为单独的文档。\n\n如果需要以原子方式更新整个文件的内容，请不要使用GridFS。作为替代方案，您可以存储每个文件的多个版本，并在元数据中指定文件的当前版本。您可以在上载新版本的文件后更新在原子更新中指示“最新”状态的元数据字段，并在以后删除以前版本。\n\n### 3.2 引用策略\n\n在主表里存储一个id值，指向另一个表中的 id 值。使用引用要注意的就是：从性能上讲，一般我们可能需要两次以上才能把需要的数据取回来。更加重要的是：需要把数据存放到两个集合里，但是目前为止MongoDB并不支持跨表的事务性，所以对于强事务的应用场景要谨慎使用。\n\n### 3.3 何时选择不同的策略\n\n先考虑内嵌，内嵌适合一对一，一对多。局限性在于文档最大16M限制，大数组性能欠佳。\n\n后考虑引用，引用适合多对多，两个对象都为主要对象。局限性在于多次查询、写入，无跨表事务性。\n\n## 4.MongoDB模式设计的终极原则\n\nMongoDB的模式设计和关系型大不相同，我们说MongoDB是为应用程序设计的，而不是为了存储优化的。如果可以达到最高性能的话，我们甚至可以做一些反范式的东西。\n\n### 4.1 数据冗余&扇出写\n\n社交app最关键的一些场景就是维护朋友关系以及朋友圈或微博墙等。使用文档模型的内嵌数组特性，我们可以很容易地把我关注的用户（following）和关注我的用户表示出来。\n\n但是有一个潜在问题就是如果我是一个明星，他们关注我的人可能有千万。一个千万级的数组会有两个问题：\n\n1） 有可能超出一个文档最大16M的硬性限制； \n\n2） MongoDB数组太大会严重影响性能。\n\n扇出读是一种比较常规的做法，就是当你需要去获得所有你关注用户的最新更新的时候，你就去到每一个你关注用户的数据区，把最新的一些数据取回来。因为需要去到不同的分片服务器去取，所以叫做扇出读。大家可以想象，这种扇出读的效率不会太高，基本上是最慢的那个服务器的响应时间决定了总体的响应时间。 当然，这种方式是比较简单的，不需要特殊处理。\n\n扇出写的具体做法，当发布的时候，一条数据会写多次，直接写到每一个关注你的粉丝的墙上。这样做的好处是当你的粉丝读他自己的微博墙的时候，他只需要去一个地方就可以把所有最新的更新连续取回来。由于一个用户的数据可一般可以存储在同一台服务器上的同一个区域，通过这种方式可以实现快速的读取微博墙数据。 代价当然也是很明显： 你的写入需求会被放大几十几百倍，存储也是相应的扩大几十几百倍。这个绝对不是关系型数据库的玩法，但是在MongoD 模式设计，这个很正常。只要保证性能，什么事情都做得出来。\n\n### 4.2 分桶\n\n在IOT这个场景里，我们可以使用一个叫做分桶的设计方式来进行几十倍的性能增长。具体来说就是把采集的数据按小时为一个桶，把每小时的数据聚合到一个文档里。这样做的好处就是大量减少文档的数量，相应的索引数量也会减少，总体写入IO将会大幅度降低并得到性能提升。\n\n存储引擎：\n\nmongodb 3.0默认存储引擎为MMAPV1，mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。","source":"_posts/2018-11-29-mongoDB文档模式设计.md","raw":"---\nlayout: lay_post\ntitle: \"mongoDB文档模式设计\"\ndate: 2018-11-29\ncategories: 中间件\ntags: [NoSQL,mongoDB]\nauthor: lvyafei\n---\n\n## 1. mongoDB安装\n\n官方手册：\nhttps://docs.mongodb.com/manual/tutorial/\n\n安装指南:\nhttps://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/\n\nmongoDB可视化工具:\nhttps://studio3t.com/\n<!-- more -->\n\n远程链接需要注意：\n\nmongodb的配置文件中的bind_ip 默认为127.0.0.1，默认只有本机可以连接。  此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。修改mongod配置文件: /etc/mongod.conf\n\n参考文档：\n\nMongoDB 进阶模式设计:\nhttps://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA\n\n## 2.关系模型和文档模型的区别在哪里？\n\n关系模型的功能：单值，多文档事物性，关联。\n\n文档模型的功能：富文档、数组、内嵌，单文档事务性，基本不支持关联\n\n两者的相同功能：动态查询，二级索引，聚合。\n\n### 2.1 文档模型的优点\n\n**读写效率高** -由于文档模型把相关数据集中在一块，在普通机械盘上读数据的时候不用花太多时间去定位磁头，因此在IO性能上有先天独厚的优势；\n\n**可扩展能力强** -关系型数据库很难做分布式的原因就是多节点海量数据关联有巨大的性能问题。如果不考虑关联，数据分区分库，水平扩展就比较简单；\n\n**动态模式** -文档模型支持可变的数据模式，不要求每个文档都具有完全相同的结构。对很多异构数据场景支持非常好；\n\n**模型自然** -文档模型最接近于我们熟悉的对象模型。从内存到存储，无需经过ORM的双向转换，性能上和理解上都很自然易懂。\n\n## 3.MongoDB文档模式设计的基本策略\n\n文档模式设计有2中基本策略：1.内嵌。2.引用\n\n### 3.1 内嵌策略\n\n如果你的对象模型数量不多，关系不是很复杂，可以使用内嵌策略。内嵌是文档模型的特色，可以充分利用MongoDB的富文档功能来享受我们刚才谈到的一些文档模型的性能和扩展性等特性。一般的一对一、一对多关系，比如说一个人多个地址多个电话等等都可以放在一个文档里用内嵌来完成。\n\n单个文档(BSON格式)大小限制为16M。这是一个坑。\n\n这个'坑' 可能会让你花时间都难以发现, 因为这又要牵扯到mongodb的另一个存储机制 ---- 无返回码. 在 < mongodb 权威指南> 一书中, 作者称之为离弦之箭. 什么意思呢？就是mongodb的插入,删除等操作, 客户端向数据库发出请求之后, 是不需要等待数据库返回操作是否成功的返回结果. 这也是mongodb插入,更新等操作速度快的原因. 这就导致, 当单个文件超过16M之后, 程序并不会报错。\n\nGridFS是用于存储和检索超过 BSON文档大小限制为16 MB的文件的规范。GridFS不是将文件存储在单个文档中，而是将文件分成多个部分或块，并将每个块存储为单独的文档。\n\n如果需要以原子方式更新整个文件的内容，请不要使用GridFS。作为替代方案，您可以存储每个文件的多个版本，并在元数据中指定文件的当前版本。您可以在上载新版本的文件后更新在原子更新中指示“最新”状态的元数据字段，并在以后删除以前版本。\n\n### 3.2 引用策略\n\n在主表里存储一个id值，指向另一个表中的 id 值。使用引用要注意的就是：从性能上讲，一般我们可能需要两次以上才能把需要的数据取回来。更加重要的是：需要把数据存放到两个集合里，但是目前为止MongoDB并不支持跨表的事务性，所以对于强事务的应用场景要谨慎使用。\n\n### 3.3 何时选择不同的策略\n\n先考虑内嵌，内嵌适合一对一，一对多。局限性在于文档最大16M限制，大数组性能欠佳。\n\n后考虑引用，引用适合多对多，两个对象都为主要对象。局限性在于多次查询、写入，无跨表事务性。\n\n## 4.MongoDB模式设计的终极原则\n\nMongoDB的模式设计和关系型大不相同，我们说MongoDB是为应用程序设计的，而不是为了存储优化的。如果可以达到最高性能的话，我们甚至可以做一些反范式的东西。\n\n### 4.1 数据冗余&扇出写\n\n社交app最关键的一些场景就是维护朋友关系以及朋友圈或微博墙等。使用文档模型的内嵌数组特性，我们可以很容易地把我关注的用户（following）和关注我的用户表示出来。\n\n但是有一个潜在问题就是如果我是一个明星，他们关注我的人可能有千万。一个千万级的数组会有两个问题：\n\n1） 有可能超出一个文档最大16M的硬性限制； \n\n2） MongoDB数组太大会严重影响性能。\n\n扇出读是一种比较常规的做法，就是当你需要去获得所有你关注用户的最新更新的时候，你就去到每一个你关注用户的数据区，把最新的一些数据取回来。因为需要去到不同的分片服务器去取，所以叫做扇出读。大家可以想象，这种扇出读的效率不会太高，基本上是最慢的那个服务器的响应时间决定了总体的响应时间。 当然，这种方式是比较简单的，不需要特殊处理。\n\n扇出写的具体做法，当发布的时候，一条数据会写多次，直接写到每一个关注你的粉丝的墙上。这样做的好处是当你的粉丝读他自己的微博墙的时候，他只需要去一个地方就可以把所有最新的更新连续取回来。由于一个用户的数据可一般可以存储在同一台服务器上的同一个区域，通过这种方式可以实现快速的读取微博墙数据。 代价当然也是很明显： 你的写入需求会被放大几十几百倍，存储也是相应的扩大几十几百倍。这个绝对不是关系型数据库的玩法，但是在MongoD 模式设计，这个很正常。只要保证性能，什么事情都做得出来。\n\n### 4.2 分桶\n\n在IOT这个场景里，我们可以使用一个叫做分桶的设计方式来进行几十倍的性能增长。具体来说就是把采集的数据按小时为一个桶，把每小时的数据聚合到一个文档里。这样做的好处就是大量减少文档的数量，相应的索引数量也会减少，总体写入IO将会大幅度降低并得到性能提升。\n\n存储引擎：\n\nmongodb 3.0默认存储引擎为MMAPV1，mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。","slug":"2018-11-29-mongoDB文档模式设计","published":1,"updated":"2018-12-01T08:24:08.240Z","comments":1,"photos":[],"link":"","_id":"cjskffodc005g4glma7q6mkam","content":"<h2 id=\"1-mongoDB安装\"><a href=\"#1-mongoDB安装\" class=\"headerlink\" title=\"1. mongoDB安装\"></a>1. mongoDB安装</h2><p>官方手册：<br><a href=\"https://docs.mongodb.com/manual/tutorial/\" target=\"_blank\" rel=\"noopener\">https://docs.mongodb.com/manual/tutorial/</a></p>\n<p>安装指南:<br><a href=\"https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/\" target=\"_blank\" rel=\"noopener\">https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/</a></p>\n<p>mongoDB可视化工具:<br><a href=\"https://studio3t.com/\" target=\"_blank\" rel=\"noopener\">https://studio3t.com/</a><br><a id=\"more\"></a></p>\n<p>远程链接需要注意：</p>\n<p>mongodb的配置文件中的bind_ip 默认为127.0.0.1，默认只有本机可以连接。  此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。修改mongod配置文件: /etc/mongod.conf</p>\n<p>参考文档：</p>\n<p>MongoDB 进阶模式设计:<br><a href=\"https://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA</a></p>\n<h2 id=\"2-关系模型和文档模型的区别在哪里？\"><a href=\"#2-关系模型和文档模型的区别在哪里？\" class=\"headerlink\" title=\"2.关系模型和文档模型的区别在哪里？\"></a>2.关系模型和文档模型的区别在哪里？</h2><p>关系模型的功能：单值，多文档事物性，关联。</p>\n<p>文档模型的功能：富文档、数组、内嵌，单文档事务性，基本不支持关联</p>\n<p>两者的相同功能：动态查询，二级索引，聚合。</p>\n<h3 id=\"2-1-文档模型的优点\"><a href=\"#2-1-文档模型的优点\" class=\"headerlink\" title=\"2.1 文档模型的优点\"></a>2.1 文档模型的优点</h3><p><strong>读写效率高</strong> -由于文档模型把相关数据集中在一块，在普通机械盘上读数据的时候不用花太多时间去定位磁头，因此在IO性能上有先天独厚的优势；</p>\n<p><strong>可扩展能力强</strong> -关系型数据库很难做分布式的原因就是多节点海量数据关联有巨大的性能问题。如果不考虑关联，数据分区分库，水平扩展就比较简单；</p>\n<p><strong>动态模式</strong> -文档模型支持可变的数据模式，不要求每个文档都具有完全相同的结构。对很多异构数据场景支持非常好；</p>\n<p><strong>模型自然</strong> -文档模型最接近于我们熟悉的对象模型。从内存到存储，无需经过ORM的双向转换，性能上和理解上都很自然易懂。</p>\n<h2 id=\"3-MongoDB文档模式设计的基本策略\"><a href=\"#3-MongoDB文档模式设计的基本策略\" class=\"headerlink\" title=\"3.MongoDB文档模式设计的基本策略\"></a>3.MongoDB文档模式设计的基本策略</h2><p>文档模式设计有2中基本策略：1.内嵌。2.引用</p>\n<h3 id=\"3-1-内嵌策略\"><a href=\"#3-1-内嵌策略\" class=\"headerlink\" title=\"3.1 内嵌策略\"></a>3.1 内嵌策略</h3><p>如果你的对象模型数量不多，关系不是很复杂，可以使用内嵌策略。内嵌是文档模型的特色，可以充分利用MongoDB的富文档功能来享受我们刚才谈到的一些文档模型的性能和扩展性等特性。一般的一对一、一对多关系，比如说一个人多个地址多个电话等等都可以放在一个文档里用内嵌来完成。</p>\n<p>单个文档(BSON格式)大小限制为16M。这是一个坑。</p>\n<p>这个’坑’ 可能会让你花时间都难以发现, 因为这又要牵扯到mongodb的另一个存储机制 —- 无返回码. 在 &lt; mongodb 权威指南&gt; 一书中, 作者称之为离弦之箭. 什么意思呢？就是mongodb的插入,删除等操作, 客户端向数据库发出请求之后, 是不需要等待数据库返回操作是否成功的返回结果. 这也是mongodb插入,更新等操作速度快的原因. 这就导致, 当单个文件超过16M之后, 程序并不会报错。</p>\n<p>GridFS是用于存储和检索超过 BSON文档大小限制为16 MB的文件的规范。GridFS不是将文件存储在单个文档中，而是将文件分成多个部分或块，并将每个块存储为单独的文档。</p>\n<p>如果需要以原子方式更新整个文件的内容，请不要使用GridFS。作为替代方案，您可以存储每个文件的多个版本，并在元数据中指定文件的当前版本。您可以在上载新版本的文件后更新在原子更新中指示“最新”状态的元数据字段，并在以后删除以前版本。</p>\n<h3 id=\"3-2-引用策略\"><a href=\"#3-2-引用策略\" class=\"headerlink\" title=\"3.2 引用策略\"></a>3.2 引用策略</h3><p>在主表里存储一个id值，指向另一个表中的 id 值。使用引用要注意的就是：从性能上讲，一般我们可能需要两次以上才能把需要的数据取回来。更加重要的是：需要把数据存放到两个集合里，但是目前为止MongoDB并不支持跨表的事务性，所以对于强事务的应用场景要谨慎使用。</p>\n<h3 id=\"3-3-何时选择不同的策略\"><a href=\"#3-3-何时选择不同的策略\" class=\"headerlink\" title=\"3.3 何时选择不同的策略\"></a>3.3 何时选择不同的策略</h3><p>先考虑内嵌，内嵌适合一对一，一对多。局限性在于文档最大16M限制，大数组性能欠佳。</p>\n<p>后考虑引用，引用适合多对多，两个对象都为主要对象。局限性在于多次查询、写入，无跨表事务性。</p>\n<h2 id=\"4-MongoDB模式设计的终极原则\"><a href=\"#4-MongoDB模式设计的终极原则\" class=\"headerlink\" title=\"4.MongoDB模式设计的终极原则\"></a>4.MongoDB模式设计的终极原则</h2><p>MongoDB的模式设计和关系型大不相同，我们说MongoDB是为应用程序设计的，而不是为了存储优化的。如果可以达到最高性能的话，我们甚至可以做一些反范式的东西。</p>\n<h3 id=\"4-1-数据冗余-amp-扇出写\"><a href=\"#4-1-数据冗余-amp-扇出写\" class=\"headerlink\" title=\"4.1 数据冗余&amp;扇出写\"></a>4.1 数据冗余&amp;扇出写</h3><p>社交app最关键的一些场景就是维护朋友关系以及朋友圈或微博墙等。使用文档模型的内嵌数组特性，我们可以很容易地把我关注的用户（following）和关注我的用户表示出来。</p>\n<p>但是有一个潜在问题就是如果我是一个明星，他们关注我的人可能有千万。一个千万级的数组会有两个问题：</p>\n<p>1） 有可能超出一个文档最大16M的硬性限制； </p>\n<p>2） MongoDB数组太大会严重影响性能。</p>\n<p>扇出读是一种比较常规的做法，就是当你需要去获得所有你关注用户的最新更新的时候，你就去到每一个你关注用户的数据区，把最新的一些数据取回来。因为需要去到不同的分片服务器去取，所以叫做扇出读。大家可以想象，这种扇出读的效率不会太高，基本上是最慢的那个服务器的响应时间决定了总体的响应时间。 当然，这种方式是比较简单的，不需要特殊处理。</p>\n<p>扇出写的具体做法，当发布的时候，一条数据会写多次，直接写到每一个关注你的粉丝的墙上。这样做的好处是当你的粉丝读他自己的微博墙的时候，他只需要去一个地方就可以把所有最新的更新连续取回来。由于一个用户的数据可一般可以存储在同一台服务器上的同一个区域，通过这种方式可以实现快速的读取微博墙数据。 代价当然也是很明显： 你的写入需求会被放大几十几百倍，存储也是相应的扩大几十几百倍。这个绝对不是关系型数据库的玩法，但是在MongoD 模式设计，这个很正常。只要保证性能，什么事情都做得出来。</p>\n<h3 id=\"4-2-分桶\"><a href=\"#4-2-分桶\" class=\"headerlink\" title=\"4.2 分桶\"></a>4.2 分桶</h3><p>在IOT这个场景里，我们可以使用一个叫做分桶的设计方式来进行几十倍的性能增长。具体来说就是把采集的数据按小时为一个桶，把每小时的数据聚合到一个文档里。这样做的好处就是大量减少文档的数量，相应的索引数量也会减少，总体写入IO将会大幅度降低并得到性能提升。</p>\n<p>存储引擎：</p>\n<p>mongodb 3.0默认存储引擎为MMAPV1，mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-mongoDB安装\"><a href=\"#1-mongoDB安装\" class=\"headerlink\" title=\"1. mongoDB安装\"></a>1. mongoDB安装</h2><p>官方手册：<br><a href=\"https://docs.mongodb.com/manual/tutorial/\" target=\"_blank\" rel=\"noopener\">https://docs.mongodb.com/manual/tutorial/</a></p>\n<p>安装指南:<br><a href=\"https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/\" target=\"_blank\" rel=\"noopener\">https://docs.mongodb.com/manual/tutorial/install-mongodb-enterprise-on-red-hat/</a></p>\n<p>mongoDB可视化工具:<br><a href=\"https://studio3t.com/\" target=\"_blank\" rel=\"noopener\">https://studio3t.com/</a><br>","more":"</p>\n<p>远程链接需要注意：</p>\n<p>mongodb的配置文件中的bind_ip 默认为127.0.0.1，默认只有本机可以连接。  此时，需要将bind_ip配置为0.0.0.0，表示接受任何IP的连接。修改mongod配置文件: /etc/mongod.conf</p>\n<p>参考文档：</p>\n<p>MongoDB 进阶模式设计:<br><a href=\"https://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/IL3L1OI9SUYN1gNaaVDVHA</a></p>\n<h2 id=\"2-关系模型和文档模型的区别在哪里？\"><a href=\"#2-关系模型和文档模型的区别在哪里？\" class=\"headerlink\" title=\"2.关系模型和文档模型的区别在哪里？\"></a>2.关系模型和文档模型的区别在哪里？</h2><p>关系模型的功能：单值，多文档事物性，关联。</p>\n<p>文档模型的功能：富文档、数组、内嵌，单文档事务性，基本不支持关联</p>\n<p>两者的相同功能：动态查询，二级索引，聚合。</p>\n<h3 id=\"2-1-文档模型的优点\"><a href=\"#2-1-文档模型的优点\" class=\"headerlink\" title=\"2.1 文档模型的优点\"></a>2.1 文档模型的优点</h3><p><strong>读写效率高</strong> -由于文档模型把相关数据集中在一块，在普通机械盘上读数据的时候不用花太多时间去定位磁头，因此在IO性能上有先天独厚的优势；</p>\n<p><strong>可扩展能力强</strong> -关系型数据库很难做分布式的原因就是多节点海量数据关联有巨大的性能问题。如果不考虑关联，数据分区分库，水平扩展就比较简单；</p>\n<p><strong>动态模式</strong> -文档模型支持可变的数据模式，不要求每个文档都具有完全相同的结构。对很多异构数据场景支持非常好；</p>\n<p><strong>模型自然</strong> -文档模型最接近于我们熟悉的对象模型。从内存到存储，无需经过ORM的双向转换，性能上和理解上都很自然易懂。</p>\n<h2 id=\"3-MongoDB文档模式设计的基本策略\"><a href=\"#3-MongoDB文档模式设计的基本策略\" class=\"headerlink\" title=\"3.MongoDB文档模式设计的基本策略\"></a>3.MongoDB文档模式设计的基本策略</h2><p>文档模式设计有2中基本策略：1.内嵌。2.引用</p>\n<h3 id=\"3-1-内嵌策略\"><a href=\"#3-1-内嵌策略\" class=\"headerlink\" title=\"3.1 内嵌策略\"></a>3.1 内嵌策略</h3><p>如果你的对象模型数量不多，关系不是很复杂，可以使用内嵌策略。内嵌是文档模型的特色，可以充分利用MongoDB的富文档功能来享受我们刚才谈到的一些文档模型的性能和扩展性等特性。一般的一对一、一对多关系，比如说一个人多个地址多个电话等等都可以放在一个文档里用内嵌来完成。</p>\n<p>单个文档(BSON格式)大小限制为16M。这是一个坑。</p>\n<p>这个’坑’ 可能会让你花时间都难以发现, 因为这又要牵扯到mongodb的另一个存储机制 —- 无返回码. 在 &lt; mongodb 权威指南&gt; 一书中, 作者称之为离弦之箭. 什么意思呢？就是mongodb的插入,删除等操作, 客户端向数据库发出请求之后, 是不需要等待数据库返回操作是否成功的返回结果. 这也是mongodb插入,更新等操作速度快的原因. 这就导致, 当单个文件超过16M之后, 程序并不会报错。</p>\n<p>GridFS是用于存储和检索超过 BSON文档大小限制为16 MB的文件的规范。GridFS不是将文件存储在单个文档中，而是将文件分成多个部分或块，并将每个块存储为单独的文档。</p>\n<p>如果需要以原子方式更新整个文件的内容，请不要使用GridFS。作为替代方案，您可以存储每个文件的多个版本，并在元数据中指定文件的当前版本。您可以在上载新版本的文件后更新在原子更新中指示“最新”状态的元数据字段，并在以后删除以前版本。</p>\n<h3 id=\"3-2-引用策略\"><a href=\"#3-2-引用策略\" class=\"headerlink\" title=\"3.2 引用策略\"></a>3.2 引用策略</h3><p>在主表里存储一个id值，指向另一个表中的 id 值。使用引用要注意的就是：从性能上讲，一般我们可能需要两次以上才能把需要的数据取回来。更加重要的是：需要把数据存放到两个集合里，但是目前为止MongoDB并不支持跨表的事务性，所以对于强事务的应用场景要谨慎使用。</p>\n<h3 id=\"3-3-何时选择不同的策略\"><a href=\"#3-3-何时选择不同的策略\" class=\"headerlink\" title=\"3.3 何时选择不同的策略\"></a>3.3 何时选择不同的策略</h3><p>先考虑内嵌，内嵌适合一对一，一对多。局限性在于文档最大16M限制，大数组性能欠佳。</p>\n<p>后考虑引用，引用适合多对多，两个对象都为主要对象。局限性在于多次查询、写入，无跨表事务性。</p>\n<h2 id=\"4-MongoDB模式设计的终极原则\"><a href=\"#4-MongoDB模式设计的终极原则\" class=\"headerlink\" title=\"4.MongoDB模式设计的终极原则\"></a>4.MongoDB模式设计的终极原则</h2><p>MongoDB的模式设计和关系型大不相同，我们说MongoDB是为应用程序设计的，而不是为了存储优化的。如果可以达到最高性能的话，我们甚至可以做一些反范式的东西。</p>\n<h3 id=\"4-1-数据冗余-amp-扇出写\"><a href=\"#4-1-数据冗余-amp-扇出写\" class=\"headerlink\" title=\"4.1 数据冗余&amp;扇出写\"></a>4.1 数据冗余&amp;扇出写</h3><p>社交app最关键的一些场景就是维护朋友关系以及朋友圈或微博墙等。使用文档模型的内嵌数组特性，我们可以很容易地把我关注的用户（following）和关注我的用户表示出来。</p>\n<p>但是有一个潜在问题就是如果我是一个明星，他们关注我的人可能有千万。一个千万级的数组会有两个问题：</p>\n<p>1） 有可能超出一个文档最大16M的硬性限制； </p>\n<p>2） MongoDB数组太大会严重影响性能。</p>\n<p>扇出读是一种比较常规的做法，就是当你需要去获得所有你关注用户的最新更新的时候，你就去到每一个你关注用户的数据区，把最新的一些数据取回来。因为需要去到不同的分片服务器去取，所以叫做扇出读。大家可以想象，这种扇出读的效率不会太高，基本上是最慢的那个服务器的响应时间决定了总体的响应时间。 当然，这种方式是比较简单的，不需要特殊处理。</p>\n<p>扇出写的具体做法，当发布的时候，一条数据会写多次，直接写到每一个关注你的粉丝的墙上。这样做的好处是当你的粉丝读他自己的微博墙的时候，他只需要去一个地方就可以把所有最新的更新连续取回来。由于一个用户的数据可一般可以存储在同一台服务器上的同一个区域，通过这种方式可以实现快速的读取微博墙数据。 代价当然也是很明显： 你的写入需求会被放大几十几百倍，存储也是相应的扩大几十几百倍。这个绝对不是关系型数据库的玩法，但是在MongoD 模式设计，这个很正常。只要保证性能，什么事情都做得出来。</p>\n<h3 id=\"4-2-分桶\"><a href=\"#4-2-分桶\" class=\"headerlink\" title=\"4.2 分桶\"></a>4.2 分桶</h3><p>在IOT这个场景里，我们可以使用一个叫做分桶的设计方式来进行几十倍的性能增长。具体来说就是把采集的数据按小时为一个桶，把每小时的数据聚合到一个文档里。这样做的好处就是大量减少文档的数量，相应的索引数量也会减少，总体写入IO将会大幅度降低并得到性能提升。</p>\n<p>存储引擎：</p>\n<p>mongodb 3.0默认存储引擎为MMAPV1，mongodb 3.2+之后，默认的存储引擎为“wiredTiger”，大量优化了存储性能，建议升级到3.2+版本。</p>"},{"layout":"lay_post","title":"RocketMQ-docker搭建","date":"2018-11-25T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.基础准备\n\n在Docker中搭建RocketMQ集群环境。\n<!-- more -->\n\njdk1.8下载地址：\n\nhttps://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n\nmaven 下载地址:\n\nhttp://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz\n\nrocketmq-4.3.2下载地址：\n\nhttps://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz\n\nrocketmq-console下载:\n\nhttps://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip\n\n配置maven镜像仓库地址:\n\n```xml\n<mirrors>\n    <mirror>\n          <id>alimaven</id>\n          <name>aliyun maven</name>\n          <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n          <mirrorOf>central</mirrorOf>        \n    </mirror>\n</mirrors>\n```\n参考资料(rocketmq集群介绍)：\n\nhttps://blog.csdn.net/leexide/article/details/80035470\n\nhttps://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html\n\n关闭防火墙:\n\n```shell\n# systemctl stop firewalld\n```\n\n## 1.RocketMQ 集群环境搭建\n\n### 1.1 RocketMQ编译\n\njava,maven环境变量首先配置正确。\n\n然后更改本地maven的镜像仓库地址,最后进入到RocketMQ的源代码文件夹中,执行编译\n\n```shell\n# mvn -Prelease-all -DskipTests clean install -U\n```\n\n执行完后，将 rocketmq-rocketmq-all-4.3.2/distribution/target 目录下的 apache-rocketmq 文件夹 copy 到 /opt 或应用存放的目录中。\n\n### 1.2 更改默认的JVM配置\n\n修改namesrv的配置：\n\n```shell\n# vim bin/runserver.sh\n...\nJAVA_OPT=\"${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\"\n...\n```\n修改broker的配置：\n\n```shell\n# vim /bin/runbroker.sh\n...\nJAVA_OPT=\"${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g\"\n...\n```\n\n### 1.3 broker配置修改\n\nbroker的配置文件在 config/broker.conf中，其中 config/2m-2s-async 为多Master多Slave模式(异步复制)集群配置，config/2m-2s-sync为多Master多Slave模式(同步双写)集群配置，config/2m-noslave 为多Master集群。每种集群模式的优缺点见参考资料。\n\n每种配置的关键配置项，如下：\n\n```properties\n#集群名称(相同名称的brokerName,根据brokerId来区别主从)\nbrokerName=broker-a|broker-b\n\n#0表示Master,>0表示Slave\nbrokerId=0\n\n#Broker在集群的角色(和borkerId对应)\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n\n#刷盘方式(2m-2s-async与2m-2s-sync的区别点就是这个配置)\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n```\n\n以上内容修改完毕后，还需要添加以下配置:\n\n```properties\n# Broker的IP地址\nbrokerIP1 = xxxxxx\n\n# NameServer地址列表，多个nameServer地址用分号隔开\nnamesrvAddr = 10.29.183.66:9876;10.29.183.81:9876;10.29.183.82:9876;10.29.183.83:9876\n\n# 是否自动创建Topic,若关闭，客户端在使用一个未事先创建好的Topic会报错，打开改配置则会自动创建\nautoCreateTopicEnable = true\n```\n\n### 1.4 启动namesrv,broker\n\n**启动namesrv：**\n\n```shell\n# nohup sh bin/mqnamesrv > /dev/null 2>&1 &\n```\n\n查看日志:\n\n```shell\n# tail -f ~/logs/rocketmqlogs/namesrv.log\n```\n\n**启动broker:**\n\n方式一：手动指定namesrv地址:\n```shell\n# nohup sh bin/mqbroker -n localhost:9876 > /dev/null 2>&1 &\n```\n\n方式二:指定配置文件(推荐):\n```shell\n# nohup sh bin/mqbroker -c conf/broker.conf > /dev/null 2>&1 &\n```\n\n查看日志：\n\n```shell\n# tail -f ~/logs/rocketmqlogs/broker.log\n```\n\n### 1.5 停止namesrv,broker\n\n```shell\n# sh bin/mqshutdown namesrv\n\n# sh bin/mqshutdown broker\n```\n### 1.6 测试Producer,Consumer\n\n首先设置namesrv的地址\n\n```shell\n# export NAMESRV_ADDR=localhost:9876\n\n```\n测试发送消息:\n\n```shell\nsh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer\n```\n\n测试接受消息:\n```shell\nsh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer\n```\n\n### 1.7 mqadmin功能一览\n\n```txt\n   # sh bin/mqadmin\n\n   updateTopic          Update or create topic\n   deleteTopic          Delete topic from broker and NameServer.\n   updateSubGroup       Update or create subscription group\n   deleteSubGroup       Delete subscription group from broker.\n   updateBrokerConfig   Update broker's config\n   updateTopicPerm      Update topic perm\n   topicRoute           Examine topic route info\n   topicStatus          Examine topic Status info\n   topicClusterList     get cluster info for topic\n   brokerStatus         Fetch broker runtime status data\n   queryMsgById         Query Message by Id\n   queryMsgByKey        Query Message by Key\n   queryMsgByUniqueKey  Query Message by Unique key\n   queryMsgByOffset     Query Message by offset\n   printMsg             Print Message Detail\n   printMsgByQueue      Print Message Detail\n   sendMsgStatus        send msg to broker.\n   brokerConsumeStats   Fetch broker consume stats data\n   producerConnection   Query producer's socket connection and client version\n   consumerConnection   Query consumer's socket connection, client version and subscription\n   consumerProgress     Query consumers's progress, speed\n   consumerStatus       Query consumer's internal data structure\n   cloneGroupOffset     clone offset from other group.\n   clusterList          List all of clusters\n   topicList            Fetch all topic list from name server\n   updateKvConfig       Create or update KV config.\n   deleteKvConfig       Delete KV config.\n   wipeWritePerm        Wipe write perm of broker in all name server\n   resetOffsetByTime    Reset consumer offset by timestamp(without client restart).\n   updateOrderConf      Create or update or delete order conf\n   cleanExpiredCQ       Clean expired ConsumeQueue on broker.\n   cleanUnusedTopic     Clean unused topic on broker.\n   startMonitoring      Start Monitoring\n   statsAll             Topic and Consumer tps stats\n   allocateMQ           Allocate MQ\n   checkMsgSendRT       check message send response time\n   clusterRT            List All clusters Message Send RT\n   getNamesrvConfig     Get configs of name server.\n   updateNamesrvConfig  Update configs of name server.\n   getBrokerConfig      Get broker config by cluster or special broker!\n   queryCq              Query cq command.\n   sendMessage          Send a message\n   consumeMessage       Consume message\n```\n\n### 1.8 broker.conf主要配置\n\n```properties\n#===================主要配置===============\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a|broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\n#nameServer地址，分号分割\nnamesrvAddr=192.168.1.101:9876;192.168.1.102:9876\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=10911\n\n#============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n\n#===================线程池配置====================\ncheckTransactionMessageEnable=false\n#发消息线程池数量\nsendMessageThreadPoolNums=128\n#拉消息线程池数量\npullMessageThreadPoolNums=128\n```\n\n## 2.Docker使用指南\n\n### 2.1 docker常用命令\n\n```shell\n# yum install -y docker  //安装docker\n\n# service docker start  //启动docker\n\n# service docker status //查看docker服务状态\n\n# service docker stop  //停止docker服务\n\n# systemctl reload docker //刷新docker配置\n```\n\n```shell\n# docker ps -a  //检查docker运行状态\n\n# docker start rocketmq  //启动容器\n\n# docker stop rocketmq  //停止容器\n\n# docker rm 容器ID/Name  //删除容器\n\n# docker rm `docker ps -a -q` //删除所有容器\n```\n\n```shell\n# docker images //查看本地镜像列表\n\n# docker rmi 镜像名称 //删除镜像\n\n# docker rmi $(docker images -q) //删除所有镜像\n```\n\n### 2.2 编辑docker仓库地址\n\n编辑仓库地址: vim /etc/docker/daemon.json\n\n```json\n{\n\"registry-mirrors\": [\"https://registry.docker-cn.com\"],\n\"insecure-registries\":[\"10.25.24.161:5000\",\"10.29.139.47:5000\",\"10.29.139.47:5001\"]\n}\n```\n参数详细说明：https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options\n\n### 2.3 获取基础镜像\n\n```shell\n# docker pull 10.29.139.47:5001/base/java\n```\n\n从docker hub上获取centos基础镜像\n\n```shell\n# docker pull centos:latest\n```\n\n### 2.4 docker run 启动容器\n\n启动容器\n\n```shell\n# docker run ...\n```\n\n--name:容器实例名称\n\n--privileged:使用该参数，container内的root拥有真正的root权限。\n\n-td：后台运行容器（--tty，--detach）\n\n-it 创建一个交互式的容器\n\n-p 映射端口(本机的端口：映射的容器的端口)\n\n-v 挂载目录/root/software:/software(本地目录：容器目录)，在创建前容器是没有software目录的，docker 容器会自己创建\n\n--privileged=true 关闭安全权限，否则你容器操作文件夹没有权限\n\n>资源限制：\n\n--ulimit memlock=-1：容器使用内存不受限制\n\n```txt\ndocker容器资源限制默认：\n\n–default-ulimit nofile=131072 \n–default-ulimit memlock=128849018880 \n–default-ulimit core=-1 \n–default-ulimit nproc=-1 \n–default-ulimit stack=-1\n```\n>网络设置：\n\n--net：网络指定\n\n```txt\ndocker容器网络选择：\n\n1. host模式： docker run 使用 --net=host指定\ndocker使用的网络实际上和宿主机一样\n\n2. container模式：使用 --net=container:container_id/container_name\n多个容器使用共同的网络，看到的ip是一样的。\n\n3. none 模式: 使用 --net=none指定\n这种模式下，不会配置任何网络。\n\n4. bridge模式: 使用 --net=bridge指定\n默认模式，不会指定。此模式会为每个容器分配一个独立的network namespace\n```\n\n使用示例:\n\n启动镜像，指定端口映射:\n\n```shell\n# docker run --name rocketmq-tmp -p 98761:98761 --privileged --ulimit memlock=-1 --net=host -td rockemq-base1 /usr/sbin/init\n```\n\n启动一个镜像，映射目录:\n```shell\n# docker run -it -p 8070:8080 -v /root/software:/software --privileged=true  docker.io/centos /bin/bash\n```\n\n### 2.5 docker exec 进入容器\n\n方式一：exec\n\n```shell\n# docker exec -it kungfu-devel bash\n```\n\n方式二：attach\n\n注意：如果从这个stdin中exit，会导致容器的停止。\n\n```shell\n# docker attach cd24b1147c40\n\n# docker attach mycentos\n```\n\n### 2.6 docker commit 保存镜像\n\n保存镜像：\n```shell\ndocker commit afcaf46e8305 rocketmq-cluster\n```\n\n查看镜像的详细信息：\n\n```shell\ndocker inspect centos-vim:afcaf46e8305\n```\n\n### 2.6 docker push 推送镜像到远端\n\n标记与推送：\n```shell\n# docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7\n\n# docker push 10.29.139.47:5001/jiagou_registry/centos7\n```\n\n需要先登录:\n\n```shell\n# docker login -u你的docker账号 -p你的docker密\n\nLogin Succeeded\n```\n\n### 2.7 docker build 从dockerfile构建镜像\n\n```shell\n# docker build -t image_name -f ./Dockerfile .\n```\n\n## 3.使用Docker搭建RocketMQ集群\n\n### 3.1 构建基础镜像 rocketmq:base\n\n1.拉取基础镜像\n\ndocker pull centos:latest\n\ndocker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7\n\ndocker tag 10.29.139.47:5001/jiagou_registry/centos7 centos7\n\n2.启动容器\n\ndocker run --name rocketmq --privileged --ulimit memlock=-1 -v /root/soft:/data/soft --net=host -td centos7 /usr/sbin/init\n\n3.在容器中配置java,maven环境\n\n```txt\nJAVA_HOME=/opt/jdk1.8.0_191\nM2_HOME=/opt/apache-maven-3.5.2\nROCKETMQ_HOME=/opt/apache-rocketmq\n```\n\n4.编译rocketmq代码,将编译过后的文件copy到/opt下，最终rocketmq的路径为：/opt/apache-rocketmq\n\n5.在/opt/apache-rocketmq/config/目录下,创建namesrv.conf配置文件\n\n```shell\n# vim namesrv.conf\n\nlistenPort=9877\n```\n\n6.修改.bashrc文件\n\n```shell\nvim ~/.bashrc\n.....\nif [ -f /etc/bashrc ]; then\n        . /etc/bashrc\nsource /etc/profile\nfi\n....\n```\n\n7.保存镜像\n\n在centos7的容器中，执行exit方法，退出容器\n\n查看刚才容器的id\n\n```shell\n# docker ps -a\n```\n\n保存，\n\n```shell\n# docker commit d4bd7510bdb2 rocketmq:base\n```\n\n### 3.2 构建namesrv镜像 rocketmq:namesrv\n\n创建目录：/root/dockerfiles/rocketmq-namesrv,进入目录执行，\n\n```shell\n# vim Dockerfile\n\nFROM rocketmq:base\n\nENV JAVA_HOME=/opt/jdk1.8.0_191\nENV M2_HOME=/opt/apache-maven-3.5.2\nENV ROCKETMQ_HOME=/opt/apache-rocketmq\nENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin\nENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nCMD cd /opt/apache-rocketmq/ \\\n && /opt/apache-rocketmq/bin/mqnamesrv -c /opt/apache-rocketmq/conf/namesrv.conf\n```\n\n在Dockerfile的目录下，执行\n\n```shell\n# docker build -t rocketmq:namesrv -f ./Dockerfile .\n```\n\n### 3.3 构建broker镜像 rocketmq:broker\n\n创建目录：/root/dockerfiles/rocketmq-broker,进入目录执行，\n\n```shell\n# vim Dockerfile\n\nFROM rocketmq:base\n\nENV JAVA_HOME=/opt/jdk1.8.0_191\nENV M2_HOME=/opt/apache-maven-3.5.2\nENV ROCKETMQ_HOME=/opt/apache-rocketmq\nENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin\nENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nCMD cd /opt/apache-rocketmq/ \\\n && /opt/apache-rocketmq/bin/mqbroker -c /config/broker.conf\n```\n\n在Dockerfile的目录下，执行\n\n```shell\n# docker build -t rocketmq:broker -f ./Dockerfile .\n```\n\n### 3.4 启动namesrv\n\n```shell\n# docker run -d -p 9877:9877 --name rmqnamesrv rocketmq:namesrv\n```\n\n### 3.5 启动broker\n\n创建以下配置目录：\n\n/opt/mqconfig/broker-a-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=20911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n/opt/mqconfig/broker-a-s-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a\n\n#0表示Master，>0表示Slave\nbrokerId=1\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole= SLAVE\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=30911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n/opt/mqconfig/broker-b-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=40911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n/opt/mqconfig/broker-b-s-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=1\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole= SLAVE\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=50911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n启动master-a:\n```shell\n# docker run -d -p 20911:20911 -p 20909:20909 -v=/opt/mqconfig/broker-a-config:/config --name rmqbroker-a rocketmq:broker\n```\n\n启动slave-a:\n```shell\n# docker run -d -p 30911:30911 -p 30909:30909 -v=/opt/mqconfig/broker-a-s-config:/config --name rmqbroker-a-s rocketmq:broker\n```\n\n启动master-b:\n```shell\n# docker run -d -p 40911:40911 -p 40909:40909 -v=/opt/mqconfig/broker-b-config:/config --name rmqbroker-b rocketmq:broker\n```\n\n启动slave-b:\n```shell\n# docker run -d -p 50911:50911 -p 50909:50909 -v=/opt/mqconfig/broker-b-s-config:/config --name rmqbroker-b-s rocketmq:broker\n```\n\n### 3.6 启动console\n\n拉取镜像：\n\n```shell\n# docker pull styletang/rocketmq-console-ng\n```\n\n启动容器，指定--link,-p\n\n```shell\n# docker run -d -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=rmqnamesrv:9877 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" --link rmqnamesrv:rmqnamesrv -p 8080:8080 --name rmqconsole -t docker.io/styletang/rocketmq-console-ng\n```\n\n### 3.7 检查服务状态\n\n查看容器状态:\n\n```shell\n# docker ps -a\n```\n\n浏览器访问：\n\nhttp://10.29.183.66:8080/\n\n![1](/images/rocketmq/1.png)\n\n![2](/images/rocketmq/2.png)\n\n![3](/images/rocketmq/3.png)\n\n## 4.docker瘦身\n\n参考网址：\n\nhttp://dockone.io/article/8174","source":"_posts/2018-11-26-RocketMQ-docker搭建.md","raw":"---\nlayout: lay_post\ntitle: \"RocketMQ-docker搭建\"\ndate: 2018-11-26\ncategories: 中间件\ntags: MQ\nauthor: lvyafei\n---\n\n## 0.基础准备\n\n在Docker中搭建RocketMQ集群环境。\n<!-- more -->\n\njdk1.8下载地址：\n\nhttps://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\n\nmaven 下载地址:\n\nhttp://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz\n\nrocketmq-4.3.2下载地址：\n\nhttps://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz\n\nrocketmq-console下载:\n\nhttps://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip\n\n配置maven镜像仓库地址:\n\n```xml\n<mirrors>\n    <mirror>\n          <id>alimaven</id>\n          <name>aliyun maven</name>\n          <url>http://maven.aliyun.com/nexus/content/groups/public/</url>\n          <mirrorOf>central</mirrorOf>        \n    </mirror>\n</mirrors>\n```\n参考资料(rocketmq集群介绍)：\n\nhttps://blog.csdn.net/leexide/article/details/80035470\n\nhttps://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html\n\n关闭防火墙:\n\n```shell\n# systemctl stop firewalld\n```\n\n## 1.RocketMQ 集群环境搭建\n\n### 1.1 RocketMQ编译\n\njava,maven环境变量首先配置正确。\n\n然后更改本地maven的镜像仓库地址,最后进入到RocketMQ的源代码文件夹中,执行编译\n\n```shell\n# mvn -Prelease-all -DskipTests clean install -U\n```\n\n执行完后，将 rocketmq-rocketmq-all-4.3.2/distribution/target 目录下的 apache-rocketmq 文件夹 copy 到 /opt 或应用存放的目录中。\n\n### 1.2 更改默认的JVM配置\n\n修改namesrv的配置：\n\n```shell\n# vim bin/runserver.sh\n...\nJAVA_OPT=\"${JAVA_OPT} -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\"\n...\n```\n修改broker的配置：\n\n```shell\n# vim /bin/runbroker.sh\n...\nJAVA_OPT=\"${JAVA_OPT} -server -Xms8g -Xmx8g -Xmn4g\"\n...\n```\n\n### 1.3 broker配置修改\n\nbroker的配置文件在 config/broker.conf中，其中 config/2m-2s-async 为多Master多Slave模式(异步复制)集群配置，config/2m-2s-sync为多Master多Slave模式(同步双写)集群配置，config/2m-noslave 为多Master集群。每种集群模式的优缺点见参考资料。\n\n每种配置的关键配置项，如下：\n\n```properties\n#集群名称(相同名称的brokerName,根据brokerId来区别主从)\nbrokerName=broker-a|broker-b\n\n#0表示Master,>0表示Slave\nbrokerId=0\n\n#Broker在集群的角色(和borkerId对应)\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n\n#刷盘方式(2m-2s-async与2m-2s-sync的区别点就是这个配置)\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n```\n\n以上内容修改完毕后，还需要添加以下配置:\n\n```properties\n# Broker的IP地址\nbrokerIP1 = xxxxxx\n\n# NameServer地址列表，多个nameServer地址用分号隔开\nnamesrvAddr = 10.29.183.66:9876;10.29.183.81:9876;10.29.183.82:9876;10.29.183.83:9876\n\n# 是否自动创建Topic,若关闭，客户端在使用一个未事先创建好的Topic会报错，打开改配置则会自动创建\nautoCreateTopicEnable = true\n```\n\n### 1.4 启动namesrv,broker\n\n**启动namesrv：**\n\n```shell\n# nohup sh bin/mqnamesrv > /dev/null 2>&1 &\n```\n\n查看日志:\n\n```shell\n# tail -f ~/logs/rocketmqlogs/namesrv.log\n```\n\n**启动broker:**\n\n方式一：手动指定namesrv地址:\n```shell\n# nohup sh bin/mqbroker -n localhost:9876 > /dev/null 2>&1 &\n```\n\n方式二:指定配置文件(推荐):\n```shell\n# nohup sh bin/mqbroker -c conf/broker.conf > /dev/null 2>&1 &\n```\n\n查看日志：\n\n```shell\n# tail -f ~/logs/rocketmqlogs/broker.log\n```\n\n### 1.5 停止namesrv,broker\n\n```shell\n# sh bin/mqshutdown namesrv\n\n# sh bin/mqshutdown broker\n```\n### 1.6 测试Producer,Consumer\n\n首先设置namesrv的地址\n\n```shell\n# export NAMESRV_ADDR=localhost:9876\n\n```\n测试发送消息:\n\n```shell\nsh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer\n```\n\n测试接受消息:\n```shell\nsh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer\n```\n\n### 1.7 mqadmin功能一览\n\n```txt\n   # sh bin/mqadmin\n\n   updateTopic          Update or create topic\n   deleteTopic          Delete topic from broker and NameServer.\n   updateSubGroup       Update or create subscription group\n   deleteSubGroup       Delete subscription group from broker.\n   updateBrokerConfig   Update broker's config\n   updateTopicPerm      Update topic perm\n   topicRoute           Examine topic route info\n   topicStatus          Examine topic Status info\n   topicClusterList     get cluster info for topic\n   brokerStatus         Fetch broker runtime status data\n   queryMsgById         Query Message by Id\n   queryMsgByKey        Query Message by Key\n   queryMsgByUniqueKey  Query Message by Unique key\n   queryMsgByOffset     Query Message by offset\n   printMsg             Print Message Detail\n   printMsgByQueue      Print Message Detail\n   sendMsgStatus        send msg to broker.\n   brokerConsumeStats   Fetch broker consume stats data\n   producerConnection   Query producer's socket connection and client version\n   consumerConnection   Query consumer's socket connection, client version and subscription\n   consumerProgress     Query consumers's progress, speed\n   consumerStatus       Query consumer's internal data structure\n   cloneGroupOffset     clone offset from other group.\n   clusterList          List all of clusters\n   topicList            Fetch all topic list from name server\n   updateKvConfig       Create or update KV config.\n   deleteKvConfig       Delete KV config.\n   wipeWritePerm        Wipe write perm of broker in all name server\n   resetOffsetByTime    Reset consumer offset by timestamp(without client restart).\n   updateOrderConf      Create or update or delete order conf\n   cleanExpiredCQ       Clean expired ConsumeQueue on broker.\n   cleanUnusedTopic     Clean unused topic on broker.\n   startMonitoring      Start Monitoring\n   statsAll             Topic and Consumer tps stats\n   allocateMQ           Allocate MQ\n   checkMsgSendRT       check message send response time\n   clusterRT            List All clusters Message Send RT\n   getNamesrvConfig     Get configs of name server.\n   updateNamesrvConfig  Update configs of name server.\n   getBrokerConfig      Get broker config by cluster or special broker!\n   queryCq              Query cq command.\n   sendMessage          Send a message\n   consumeMessage       Consume message\n```\n\n### 1.8 broker.conf主要配置\n\n```properties\n#===================主要配置===============\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a|broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\n#nameServer地址，分号分割\nnamesrvAddr=192.168.1.101:9876;192.168.1.102:9876\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=10911\n\n#============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n\n#===================线程池配置====================\ncheckTransactionMessageEnable=false\n#发消息线程池数量\nsendMessageThreadPoolNums=128\n#拉消息线程池数量\npullMessageThreadPoolNums=128\n```\n\n## 2.Docker使用指南\n\n### 2.1 docker常用命令\n\n```shell\n# yum install -y docker  //安装docker\n\n# service docker start  //启动docker\n\n# service docker status //查看docker服务状态\n\n# service docker stop  //停止docker服务\n\n# systemctl reload docker //刷新docker配置\n```\n\n```shell\n# docker ps -a  //检查docker运行状态\n\n# docker start rocketmq  //启动容器\n\n# docker stop rocketmq  //停止容器\n\n# docker rm 容器ID/Name  //删除容器\n\n# docker rm `docker ps -a -q` //删除所有容器\n```\n\n```shell\n# docker images //查看本地镜像列表\n\n# docker rmi 镜像名称 //删除镜像\n\n# docker rmi $(docker images -q) //删除所有镜像\n```\n\n### 2.2 编辑docker仓库地址\n\n编辑仓库地址: vim /etc/docker/daemon.json\n\n```json\n{\n\"registry-mirrors\": [\"https://registry.docker-cn.com\"],\n\"insecure-registries\":[\"10.25.24.161:5000\",\"10.29.139.47:5000\",\"10.29.139.47:5001\"]\n}\n```\n参数详细说明：https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options\n\n### 2.3 获取基础镜像\n\n```shell\n# docker pull 10.29.139.47:5001/base/java\n```\n\n从docker hub上获取centos基础镜像\n\n```shell\n# docker pull centos:latest\n```\n\n### 2.4 docker run 启动容器\n\n启动容器\n\n```shell\n# docker run ...\n```\n\n--name:容器实例名称\n\n--privileged:使用该参数，container内的root拥有真正的root权限。\n\n-td：后台运行容器（--tty，--detach）\n\n-it 创建一个交互式的容器\n\n-p 映射端口(本机的端口：映射的容器的端口)\n\n-v 挂载目录/root/software:/software(本地目录：容器目录)，在创建前容器是没有software目录的，docker 容器会自己创建\n\n--privileged=true 关闭安全权限，否则你容器操作文件夹没有权限\n\n>资源限制：\n\n--ulimit memlock=-1：容器使用内存不受限制\n\n```txt\ndocker容器资源限制默认：\n\n–default-ulimit nofile=131072 \n–default-ulimit memlock=128849018880 \n–default-ulimit core=-1 \n–default-ulimit nproc=-1 \n–default-ulimit stack=-1\n```\n>网络设置：\n\n--net：网络指定\n\n```txt\ndocker容器网络选择：\n\n1. host模式： docker run 使用 --net=host指定\ndocker使用的网络实际上和宿主机一样\n\n2. container模式：使用 --net=container:container_id/container_name\n多个容器使用共同的网络，看到的ip是一样的。\n\n3. none 模式: 使用 --net=none指定\n这种模式下，不会配置任何网络。\n\n4. bridge模式: 使用 --net=bridge指定\n默认模式，不会指定。此模式会为每个容器分配一个独立的network namespace\n```\n\n使用示例:\n\n启动镜像，指定端口映射:\n\n```shell\n# docker run --name rocketmq-tmp -p 98761:98761 --privileged --ulimit memlock=-1 --net=host -td rockemq-base1 /usr/sbin/init\n```\n\n启动一个镜像，映射目录:\n```shell\n# docker run -it -p 8070:8080 -v /root/software:/software --privileged=true  docker.io/centos /bin/bash\n```\n\n### 2.5 docker exec 进入容器\n\n方式一：exec\n\n```shell\n# docker exec -it kungfu-devel bash\n```\n\n方式二：attach\n\n注意：如果从这个stdin中exit，会导致容器的停止。\n\n```shell\n# docker attach cd24b1147c40\n\n# docker attach mycentos\n```\n\n### 2.6 docker commit 保存镜像\n\n保存镜像：\n```shell\ndocker commit afcaf46e8305 rocketmq-cluster\n```\n\n查看镜像的详细信息：\n\n```shell\ndocker inspect centos-vim:afcaf46e8305\n```\n\n### 2.6 docker push 推送镜像到远端\n\n标记与推送：\n```shell\n# docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7\n\n# docker push 10.29.139.47:5001/jiagou_registry/centos7\n```\n\n需要先登录:\n\n```shell\n# docker login -u你的docker账号 -p你的docker密\n\nLogin Succeeded\n```\n\n### 2.7 docker build 从dockerfile构建镜像\n\n```shell\n# docker build -t image_name -f ./Dockerfile .\n```\n\n## 3.使用Docker搭建RocketMQ集群\n\n### 3.1 构建基础镜像 rocketmq:base\n\n1.拉取基础镜像\n\ndocker pull centos:latest\n\ndocker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7\n\ndocker tag 10.29.139.47:5001/jiagou_registry/centos7 centos7\n\n2.启动容器\n\ndocker run --name rocketmq --privileged --ulimit memlock=-1 -v /root/soft:/data/soft --net=host -td centos7 /usr/sbin/init\n\n3.在容器中配置java,maven环境\n\n```txt\nJAVA_HOME=/opt/jdk1.8.0_191\nM2_HOME=/opt/apache-maven-3.5.2\nROCKETMQ_HOME=/opt/apache-rocketmq\n```\n\n4.编译rocketmq代码,将编译过后的文件copy到/opt下，最终rocketmq的路径为：/opt/apache-rocketmq\n\n5.在/opt/apache-rocketmq/config/目录下,创建namesrv.conf配置文件\n\n```shell\n# vim namesrv.conf\n\nlistenPort=9877\n```\n\n6.修改.bashrc文件\n\n```shell\nvim ~/.bashrc\n.....\nif [ -f /etc/bashrc ]; then\n        . /etc/bashrc\nsource /etc/profile\nfi\n....\n```\n\n7.保存镜像\n\n在centos7的容器中，执行exit方法，退出容器\n\n查看刚才容器的id\n\n```shell\n# docker ps -a\n```\n\n保存，\n\n```shell\n# docker commit d4bd7510bdb2 rocketmq:base\n```\n\n### 3.2 构建namesrv镜像 rocketmq:namesrv\n\n创建目录：/root/dockerfiles/rocketmq-namesrv,进入目录执行，\n\n```shell\n# vim Dockerfile\n\nFROM rocketmq:base\n\nENV JAVA_HOME=/opt/jdk1.8.0_191\nENV M2_HOME=/opt/apache-maven-3.5.2\nENV ROCKETMQ_HOME=/opt/apache-rocketmq\nENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin\nENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nCMD cd /opt/apache-rocketmq/ \\\n && /opt/apache-rocketmq/bin/mqnamesrv -c /opt/apache-rocketmq/conf/namesrv.conf\n```\n\n在Dockerfile的目录下，执行\n\n```shell\n# docker build -t rocketmq:namesrv -f ./Dockerfile .\n```\n\n### 3.3 构建broker镜像 rocketmq:broker\n\n创建目录：/root/dockerfiles/rocketmq-broker,进入目录执行，\n\n```shell\n# vim Dockerfile\n\nFROM rocketmq:base\n\nENV JAVA_HOME=/opt/jdk1.8.0_191\nENV M2_HOME=/opt/apache-maven-3.5.2\nENV ROCKETMQ_HOME=/opt/apache-rocketmq\nENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin\nENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nCMD cd /opt/apache-rocketmq/ \\\n && /opt/apache-rocketmq/bin/mqbroker -c /config/broker.conf\n```\n\n在Dockerfile的目录下，执行\n\n```shell\n# docker build -t rocketmq:broker -f ./Dockerfile .\n```\n\n### 3.4 启动namesrv\n\n```shell\n# docker run -d -p 9877:9877 --name rmqnamesrv rocketmq:namesrv\n```\n\n### 3.5 启动broker\n\n创建以下配置目录：\n\n/opt/mqconfig/broker-a-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=20911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n/opt/mqconfig/broker-a-s-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-a\n\n#0表示Master，>0表示Slave\nbrokerId=1\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole= SLAVE\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=30911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n/opt/mqconfig/broker-b-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=0\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole=ASYNC_MASTER\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=40911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n/opt/mqconfig/broker-b-s-config/broker.conf\n\n```shell\nvim broker.conf\n\n#所属集群名字\nbrokerClusterName=rocketmq-cluster\n\n#broker名字，注意此处不同的配置文件填写的不一样\nbrokerName=broker-b\n\n#0表示Master，>0表示Slave\nbrokerId=1\n\nbrokerIP1 = 10.29.183.66\n#nameServer地址，分号分割\nnamesrvAddr = 10.29.183.66:9877\n\n#限制的消息大小\nmaxMessageSize=65536\n#flushCommitLogLeastPages=4\n#flushConsumeQueueLeastPages=2\n#flushCommitLogThoroughInterval=10000\n#flushConsumeQueueThoroughInterval=60000\n\n#Broker 的角色\n#- ASYNC_MASTER 异步复制Master\n#- SYNC_MASTER 同步双写Master\n#- SLAVE\nbrokerRole= SLAVE\n#刷盘方式\n#- ASYNC_FLUSH 异步刷盘\n#- SYNC_FLUSH 同步刷盘\nflushDiskType=ASYNC_FLUSH\n\n#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数\ndefaultTopicQueueNums=4\n\n#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭\nautoCreateTopicEnable=true\n\n#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭\nautoCreateSubscriptionGroup=true\n\n#Broker 对外服务的监听端口\nlistenPort=50911\n\n============持久化配置=================\n\n#删除文件时间点，默认凌晨 4点\ndeleteWhen=04\n#文件保留时间，默认 48 小时\nfileReservedTime=120\n\n#commitLog每个文件的大小默认1G\nmapedFileSizeCommitLog=1073741824\n#ConsumeQueue每个文件默认存30W条，根据业务情况调整\nmapedFileSizeConsumeQueue=300000\n#destroyMapedFileIntervalForcibly=120000\n#redeleteHangedFileInterval=120000\n#检测物理文件磁盘空间\ndiskMaxUsedSpaceRatio=88\n#存储路径\nstorePathRootDir=/data/rocketmq/store\n#commitLog 存储路径\nstorePathCommitLog=/data/rocketmq/store/commitlog\n#消费队列存储路径存储路径\nstorePathConsumeQueue=/data/rocketmq/store/consumequeue\n#消息索引存储路径\nstorePathIndex=/data/rocketmq/store/index\n#checkpoint 文件存储路径\nstoreCheckpoint=/data/rocketmq/store/checkpoint\n#abort 文件存储路径\nabortFile=/data/rocketmq/store/abort\n```\n\n启动master-a:\n```shell\n# docker run -d -p 20911:20911 -p 20909:20909 -v=/opt/mqconfig/broker-a-config:/config --name rmqbroker-a rocketmq:broker\n```\n\n启动slave-a:\n```shell\n# docker run -d -p 30911:30911 -p 30909:30909 -v=/opt/mqconfig/broker-a-s-config:/config --name rmqbroker-a-s rocketmq:broker\n```\n\n启动master-b:\n```shell\n# docker run -d -p 40911:40911 -p 40909:40909 -v=/opt/mqconfig/broker-b-config:/config --name rmqbroker-b rocketmq:broker\n```\n\n启动slave-b:\n```shell\n# docker run -d -p 50911:50911 -p 50909:50909 -v=/opt/mqconfig/broker-b-s-config:/config --name rmqbroker-b-s rocketmq:broker\n```\n\n### 3.6 启动console\n\n拉取镜像：\n\n```shell\n# docker pull styletang/rocketmq-console-ng\n```\n\n启动容器，指定--link,-p\n\n```shell\n# docker run -d -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=rmqnamesrv:9877 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" --link rmqnamesrv:rmqnamesrv -p 8080:8080 --name rmqconsole -t docker.io/styletang/rocketmq-console-ng\n```\n\n### 3.7 检查服务状态\n\n查看容器状态:\n\n```shell\n# docker ps -a\n```\n\n浏览器访问：\n\nhttp://10.29.183.66:8080/\n\n![1](/images/rocketmq/1.png)\n\n![2](/images/rocketmq/2.png)\n\n![3](/images/rocketmq/3.png)\n\n## 4.docker瘦身\n\n参考网址：\n\nhttp://dockone.io/article/8174","slug":"2018-11-26-RocketMQ-docker搭建","published":1,"updated":"2018-11-29T12:51:25.297Z","comments":1,"photos":[],"link":"","_id":"cjskffodc005k4glmrtwkxtca","content":"<h2 id=\"0-基础准备\"><a href=\"#0-基础准备\" class=\"headerlink\" title=\"0.基础准备\"></a>0.基础准备</h2><p>在Docker中搭建RocketMQ集群环境。<br><a id=\"more\"></a></p>\n<p>jdk1.8下载地址：</p>\n<p><a href=\"https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>\n<p>maven 下载地址:</p>\n<p><a href=\"http://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz\" target=\"_blank\" rel=\"noopener\">http://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz</a></p>\n<p>rocketmq-4.3.2下载地址：</p>\n<p><a href=\"https://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz</a></p>\n<p>rocketmq-console下载:</p>\n<p><a href=\"https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip</a></p>\n<p>配置maven镜像仓库地址:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>alimaven<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>aliyun maven<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>central<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span>        </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>参考资料(rocketmq集群介绍)：</p>\n<p><a href=\"https://blog.csdn.net/leexide/article/details/80035470\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leexide/article/details/80035470</a></p>\n<p><a href=\"https://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html\" target=\"_blank\" rel=\"noopener\">https://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html</a></p>\n<p>关闭防火墙:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> systemctl stop firewalld</span><br></pre></td></tr></table></figure>\n<h2 id=\"1-RocketMQ-集群环境搭建\"><a href=\"#1-RocketMQ-集群环境搭建\" class=\"headerlink\" title=\"1.RocketMQ 集群环境搭建\"></a>1.RocketMQ 集群环境搭建</h2><h3 id=\"1-1-RocketMQ编译\"><a href=\"#1-1-RocketMQ编译\" class=\"headerlink\" title=\"1.1 RocketMQ编译\"></a>1.1 RocketMQ编译</h3><p>java,maven环境变量首先配置正确。</p>\n<p>然后更改本地maven的镜像仓库地址,最后进入到RocketMQ的源代码文件夹中,执行编译</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> mvn -Prelease-all -DskipTests clean install -U</span><br></pre></td></tr></table></figure>\n<p>执行完后，将 rocketmq-rocketmq-all-4.3.2/distribution/target 目录下的 apache-rocketmq 文件夹 copy 到 /opt 或应用存放的目录中。</p>\n<h3 id=\"1-2-更改默认的JVM配置\"><a href=\"#1-2-更改默认的JVM配置\" class=\"headerlink\" title=\"1.2 更改默认的JVM配置\"></a>1.2 更改默认的JVM配置</h3><p>修改namesrv的配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim bin/runserver.sh</span><br><span class=\"line\">...</span><br><span class=\"line\">JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\"</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>修改broker的配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim /bin/runbroker.sh</span><br><span class=\"line\">...</span><br><span class=\"line\">JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g\"</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-broker配置修改\"><a href=\"#1-3-broker配置修改\" class=\"headerlink\" title=\"1.3 broker配置修改\"></a>1.3 broker配置修改</h3><p>broker的配置文件在 config/broker.conf中，其中 config/2m-2s-async 为多Master多Slave模式(异步复制)集群配置，config/2m-2s-sync为多Master多Slave模式(同步双写)集群配置，config/2m-noslave 为多Master集群。每种集群模式的优缺点见参考资料。</p>\n<p>每种配置的关键配置项，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#集群名称(相同名称的brokerName,根据brokerId来区别主从)</span><br><span class=\"line\">brokerName=broker-a|broker-b</span><br><span class=\"line\"></span><br><span class=\"line\">#0表示Master,&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker在集群的角色(和borkerId对应)</span><br><span class=\"line\">#- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\">#- SYNC_MASTER 同步双写Master</span><br><span class=\"line\">#- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"></span><br><span class=\"line\">#刷盘方式(2m-2s-async与2m-2s-sync的区别点就是这个配置)</span><br><span class=\"line\">#- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\">#- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br></pre></td></tr></table></figure>\n<p>以上内容修改完毕后，还需要添加以下配置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Broker的IP地址</span><br><span class=\"line\">brokerIP1 = xxxxxx</span><br><span class=\"line\"></span><br><span class=\"line\"># NameServer地址列表，多个nameServer地址用分号隔开</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9876;10.29.183.81:9876;10.29.183.82:9876;10.29.183.83:9876</span><br><span class=\"line\"></span><br><span class=\"line\"># 是否自动创建Topic,若关闭，客户端在使用一个未事先创建好的Topic会报错，打开改配置则会自动创建</span><br><span class=\"line\">autoCreateTopicEnable = true</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-启动namesrv-broker\"><a href=\"#1-4-启动namesrv-broker\" class=\"headerlink\" title=\"1.4 启动namesrv,broker\"></a>1.4 启动namesrv,broker</h3><p><strong>启动namesrv：</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqnamesrv &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>查看日志:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> tail -f ~/logs/rocketmqlogs/namesrv.log</span><br></pre></td></tr></table></figure>\n<p><strong>启动broker:</strong></p>\n<p>方式一：手动指定namesrv地址:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqbroker -n localhost:9876 &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>\n<p>方式二:指定配置文件(推荐):<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqbroker -c conf/broker.conf &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>\n<p>查看日志：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> tail -f ~/logs/rocketmqlogs/broker.log</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-5-停止namesrv-broker\"><a href=\"#1-5-停止namesrv-broker\" class=\"headerlink\" title=\"1.5 停止namesrv,broker\"></a>1.5 停止namesrv,broker</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sh bin/mqshutdown namesrv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> sh bin/mqshutdown broker</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-6-测试Producer-Consumer\"><a href=\"#1-6-测试Producer-Consumer\" class=\"headerlink\" title=\"1.6 测试Producer,Consumer\"></a>1.6 测试Producer,Consumer</h3><p>首先设置namesrv的地址</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> export NAMESRV_ADDR=localhost:9876</span><br></pre></td></tr></table></figure>\n<p>测试发送消息:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer</span><br></pre></td></tr></table></figure>\n<p>测试接受消息:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"1-7-mqadmin功能一览\"><a href=\"#1-7-mqadmin功能一览\" class=\"headerlink\" title=\"1.7 mqadmin功能一览\"></a>1.7 mqadmin功能一览</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># sh bin/mqadmin</span><br><span class=\"line\"></span><br><span class=\"line\">updateTopic          Update or create topic</span><br><span class=\"line\">deleteTopic          Delete topic from broker and NameServer.</span><br><span class=\"line\">updateSubGroup       Update or create subscription group</span><br><span class=\"line\">deleteSubGroup       Delete subscription group from broker.</span><br><span class=\"line\">updateBrokerConfig   Update broker&apos;s config</span><br><span class=\"line\">updateTopicPerm      Update topic perm</span><br><span class=\"line\">topicRoute           Examine topic route info</span><br><span class=\"line\">topicStatus          Examine topic Status info</span><br><span class=\"line\">topicClusterList     get cluster info for topic</span><br><span class=\"line\">brokerStatus         Fetch broker runtime status data</span><br><span class=\"line\">queryMsgById         Query Message by Id</span><br><span class=\"line\">queryMsgByKey        Query Message by Key</span><br><span class=\"line\">queryMsgByUniqueKey  Query Message by Unique key</span><br><span class=\"line\">queryMsgByOffset     Query Message by offset</span><br><span class=\"line\">printMsg             Print Message Detail</span><br><span class=\"line\">printMsgByQueue      Print Message Detail</span><br><span class=\"line\">sendMsgStatus        send msg to broker.</span><br><span class=\"line\">brokerConsumeStats   Fetch broker consume stats data</span><br><span class=\"line\">producerConnection   Query producer&apos;s socket connection and client version</span><br><span class=\"line\">consumerConnection   Query consumer&apos;s socket connection, client version and subscription</span><br><span class=\"line\">consumerProgress     Query consumers&apos;s progress, speed</span><br><span class=\"line\">consumerStatus       Query consumer&apos;s internal data structure</span><br><span class=\"line\">cloneGroupOffset     clone offset from other group.</span><br><span class=\"line\">clusterList          List all of clusters</span><br><span class=\"line\">topicList            Fetch all topic list from name server</span><br><span class=\"line\">updateKvConfig       Create or update KV config.</span><br><span class=\"line\">deleteKvConfig       Delete KV config.</span><br><span class=\"line\">wipeWritePerm        Wipe write perm of broker in all name server</span><br><span class=\"line\">resetOffsetByTime    Reset consumer offset by timestamp(without client restart).</span><br><span class=\"line\">updateOrderConf      Create or update or delete order conf</span><br><span class=\"line\">cleanExpiredCQ       Clean expired ConsumeQueue on broker.</span><br><span class=\"line\">cleanUnusedTopic     Clean unused topic on broker.</span><br><span class=\"line\">startMonitoring      Start Monitoring</span><br><span class=\"line\">statsAll             Topic and Consumer tps stats</span><br><span class=\"line\">allocateMQ           Allocate MQ</span><br><span class=\"line\">checkMsgSendRT       check message send response time</span><br><span class=\"line\">clusterRT            List All clusters Message Send RT</span><br><span class=\"line\">getNamesrvConfig     Get configs of name server.</span><br><span class=\"line\">updateNamesrvConfig  Update configs of name server.</span><br><span class=\"line\">getBrokerConfig      Get broker config by cluster or special broker!</span><br><span class=\"line\">queryCq              Query cq command.</span><br><span class=\"line\">sendMessage          Send a message</span><br><span class=\"line\">consumeMessage       Consume message</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-8-broker-conf主要配置\"><a href=\"#1-8-broker-conf主要配置\" class=\"headerlink\" title=\"1.8 broker.conf主要配置\"></a>1.8 broker.conf主要配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#===================主要配置===============</span><br><span class=\"line\"></span><br><span class=\"line\">#所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\">#broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a|broker-b</span><br><span class=\"line\"></span><br><span class=\"line\">#0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">#nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr=192.168.1.101:9876;192.168.1.102:9876</span><br><span class=\"line\"></span><br><span class=\"line\">#限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\">#flushCommitLogLeastPages=4</span><br><span class=\"line\">#flushConsumeQueueLeastPages=2</span><br><span class=\"line\">#flushCommitLogThoroughInterval=10000</span><br><span class=\"line\">#flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker 的角色</span><br><span class=\"line\">#- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\">#- SYNC_MASTER 同步双写Master</span><br><span class=\"line\">#- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\">#刷盘方式</span><br><span class=\"line\">#- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\">#- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\">#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\">#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\">#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=10911</span><br><span class=\"line\"></span><br><span class=\"line\">#============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\">#删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">#文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\">#commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\">#ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\">#destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\">#redeleteHangedFileInterval=120000</span><br><span class=\"line\">#检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\">#存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\">#commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\">#消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\">#消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\">#checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\">#abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br><span class=\"line\"></span><br><span class=\"line\">#===================线程池配置====================</span><br><span class=\"line\">checkTransactionMessageEnable=false</span><br><span class=\"line\">#发消息线程池数量</span><br><span class=\"line\">sendMessageThreadPoolNums=128</span><br><span class=\"line\">#拉消息线程池数量</span><br><span class=\"line\">pullMessageThreadPoolNums=128</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-Docker使用指南\"><a href=\"#2-Docker使用指南\" class=\"headerlink\" title=\"2.Docker使用指南\"></a>2.Docker使用指南</h2><h3 id=\"2-1-docker常用命令\"><a href=\"#2-1-docker常用命令\" class=\"headerlink\" title=\"2.1 docker常用命令\"></a>2.1 docker常用命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> yum install -y docker  //安装docker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker start  //启动docker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker status //查看docker服务状态</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker stop  //停止docker服务</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> systemctl reload docker //刷新docker配置</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a  //检查docker运行状态</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker start rocketmq  //启动容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker stop rocketmq  //停止容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rm 容器ID/Name  //删除容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rm `docker ps -a -q` //删除所有容器</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker images //查看本地镜像列表</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rmi 镜像名称 //删除镜像</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rmi $(docker images -q) //删除所有镜像</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-编辑docker仓库地址\"><a href=\"#2-2-编辑docker仓库地址\" class=\"headerlink\" title=\"2.2 编辑docker仓库地址\"></a>2.2 编辑docker仓库地址</h3><p>编辑仓库地址: vim /etc/docker/daemon.json</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"registry-mirrors\"</span>: [<span class=\"string\">\"https://registry.docker-cn.com\"</span>],</span><br><span class=\"line\"><span class=\"attr\">\"insecure-registries\"</span>:[<span class=\"string\">\"10.25.24.161:5000\"</span>,<span class=\"string\">\"10.29.139.47:5000\"</span>,<span class=\"string\">\"10.29.139.47:5001\"</span>]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>参数详细说明：<a href=\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options</a></p>\n<h3 id=\"2-3-获取基础镜像\"><a href=\"#2-3-获取基础镜像\" class=\"headerlink\" title=\"2.3 获取基础镜像\"></a>2.3 获取基础镜像</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull 10.29.139.47:5001/base/java</span><br></pre></td></tr></table></figure>\n<p>从docker hub上获取centos基础镜像</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull centos:latest</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-docker-run-启动容器\"><a href=\"#2-4-docker-run-启动容器\" class=\"headerlink\" title=\"2.4 docker run 启动容器\"></a>2.4 docker run 启动容器</h3><p>启动容器</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run ...</span><br></pre></td></tr></table></figure>\n<p>–name:容器实例名称</p>\n<p>–privileged:使用该参数，container内的root拥有真正的root权限。</p>\n<p>-td：后台运行容器（–tty，–detach）</p>\n<p>-it 创建一个交互式的容器</p>\n<p>-p 映射端口(本机的端口：映射的容器的端口)</p>\n<p>-v 挂载目录/root/software:/software(本地目录：容器目录)，在创建前容器是没有software目录的，docker 容器会自己创建</p>\n<p>–privileged=true 关闭安全权限，否则你容器操作文件夹没有权限</p>\n<blockquote>\n<p>资源限制：</p>\n</blockquote>\n<p>–ulimit memlock=-1：容器使用内存不受限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker容器资源限制默认：</span><br><span class=\"line\"></span><br><span class=\"line\">–default-ulimit nofile=131072 </span><br><span class=\"line\">–default-ulimit memlock=128849018880 </span><br><span class=\"line\">–default-ulimit core=-1 </span><br><span class=\"line\">–default-ulimit nproc=-1 </span><br><span class=\"line\">–default-ulimit stack=-1</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>网络设置：</p>\n</blockquote>\n<p>–net：网络指定</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker容器网络选择：</span><br><span class=\"line\"></span><br><span class=\"line\">1. host模式： docker run 使用 --net=host指定</span><br><span class=\"line\">docker使用的网络实际上和宿主机一样</span><br><span class=\"line\"></span><br><span class=\"line\">2. container模式：使用 --net=container:container_id/container_name</span><br><span class=\"line\">多个容器使用共同的网络，看到的ip是一样的。</span><br><span class=\"line\"></span><br><span class=\"line\">3. none 模式: 使用 --net=none指定</span><br><span class=\"line\">这种模式下，不会配置任何网络。</span><br><span class=\"line\"></span><br><span class=\"line\">4. bridge模式: 使用 --net=bridge指定</span><br><span class=\"line\">默认模式，不会指定。此模式会为每个容器分配一个独立的network namespace</span><br></pre></td></tr></table></figure>\n<p>使用示例:</p>\n<p>启动镜像，指定端口映射:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run --name rocketmq-tmp -p 98761:98761 --privileged --ulimit memlock=-1 --net=host -td rockemq-base1 /usr/sbin/init</span><br></pre></td></tr></table></figure>\n<p>启动一个镜像，映射目录:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -it -p 8070:8080 -v /root/software:/software --privileged=true  docker.io/centos /bin/bash</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-5-docker-exec-进入容器\"><a href=\"#2-5-docker-exec-进入容器\" class=\"headerlink\" title=\"2.5 docker exec 进入容器\"></a>2.5 docker exec 进入容器</h3><p>方式一：exec</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker exec -it kungfu-devel bash</span><br></pre></td></tr></table></figure>\n<p>方式二：attach</p>\n<p>注意：如果从这个stdin中exit，会导致容器的停止。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker attach cd24b1147c40</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker attach mycentos</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-6-docker-commit-保存镜像\"><a href=\"#2-6-docker-commit-保存镜像\" class=\"headerlink\" title=\"2.6 docker commit 保存镜像\"></a>2.6 docker commit 保存镜像</h3><p>保存镜像：<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker commit afcaf46e8305 rocketmq-cluster</span><br></pre></td></tr></table></figure></p>\n<p>查看镜像的详细信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker inspect centos-vim:afcaf46e8305</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-6-docker-push-推送镜像到远端\"><a href=\"#2-6-docker-push-推送镜像到远端\" class=\"headerlink\" title=\"2.6 docker push 推送镜像到远端\"></a>2.6 docker push 推送镜像到远端</h3><p>标记与推送：<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker push 10.29.139.47:5001/jiagou_registry/centos7</span><br></pre></td></tr></table></figure></p>\n<p>需要先登录:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker login -u你的docker账号 -p你的docker密</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-7-docker-build-从dockerfile构建镜像\"><a href=\"#2-7-docker-build-从dockerfile构建镜像\" class=\"headerlink\" title=\"2.7 docker build 从dockerfile构建镜像\"></a>2.7 docker build 从dockerfile构建镜像</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t image_name -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-使用Docker搭建RocketMQ集群\"><a href=\"#3-使用Docker搭建RocketMQ集群\" class=\"headerlink\" title=\"3.使用Docker搭建RocketMQ集群\"></a>3.使用Docker搭建RocketMQ集群</h2><h3 id=\"3-1-构建基础镜像-rocketmq-base\"><a href=\"#3-1-构建基础镜像-rocketmq-base\" class=\"headerlink\" title=\"3.1 构建基础镜像 rocketmq:base\"></a>3.1 构建基础镜像 rocketmq:base</h3><p>1.拉取基础镜像</p>\n<p>docker pull centos:latest</p>\n<p>docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7</p>\n<p>docker tag 10.29.139.47:5001/jiagou_registry/centos7 centos7</p>\n<p>2.启动容器</p>\n<p>docker run –name rocketmq –privileged –ulimit memlock=-1 -v /root/soft:/data/soft –net=host -td centos7 /usr/sbin/init</p>\n<p>3.在容器中配置java,maven环境</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ROCKETMQ_HOME=/opt/apache-rocketmq</span><br></pre></td></tr></table></figure>\n<p>4.编译rocketmq代码,将编译过后的文件copy到/opt下，最终rocketmq的路径为：/opt/apache-rocketmq</p>\n<p>5.在/opt/apache-rocketmq/config/目录下,创建namesrv.conf配置文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim namesrv.conf</span><br><span class=\"line\"></span><br><span class=\"line\">listenPort=9877</span><br></pre></td></tr></table></figure>\n<p>6.修改.bashrc文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim ~/.bashrc</span><br><span class=\"line\">.....</span><br><span class=\"line\">if [ -f /etc/bashrc ]; then</span><br><span class=\"line\">        . /etc/bashrc</span><br><span class=\"line\">source /etc/profile</span><br><span class=\"line\">fi</span><br><span class=\"line\">....</span><br></pre></td></tr></table></figure>\n<p>7.保存镜像</p>\n<p>在centos7的容器中，执行exit方法，退出容器</p>\n<p>查看刚才容器的id</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a</span><br></pre></td></tr></table></figure>\n<p>保存，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker commit d4bd7510bdb2 rocketmq:base</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-构建namesrv镜像-rocketmq-namesrv\"><a href=\"#3-2-构建namesrv镜像-rocketmq-namesrv\" class=\"headerlink\" title=\"3.2 构建namesrv镜像 rocketmq:namesrv\"></a>3.2 构建namesrv镜像 rocketmq:namesrv</h3><p>创建目录：/root/dockerfiles/rocketmq-namesrv,进入目录执行，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim Dockerfile</span><br><span class=\"line\"></span><br><span class=\"line\">FROM rocketmq:base</span><br><span class=\"line\"></span><br><span class=\"line\">ENV JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">ENV M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ENV ROCKETMQ_HOME=/opt/apache-rocketmq</span><br><span class=\"line\">ENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin</span><br><span class=\"line\">ENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class=\"line\"></span><br><span class=\"line\">CMD cd /opt/apache-rocketmq/ \\</span><br><span class=\"line\"> &amp;&amp; /opt/apache-rocketmq/bin/mqnamesrv -c /opt/apache-rocketmq/conf/namesrv.conf</span><br></pre></td></tr></table></figure>\n<p>在Dockerfile的目录下，执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t rocketmq:namesrv -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-3-构建broker镜像-rocketmq-broker\"><a href=\"#3-3-构建broker镜像-rocketmq-broker\" class=\"headerlink\" title=\"3.3 构建broker镜像 rocketmq:broker\"></a>3.3 构建broker镜像 rocketmq:broker</h3><p>创建目录：/root/dockerfiles/rocketmq-broker,进入目录执行，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim Dockerfile</span><br><span class=\"line\"></span><br><span class=\"line\">FROM rocketmq:base</span><br><span class=\"line\"></span><br><span class=\"line\">ENV JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">ENV M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ENV ROCKETMQ_HOME=/opt/apache-rocketmq</span><br><span class=\"line\">ENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin</span><br><span class=\"line\">ENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class=\"line\"></span><br><span class=\"line\">CMD cd /opt/apache-rocketmq/ \\</span><br><span class=\"line\"> &amp;&amp; /opt/apache-rocketmq/bin/mqbroker -c /config/broker.conf</span><br></pre></td></tr></table></figure>\n<p>在Dockerfile的目录下，执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t rocketmq:broker -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-4-启动namesrv\"><a href=\"#3-4-启动namesrv\" class=\"headerlink\" title=\"3.4 启动namesrv\"></a>3.4 启动namesrv</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 9877:9877 --name rmqnamesrv rocketmq:namesrv</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-5-启动broker\"><a href=\"#3-5-启动broker\" class=\"headerlink\" title=\"3.5 启动broker\"></a>3.5 启动broker</h3><p>创建以下配置目录：</p>\n<p>/opt/mqconfig/broker-a-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=20911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-a-s-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole= SLAVE</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=30911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-b-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=40911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-b-s-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole= SLAVE</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=50911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>启动master-a:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 20911:20911 -p 20909:20909 -v=/opt/mqconfig/broker-a-config:/config --name rmqbroker-a rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动slave-a:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 30911:30911 -p 30909:30909 -v=/opt/mqconfig/broker-a-s-config:/config --name rmqbroker-a-s rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动master-b:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 40911:40911 -p 40909:40909 -v=/opt/mqconfig/broker-b-config:/config --name rmqbroker-b rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动slave-b:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 50911:50911 -p 50909:50909 -v=/opt/mqconfig/broker-b-s-config:/config --name rmqbroker-b-s rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-6-启动console\"><a href=\"#3-6-启动console\" class=\"headerlink\" title=\"3.6 启动console\"></a>3.6 启动console</h3><p>拉取镜像：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull styletang/rocketmq-console-ng</span><br></pre></td></tr></table></figure>\n<p>启动容器，指定–link,-p</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=rmqnamesrv:9877 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" --link rmqnamesrv:rmqnamesrv -p 8080:8080 --name rmqconsole -t docker.io/styletang/rocketmq-console-ng</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-7-检查服务状态\"><a href=\"#3-7-检查服务状态\" class=\"headerlink\" title=\"3.7 检查服务状态\"></a>3.7 检查服务状态</h3><p>查看容器状态:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a</span><br></pre></td></tr></table></figure>\n<p>浏览器访问：</p>\n<p><a href=\"http://10.29.183.66:8080/\" target=\"_blank\" rel=\"noopener\">http://10.29.183.66:8080/</a></p>\n<p><img src=\"/images/rocketmq/1.png\" alt=\"1\"></p>\n<p><img src=\"/images/rocketmq/2.png\" alt=\"2\"></p>\n<p><img src=\"/images/rocketmq/3.png\" alt=\"3\"></p>\n<h2 id=\"4-docker瘦身\"><a href=\"#4-docker瘦身\" class=\"headerlink\" title=\"4.docker瘦身\"></a>4.docker瘦身</h2><p>参考网址：</p>\n<p><a href=\"http://dockone.io/article/8174\" target=\"_blank\" rel=\"noopener\">http://dockone.io/article/8174</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-基础准备\"><a href=\"#0-基础准备\" class=\"headerlink\" title=\"0.基础准备\"></a>0.基础准备</h2><p>在Docker中搭建RocketMQ集群环境。<br>","more":"</p>\n<p>jdk1.8下载地址：</p>\n<p><a href=\"https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html\" target=\"_blank\" rel=\"noopener\">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>\n<p>maven 下载地址:</p>\n<p><a href=\"http://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz\" target=\"_blank\" rel=\"noopener\">http://archive.apache.org/dist/maven/maven-3/3.5.2/binaries/apache-maven-3.5.2-bin.tar.gz</a></p>\n<p>rocketmq-4.3.2下载地址：</p>\n<p><a href=\"https://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq/archive/rocketmq-all-4.3.2.tar.gz</a></p>\n<p>rocketmq-console下载:</p>\n<p><a href=\"https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq-externals/archive/rocketmq-console-1.0.0.zip</a></p>\n<p>配置maven镜像仓库地址:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">mirrors</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">id</span>&gt;</span>alimaven<span class=\"tag\">&lt;/<span class=\"name\">id</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">name</span>&gt;</span>aliyun maven<span class=\"tag\">&lt;/<span class=\"name\">name</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">url</span>&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class=\"tag\">&lt;/<span class=\"name\">url</span>&gt;</span></span><br><span class=\"line\">          <span class=\"tag\">&lt;<span class=\"name\">mirrorOf</span>&gt;</span>central<span class=\"tag\">&lt;/<span class=\"name\">mirrorOf</span>&gt;</span>        </span><br><span class=\"line\">    <span class=\"tag\">&lt;/<span class=\"name\">mirror</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>参考资料(rocketmq集群介绍)：</p>\n<p><a href=\"https://blog.csdn.net/leexide/article/details/80035470\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leexide/article/details/80035470</a></p>\n<p><a href=\"https://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html\" target=\"_blank\" rel=\"noopener\">https://roc-wong.github.io/blog/2018/11/RocketMQ-at-a-glance.html</a></p>\n<p>关闭防火墙:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> systemctl stop firewalld</span><br></pre></td></tr></table></figure>\n<h2 id=\"1-RocketMQ-集群环境搭建\"><a href=\"#1-RocketMQ-集群环境搭建\" class=\"headerlink\" title=\"1.RocketMQ 集群环境搭建\"></a>1.RocketMQ 集群环境搭建</h2><h3 id=\"1-1-RocketMQ编译\"><a href=\"#1-1-RocketMQ编译\" class=\"headerlink\" title=\"1.1 RocketMQ编译\"></a>1.1 RocketMQ编译</h3><p>java,maven环境变量首先配置正确。</p>\n<p>然后更改本地maven的镜像仓库地址,最后进入到RocketMQ的源代码文件夹中,执行编译</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> mvn -Prelease-all -DskipTests clean install -U</span><br></pre></td></tr></table></figure>\n<p>执行完后，将 rocketmq-rocketmq-all-4.3.2/distribution/target 目录下的 apache-rocketmq 文件夹 copy 到 /opt 或应用存放的目录中。</p>\n<h3 id=\"1-2-更改默认的JVM配置\"><a href=\"#1-2-更改默认的JVM配置\" class=\"headerlink\" title=\"1.2 更改默认的JVM配置\"></a>1.2 更改默认的JVM配置</h3><p>修改namesrv的配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim bin/runserver.sh</span><br><span class=\"line\">...</span><br><span class=\"line\">JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms4g -Xmx4g -Xmn2g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\"</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<p>修改broker的配置：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim /bin/runbroker.sh</span><br><span class=\"line\">...</span><br><span class=\"line\">JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g\"</span><br><span class=\"line\">...</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-broker配置修改\"><a href=\"#1-3-broker配置修改\" class=\"headerlink\" title=\"1.3 broker配置修改\"></a>1.3 broker配置修改</h3><p>broker的配置文件在 config/broker.conf中，其中 config/2m-2s-async 为多Master多Slave模式(异步复制)集群配置，config/2m-2s-sync为多Master多Slave模式(同步双写)集群配置，config/2m-noslave 为多Master集群。每种集群模式的优缺点见参考资料。</p>\n<p>每种配置的关键配置项，如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#集群名称(相同名称的brokerName,根据brokerId来区别主从)</span><br><span class=\"line\">brokerName=broker-a|broker-b</span><br><span class=\"line\"></span><br><span class=\"line\">#0表示Master,&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker在集群的角色(和borkerId对应)</span><br><span class=\"line\">#- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\">#- SYNC_MASTER 同步双写Master</span><br><span class=\"line\">#- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"></span><br><span class=\"line\">#刷盘方式(2m-2s-async与2m-2s-sync的区别点就是这个配置)</span><br><span class=\"line\">#- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\">#- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br></pre></td></tr></table></figure>\n<p>以上内容修改完毕后，还需要添加以下配置:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Broker的IP地址</span><br><span class=\"line\">brokerIP1 = xxxxxx</span><br><span class=\"line\"></span><br><span class=\"line\"># NameServer地址列表，多个nameServer地址用分号隔开</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9876;10.29.183.81:9876;10.29.183.82:9876;10.29.183.83:9876</span><br><span class=\"line\"></span><br><span class=\"line\"># 是否自动创建Topic,若关闭，客户端在使用一个未事先创建好的Topic会报错，打开改配置则会自动创建</span><br><span class=\"line\">autoCreateTopicEnable = true</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-启动namesrv-broker\"><a href=\"#1-4-启动namesrv-broker\" class=\"headerlink\" title=\"1.4 启动namesrv,broker\"></a>1.4 启动namesrv,broker</h3><p><strong>启动namesrv：</strong></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqnamesrv &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>\n<p>查看日志:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> tail -f ~/logs/rocketmqlogs/namesrv.log</span><br></pre></td></tr></table></figure>\n<p><strong>启动broker:</strong></p>\n<p>方式一：手动指定namesrv地址:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqbroker -n localhost:9876 &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>\n<p>方式二:指定配置文件(推荐):<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> nohup sh bin/mqbroker -c conf/broker.conf &gt; /dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></p>\n<p>查看日志：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> tail -f ~/logs/rocketmqlogs/broker.log</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-5-停止namesrv-broker\"><a href=\"#1-5-停止namesrv-broker\" class=\"headerlink\" title=\"1.5 停止namesrv,broker\"></a>1.5 停止namesrv,broker</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sh bin/mqshutdown namesrv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> sh bin/mqshutdown broker</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-6-测试Producer-Consumer\"><a href=\"#1-6-测试Producer-Consumer\" class=\"headerlink\" title=\"1.6 测试Producer,Consumer\"></a>1.6 测试Producer,Consumer</h3><p>首先设置namesrv的地址</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> export NAMESRV_ADDR=localhost:9876</span><br></pre></td></tr></table></figure>\n<p>测试发送消息:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer</span><br></pre></td></tr></table></figure>\n<p>测试接受消息:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"1-7-mqadmin功能一览\"><a href=\"#1-7-mqadmin功能一览\" class=\"headerlink\" title=\"1.7 mqadmin功能一览\"></a>1.7 mqadmin功能一览</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># sh bin/mqadmin</span><br><span class=\"line\"></span><br><span class=\"line\">updateTopic          Update or create topic</span><br><span class=\"line\">deleteTopic          Delete topic from broker and NameServer.</span><br><span class=\"line\">updateSubGroup       Update or create subscription group</span><br><span class=\"line\">deleteSubGroup       Delete subscription group from broker.</span><br><span class=\"line\">updateBrokerConfig   Update broker&apos;s config</span><br><span class=\"line\">updateTopicPerm      Update topic perm</span><br><span class=\"line\">topicRoute           Examine topic route info</span><br><span class=\"line\">topicStatus          Examine topic Status info</span><br><span class=\"line\">topicClusterList     get cluster info for topic</span><br><span class=\"line\">brokerStatus         Fetch broker runtime status data</span><br><span class=\"line\">queryMsgById         Query Message by Id</span><br><span class=\"line\">queryMsgByKey        Query Message by Key</span><br><span class=\"line\">queryMsgByUniqueKey  Query Message by Unique key</span><br><span class=\"line\">queryMsgByOffset     Query Message by offset</span><br><span class=\"line\">printMsg             Print Message Detail</span><br><span class=\"line\">printMsgByQueue      Print Message Detail</span><br><span class=\"line\">sendMsgStatus        send msg to broker.</span><br><span class=\"line\">brokerConsumeStats   Fetch broker consume stats data</span><br><span class=\"line\">producerConnection   Query producer&apos;s socket connection and client version</span><br><span class=\"line\">consumerConnection   Query consumer&apos;s socket connection, client version and subscription</span><br><span class=\"line\">consumerProgress     Query consumers&apos;s progress, speed</span><br><span class=\"line\">consumerStatus       Query consumer&apos;s internal data structure</span><br><span class=\"line\">cloneGroupOffset     clone offset from other group.</span><br><span class=\"line\">clusterList          List all of clusters</span><br><span class=\"line\">topicList            Fetch all topic list from name server</span><br><span class=\"line\">updateKvConfig       Create or update KV config.</span><br><span class=\"line\">deleteKvConfig       Delete KV config.</span><br><span class=\"line\">wipeWritePerm        Wipe write perm of broker in all name server</span><br><span class=\"line\">resetOffsetByTime    Reset consumer offset by timestamp(without client restart).</span><br><span class=\"line\">updateOrderConf      Create or update or delete order conf</span><br><span class=\"line\">cleanExpiredCQ       Clean expired ConsumeQueue on broker.</span><br><span class=\"line\">cleanUnusedTopic     Clean unused topic on broker.</span><br><span class=\"line\">startMonitoring      Start Monitoring</span><br><span class=\"line\">statsAll             Topic and Consumer tps stats</span><br><span class=\"line\">allocateMQ           Allocate MQ</span><br><span class=\"line\">checkMsgSendRT       check message send response time</span><br><span class=\"line\">clusterRT            List All clusters Message Send RT</span><br><span class=\"line\">getNamesrvConfig     Get configs of name server.</span><br><span class=\"line\">updateNamesrvConfig  Update configs of name server.</span><br><span class=\"line\">getBrokerConfig      Get broker config by cluster or special broker!</span><br><span class=\"line\">queryCq              Query cq command.</span><br><span class=\"line\">sendMessage          Send a message</span><br><span class=\"line\">consumeMessage       Consume message</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-8-broker-conf主要配置\"><a href=\"#1-8-broker-conf主要配置\" class=\"headerlink\" title=\"1.8 broker.conf主要配置\"></a>1.8 broker.conf主要配置</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#===================主要配置===============</span><br><span class=\"line\"></span><br><span class=\"line\">#所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\">#broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a|broker-b</span><br><span class=\"line\"></span><br><span class=\"line\">#0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">#nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr=192.168.1.101:9876;192.168.1.102:9876</span><br><span class=\"line\"></span><br><span class=\"line\">#限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\">#flushCommitLogLeastPages=4</span><br><span class=\"line\">#flushConsumeQueueLeastPages=2</span><br><span class=\"line\">#flushCommitLogThoroughInterval=10000</span><br><span class=\"line\">#flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker 的角色</span><br><span class=\"line\">#- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\">#- SYNC_MASTER 同步双写Master</span><br><span class=\"line\">#- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\">#刷盘方式</span><br><span class=\"line\">#- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\">#- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\">#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\">#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\">#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\">#Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=10911</span><br><span class=\"line\"></span><br><span class=\"line\">#============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\">#删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\">#文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\">#commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\">#ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\">#destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\">#redeleteHangedFileInterval=120000</span><br><span class=\"line\">#检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\">#存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\">#commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\">#消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\">#消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\">#checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\">#abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br><span class=\"line\"></span><br><span class=\"line\">#===================线程池配置====================</span><br><span class=\"line\">checkTransactionMessageEnable=false</span><br><span class=\"line\">#发消息线程池数量</span><br><span class=\"line\">sendMessageThreadPoolNums=128</span><br><span class=\"line\">#拉消息线程池数量</span><br><span class=\"line\">pullMessageThreadPoolNums=128</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-Docker使用指南\"><a href=\"#2-Docker使用指南\" class=\"headerlink\" title=\"2.Docker使用指南\"></a>2.Docker使用指南</h2><h3 id=\"2-1-docker常用命令\"><a href=\"#2-1-docker常用命令\" class=\"headerlink\" title=\"2.1 docker常用命令\"></a>2.1 docker常用命令</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> yum install -y docker  //安装docker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker start  //启动docker</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker status //查看docker服务状态</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> service docker stop  //停止docker服务</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> systemctl reload docker //刷新docker配置</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a  //检查docker运行状态</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker start rocketmq  //启动容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker stop rocketmq  //停止容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rm 容器ID/Name  //删除容器</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rm `docker ps -a -q` //删除所有容器</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker images //查看本地镜像列表</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rmi 镜像名称 //删除镜像</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker rmi $(docker images -q) //删除所有镜像</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-编辑docker仓库地址\"><a href=\"#2-2-编辑docker仓库地址\" class=\"headerlink\" title=\"2.2 编辑docker仓库地址\"></a>2.2 编辑docker仓库地址</h3><p>编辑仓库地址: vim /etc/docker/daemon.json</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\"><span class=\"attr\">\"registry-mirrors\"</span>: [<span class=\"string\">\"https://registry.docker-cn.com\"</span>],</span><br><span class=\"line\"><span class=\"attr\">\"insecure-registries\"</span>:[<span class=\"string\">\"10.25.24.161:5000\"</span>,<span class=\"string\">\"10.29.139.47:5000\"</span>,<span class=\"string\">\"10.29.139.47:5001\"</span>]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>参数详细说明：<a href=\"https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options\" target=\"_blank\" rel=\"noopener\">https://docs.docker.com/engine/reference/commandline/dockerd/#daemon-user-namespace-options</a></p>\n<h3 id=\"2-3-获取基础镜像\"><a href=\"#2-3-获取基础镜像\" class=\"headerlink\" title=\"2.3 获取基础镜像\"></a>2.3 获取基础镜像</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull 10.29.139.47:5001/base/java</span><br></pre></td></tr></table></figure>\n<p>从docker hub上获取centos基础镜像</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull centos:latest</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-docker-run-启动容器\"><a href=\"#2-4-docker-run-启动容器\" class=\"headerlink\" title=\"2.4 docker run 启动容器\"></a>2.4 docker run 启动容器</h3><p>启动容器</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run ...</span><br></pre></td></tr></table></figure>\n<p>–name:容器实例名称</p>\n<p>–privileged:使用该参数，container内的root拥有真正的root权限。</p>\n<p>-td：后台运行容器（–tty，–detach）</p>\n<p>-it 创建一个交互式的容器</p>\n<p>-p 映射端口(本机的端口：映射的容器的端口)</p>\n<p>-v 挂载目录/root/software:/software(本地目录：容器目录)，在创建前容器是没有software目录的，docker 容器会自己创建</p>\n<p>–privileged=true 关闭安全权限，否则你容器操作文件夹没有权限</p>\n<blockquote>\n<p>资源限制：</p>\n</blockquote>\n<p>–ulimit memlock=-1：容器使用内存不受限制</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker容器资源限制默认：</span><br><span class=\"line\"></span><br><span class=\"line\">–default-ulimit nofile=131072 </span><br><span class=\"line\">–default-ulimit memlock=128849018880 </span><br><span class=\"line\">–default-ulimit core=-1 </span><br><span class=\"line\">–default-ulimit nproc=-1 </span><br><span class=\"line\">–default-ulimit stack=-1</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>网络设置：</p>\n</blockquote>\n<p>–net：网络指定</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker容器网络选择：</span><br><span class=\"line\"></span><br><span class=\"line\">1. host模式： docker run 使用 --net=host指定</span><br><span class=\"line\">docker使用的网络实际上和宿主机一样</span><br><span class=\"line\"></span><br><span class=\"line\">2. container模式：使用 --net=container:container_id/container_name</span><br><span class=\"line\">多个容器使用共同的网络，看到的ip是一样的。</span><br><span class=\"line\"></span><br><span class=\"line\">3. none 模式: 使用 --net=none指定</span><br><span class=\"line\">这种模式下，不会配置任何网络。</span><br><span class=\"line\"></span><br><span class=\"line\">4. bridge模式: 使用 --net=bridge指定</span><br><span class=\"line\">默认模式，不会指定。此模式会为每个容器分配一个独立的network namespace</span><br></pre></td></tr></table></figure>\n<p>使用示例:</p>\n<p>启动镜像，指定端口映射:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run --name rocketmq-tmp -p 98761:98761 --privileged --ulimit memlock=-1 --net=host -td rockemq-base1 /usr/sbin/init</span><br></pre></td></tr></table></figure>\n<p>启动一个镜像，映射目录:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -it -p 8070:8080 -v /root/software:/software --privileged=true  docker.io/centos /bin/bash</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-5-docker-exec-进入容器\"><a href=\"#2-5-docker-exec-进入容器\" class=\"headerlink\" title=\"2.5 docker exec 进入容器\"></a>2.5 docker exec 进入容器</h3><p>方式一：exec</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker exec -it kungfu-devel bash</span><br></pre></td></tr></table></figure>\n<p>方式二：attach</p>\n<p>注意：如果从这个stdin中exit，会导致容器的停止。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker attach cd24b1147c40</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker attach mycentos</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-6-docker-commit-保存镜像\"><a href=\"#2-6-docker-commit-保存镜像\" class=\"headerlink\" title=\"2.6 docker commit 保存镜像\"></a>2.6 docker commit 保存镜像</h3><p>保存镜像：<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker commit afcaf46e8305 rocketmq-cluster</span><br></pre></td></tr></table></figure></p>\n<p>查看镜像的详细信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker inspect centos-vim:afcaf46e8305</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-6-docker-push-推送镜像到远端\"><a href=\"#2-6-docker-push-推送镜像到远端\" class=\"headerlink\" title=\"2.6 docker push 推送镜像到远端\"></a>2.6 docker push 推送镜像到远端</h3><p>标记与推送：<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span> docker push 10.29.139.47:5001/jiagou_registry/centos7</span><br></pre></td></tr></table></figure></p>\n<p>需要先登录:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker login -u你的docker账号 -p你的docker密</span><br><span class=\"line\"></span><br><span class=\"line\">Login Succeeded</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-7-docker-build-从dockerfile构建镜像\"><a href=\"#2-7-docker-build-从dockerfile构建镜像\" class=\"headerlink\" title=\"2.7 docker build 从dockerfile构建镜像\"></a>2.7 docker build 从dockerfile构建镜像</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t image_name -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h2 id=\"3-使用Docker搭建RocketMQ集群\"><a href=\"#3-使用Docker搭建RocketMQ集群\" class=\"headerlink\" title=\"3.使用Docker搭建RocketMQ集群\"></a>3.使用Docker搭建RocketMQ集群</h2><h3 id=\"3-1-构建基础镜像-rocketmq-base\"><a href=\"#3-1-构建基础镜像-rocketmq-base\" class=\"headerlink\" title=\"3.1 构建基础镜像 rocketmq:base\"></a>3.1 构建基础镜像 rocketmq:base</h3><p>1.拉取基础镜像</p>\n<p>docker pull centos:latest</p>\n<p>docker tag docker.io/centos 10.29.139.47:5001/jiagou_registry/centos7</p>\n<p>docker tag 10.29.139.47:5001/jiagou_registry/centos7 centos7</p>\n<p>2.启动容器</p>\n<p>docker run –name rocketmq –privileged –ulimit memlock=-1 -v /root/soft:/data/soft –net=host -td centos7 /usr/sbin/init</p>\n<p>3.在容器中配置java,maven环境</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ROCKETMQ_HOME=/opt/apache-rocketmq</span><br></pre></td></tr></table></figure>\n<p>4.编译rocketmq代码,将编译过后的文件copy到/opt下，最终rocketmq的路径为：/opt/apache-rocketmq</p>\n<p>5.在/opt/apache-rocketmq/config/目录下,创建namesrv.conf配置文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim namesrv.conf</span><br><span class=\"line\"></span><br><span class=\"line\">listenPort=9877</span><br></pre></td></tr></table></figure>\n<p>6.修改.bashrc文件</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim ~/.bashrc</span><br><span class=\"line\">.....</span><br><span class=\"line\">if [ -f /etc/bashrc ]; then</span><br><span class=\"line\">        . /etc/bashrc</span><br><span class=\"line\">source /etc/profile</span><br><span class=\"line\">fi</span><br><span class=\"line\">....</span><br></pre></td></tr></table></figure>\n<p>7.保存镜像</p>\n<p>在centos7的容器中，执行exit方法，退出容器</p>\n<p>查看刚才容器的id</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a</span><br></pre></td></tr></table></figure>\n<p>保存，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker commit d4bd7510bdb2 rocketmq:base</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-构建namesrv镜像-rocketmq-namesrv\"><a href=\"#3-2-构建namesrv镜像-rocketmq-namesrv\" class=\"headerlink\" title=\"3.2 构建namesrv镜像 rocketmq:namesrv\"></a>3.2 构建namesrv镜像 rocketmq:namesrv</h3><p>创建目录：/root/dockerfiles/rocketmq-namesrv,进入目录执行，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim Dockerfile</span><br><span class=\"line\"></span><br><span class=\"line\">FROM rocketmq:base</span><br><span class=\"line\"></span><br><span class=\"line\">ENV JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">ENV M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ENV ROCKETMQ_HOME=/opt/apache-rocketmq</span><br><span class=\"line\">ENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin</span><br><span class=\"line\">ENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class=\"line\"></span><br><span class=\"line\">CMD cd /opt/apache-rocketmq/ \\</span><br><span class=\"line\"> &amp;&amp; /opt/apache-rocketmq/bin/mqnamesrv -c /opt/apache-rocketmq/conf/namesrv.conf</span><br></pre></td></tr></table></figure>\n<p>在Dockerfile的目录下，执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t rocketmq:namesrv -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-3-构建broker镜像-rocketmq-broker\"><a href=\"#3-3-构建broker镜像-rocketmq-broker\" class=\"headerlink\" title=\"3.3 构建broker镜像 rocketmq:broker\"></a>3.3 构建broker镜像 rocketmq:broker</h3><p>创建目录：/root/dockerfiles/rocketmq-broker,进入目录执行，</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> vim Dockerfile</span><br><span class=\"line\"></span><br><span class=\"line\">FROM rocketmq:base</span><br><span class=\"line\"></span><br><span class=\"line\">ENV JAVA_HOME=/opt/jdk1.8.0_191</span><br><span class=\"line\">ENV M2_HOME=/opt/apache-maven-3.5.2</span><br><span class=\"line\">ENV ROCKETMQ_HOME=/opt/apache-rocketmq</span><br><span class=\"line\">ENV PATH=$PATH:$JAVA_HOME/bin:$M2_HOME/bin</span><br><span class=\"line\">ENV CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class=\"line\"></span><br><span class=\"line\">CMD cd /opt/apache-rocketmq/ \\</span><br><span class=\"line\"> &amp;&amp; /opt/apache-rocketmq/bin/mqbroker -c /config/broker.conf</span><br></pre></td></tr></table></figure>\n<p>在Dockerfile的目录下，执行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker build -t rocketmq:broker -f ./Dockerfile .</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-4-启动namesrv\"><a href=\"#3-4-启动namesrv\" class=\"headerlink\" title=\"3.4 启动namesrv\"></a>3.4 启动namesrv</h3><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 9877:9877 --name rmqnamesrv rocketmq:namesrv</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-5-启动broker\"><a href=\"#3-5-启动broker\" class=\"headerlink\" title=\"3.5 启动broker\"></a>3.5 启动broker</h3><p>创建以下配置目录：</p>\n<p>/opt/mqconfig/broker-a-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=20911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-a-s-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-a</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole= SLAVE</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=30911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-b-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=0</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole=ASYNC_MASTER</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=40911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>/opt/mqconfig/broker-b-s-config/broker.conf</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim broker.conf</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>所属集群名字</span><br><span class=\"line\">brokerClusterName=rocketmq-cluster</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>broker名字，注意此处不同的配置文件填写的不一样</span><br><span class=\"line\">brokerName=broker-b</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>0表示Master，&gt;0表示Slave</span><br><span class=\"line\">brokerId=1</span><br><span class=\"line\"></span><br><span class=\"line\">brokerIP1 = 10.29.183.66</span><br><span class=\"line\"><span class=\"meta\">#</span>nameServer地址，分号分割</span><br><span class=\"line\">namesrvAddr = 10.29.183.66:9877</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>限制的消息大小</span><br><span class=\"line\">maxMessageSize=65536</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogLeastPages=4</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueLeastPages=2</span><br><span class=\"line\"><span class=\"meta\">#</span>flushCommitLogThoroughInterval=10000</span><br><span class=\"line\"><span class=\"meta\">#</span>flushConsumeQueueThoroughInterval=60000</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 的角色</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_MASTER 异步复制Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_MASTER 同步双写Master</span><br><span class=\"line\"><span class=\"meta\">#</span>- SLAVE</span><br><span class=\"line\">brokerRole= SLAVE</span><br><span class=\"line\"><span class=\"meta\">#</span>刷盘方式</span><br><span class=\"line\"><span class=\"meta\">#</span>- ASYNC_FLUSH 异步刷盘</span><br><span class=\"line\"><span class=\"meta\">#</span>- SYNC_FLUSH 同步刷盘</span><br><span class=\"line\">flushDiskType=ASYNC_FLUSH</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>在发送消息时，自动创建服务器不存在的topic，默认创建的队列数</span><br><span class=\"line\">defaultTopicQueueNums=4</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建Topic，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateTopicEnable=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭</span><br><span class=\"line\">autoCreateSubscriptionGroup=true</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>Broker 对外服务的监听端口</span><br><span class=\"line\">listenPort=50911</span><br><span class=\"line\"></span><br><span class=\"line\">============持久化配置=================</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>删除文件时间点，默认凌晨 4点</span><br><span class=\"line\">deleteWhen=04</span><br><span class=\"line\"><span class=\"meta\">#</span>文件保留时间，默认 48 小时</span><br><span class=\"line\">fileReservedTime=120</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog每个文件的大小默认1G</span><br><span class=\"line\">mapedFileSizeCommitLog=1073741824</span><br><span class=\"line\"><span class=\"meta\">#</span>ConsumeQueue每个文件默认存30W条，根据业务情况调整</span><br><span class=\"line\">mapedFileSizeConsumeQueue=300000</span><br><span class=\"line\"><span class=\"meta\">#</span>destroyMapedFileIntervalForcibly=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>redeleteHangedFileInterval=120000</span><br><span class=\"line\"><span class=\"meta\">#</span>检测物理文件磁盘空间</span><br><span class=\"line\">diskMaxUsedSpaceRatio=88</span><br><span class=\"line\"><span class=\"meta\">#</span>存储路径</span><br><span class=\"line\">storePathRootDir=/data/rocketmq/store</span><br><span class=\"line\"><span class=\"meta\">#</span>commitLog 存储路径</span><br><span class=\"line\">storePathCommitLog=/data/rocketmq/store/commitlog</span><br><span class=\"line\"><span class=\"meta\">#</span>消费队列存储路径存储路径</span><br><span class=\"line\">storePathConsumeQueue=/data/rocketmq/store/consumequeue</span><br><span class=\"line\"><span class=\"meta\">#</span>消息索引存储路径</span><br><span class=\"line\">storePathIndex=/data/rocketmq/store/index</span><br><span class=\"line\"><span class=\"meta\">#</span>checkpoint 文件存储路径</span><br><span class=\"line\">storeCheckpoint=/data/rocketmq/store/checkpoint</span><br><span class=\"line\"><span class=\"meta\">#</span>abort 文件存储路径</span><br><span class=\"line\">abortFile=/data/rocketmq/store/abort</span><br></pre></td></tr></table></figure>\n<p>启动master-a:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 20911:20911 -p 20909:20909 -v=/opt/mqconfig/broker-a-config:/config --name rmqbroker-a rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动slave-a:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 30911:30911 -p 30909:30909 -v=/opt/mqconfig/broker-a-s-config:/config --name rmqbroker-a-s rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动master-b:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 40911:40911 -p 40909:40909 -v=/opt/mqconfig/broker-b-config:/config --name rmqbroker-b rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<p>启动slave-b:<br><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -p 50911:50911 -p 50909:50909 -v=/opt/mqconfig/broker-b-s-config:/config --name rmqbroker-b-s rocketmq:broker</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"3-6-启动console\"><a href=\"#3-6-启动console\" class=\"headerlink\" title=\"3.6 启动console\"></a>3.6 启动console</h3><p>拉取镜像：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker pull styletang/rocketmq-console-ng</span><br></pre></td></tr></table></figure>\n<p>启动容器，指定–link,-p</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker run -d -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=rmqnamesrv:9877 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" --link rmqnamesrv:rmqnamesrv -p 8080:8080 --name rmqconsole -t docker.io/styletang/rocketmq-console-ng</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-7-检查服务状态\"><a href=\"#3-7-检查服务状态\" class=\"headerlink\" title=\"3.7 检查服务状态\"></a>3.7 检查服务状态</h3><p>查看容器状态:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> docker ps -a</span><br></pre></td></tr></table></figure>\n<p>浏览器访问：</p>\n<p><a href=\"http://10.29.183.66:8080/\" target=\"_blank\" rel=\"noopener\">http://10.29.183.66:8080/</a></p>\n<p><img src=\"/images/rocketmq/1.png\" alt=\"1\"></p>\n<p><img src=\"/images/rocketmq/2.png\" alt=\"2\"></p>\n<p><img src=\"/images/rocketmq/3.png\" alt=\"3\"></p>\n<h2 id=\"4-docker瘦身\"><a href=\"#4-docker瘦身\" class=\"headerlink\" title=\"4.docker瘦身\"></a>4.docker瘦身</h2><p>参考网址：</p>\n<p><a href=\"http://dockone.io/article/8174\" target=\"_blank\" rel=\"noopener\">http://dockone.io/article/8174</a></p>"},{"layout":"lay_post","title":"CSS布局(layout)三大器-display-position-float","date":"2017-04-08T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\nCSS布局常用方式有display(显示),position(定位),float(浮动)三种手段，每种手段对应的使用场景也不一样。\n<!-- more -->\n\n## 1.display属性\n\ndisplay的常用值有:inline,block,flex,grid,table。还有不显示none,以及交叉组合:inline-block,inline-flex,inline-grid,inline-table。\n\n**inline**:行内元素\n\n**block**:块元素\n\n**flex**:Flexible Box弹性布局\n\n**grid**:网格布局\n\n**table**:表格布局\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"utf-8\" />\n\t<title>test</title>\n</head>\n<body>\n\n<h2>1.块元素(block-element)</h2>\n<span>a:块级元素会独占一行,其宽度自动填满其父元素宽度。<br/></span>\n<span>b:块级元素可以设置 width,height属性,块级元素即使设置了宽度,仍然是独占一行的。<br/></span>\n<span>c:块级元素可以设置margin和padding。<br/></span>\n<span>d:block元素可以包含block元素和inline元素；但inline元素只能包含inline元素。要注意的是这个是个大概的说法，每个特定的元素能包含的元素也是特定的，所以具体到个别元素上，这条规律是不适用的。比如 P 元素，只能包含inline元素，而不能包含block元素。<br/></span>\n\n<h4>1.1 div</h4>\n<div style=\"height:80px;width:50px;border:1px solid red\"></div>\n<div style=\"height:80px;width:120px;border:1px solid blue\"></div>\n\n<h4>1.2 p</h4>\n<p style=\"height: 20px;width:200px;background-color:red\">\n\t<span>这是p标签中的span标签</span>\n</p>\n\n<h4>1.3 form</h4>\n<form style=\"border:1px solid blue\">\n\t<span>form中的span标签</span>\n</form>\n\n<h4>1.4 块元素汇总</h4>\n<span>\n* address - 地址<br/>\n* blockquote - 块引用<br/>\n* center - 举中对齐块<br/>\n* dir - 目录列表<br/>\n* div - 常用块级容易，也是css layout的主要标签<br/>\n* dl - 定义列表<br/>\n* fieldset - form控制组<br/>\n* form - 交互表单<br/>\n* h1 - 大标题<br/>\n* h2 - 副标题<br/>\n* h3 - 3级标题<br/>\n* h4 - 4级标题<br/>\n* h5 - 5级标题<br/>\n* h6 - 6级标题<br/>\n* hr - 水平分隔线<br/>\n* isindex - input prompt<br/>\n* menu - 菜单列表<br/>\n* noframes - frames可选内容，（对于不支持frame的浏览器显示此区块内容<br/>\n* noscript - ）可选脚本内容（对于不支持script的浏览器显示此内容）<br/>\n* ol - 排序表单<br/>\n* p - 段落<br/>\n* pre - 格式化文本<br/>\n* table - 表格<br/>\n* ul - 非排序列表<br/>\n</span>\n\n<h2>2.行内元素(inline-element)</h2>\n<span>a:行内元素不会独占一行,相邻的行内元素会排列在同一行里,直到一行排不下,才会换行,其宽度随元素的内容而变化。<br/></span>\n<span>b:行内元素设置width,height无效。<br/></span>\n<span>c:行内元素的水平方向的padding-left,padding-right,margin-left,margin-right 都产生边距效果，但是竖直方向的padding-top,padding-bottom,margin-top,margin-bottom都不会产生边距效果。<br/></span>\n\n<h4>2.1 input</h4>\n<input type=\"button\" value=\"button1\" />\n<input type=\"button\" value=\"button2\" />\n\n<h4>2.2 label</h4>\n<label>label1</label>\n<label>label2</label>\n<label>label3</label>\n\n<h4>2.3 select</h4>\n<select>\n\t<option>sele1</option>\n\t<option>sele2</option>\n\t<option selected=\"true\">sele3</option>\n\t<option>sele4</option>\n\t<option>sele5</option>\n</select>\n<select>\n\t<option>水果1</option>\n\t<option selected=\"true\">水果2</option>\n\t<option>水果3</option>\n\t<option>水果4</option>\n\t<option>水果5</option>\n</select>\n\n<h4>2.4 行内元素汇总</h4>\n<span>\n* a - 锚点<br/>\n* abbr - 缩写<br/>\n* acronym - 首字<br/>\n* b - 粗体(不推荐)<br/>\n* bdo - bidi override<br/>\n* big - 大字体<br/>\n* br - 换行<br/>\n* cite - 引用<br/>\n* code - 计算机代码(在引用源码的时候需要)<br/>\n* dfn - 定义字段<br/>\n* em - 强调<br/>\n* font - 字体设定(不推荐)<br/>\n* i - 斜体<br/>\n* img - 图片<br/>\n* input - 输入框<br/>\n* kbd - 定义键盘文本<br/>\n* label - 表格标签<br/>\n* q - 短引用<br/>\n* s - 中划线(不推荐)<br/>\n* samp - 定义范例计算机代码<br/>\n* select - 项目选择<br/>\n* small - 小字体文本<br/>\n* span - 常用内联容器，定义文本内区块<br/>\n* strike - 中划线<br/>\n* strong - 粗体强调<br/>\n* sub - 下标<br/>\n* sup - 上标<br/>\n* textarea - 多行文本输入框<br/>\n* tt - 电传文本<br/>\n* u - 下划线<br/>\n* var - 定义变量<br/>\n</span>\n\n<h2>3.inlinke-block</h2>\n<span>简单来说就是将对象呈现为inline对象，但是对象的内容作为block对象呈现。之后的内联对象会被排列在同一行内。比如我们可以给一个link（a元素）inline-block属性值，使其既具有block的宽度高度特性又具有inline的同行特性</span>\n\n<h2>4.可变元素</h2>\n<span>4.1可变元素为根据上下文语境决定该元素为块元素或者内联元素。<br/></span>\n<span>\n<br/>\n* applet - java applet<br/>\n* button - 按钮<br/>\n* del - 删除文本<br/>\n* iframe - inline frame<br/>\n* ins - 插入的文本<br/>\n* map - 图片区块(map)<br/>\n* object - object对象<br/>\n* script - 客户端脚本<br/>\n</span>\n\n<h2>5.布局设置display</h2>\n<span>一般来说，可以通过display:inline和display:block的设置，改变元素的布局级别。display可以设置的参数不止以上三种，只是比较常用而已。</span>\n\n</body>\n</html>\n\n```\n\n## 2.position属性\n\nposition属性的值有:absolute(绝对布局),relative(相对布局),fixed(固定布局),static(默认布局),inherit(继承父标签position属性值)\n\n和position搭配使用的属性有:left,right,top,bottom和层次属性z-index.\n\n## 3.float属性\n\nfloat属性的值有:left,right,none(默认值,不浮动),inherit(继承父标签float属性值)\n\n","source":"_posts/2017-04-09-CSS布局(layout)三大器-display-position-float.md","raw":"---\nlayout: lay_post\ntitle: \"CSS布局(layout)三大器-display-position-float\"\ndate: 2017-04-09\ncategories: CSS布局\ntags: WEB技术\nauthor: lvyafei\n---\n\n## 0.概述\n\nCSS布局常用方式有display(显示),position(定位),float(浮动)三种手段，每种手段对应的使用场景也不一样。\n<!-- more -->\n\n## 1.display属性\n\ndisplay的常用值有:inline,block,flex,grid,table。还有不显示none,以及交叉组合:inline-block,inline-flex,inline-grid,inline-table。\n\n**inline**:行内元素\n\n**block**:块元素\n\n**flex**:Flexible Box弹性布局\n\n**grid**:网格布局\n\n**table**:表格布局\n\n```html\n\n<!DOCTYPE html>\n<html>\n<head>\n    <meta charset=\"utf-8\" />\n\t<title>test</title>\n</head>\n<body>\n\n<h2>1.块元素(block-element)</h2>\n<span>a:块级元素会独占一行,其宽度自动填满其父元素宽度。<br/></span>\n<span>b:块级元素可以设置 width,height属性,块级元素即使设置了宽度,仍然是独占一行的。<br/></span>\n<span>c:块级元素可以设置margin和padding。<br/></span>\n<span>d:block元素可以包含block元素和inline元素；但inline元素只能包含inline元素。要注意的是这个是个大概的说法，每个特定的元素能包含的元素也是特定的，所以具体到个别元素上，这条规律是不适用的。比如 P 元素，只能包含inline元素，而不能包含block元素。<br/></span>\n\n<h4>1.1 div</h4>\n<div style=\"height:80px;width:50px;border:1px solid red\"></div>\n<div style=\"height:80px;width:120px;border:1px solid blue\"></div>\n\n<h4>1.2 p</h4>\n<p style=\"height: 20px;width:200px;background-color:red\">\n\t<span>这是p标签中的span标签</span>\n</p>\n\n<h4>1.3 form</h4>\n<form style=\"border:1px solid blue\">\n\t<span>form中的span标签</span>\n</form>\n\n<h4>1.4 块元素汇总</h4>\n<span>\n* address - 地址<br/>\n* blockquote - 块引用<br/>\n* center - 举中对齐块<br/>\n* dir - 目录列表<br/>\n* div - 常用块级容易，也是css layout的主要标签<br/>\n* dl - 定义列表<br/>\n* fieldset - form控制组<br/>\n* form - 交互表单<br/>\n* h1 - 大标题<br/>\n* h2 - 副标题<br/>\n* h3 - 3级标题<br/>\n* h4 - 4级标题<br/>\n* h5 - 5级标题<br/>\n* h6 - 6级标题<br/>\n* hr - 水平分隔线<br/>\n* isindex - input prompt<br/>\n* menu - 菜单列表<br/>\n* noframes - frames可选内容，（对于不支持frame的浏览器显示此区块内容<br/>\n* noscript - ）可选脚本内容（对于不支持script的浏览器显示此内容）<br/>\n* ol - 排序表单<br/>\n* p - 段落<br/>\n* pre - 格式化文本<br/>\n* table - 表格<br/>\n* ul - 非排序列表<br/>\n</span>\n\n<h2>2.行内元素(inline-element)</h2>\n<span>a:行内元素不会独占一行,相邻的行内元素会排列在同一行里,直到一行排不下,才会换行,其宽度随元素的内容而变化。<br/></span>\n<span>b:行内元素设置width,height无效。<br/></span>\n<span>c:行内元素的水平方向的padding-left,padding-right,margin-left,margin-right 都产生边距效果，但是竖直方向的padding-top,padding-bottom,margin-top,margin-bottom都不会产生边距效果。<br/></span>\n\n<h4>2.1 input</h4>\n<input type=\"button\" value=\"button1\" />\n<input type=\"button\" value=\"button2\" />\n\n<h4>2.2 label</h4>\n<label>label1</label>\n<label>label2</label>\n<label>label3</label>\n\n<h4>2.3 select</h4>\n<select>\n\t<option>sele1</option>\n\t<option>sele2</option>\n\t<option selected=\"true\">sele3</option>\n\t<option>sele4</option>\n\t<option>sele5</option>\n</select>\n<select>\n\t<option>水果1</option>\n\t<option selected=\"true\">水果2</option>\n\t<option>水果3</option>\n\t<option>水果4</option>\n\t<option>水果5</option>\n</select>\n\n<h4>2.4 行内元素汇总</h4>\n<span>\n* a - 锚点<br/>\n* abbr - 缩写<br/>\n* acronym - 首字<br/>\n* b - 粗体(不推荐)<br/>\n* bdo - bidi override<br/>\n* big - 大字体<br/>\n* br - 换行<br/>\n* cite - 引用<br/>\n* code - 计算机代码(在引用源码的时候需要)<br/>\n* dfn - 定义字段<br/>\n* em - 强调<br/>\n* font - 字体设定(不推荐)<br/>\n* i - 斜体<br/>\n* img - 图片<br/>\n* input - 输入框<br/>\n* kbd - 定义键盘文本<br/>\n* label - 表格标签<br/>\n* q - 短引用<br/>\n* s - 中划线(不推荐)<br/>\n* samp - 定义范例计算机代码<br/>\n* select - 项目选择<br/>\n* small - 小字体文本<br/>\n* span - 常用内联容器，定义文本内区块<br/>\n* strike - 中划线<br/>\n* strong - 粗体强调<br/>\n* sub - 下标<br/>\n* sup - 上标<br/>\n* textarea - 多行文本输入框<br/>\n* tt - 电传文本<br/>\n* u - 下划线<br/>\n* var - 定义变量<br/>\n</span>\n\n<h2>3.inlinke-block</h2>\n<span>简单来说就是将对象呈现为inline对象，但是对象的内容作为block对象呈现。之后的内联对象会被排列在同一行内。比如我们可以给一个link（a元素）inline-block属性值，使其既具有block的宽度高度特性又具有inline的同行特性</span>\n\n<h2>4.可变元素</h2>\n<span>4.1可变元素为根据上下文语境决定该元素为块元素或者内联元素。<br/></span>\n<span>\n<br/>\n* applet - java applet<br/>\n* button - 按钮<br/>\n* del - 删除文本<br/>\n* iframe - inline frame<br/>\n* ins - 插入的文本<br/>\n* map - 图片区块(map)<br/>\n* object - object对象<br/>\n* script - 客户端脚本<br/>\n</span>\n\n<h2>5.布局设置display</h2>\n<span>一般来说，可以通过display:inline和display:block的设置，改变元素的布局级别。display可以设置的参数不止以上三种，只是比较常用而已。</span>\n\n</body>\n</html>\n\n```\n\n## 2.position属性\n\nposition属性的值有:absolute(绝对布局),relative(相对布局),fixed(固定布局),static(默认布局),inherit(继承父标签position属性值)\n\n和position搭配使用的属性有:left,right,top,bottom和层次属性z-index.\n\n## 3.float属性\n\nfloat属性的值有:left,right,none(默认值,不浮动),inherit(继承父标签float属性值)\n\n","slug":"2017-04-09-CSS布局(layout)三大器-display-position-float","published":1,"updated":"2018-12-01T08:24:08.230Z","comments":1,"photos":[],"link":"","_id":"cjskffoe7005o4glmug81m8lz","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>CSS布局常用方式有display(显示),position(定位),float(浮动)三种手段，每种手段对应的使用场景也不一样。<br><a id=\"more\"></a></p>\n<h2 id=\"1-display属性\"><a href=\"#1-display属性\" class=\"headerlink\" title=\"1.display属性\"></a>1.display属性</h2><p>display的常用值有:inline,block,flex,grid,table。还有不显示none,以及交叉组合:inline-block,inline-flex,inline-grid,inline-table。</p>\n<p><strong>inline</strong>:行内元素</p>\n<p><strong>block</strong>:块元素</p>\n<p><strong>flex</strong>:Flexible Box弹性布局</p>\n<p><strong>grid</strong>:网格布局</p>\n<p><strong>table</strong>:表格布局</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"utf-8\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>1.块元素(block-element)<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>a:块级元素会独占一行,其宽度自动填满其父元素宽度。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>b:块级元素可以设置 width,height属性,块级元素即使设置了宽度,仍然是独占一行的。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>c:块级元素可以设置margin和padding。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>d:block元素可以包含block元素和inline元素；但inline元素只能包含inline元素。要注意的是这个是个大概的说法，每个特定的元素能包含的元素也是特定的，所以具体到个别元素上，这条规律是不适用的。比如 P 元素，只能包含inline元素，而不能包含block元素。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.1 div<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height:80px;width:50px;border:1px solid red\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height:80px;width:120px;border:1px solid blue\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.2 p<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height: 20px;width:200px;background-color:red\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>这是p标签中的span标签<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.3 form<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">style</span>=<span class=\"string\">\"border:1px solid blue\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>form中的span标签<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.4 块元素汇总<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\">* address - 地址<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* blockquote - 块引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* center - 举中对齐块<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dir - 目录列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* div - 常用块级容易，也是css layout的主要标签<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dl - 定义列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* fieldset - form控制组<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* form - 交互表单<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h1 - 大标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h2 - 副标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h3 - 3级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h4 - 4级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h5 - 5级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h6 - 6级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* hr - 水平分隔线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* isindex - input prompt<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* menu - 菜单列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* noframes - frames可选内容，（对于不支持frame的浏览器显示此区块内容<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* noscript - ）可选脚本内容（对于不支持script的浏览器显示此内容）<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ol - 排序表单<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* p - 段落<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* pre - 格式化文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* table - 表格<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ul - 非排序列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>2.行内元素(inline-element)<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>a:行内元素不会独占一行,相邻的行内元素会排列在同一行里,直到一行排不下,才会换行,其宽度随元素的内容而变化。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>b:行内元素设置width,height无效。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>c:行内元素的水平方向的padding-left,padding-right,margin-left,margin-right 都产生边距效果，但是竖直方向的padding-top,padding-bottom,margin-top,margin-bottom都不会产生边距效果。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.1 input<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"button1\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"button2\"</span> /&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.2 label<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label1<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label2<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label3<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.3 select<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele1<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele2<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">selected</span>=<span class=\"string\">\"true\"</span>&gt;</span>sele3<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele4<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele5<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果1<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">selected</span>=<span class=\"string\">\"true\"</span>&gt;</span>水果2<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果3<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果4<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果5<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.4 行内元素汇总<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\">* a - 锚点<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* abbr - 缩写<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* acronym - 首字<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* b - 粗体(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* bdo - bidi override<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* big - 大字体<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* br - 换行<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* cite - 引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* code - 计算机代码(在引用源码的时候需要)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dfn - 定义字段<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* em - 强调<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* font - 字体设定(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* i - 斜体<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* img - 图片<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* input - 输入框<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* kbd - 定义键盘文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* label - 表格标签<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* q - 短引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* s - 中划线(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* samp - 定义范例计算机代码<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* select - 项目选择<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* small - 小字体文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* span - 常用内联容器，定义文本内区块<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* strike - 中划线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* strong - 粗体强调<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* sub - 下标<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* sup - 上标<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* textarea - 多行文本输入框<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* tt - 电传文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* u - 下划线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* var - 定义变量<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>3.inlinke-block<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>简单来说就是将对象呈现为inline对象，但是对象的内容作为block对象呈现。之后的内联对象会被排列在同一行内。比如我们可以给一个link（a元素）inline-block属性值，使其既具有block的宽度高度特性又具有inline的同行特性<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>4.可变元素<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>4.1可变元素为根据上下文语境决定该元素为块元素或者内联元素。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* applet - java applet<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* button - 按钮<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* del - 删除文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* iframe - inline frame<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ins - 插入的文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* map - 图片区块(map)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* object - object对象<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* script - 客户端脚本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>5.布局设置display<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>一般来说，可以通过display:inline和display:block的设置，改变元素的布局级别。display可以设置的参数不止以上三种，只是比较常用而已。<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-position属性\"><a href=\"#2-position属性\" class=\"headerlink\" title=\"2.position属性\"></a>2.position属性</h2><p>position属性的值有:absolute(绝对布局),relative(相对布局),fixed(固定布局),static(默认布局),inherit(继承父标签position属性值)</p>\n<p>和position搭配使用的属性有:left,right,top,bottom和层次属性z-index.</p>\n<h2 id=\"3-float属性\"><a href=\"#3-float属性\" class=\"headerlink\" title=\"3.float属性\"></a>3.float属性</h2><p>float属性的值有:left,right,none(默认值,不浮动),inherit(继承父标签float属性值)</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>CSS布局常用方式有display(显示),position(定位),float(浮动)三种手段，每种手段对应的使用场景也不一样。<br>","more":"</p>\n<h2 id=\"1-display属性\"><a href=\"#1-display属性\" class=\"headerlink\" title=\"1.display属性\"></a>1.display属性</h2><p>display的常用值有:inline,block,flex,grid,table。还有不显示none,以及交叉组合:inline-block,inline-flex,inline-grid,inline-table。</p>\n<p><strong>inline</strong>:行内元素</p>\n<p><strong>block</strong>:块元素</p>\n<p><strong>flex</strong>:Flexible Box弹性布局</p>\n<p><strong>grid</strong>:网格布局</p>\n<p><strong>table</strong>:表格布局</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">    <span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"utf-8\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>1.块元素(block-element)<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>a:块级元素会独占一行,其宽度自动填满其父元素宽度。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>b:块级元素可以设置 width,height属性,块级元素即使设置了宽度,仍然是独占一行的。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>c:块级元素可以设置margin和padding。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>d:block元素可以包含block元素和inline元素；但inline元素只能包含inline元素。要注意的是这个是个大概的说法，每个特定的元素能包含的元素也是特定的，所以具体到个别元素上，这条规律是不适用的。比如 P 元素，只能包含inline元素，而不能包含block元素。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.1 div<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height:80px;width:50px;border:1px solid red\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height:80px;width:120px;border:1px solid blue\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.2 p<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">p</span> <span class=\"attr\">style</span>=<span class=\"string\">\"height: 20px;width:200px;background-color:red\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>这是p标签中的span标签<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">p</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.3 form<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">form</span> <span class=\"attr\">style</span>=<span class=\"string\">\"border:1px solid blue\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>form中的span标签<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">form</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>1.4 块元素汇总<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\">* address - 地址<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* blockquote - 块引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* center - 举中对齐块<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dir - 目录列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* div - 常用块级容易，也是css layout的主要标签<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dl - 定义列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* fieldset - form控制组<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* form - 交互表单<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h1 - 大标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h2 - 副标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h3 - 3级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h4 - 4级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h5 - 5级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* h6 - 6级标题<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* hr - 水平分隔线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* isindex - input prompt<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* menu - 菜单列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* noframes - frames可选内容，（对于不支持frame的浏览器显示此区块内容<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* noscript - ）可选脚本内容（对于不支持script的浏览器显示此内容）<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ol - 排序表单<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* p - 段落<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* pre - 格式化文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* table - 表格<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ul - 非排序列表<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>2.行内元素(inline-element)<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>a:行内元素不会独占一行,相邻的行内元素会排列在同一行里,直到一行排不下,才会换行,其宽度随元素的内容而变化。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>b:行内元素设置width,height无效。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>c:行内元素的水平方向的padding-left,padding-right,margin-left,margin-right 都产生边距效果，但是竖直方向的padding-top,padding-bottom,margin-top,margin-bottom都不会产生边距效果。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.1 input<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"button1\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">input</span> <span class=\"attr\">type</span>=<span class=\"string\">\"button\"</span> <span class=\"attr\">value</span>=<span class=\"string\">\"button2\"</span> /&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.2 label<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label1<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label2<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">label</span>&gt;</span>label3<span class=\"tag\">&lt;/<span class=\"name\">label</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.3 select<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele1<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele2<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">selected</span>=<span class=\"string\">\"true\"</span>&gt;</span>sele3<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele4<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>sele5<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果1<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span> <span class=\"attr\">selected</span>=<span class=\"string\">\"true\"</span>&gt;</span>水果2<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果3<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果4<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">option</span>&gt;</span>水果5<span class=\"tag\">&lt;/<span class=\"name\">option</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">select</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h4</span>&gt;</span>2.4 行内元素汇总<span class=\"tag\">&lt;/<span class=\"name\">h4</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\">* a - 锚点<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* abbr - 缩写<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* acronym - 首字<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* b - 粗体(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* bdo - bidi override<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* big - 大字体<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* br - 换行<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* cite - 引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* code - 计算机代码(在引用源码的时候需要)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* dfn - 定义字段<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* em - 强调<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* font - 字体设定(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* i - 斜体<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* img - 图片<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* input - 输入框<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* kbd - 定义键盘文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* label - 表格标签<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* q - 短引用<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* s - 中划线(不推荐)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* samp - 定义范例计算机代码<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* select - 项目选择<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* small - 小字体文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* span - 常用内联容器，定义文本内区块<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* strike - 中划线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* strong - 粗体强调<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* sub - 下标<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* sup - 上标<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* textarea - 多行文本输入框<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* tt - 电传文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* u - 下划线<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* var - 定义变量<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>3.inlinke-block<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>简单来说就是将对象呈现为inline对象，但是对象的内容作为block对象呈现。之后的内联对象会被排列在同一行内。比如我们可以给一个link（a元素）inline-block属性值，使其既具有block的宽度高度特性又具有inline的同行特性<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>4.可变元素<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>4.1可变元素为根据上下文语境决定该元素为块元素或者内联元素。<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* applet - java applet<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* button - 按钮<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* del - 删除文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* iframe - inline frame<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* ins - 插入的文本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* map - 图片区块(map)<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* object - object对象<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\">* script - 客户端脚本<span class=\"tag\">&lt;<span class=\"name\">br</span>/&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">h2</span>&gt;</span>5.布局设置display<span class=\"tag\">&lt;/<span class=\"name\">h2</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">span</span>&gt;</span>一般来说，可以通过display:inline和display:block的设置，改变元素的布局级别。display可以设置的参数不止以上三种，只是比较常用而已。<span class=\"tag\">&lt;/<span class=\"name\">span</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"2-position属性\"><a href=\"#2-position属性\" class=\"headerlink\" title=\"2.position属性\"></a>2.position属性</h2><p>position属性的值有:absolute(绝对布局),relative(相对布局),fixed(固定布局),static(默认布局),inherit(继承父标签position属性值)</p>\n<p>和position搭配使用的属性有:left,right,top,bottom和层次属性z-index.</p>\n<h2 id=\"3-float属性\"><a href=\"#3-float属性\" class=\"headerlink\" title=\"3.float属性\"></a>3.float属性</h2><p>float属性的值有:left,right,none(默认值,不浮动),inherit(继承父标签float属性值)</p>"},{"layout":"lay_post","title":"JWT-基于Token的身份验证","date":"2017-02-19T16:00:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n对Token有过使用和了解，但都没有一个系统的学习，从网上看到一篇文章简单并全面的介绍了下Token，特此摘录了下。\n<!-- more -->\n\n## 1.背景\n\n很多大型网站也都在用，比如 Facebook，Twitter，Google+，Github 等等，比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。Token 的中文有人翻译成 “令牌”，我觉得挺好，意思就是，你拿着这个令牌，才能过一些关卡。\n\n## 2.传统身份验证的方法\n\nHTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。\n\n解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。\n\n上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。\n\n## 3.基于 Token 的身份验证方法\n\n使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：\n\n1.客户端使用用户名跟密码请求登录\n\n2.服务端收到请求，去验证用户名与密码\n\n3.验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端\n\n4.客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里\n\n5.客户端每次向服务端请求资源的时候需要带着服务端签发的 Token\n\n6.服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据\n\n## 4.JWT\n\n实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：\n\n**header**\n\n**payload**\n\n**signature**\n\n中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n>Header\n\nheader 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。\n\n`\n{\n  \"typ\": \"JWT\",\n  \"alg\": \"HS256\"\n}\n`\n\n上面的内容要用 Base64 的形式编码一下，所以就变成这样：\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\n`\n\n>Payload\n\nPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：\n\niss：Issuer，发行者\n\nsub：Subject，主题\n\naud：Audience，观众\n\nexp：Expiration time，过期时间\n\nnbf：Not before\n\niat：Issued at，发行时间\n\njti：JWT ID\n\n比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。\n\n`\n{\n \"iss\": \"ninghao.net\",\n \"exp\": \"1438955445\",\n \"name\": \"wanghao\",\n \"admin\": true\n}\n`\n\n使用 Base64 编码以后就变成了这个样子：\n\n`\neyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ\n`\n\n>Signature\n\nJWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。\n\nheader\n\npayload\n\nsecret\n\n`\nvar encodedString = base64UrlEncode(header) + \".\" + base64UrlEncode(payload); \nHMACSHA256(encodedString, 'secret');\n`\n\n处理完成以后看起来像这样：\n\n`\nSwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。\n\n## 5.相关链接\n\nhttp://jwt.io/\n\nhttps://github.com/firebase/php-jwt\n\nhttps://scotch.io/tutorials/the-anatomy-of-a-json-web-token\n\nhttps://github.com/auth0/jwt-decode\n\nhttps://ninghao.net/blog/2834","source":"_posts/2017-02-20-JWT-基于Token的身份验证.md","raw":"---\nlayout: lay_post\ntitle: \"JWT-基于Token的身份验证\"\ndate: 2017-02-20\ncategories: Token详解\ntags: WEB技术\nauthor: lvyafei\n---\n\n## 0.概述\n\n对Token有过使用和了解，但都没有一个系统的学习，从网上看到一篇文章简单并全面的介绍了下Token，特此摘录了下。\n<!-- more -->\n\n## 1.背景\n\n很多大型网站也都在用，比如 Facebook，Twitter，Google+，Github 等等，比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。Token 的中文有人翻译成 “令牌”，我觉得挺好，意思就是，你拿着这个令牌，才能过一些关卡。\n\n## 2.传统身份验证的方法\n\nHTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。\n\n解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。\n\n上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。\n\n## 3.基于 Token 的身份验证方法\n\n使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：\n\n1.客户端使用用户名跟密码请求登录\n\n2.服务端收到请求，去验证用户名与密码\n\n3.验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端\n\n4.客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里\n\n5.客户端每次向服务端请求资源的时候需要带着服务端签发的 Token\n\n6.服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据\n\n## 4.JWT\n\n实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：\n\n**header**\n\n**payload**\n\n**signature**\n\n中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n>Header\n\nheader 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。\n\n`\n{\n  \"typ\": \"JWT\",\n  \"alg\": \"HS256\"\n}\n`\n\n上面的内容要用 Base64 的形式编码一下，所以就变成这样：\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\n`\n\n>Payload\n\nPayload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：\n\niss：Issuer，发行者\n\nsub：Subject，主题\n\naud：Audience，观众\n\nexp：Expiration time，过期时间\n\nnbf：Not before\n\niat：Issued at，发行时间\n\njti：JWT ID\n\n比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。\n\n`\n{\n \"iss\": \"ninghao.net\",\n \"exp\": \"1438955445\",\n \"name\": \"wanghao\",\n \"admin\": true\n}\n`\n\n使用 Base64 编码以后就变成了这个样子：\n\n`\neyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ\n`\n\n>Signature\n\nJWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。\n\nheader\n\npayload\n\nsecret\n\n`\nvar encodedString = base64UrlEncode(header) + \".\" + base64UrlEncode(payload); \nHMACSHA256(encodedString, 'secret');\n`\n\n处理完成以后看起来像这样：\n\n`\nSwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：\n\n`\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc\n`\n\n客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。\n\n## 5.相关链接\n\nhttp://jwt.io/\n\nhttps://github.com/firebase/php-jwt\n\nhttps://scotch.io/tutorials/the-anatomy-of-a-json-web-token\n\nhttps://github.com/auth0/jwt-decode\n\nhttps://ninghao.net/blog/2834","slug":"2017-02-20-JWT-基于Token的身份验证","published":1,"updated":"2018-12-01T08:24:08.223Z","comments":1,"photos":[],"link":"","_id":"cjskffoen005s4glm4whqaqcz","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对Token有过使用和了解，但都没有一个系统的学习，从网上看到一篇文章简单并全面的介绍了下Token，特此摘录了下。<br><a id=\"more\"></a></p>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1.背景\"></a>1.背景</h2><p>很多大型网站也都在用，比如 Facebook，Twitter，Google+，Github 等等，比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。Token 的中文有人翻译成 “令牌”，我觉得挺好，意思就是，你拿着这个令牌，才能过一些关卡。</p>\n<h2 id=\"2-传统身份验证的方法\"><a href=\"#2-传统身份验证的方法\" class=\"headerlink\" title=\"2.传统身份验证的方法\"></a>2.传统身份验证的方法</h2><p>HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。</p>\n<p>解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。</p>\n<p>上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。</p>\n<h2 id=\"3-基于-Token-的身份验证方法\"><a href=\"#3-基于-Token-的身份验证方法\" class=\"headerlink\" title=\"3.基于 Token 的身份验证方法\"></a>3.基于 Token 的身份验证方法</h2><p>使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：</p>\n<p>1.客户端使用用户名跟密码请求登录</p>\n<p>2.服务端收到请求，去验证用户名与密码</p>\n<p>3.验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端</p>\n<p>4.客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里</p>\n<p>5.客户端每次向服务端请求资源的时候需要带着服务端签发的 Token</p>\n<p>6.服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据</p>\n<h2 id=\"4-JWT\"><a href=\"#4-JWT\" class=\"headerlink\" title=\"4.JWT\"></a>4.JWT</h2><p>实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：</p>\n<p><strong>header</strong></p>\n<p><strong>payload</strong></p>\n<p><strong>signature</strong></p>\n<p>中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<blockquote>\n<p>Header</p>\n</blockquote>\n<p>header 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。</p>\n<p><code>{\n  &quot;typ&quot;: &quot;JWT&quot;,\n  &quot;alg&quot;: &quot;HS256&quot;\n}</code></p>\n<p>上面的内容要用 Base64 的形式编码一下，所以就变成这样：</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</code></p>\n<blockquote>\n<p>Payload</p>\n</blockquote>\n<p>Payload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：</p>\n<p>iss：Issuer，发行者</p>\n<p>sub：Subject，主题</p>\n<p>aud：Audience，观众</p>\n<p>exp：Expiration time，过期时间</p>\n<p>nbf：Not before</p>\n<p>iat：Issued at，发行时间</p>\n<p>jti：JWT ID</p>\n<p>比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。</p>\n<p><code>{\n &quot;iss&quot;: &quot;ninghao.net&quot;,\n &quot;exp&quot;: &quot;1438955445&quot;,\n &quot;name&quot;: &quot;wanghao&quot;,\n &quot;admin&quot;: true\n}</code></p>\n<p>使用 Base64 编码以后就变成了这个样子：</p>\n<p><code>eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ</code></p>\n<blockquote>\n<p>Signature</p>\n</blockquote>\n<p>JWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。</p>\n<p>header</p>\n<p>payload</p>\n<p>secret</p>\n<p><code>var encodedString = base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload); \nHMACSHA256(encodedString, &#39;secret&#39;);</code></p>\n<p>处理完成以后看起来像这样：</p>\n<p><code>SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<p>最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<p>客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。</p>\n<h2 id=\"5-相关链接\"><a href=\"#5-相关链接\" class=\"headerlink\" title=\"5.相关链接\"></a>5.相关链接</h2><p><a href=\"http://jwt.io/\" target=\"_blank\" rel=\"noopener\">http://jwt.io/</a></p>\n<p><a href=\"https://github.com/firebase/php-jwt\" target=\"_blank\" rel=\"noopener\">https://github.com/firebase/php-jwt</a></p>\n<p><a href=\"https://scotch.io/tutorials/the-anatomy-of-a-json-web-token\" target=\"_blank\" rel=\"noopener\">https://scotch.io/tutorials/the-anatomy-of-a-json-web-token</a></p>\n<p><a href=\"https://github.com/auth0/jwt-decode\" target=\"_blank\" rel=\"noopener\">https://github.com/auth0/jwt-decode</a></p>\n<p><a href=\"https://ninghao.net/blog/2834\" target=\"_blank\" rel=\"noopener\">https://ninghao.net/blog/2834</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>对Token有过使用和了解，但都没有一个系统的学习，从网上看到一篇文章简单并全面的介绍了下Token，特此摘录了下。<br>","more":"</p>\n<h2 id=\"1-背景\"><a href=\"#1-背景\" class=\"headerlink\" title=\"1.背景\"></a>1.背景</h2><p>很多大型网站也都在用，比如 Facebook，Twitter，Google+，Github 等等，比起传统的身份验证方法，Token 扩展性更强，也更安全点，非常适合用在 Web 应用或者移动应用上。Token 的中文有人翻译成 “令牌”，我觉得挺好，意思就是，你拿着这个令牌，才能过一些关卡。</p>\n<h2 id=\"2-传统身份验证的方法\"><a href=\"#2-传统身份验证的方法\" class=\"headerlink\" title=\"2.传统身份验证的方法\"></a>2.传统身份验证的方法</h2><p>HTTP 是一种没有状态的协议，也就是它并不知道是谁是访问应用。这里我们把用户看成是客户端，客户端使用用户名还有密码通过了身份验证，不过下回这个客户端再发送请求时候，还得再验证一下。</p>\n<p>解决的方法就是，当用户请求登录的时候，如果没有问题，我们在服务端生成一条记录，这个记录里可以说明一下登录的用户是谁，然后把这条记录的 ID 号发送给客户端，客户端收到以后把这个 ID 号存储在 Cookie 里，下次这个用户再向服务端发送请求的时候，可以带着这个 Cookie ，这样服务端会验证一个这个 Cookie 里的信息，看看能不能在服务端这里找到对应的记录，如果可以，说明用户已经通过了身份验证，就把用户请求的数据返回给客户端。</p>\n<p>上面说的就是 Session，我们需要在服务端存储为登录的用户生成的 Session ，这些 Session 可能会存储在内存，磁盘，或者数据库里。我们可能需要在服务端定期的去清理过期的 Session 。</p>\n<h2 id=\"3-基于-Token-的身份验证方法\"><a href=\"#3-基于-Token-的身份验证方法\" class=\"headerlink\" title=\"3.基于 Token 的身份验证方法\"></a>3.基于 Token 的身份验证方法</h2><p>使用基于 Token 的身份验证方法，在服务端不需要存储用户的登录记录。大概的流程是这样的：</p>\n<p>1.客户端使用用户名跟密码请求登录</p>\n<p>2.服务端收到请求，去验证用户名与密码</p>\n<p>3.验证成功后，服务端会签发一个 Token，再把这个 Token 发送给客户端</p>\n<p>4.客户端收到 Token 以后可以把它存储起来，比如放在 Cookie 里或者 Local Storage 里</p>\n<p>5.客户端每次向服务端请求资源的时候需要带着服务端签发的 Token</p>\n<p>6.服务端收到请求，然后去验证客户端请求里面带着的 Token，如果验证成功，就向客户端返回请求的数据</p>\n<h2 id=\"4-JWT\"><a href=\"#4-JWT\" class=\"headerlink\" title=\"4.JWT\"></a>4.JWT</h2><p>实施 Token 验证的方法挺多的，还有一些标准方法，比如 JWT，读作：jot ，表示：JSON Web Tokens 。JWT 标准的 Token 有三个部分：</p>\n<p><strong>header</strong></p>\n<p><strong>payload</strong></p>\n<p><strong>signature</strong></p>\n<p>中间用点分隔开，并且都会使用 Base64 编码，所以真正的 Token 看起来像这样</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<blockquote>\n<p>Header</p>\n</blockquote>\n<p>header 部分主要是两部分内容，一个是 Token 的类型，另一个是使用的算法，比如下面类型就是 JWT，使用的算法是 HS256。</p>\n<p><code>{\n  &quot;typ&quot;: &quot;JWT&quot;,\n  &quot;alg&quot;: &quot;HS256&quot;\n}</code></p>\n<p>上面的内容要用 Base64 的形式编码一下，所以就变成这样：</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</code></p>\n<blockquote>\n<p>Payload</p>\n</blockquote>\n<p>Payload 里面是 Token 的具体内容，这些内容里面有一些是标准字段，你也可以添加其它需要的内容。下面是标准字段：</p>\n<p>iss：Issuer，发行者</p>\n<p>sub：Subject，主题</p>\n<p>aud：Audience，观众</p>\n<p>exp：Expiration time，过期时间</p>\n<p>nbf：Not before</p>\n<p>iat：Issued at，发行时间</p>\n<p>jti：JWT ID</p>\n<p>比如下面这个 Payload ，用到了 iss 发行人，还有 exp 过期时间。另外还有两个自定义的字段，一个是 name ，还有一个是 admin 。</p>\n<p><code>{\n &quot;iss&quot;: &quot;ninghao.net&quot;,\n &quot;exp&quot;: &quot;1438955445&quot;,\n &quot;name&quot;: &quot;wanghao&quot;,\n &quot;admin&quot;: true\n}</code></p>\n<p>使用 Base64 编码以后就变成了这个样子：</p>\n<p><code>eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ</code></p>\n<blockquote>\n<p>Signature</p>\n</blockquote>\n<p>JWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。</p>\n<p>header</p>\n<p>payload</p>\n<p>secret</p>\n<p><code>var encodedString = base64UrlEncode(header) + &quot;.&quot; + base64UrlEncode(payload); \nHMACSHA256(encodedString, &#39;secret&#39;);</code></p>\n<p>处理完成以后看起来像这样：</p>\n<p><code>SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<p>最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：</p>\n<p><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJuaW5naGFvLm5ldCIsImV4cCI6IjE0Mzg5NTU0NDUiLCJuYW1lIjoid2FuZ2hhbyIsImFkbWluIjp0cnVlfQ.SwyHTEx_RQppr97g4J5lKXtabJecpejuef8AqKYMAJc</code></p>\n<p>客户端收到这个 Token 以后把它存储下来，下回向服务端发送请求的时候就带着这个 Token 。服务端收到这个 Token ，然后进行验证，通过以后就会返回给客户端想要的资源。</p>\n<h2 id=\"5-相关链接\"><a href=\"#5-相关链接\" class=\"headerlink\" title=\"5.相关链接\"></a>5.相关链接</h2><p><a href=\"http://jwt.io/\" target=\"_blank\" rel=\"noopener\">http://jwt.io/</a></p>\n<p><a href=\"https://github.com/firebase/php-jwt\" target=\"_blank\" rel=\"noopener\">https://github.com/firebase/php-jwt</a></p>\n<p><a href=\"https://scotch.io/tutorials/the-anatomy-of-a-json-web-token\" target=\"_blank\" rel=\"noopener\">https://scotch.io/tutorials/the-anatomy-of-a-json-web-token</a></p>\n<p><a href=\"https://github.com/auth0/jwt-decode\" target=\"_blank\" rel=\"noopener\">https://github.com/auth0/jwt-decode</a></p>\n<p><a href=\"https://ninghao.net/blog/2834\" target=\"_blank\" rel=\"noopener\">https://ninghao.net/blog/2834</a></p>"},{"layout":"lay_post","title":"MySQL读写分离方案选型","date":"2018-12-01T16:00:00.000Z","author":"lvyafei","_content":"\n## 1.读写分离方案\n\n目前要实现mysql的主从读写分离，主要有以下几种方案：\n<!--more-->\n\n### 1.1 修改源码\n\n通过程序实现，网上很多现成的代码，比较复杂，如果添加从服务器要更改多台服务器的代码。\n\n### 1.2 自研\n\n自己开发接口实现，这种方案门槛高，开发成本高，不是一般的小公司能承担得起。\n\n### 1.3 中间件\n\n由于mysql-proxy的主从读写分离是通过lua脚本来实现，目前lua的脚本的开发跟不上节奏，而写没有完美的现成的脚本，因此导致用于生产环境的话风险比较大，据网上很多人说mysql-proxy的性能不高。阿里开源项目Amoeba具有负载均衡、高可用性、sql过滤、读写分离、可路由相关的query到目标数据库，并且安装配置非常简单。\n\n## 2.读写分离中间件\n\n### 2.1 活跃中的项目\n\n#### 2.1.1 [活跃]-MySQL-Router(官方)\n\n官网地址: https://dev.mysql.com/doc/mysql-router/8.0/en/\n\n由MySQL官方提供，MySQL Router用于取代MySQL Proxy，建议MySQL Router与应用程序部署在一台机器。应用程序像访问MySQL一样访问MySQL Proxy，由MySQL Proxy将数据转发给后端的MySQL。支持各种操作系统。\n\n![架构图](https://image-static.segmentfault.com/290/493/2904939003-5a074a6f6e7ea_articlex)\n\n使用MySQL-Router实现应用程序的高可用: https://segmentfault.com/a/1190000011970688\n\n#### 2.1.2 [活跃]-MySQL-Cluster(官方)\n\nMySQL Cluster 是MySQL 官方集群部署方案，它的历史较久。支持通过自动分片支持读写扩展，通过实时备份冗余数据，是可用性最高的方案，声称可做到99.999%的可用性。MySQL-Cluster 的稳定性也不是太好。\n\n![MySQL-Cluster](http://www.2cto.com/uploadfile/Collfiles/20150402/2015040210055875.png)\n\n实战体验几种MySQLCluster方案: https://www.2cto.com/database/201504/387166.html\n\n#### 2.1.3 [活跃]-MaxScale(MariaDB)\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\n\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\nMaxScale是mariadb开发的一个MySQL数据中间件，配置好MySQL的主从复制架构后，可以实现读写分离，把读操作分散到从服务器中，并且对多个服务器实现负载均衡。MaxScale是插件式结构，允许用户开发适合自己的插件。MaxScale 使用 C 语言开发，利用 Linux 下的异步 I/O 功能。使用 epoll 作为事件驱动框架。\n\nMaxScale有两种方式实现读/写分离。一种是基于connect的，类似于Haproxy，不解析SQL语句，可以通过PHP Yii框架或Java Mybatis框架实现。在此方式中，用Maxscale做多台slave的负载均衡，并且支持主从同步延迟检测功能。\n\n![负载均衡](https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115910151-347833274.png)\n\n![读写分离](https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115734901-1106073519.png)\n\n官网地址: https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/\n\n利用Maxscale实现MySQL读写分离：https://www.cnblogs.com/darren-lee/p/7591416.html\n\n#### 2.1.4 [活跃]-Galera-Cluster(MariaDB)\n\nMariadb Galera Cluster是一款优秀的中间件软件，同样可以实现读写分离，负载均衡等功能，并且稳定性要大大超过MySQL-Proxy，建议大家用来替代MySQL-Proxy，甚至MySQL-Cluster。\n\n浅谈MariaDB Galera Cluster架构: https://www.cnblogs.com/vadim/p/6930566.html\n\n### 2.2 停滞或未开源的项目 \n\n#### 2.2.1 [停滞]-MySQL-Proxy(官方)\n\nmysql官方提供的mysql中间件服务，上游可接入若干个mysql-client，后端可连接若干个mysql-server。它使用mysql协议，任何使用mysql-client的上游无需修改任何代码，即可迁移至mysql-proxy上。MySQL Proxy强大的一项功能是实现“读写分离（Read/Write Splitting）”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。\n\nMySQL-Proxy实现读写分离提高并发负载案例：http://blog.jobbole.com/94606/\n\nMySQL-Proxy实际上非常不稳定，在高并发或有错误连接的情况下，进程很容易自动关闭，因此打开--keepalive参数让进程自动恢复是个比较好的办法，但还是不能从根本上解决问题，因此通常最稳妥的做法是在每个从服务器上安装一个MySQL-Proxy供自身使用，虽然比较低效但却能保证稳定性；\n\n#### 2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)\n\nAtlas是由 Qihoo 360公司Web平台部基础架构团队开发维护的一个基于MySQL协议的数据中间层项目。它在MySQL官方推出的MySQL-Proxy 0.8.2版本的基础上，修改了大量bug，添加了很多功能特性。由于团队精力有限, 不再主要维护，很多Issue很难再继续满足。\n\n项目地址: https://github.com/Qihoo360/Atlas\n\n#### 2.2.3 [停滞]-DBProxy(Atlas美团版)\n\n项目地址: https://github.com/Meituan-Dianping/DBProxy\n\nDBProxy是由美团点评公司技术工程部DBA团队（北京）开发维护的一个基于MySQL协议的数据中间层。它在奇虎360公司开源的Atlas基础上，修改了部分bug，并且添加了很多特性。最后提交时间2016年。\n\n#### 2.2.4 [未开源]-MTAtlas(Atlas美团版)\n\n原美团DBA团队在开源Atlas基础上做的一系列升级改造。在读写分离、单库分表的基础上，完成了分库分表的功能开发。\n\n#### 2.2.5 [未开源]-ArkProxy(极数云舟)\n\n极数云舟(http://www.cloud-ark.com) 公司开发的数据库中间件，核心特性包括:透明读写分离,兼容性,友好性,权重分发,消息压缩,从库接入,用户连接数限制及统计,丰富的参数配置,连接池,失败重试。\n\n![ArkProxy](http://www.cloud-ark.com/static/product_img/Arkproxy.png)\n\n#### 2.2.6 [停滞]-Amoeba(阿里)\n\nAmoeba是淘宝的得力作品。支持读写分离，表和库级别的读写分离，数据库水平分割，垂直分割，还有集群。mysql-proxy 只是轻量级的读写分离程序，虽然C写的，但是驱动是需要lua的脚本跑，而且在高并发下经常挂掉。程序还忽略了一些字符设定，如果数据库不是同一编码还会出现乱码,amoeba就不存在。\n\nAmoeba致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的 时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间,对客户端透明。具有负载均衡、高可用性、SQL 过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。\n\nAmoeba作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar，现在Cobar已经开源了，详情见： http://www.mysqlops.com/2012/06/19/cobar-alibaba.html\n\n项目地址：https://sourceforge.net/projects/amoeba/\n\n## 3.数据同步工具\n\n### 3.1 [离线]-DataX\n\n阿里的Datax是比较优秀的产品，基于python，提供各种数据库的读写插件，多线程执行，使用起来也很简单，定义好配置json文件执行脚本就可以了，非常适合离线数据，增量数据可以使用一些编码的方式实现，但是也仅仅针对insert数据比较有效，update数据就不适合。\n\ngithub地址：https://github.com/alibaba/DataX\n\n### 3.2 [离线]-Sqoop\n\nSqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop在数据库的支持的丰富性上不如DataX，但是如果你用hadoop，用sqoop是更好的选择，因为做Apache的顶级项目，他背后的支持远远比阿里一家公司靠谱的多。\n\n官网：http://sqoop.apache.org/\n\n### 3.3 [离线]-Kettle\n\nKettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle作为传统ETL工具，目前也都已经有了nosql数据库的支持，而且kettle还有图形界面可以用，使用起来简单多了。而且本来就是专门做ETL的，是Pentaho指定的ETL组件，对于数据清洗等处理数据的环节支持更好。但是数据效率一般，而且在生产环境也很少弄台windows机器，适合小项目，数据量比较小的同步。\n\nKettle 中文名称叫水壶，该项目的主程序员MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。\n\n官网：https://community.hitachivantara.com/docs/DOC-1009855\n\n### 3.4 [实时]-Canal\n\nCanal是基于mysql的binlog进行数据同步的中间件。简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。\n\n使用的话，安装好canal，配置好数据库参数，再编写一个客户端消费canal传过来的数据就可以了。\n\ngithub地址：https://github.com/alibaba/canal\n\n### 3.5 [实时]-Otter\n\notter是在canal基础上又重新实现了可配置的消费者，使用otter的话，刚才说过的消费者就不需要写了，而otter提供了一个web界面，可以自定义同步任务及map表。非常适合mysql库之间的同步。而且通过retl_buff表的监控，也可以实现一些全量数据的同步。\n\n但是otter也有一些不好的地方，比如界面上的参数并不是所有的都有用，文档写的一般，不是很清晰。但是想想省了好多事，还是非常好的一款中间件。\n\ngithub地址：https://github.com/alibaba/otter\n\n### 3.6 [实时]-Databus\n\nDatabus是LinkedIn开源的一款低延迟的分布式数据库同步系统（a source-agnostic distributed change data capture system），它提供可靠的数据捕获、流转和数据处理功能。Databus将数据库作为唯一真实数据来源，并将变更从事务或提交日志中提取出来，然后通知相关的衍生数据库或缓存。 Databus传输层端到端的延迟是微秒级别的，这意味着每台服务器每秒可以处理数千次数据吞吐变更事件,同时还支持无限回溯能力和丰富的变更订阅功能，\n\n项目地址: https://github.com/linkedin/databus\n\n### 3.7 [实时]-MySQL主从同步\n\n**1.asynchronous 异步复制**\n\n原理：在异步复制中，master写数据到binlog且sync，无需等待slave。slave request binlog后写入relay-log并flush disk。\n\n优点：复制的性能最好\n\n缺点：master挂掉后，slave可能会丢失事务\n\n代表：MySQL原生的复制\n\n![异步复制](https://yqfile.alicdn.com/f30dd5a58ea24c87365127b3951a067a3c23134d.jpeg)\n\n**2.fully synchronous 全同步复制**\n\n原理：在全同步复制中，master写数据到binlog且sync，所有slave request binlog后写入relay-log并flush disk，并且回放完日志再commit。\n\n优点：数据不会丢失\n\n缺点：会阻塞master session，性能太差，非常依赖网络\n\n代表：MySQL-Cluster\n\n![全同步复制](https://yqfile.alicdn.com/99ecf19b4f839b8a6df909c5584a5a0144f090fa.jpeg)\n\n**3.semi synchronous 半同步复制**\n\n原理: 在半同步复制中，master写数据到binlog且sync，且commit，然后一直等待ACK。当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）\n\n优点：会有数据丢失风险（低）\n\n缺点：会阻塞master session，性能差，非常依赖网络\n\n代表：after commit, 原生的半同步\n\n重点：由于master是在三段提交的最后commit阶段完成后才等待，所以master的其他session是可以看到这个提交事务的，所以这时候master上的数据和slave不一致，master crash后，slave数据丢失。\n\n![半同步复制](https://yqfile.alicdn.com/7f465154accff14368ff16d0b011dfc1b82cbac6.jpeg)\n\n**4.lossless replication 无损复制**\n\n原理: 在半同步复制中，master写数据到binlog且sync，然后一直等待ACK. 当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）\n\n优点：数据零丢失（前提是让其一直是lossless replication），性能好\n\n缺点：会阻塞master session，非常依赖网络\n\n代表：after sync, 原生的半同步\n\n重点：由于master是在三段提交的第二阶段sync binlog完成后才等待, 所以master的其他session是看不见这个提交事务的，所以这时候master上的数据和slave一致，master crash后，slave没有丢失数据。\n\n![无损复制](https://yqfile.alicdn.com/6c77a9f51c3a9cdb0e783607752ebcbad01cbbf3.jpeg)\n\n## 4.延迟同步如何解决？\n\n### 4.1 主从同步的原理\n\n主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。master可以并发，Slave_SQL_Running线程不可以并发。\n\n### 4.2 延迟怎么产生的\n\n当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。\n\n首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高。\n\n次要原因：读写binlog带来的性能影响，网络传输延迟。\n\n### 4.3 同步延迟解决方案\n\n**一、架构方面**\n\n1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。\n\n2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。\n\n3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。\n\n4.不同业务的mysql物理上放在不同机器，分散压力。\n\n5.使用比主库更好的硬件设备作为slave\n\n总结，mysql压力小，延迟自然会变小。\n\n**二、硬件方面**\n\n1.采用好服务器，比如4u比2u性能明显好，2u比1u性能明显好。\n\n2.存储用ssd或者盘阵或者san，提升随机写的性能。\n\n3.主从间保证处在同一个交换机下面，并且是万兆环境。\n\n总结，硬件强劲，延迟自然会变小。一句话，缩小延迟的解决方案就是花钱和花时间。\n\n**三、主从同步加速**\n\n1、sync_binlog在slave端设置为0\n\n2、–logs-slave-updates 从服务器从主服务器接收到的更新不记入它的二进制日志。\n\n3、直接禁用slave端的binlog\n\n4、slave端，如果使用的存储引擎是innodb，innodb_flush_log_at_trx_commit =2\n\n**四、文件系统属性优化**\n\nmaster端修改linux、Unix文件系统中文件的etime属性， 由于每当读文件时OS都会将读取操作发生的时间回写到磁盘上，对于读操作频繁的数据库文件来说这是没必要的，只会增加磁盘系统的负担影响I/O性能。可以通过设置文件系统的mount属性，组织操作系统写atime信息，在linux上的操作为：\n打开/etc/fstab，加上noatime参数 /dev/sdb1 /data reiserfs noatime 1 2 然后重新mount文件系统 #mount -oremount /data\n\n## 5.参考资料\n\nMySQL的读写分离的几种选择；https://www.cnblogs.com/fyc119/p/7529902.html\n\nmysql的读写分离Amoeba：http://blog.51cto.com/freeze/860111\n\nAmoeba搞定mysql主从读写分离: http://blog.chinaunix.net/uid-20639775-id-154600.html\n\nMySQL主从延时这么长，要怎么优化？: https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ\n\nmysql数据库从库同步延迟的问题：https://blog.csdn.net/caomiao2006/article/details/51011373\n\nMySQL 主从同步延迟的原因及解决办法：https://blog.csdn.net/Soar_Away/article/details/72615012\n\n数据同步工具: https://blog.csdn.net/frog4/article/details/79624664\n\nDatabus简介: https://blog.csdn.net/acm_lkl/article/details/78645406\n\nDataBus&Canal对比: http://www.cnblogs.com/xunshao/p/9762377.html\n\nMySQL无损复制： https://yq.aliyun.com/articles/59258","source":"_posts/2018-12-02-MySQL读写分离方案选型.md","raw":"---\nlayout: lay_post\ntitle: \"MySQL读写分离方案选型\"\ndate: 2018-12-02\ncategories: 中间件\ntags: MySQL\nauthor: lvyafei\n---\n\n## 1.读写分离方案\n\n目前要实现mysql的主从读写分离，主要有以下几种方案：\n<!--more-->\n\n### 1.1 修改源码\n\n通过程序实现，网上很多现成的代码，比较复杂，如果添加从服务器要更改多台服务器的代码。\n\n### 1.2 自研\n\n自己开发接口实现，这种方案门槛高，开发成本高，不是一般的小公司能承担得起。\n\n### 1.3 中间件\n\n由于mysql-proxy的主从读写分离是通过lua脚本来实现，目前lua的脚本的开发跟不上节奏，而写没有完美的现成的脚本，因此导致用于生产环境的话风险比较大，据网上很多人说mysql-proxy的性能不高。阿里开源项目Amoeba具有负载均衡、高可用性、sql过滤、读写分离、可路由相关的query到目标数据库，并且安装配置非常简单。\n\n## 2.读写分离中间件\n\n### 2.1 活跃中的项目\n\n#### 2.1.1 [活跃]-MySQL-Router(官方)\n\n官网地址: https://dev.mysql.com/doc/mysql-router/8.0/en/\n\n由MySQL官方提供，MySQL Router用于取代MySQL Proxy，建议MySQL Router与应用程序部署在一台机器。应用程序像访问MySQL一样访问MySQL Proxy，由MySQL Proxy将数据转发给后端的MySQL。支持各种操作系统。\n\n![架构图](https://image-static.segmentfault.com/290/493/2904939003-5a074a6f6e7ea_articlex)\n\n使用MySQL-Router实现应用程序的高可用: https://segmentfault.com/a/1190000011970688\n\n#### 2.1.2 [活跃]-MySQL-Cluster(官方)\n\nMySQL Cluster 是MySQL 官方集群部署方案，它的历史较久。支持通过自动分片支持读写扩展，通过实时备份冗余数据，是可用性最高的方案，声称可做到99.999%的可用性。MySQL-Cluster 的稳定性也不是太好。\n\n![MySQL-Cluster](http://www.2cto.com/uploadfile/Collfiles/20150402/2015040210055875.png)\n\n实战体验几种MySQLCluster方案: https://www.2cto.com/database/201504/387166.html\n\n#### 2.1.3 [活跃]-MaxScale(MariaDB)\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\n\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\nMaxScale是mariadb开发的一个MySQL数据中间件，配置好MySQL的主从复制架构后，可以实现读写分离，把读操作分散到从服务器中，并且对多个服务器实现负载均衡。MaxScale是插件式结构，允许用户开发适合自己的插件。MaxScale 使用 C 语言开发，利用 Linux 下的异步 I/O 功能。使用 epoll 作为事件驱动框架。\n\nMaxScale有两种方式实现读/写分离。一种是基于connect的，类似于Haproxy，不解析SQL语句，可以通过PHP Yii框架或Java Mybatis框架实现。在此方式中，用Maxscale做多台slave的负载均衡，并且支持主从同步延迟检测功能。\n\n![负载均衡](https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115910151-347833274.png)\n\n![读写分离](https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115734901-1106073519.png)\n\n官网地址: https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/\n\n利用Maxscale实现MySQL读写分离：https://www.cnblogs.com/darren-lee/p/7591416.html\n\n#### 2.1.4 [活跃]-Galera-Cluster(MariaDB)\n\nMariadb Galera Cluster是一款优秀的中间件软件，同样可以实现读写分离，负载均衡等功能，并且稳定性要大大超过MySQL-Proxy，建议大家用来替代MySQL-Proxy，甚至MySQL-Cluster。\n\n浅谈MariaDB Galera Cluster架构: https://www.cnblogs.com/vadim/p/6930566.html\n\n### 2.2 停滞或未开源的项目 \n\n#### 2.2.1 [停滞]-MySQL-Proxy(官方)\n\nmysql官方提供的mysql中间件服务，上游可接入若干个mysql-client，后端可连接若干个mysql-server。它使用mysql协议，任何使用mysql-client的上游无需修改任何代码，即可迁移至mysql-proxy上。MySQL Proxy强大的一项功能是实现“读写分离（Read/Write Splitting）”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。\n\nMySQL-Proxy实现读写分离提高并发负载案例：http://blog.jobbole.com/94606/\n\nMySQL-Proxy实际上非常不稳定，在高并发或有错误连接的情况下，进程很容易自动关闭，因此打开--keepalive参数让进程自动恢复是个比较好的办法，但还是不能从根本上解决问题，因此通常最稳妥的做法是在每个从服务器上安装一个MySQL-Proxy供自身使用，虽然比较低效但却能保证稳定性；\n\n#### 2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)\n\nAtlas是由 Qihoo 360公司Web平台部基础架构团队开发维护的一个基于MySQL协议的数据中间层项目。它在MySQL官方推出的MySQL-Proxy 0.8.2版本的基础上，修改了大量bug，添加了很多功能特性。由于团队精力有限, 不再主要维护，很多Issue很难再继续满足。\n\n项目地址: https://github.com/Qihoo360/Atlas\n\n#### 2.2.3 [停滞]-DBProxy(Atlas美团版)\n\n项目地址: https://github.com/Meituan-Dianping/DBProxy\n\nDBProxy是由美团点评公司技术工程部DBA团队（北京）开发维护的一个基于MySQL协议的数据中间层。它在奇虎360公司开源的Atlas基础上，修改了部分bug，并且添加了很多特性。最后提交时间2016年。\n\n#### 2.2.4 [未开源]-MTAtlas(Atlas美团版)\n\n原美团DBA团队在开源Atlas基础上做的一系列升级改造。在读写分离、单库分表的基础上，完成了分库分表的功能开发。\n\n#### 2.2.5 [未开源]-ArkProxy(极数云舟)\n\n极数云舟(http://www.cloud-ark.com) 公司开发的数据库中间件，核心特性包括:透明读写分离,兼容性,友好性,权重分发,消息压缩,从库接入,用户连接数限制及统计,丰富的参数配置,连接池,失败重试。\n\n![ArkProxy](http://www.cloud-ark.com/static/product_img/Arkproxy.png)\n\n#### 2.2.6 [停滞]-Amoeba(阿里)\n\nAmoeba是淘宝的得力作品。支持读写分离，表和库级别的读写分离，数据库水平分割，垂直分割，还有集群。mysql-proxy 只是轻量级的读写分离程序，虽然C写的，但是驱动是需要lua的脚本跑，而且在高并发下经常挂掉。程序还忽略了一些字符设定，如果数据库不是同一编码还会出现乱码,amoeba就不存在。\n\nAmoeba致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的 时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间,对客户端透明。具有负载均衡、高可用性、SQL 过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。\n\nAmoeba作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar，现在Cobar已经开源了，详情见： http://www.mysqlops.com/2012/06/19/cobar-alibaba.html\n\n项目地址：https://sourceforge.net/projects/amoeba/\n\n## 3.数据同步工具\n\n### 3.1 [离线]-DataX\n\n阿里的Datax是比较优秀的产品，基于python，提供各种数据库的读写插件，多线程执行，使用起来也很简单，定义好配置json文件执行脚本就可以了，非常适合离线数据，增量数据可以使用一些编码的方式实现，但是也仅仅针对insert数据比较有效，update数据就不适合。\n\ngithub地址：https://github.com/alibaba/DataX\n\n### 3.2 [离线]-Sqoop\n\nSqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop在数据库的支持的丰富性上不如DataX，但是如果你用hadoop，用sqoop是更好的选择，因为做Apache的顶级项目，他背后的支持远远比阿里一家公司靠谱的多。\n\n官网：http://sqoop.apache.org/\n\n### 3.3 [离线]-Kettle\n\nKettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle作为传统ETL工具，目前也都已经有了nosql数据库的支持，而且kettle还有图形界面可以用，使用起来简单多了。而且本来就是专门做ETL的，是Pentaho指定的ETL组件，对于数据清洗等处理数据的环节支持更好。但是数据效率一般，而且在生产环境也很少弄台windows机器，适合小项目，数据量比较小的同步。\n\nKettle 中文名称叫水壶，该项目的主程序员MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。\n\n官网：https://community.hitachivantara.com/docs/DOC-1009855\n\n### 3.4 [实时]-Canal\n\nCanal是基于mysql的binlog进行数据同步的中间件。简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。\n\n使用的话，安装好canal，配置好数据库参数，再编写一个客户端消费canal传过来的数据就可以了。\n\ngithub地址：https://github.com/alibaba/canal\n\n### 3.5 [实时]-Otter\n\notter是在canal基础上又重新实现了可配置的消费者，使用otter的话，刚才说过的消费者就不需要写了，而otter提供了一个web界面，可以自定义同步任务及map表。非常适合mysql库之间的同步。而且通过retl_buff表的监控，也可以实现一些全量数据的同步。\n\n但是otter也有一些不好的地方，比如界面上的参数并不是所有的都有用，文档写的一般，不是很清晰。但是想想省了好多事，还是非常好的一款中间件。\n\ngithub地址：https://github.com/alibaba/otter\n\n### 3.6 [实时]-Databus\n\nDatabus是LinkedIn开源的一款低延迟的分布式数据库同步系统（a source-agnostic distributed change data capture system），它提供可靠的数据捕获、流转和数据处理功能。Databus将数据库作为唯一真实数据来源，并将变更从事务或提交日志中提取出来，然后通知相关的衍生数据库或缓存。 Databus传输层端到端的延迟是微秒级别的，这意味着每台服务器每秒可以处理数千次数据吞吐变更事件,同时还支持无限回溯能力和丰富的变更订阅功能，\n\n项目地址: https://github.com/linkedin/databus\n\n### 3.7 [实时]-MySQL主从同步\n\n**1.asynchronous 异步复制**\n\n原理：在异步复制中，master写数据到binlog且sync，无需等待slave。slave request binlog后写入relay-log并flush disk。\n\n优点：复制的性能最好\n\n缺点：master挂掉后，slave可能会丢失事务\n\n代表：MySQL原生的复制\n\n![异步复制](https://yqfile.alicdn.com/f30dd5a58ea24c87365127b3951a067a3c23134d.jpeg)\n\n**2.fully synchronous 全同步复制**\n\n原理：在全同步复制中，master写数据到binlog且sync，所有slave request binlog后写入relay-log并flush disk，并且回放完日志再commit。\n\n优点：数据不会丢失\n\n缺点：会阻塞master session，性能太差，非常依赖网络\n\n代表：MySQL-Cluster\n\n![全同步复制](https://yqfile.alicdn.com/99ecf19b4f839b8a6df909c5584a5a0144f090fa.jpeg)\n\n**3.semi synchronous 半同步复制**\n\n原理: 在半同步复制中，master写数据到binlog且sync，且commit，然后一直等待ACK。当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）\n\n优点：会有数据丢失风险（低）\n\n缺点：会阻塞master session，性能差，非常依赖网络\n\n代表：after commit, 原生的半同步\n\n重点：由于master是在三段提交的最后commit阶段完成后才等待，所以master的其他session是可以看到这个提交事务的，所以这时候master上的数据和slave不一致，master crash后，slave数据丢失。\n\n![半同步复制](https://yqfile.alicdn.com/7f465154accff14368ff16d0b011dfc1b82cbac6.jpeg)\n\n**4.lossless replication 无损复制**\n\n原理: 在半同步复制中，master写数据到binlog且sync，然后一直等待ACK. 当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）\n\n优点：数据零丢失（前提是让其一直是lossless replication），性能好\n\n缺点：会阻塞master session，非常依赖网络\n\n代表：after sync, 原生的半同步\n\n重点：由于master是在三段提交的第二阶段sync binlog完成后才等待, 所以master的其他session是看不见这个提交事务的，所以这时候master上的数据和slave一致，master crash后，slave没有丢失数据。\n\n![无损复制](https://yqfile.alicdn.com/6c77a9f51c3a9cdb0e783607752ebcbad01cbbf3.jpeg)\n\n## 4.延迟同步如何解决？\n\n### 4.1 主从同步的原理\n\n主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。master可以并发，Slave_SQL_Running线程不可以并发。\n\n### 4.2 延迟怎么产生的\n\n当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。\n\n首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高。\n\n次要原因：读写binlog带来的性能影响，网络传输延迟。\n\n### 4.3 同步延迟解决方案\n\n**一、架构方面**\n\n1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。\n\n2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。\n\n3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。\n\n4.不同业务的mysql物理上放在不同机器，分散压力。\n\n5.使用比主库更好的硬件设备作为slave\n\n总结，mysql压力小，延迟自然会变小。\n\n**二、硬件方面**\n\n1.采用好服务器，比如4u比2u性能明显好，2u比1u性能明显好。\n\n2.存储用ssd或者盘阵或者san，提升随机写的性能。\n\n3.主从间保证处在同一个交换机下面，并且是万兆环境。\n\n总结，硬件强劲，延迟自然会变小。一句话，缩小延迟的解决方案就是花钱和花时间。\n\n**三、主从同步加速**\n\n1、sync_binlog在slave端设置为0\n\n2、–logs-slave-updates 从服务器从主服务器接收到的更新不记入它的二进制日志。\n\n3、直接禁用slave端的binlog\n\n4、slave端，如果使用的存储引擎是innodb，innodb_flush_log_at_trx_commit =2\n\n**四、文件系统属性优化**\n\nmaster端修改linux、Unix文件系统中文件的etime属性， 由于每当读文件时OS都会将读取操作发生的时间回写到磁盘上，对于读操作频繁的数据库文件来说这是没必要的，只会增加磁盘系统的负担影响I/O性能。可以通过设置文件系统的mount属性，组织操作系统写atime信息，在linux上的操作为：\n打开/etc/fstab，加上noatime参数 /dev/sdb1 /data reiserfs noatime 1 2 然后重新mount文件系统 #mount -oremount /data\n\n## 5.参考资料\n\nMySQL的读写分离的几种选择；https://www.cnblogs.com/fyc119/p/7529902.html\n\nmysql的读写分离Amoeba：http://blog.51cto.com/freeze/860111\n\nAmoeba搞定mysql主从读写分离: http://blog.chinaunix.net/uid-20639775-id-154600.html\n\nMySQL主从延时这么长，要怎么优化？: https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ\n\nmysql数据库从库同步延迟的问题：https://blog.csdn.net/caomiao2006/article/details/51011373\n\nMySQL 主从同步延迟的原因及解决办法：https://blog.csdn.net/Soar_Away/article/details/72615012\n\n数据同步工具: https://blog.csdn.net/frog4/article/details/79624664\n\nDatabus简介: https://blog.csdn.net/acm_lkl/article/details/78645406\n\nDataBus&Canal对比: http://www.cnblogs.com/xunshao/p/9762377.html\n\nMySQL无损复制： https://yq.aliyun.com/articles/59258","slug":"2018-12-02-MySQL读写分离方案选型","published":1,"updated":"2018-12-04T13:27:34.969Z","comments":1,"photos":[],"link":"","_id":"cjskffoen005v4glmfcdb3ouv","content":"<h2 id=\"1-读写分离方案\"><a href=\"#1-读写分离方案\" class=\"headerlink\" title=\"1.读写分离方案\"></a>1.读写分离方案</h2><p>目前要实现mysql的主从读写分离，主要有以下几种方案：<br><a id=\"more\"></a></p>\n<h3 id=\"1-1-修改源码\"><a href=\"#1-1-修改源码\" class=\"headerlink\" title=\"1.1 修改源码\"></a>1.1 修改源码</h3><p>通过程序实现，网上很多现成的代码，比较复杂，如果添加从服务器要更改多台服务器的代码。</p>\n<h3 id=\"1-2-自研\"><a href=\"#1-2-自研\" class=\"headerlink\" title=\"1.2 自研\"></a>1.2 自研</h3><p>自己开发接口实现，这种方案门槛高，开发成本高，不是一般的小公司能承担得起。</p>\n<h3 id=\"1-3-中间件\"><a href=\"#1-3-中间件\" class=\"headerlink\" title=\"1.3 中间件\"></a>1.3 中间件</h3><p>由于mysql-proxy的主从读写分离是通过lua脚本来实现，目前lua的脚本的开发跟不上节奏，而写没有完美的现成的脚本，因此导致用于生产环境的话风险比较大，据网上很多人说mysql-proxy的性能不高。阿里开源项目Amoeba具有负载均衡、高可用性、sql过滤、读写分离、可路由相关的query到目标数据库，并且安装配置非常简单。</p>\n<h2 id=\"2-读写分离中间件\"><a href=\"#2-读写分离中间件\" class=\"headerlink\" title=\"2.读写分离中间件\"></a>2.读写分离中间件</h2><h3 id=\"2-1-活跃中的项目\"><a href=\"#2-1-活跃中的项目\" class=\"headerlink\" title=\"2.1 活跃中的项目\"></a>2.1 活跃中的项目</h3><h4 id=\"2-1-1-活跃-MySQL-Router-官方\"><a href=\"#2-1-1-活跃-MySQL-Router-官方\" class=\"headerlink\" title=\"2.1.1 [活跃]-MySQL-Router(官方)\"></a>2.1.1 [活跃]-MySQL-Router(官方)</h4><p>官网地址: <a href=\"https://dev.mysql.com/doc/mysql-router/8.0/en/\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/mysql-router/8.0/en/</a></p>\n<p>由MySQL官方提供，MySQL Router用于取代MySQL Proxy，建议MySQL Router与应用程序部署在一台机器。应用程序像访问MySQL一样访问MySQL Proxy，由MySQL Proxy将数据转发给后端的MySQL。支持各种操作系统。</p>\n<p><img src=\"https://image-static.segmentfault.com/290/493/2904939003-5a074a6f6e7ea_articlex\" alt=\"架构图\"></p>\n<p>使用MySQL-Router实现应用程序的高可用: <a href=\"https://segmentfault.com/a/1190000011970688\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000011970688</a></p>\n<h4 id=\"2-1-2-活跃-MySQL-Cluster-官方\"><a href=\"#2-1-2-活跃-MySQL-Cluster-官方\" class=\"headerlink\" title=\"2.1.2 [活跃]-MySQL-Cluster(官方)\"></a>2.1.2 [活跃]-MySQL-Cluster(官方)</h4><p>MySQL Cluster 是MySQL 官方集群部署方案，它的历史较久。支持通过自动分片支持读写扩展，通过实时备份冗余数据，是可用性最高的方案，声称可做到99.999%的可用性。MySQL-Cluster 的稳定性也不是太好。</p>\n<p><img src=\"http://www.2cto.com/uploadfile/Collfiles/20150402/2015040210055875.png\" alt=\"MySQL-Cluster\"></p>\n<p>实战体验几种MySQLCluster方案: <a href=\"https://www.2cto.com/database/201504/387166.html\" target=\"_blank\" rel=\"noopener\">https://www.2cto.com/database/201504/387166.html</a></p>\n<h4 id=\"2-1-3-活跃-MaxScale-MariaDB\"><a href=\"#2-1-3-活跃-MaxScale-MariaDB\" class=\"headerlink\" title=\"2.1.3 [活跃]-MaxScale(MariaDB)\"></a>2.1.3 [活跃]-MaxScale(MariaDB)</h4><p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。</p>\n<p>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>MaxScale是mariadb开发的一个MySQL数据中间件，配置好MySQL的主从复制架构后，可以实现读写分离，把读操作分散到从服务器中，并且对多个服务器实现负载均衡。MaxScale是插件式结构，允许用户开发适合自己的插件。MaxScale 使用 C 语言开发，利用 Linux 下的异步 I/O 功能。使用 epoll 作为事件驱动框架。</p>\n<p>MaxScale有两种方式实现读/写分离。一种是基于connect的，类似于Haproxy，不解析SQL语句，可以通过PHP Yii框架或Java Mybatis框架实现。在此方式中，用Maxscale做多台slave的负载均衡，并且支持主从同步延迟检测功能。</p>\n<p><img src=\"https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115910151-347833274.png\" alt=\"负载均衡\"></p>\n<p><img src=\"https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115734901-1106073519.png\" alt=\"读写分离\"></p>\n<p>官网地址: <a href=\"https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/\" target=\"_blank\" rel=\"noopener\">https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/</a></p>\n<p>利用Maxscale实现MySQL读写分离：<a href=\"https://www.cnblogs.com/darren-lee/p/7591416.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/darren-lee/p/7591416.html</a></p>\n<h4 id=\"2-1-4-活跃-Galera-Cluster-MariaDB\"><a href=\"#2-1-4-活跃-Galera-Cluster-MariaDB\" class=\"headerlink\" title=\"2.1.4 [活跃]-Galera-Cluster(MariaDB)\"></a>2.1.4 [活跃]-Galera-Cluster(MariaDB)</h4><p>Mariadb Galera Cluster是一款优秀的中间件软件，同样可以实现读写分离，负载均衡等功能，并且稳定性要大大超过MySQL-Proxy，建议大家用来替代MySQL-Proxy，甚至MySQL-Cluster。</p>\n<p>浅谈MariaDB Galera Cluster架构: <a href=\"https://www.cnblogs.com/vadim/p/6930566.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/vadim/p/6930566.html</a></p>\n<h3 id=\"2-2-停滞或未开源的项目\"><a href=\"#2-2-停滞或未开源的项目\" class=\"headerlink\" title=\"2.2 停滞或未开源的项目\"></a>2.2 停滞或未开源的项目</h3><h4 id=\"2-2-1-停滞-MySQL-Proxy-官方\"><a href=\"#2-2-1-停滞-MySQL-Proxy-官方\" class=\"headerlink\" title=\"2.2.1 [停滞]-MySQL-Proxy(官方)\"></a>2.2.1 [停滞]-MySQL-Proxy(官方)</h4><p>mysql官方提供的mysql中间件服务，上游可接入若干个mysql-client，后端可连接若干个mysql-server。它使用mysql协议，任何使用mysql-client的上游无需修改任何代码，即可迁移至mysql-proxy上。MySQL Proxy强大的一项功能是实现“读写分离（Read/Write Splitting）”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。</p>\n<p>MySQL-Proxy实现读写分离提高并发负载案例：<a href=\"http://blog.jobbole.com/94606/\" target=\"_blank\" rel=\"noopener\">http://blog.jobbole.com/94606/</a></p>\n<p>MySQL-Proxy实际上非常不稳定，在高并发或有错误连接的情况下，进程很容易自动关闭，因此打开–keepalive参数让进程自动恢复是个比较好的办法，但还是不能从根本上解决问题，因此通常最稳妥的做法是在每个从服务器上安装一个MySQL-Proxy供自身使用，虽然比较低效但却能保证稳定性；</p>\n<h4 id=\"2-2-2-停滞-Atlas-MySQL-Proxy增强版\"><a href=\"#2-2-2-停滞-Atlas-MySQL-Proxy增强版\" class=\"headerlink\" title=\"2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)\"></a>2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)</h4><p>Atlas是由 Qihoo 360公司Web平台部基础架构团队开发维护的一个基于MySQL协议的数据中间层项目。它在MySQL官方推出的MySQL-Proxy 0.8.2版本的基础上，修改了大量bug，添加了很多功能特性。由于团队精力有限, 不再主要维护，很多Issue很难再继续满足。</p>\n<p>项目地址: <a href=\"https://github.com/Qihoo360/Atlas\" target=\"_blank\" rel=\"noopener\">https://github.com/Qihoo360/Atlas</a></p>\n<h4 id=\"2-2-3-停滞-DBProxy-Atlas美团版\"><a href=\"#2-2-3-停滞-DBProxy-Atlas美团版\" class=\"headerlink\" title=\"2.2.3 [停滞]-DBProxy(Atlas美团版)\"></a>2.2.3 [停滞]-DBProxy(Atlas美团版)</h4><p>项目地址: <a href=\"https://github.com/Meituan-Dianping/DBProxy\" target=\"_blank\" rel=\"noopener\">https://github.com/Meituan-Dianping/DBProxy</a></p>\n<p>DBProxy是由美团点评公司技术工程部DBA团队（北京）开发维护的一个基于MySQL协议的数据中间层。它在奇虎360公司开源的Atlas基础上，修改了部分bug，并且添加了很多特性。最后提交时间2016年。</p>\n<h4 id=\"2-2-4-未开源-MTAtlas-Atlas美团版\"><a href=\"#2-2-4-未开源-MTAtlas-Atlas美团版\" class=\"headerlink\" title=\"2.2.4 [未开源]-MTAtlas(Atlas美团版)\"></a>2.2.4 [未开源]-MTAtlas(Atlas美团版)</h4><p>原美团DBA团队在开源Atlas基础上做的一系列升级改造。在读写分离、单库分表的基础上，完成了分库分表的功能开发。</p>\n<h4 id=\"2-2-5-未开源-ArkProxy-极数云舟\"><a href=\"#2-2-5-未开源-ArkProxy-极数云舟\" class=\"headerlink\" title=\"2.2.5 [未开源]-ArkProxy(极数云舟)\"></a>2.2.5 [未开源]-ArkProxy(极数云舟)</h4><p>极数云舟(<a href=\"http://www.cloud-ark.com\" target=\"_blank\" rel=\"noopener\">http://www.cloud-ark.com</a>) 公司开发的数据库中间件，核心特性包括:透明读写分离,兼容性,友好性,权重分发,消息压缩,从库接入,用户连接数限制及统计,丰富的参数配置,连接池,失败重试。</p>\n<p><img src=\"http://www.cloud-ark.com/static/product_img/Arkproxy.png\" alt=\"ArkProxy\"></p>\n<h4 id=\"2-2-6-停滞-Amoeba-阿里\"><a href=\"#2-2-6-停滞-Amoeba-阿里\" class=\"headerlink\" title=\"2.2.6 [停滞]-Amoeba(阿里)\"></a>2.2.6 [停滞]-Amoeba(阿里)</h4><p>Amoeba是淘宝的得力作品。支持读写分离，表和库级别的读写分离，数据库水平分割，垂直分割，还有集群。mysql-proxy 只是轻量级的读写分离程序，虽然C写的，但是驱动是需要lua的脚本跑，而且在高并发下经常挂掉。程序还忽略了一些字符设定，如果数据库不是同一编码还会出现乱码,amoeba就不存在。</p>\n<p>Amoeba致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的 时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间,对客户端透明。具有负载均衡、高可用性、SQL 过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。</p>\n<p>Amoeba作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar，现在Cobar已经开源了，详情见： <a href=\"http://www.mysqlops.com/2012/06/19/cobar-alibaba.html\" target=\"_blank\" rel=\"noopener\">http://www.mysqlops.com/2012/06/19/cobar-alibaba.html</a></p>\n<p>项目地址：<a href=\"https://sourceforge.net/projects/amoeba/\" target=\"_blank\" rel=\"noopener\">https://sourceforge.net/projects/amoeba/</a></p>\n<h2 id=\"3-数据同步工具\"><a href=\"#3-数据同步工具\" class=\"headerlink\" title=\"3.数据同步工具\"></a>3.数据同步工具</h2><h3 id=\"3-1-离线-DataX\"><a href=\"#3-1-离线-DataX\" class=\"headerlink\" title=\"3.1 [离线]-DataX\"></a>3.1 [离线]-DataX</h3><p>阿里的Datax是比较优秀的产品，基于python，提供各种数据库的读写插件，多线程执行，使用起来也很简单，定义好配置json文件执行脚本就可以了，非常适合离线数据，增量数据可以使用一些编码的方式实现，但是也仅仅针对insert数据比较有效，update数据就不适合。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/DataX\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/DataX</a></p>\n<h3 id=\"3-2-离线-Sqoop\"><a href=\"#3-2-离线-Sqoop\" class=\"headerlink\" title=\"3.2 [离线]-Sqoop\"></a>3.2 [离线]-Sqoop</h3><p>Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop在数据库的支持的丰富性上不如DataX，但是如果你用hadoop，用sqoop是更好的选择，因为做Apache的顶级项目，他背后的支持远远比阿里一家公司靠谱的多。</p>\n<p>官网：<a href=\"http://sqoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://sqoop.apache.org/</a></p>\n<h3 id=\"3-3-离线-Kettle\"><a href=\"#3-3-离线-Kettle\" class=\"headerlink\" title=\"3.3 [离线]-Kettle\"></a>3.3 [离线]-Kettle</h3><p>Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle作为传统ETL工具，目前也都已经有了nosql数据库的支持，而且kettle还有图形界面可以用，使用起来简单多了。而且本来就是专门做ETL的，是Pentaho指定的ETL组件，对于数据清洗等处理数据的环节支持更好。但是数据效率一般，而且在生产环境也很少弄台windows机器，适合小项目，数据量比较小的同步。</p>\n<p>Kettle 中文名称叫水壶，该项目的主程序员MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。</p>\n<p>官网：<a href=\"https://community.hitachivantara.com/docs/DOC-1009855\" target=\"_blank\" rel=\"noopener\">https://community.hitachivantara.com/docs/DOC-1009855</a></p>\n<h3 id=\"3-4-实时-Canal\"><a href=\"#3-4-实时-Canal\" class=\"headerlink\" title=\"3.4 [实时]-Canal\"></a>3.4 [实时]-Canal</h3><p>Canal是基于mysql的binlog进行数据同步的中间件。简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。</p>\n<p>使用的话，安装好canal，配置好数据库参数，再编写一个客户端消费canal传过来的数据就可以了。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/canal\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/canal</a></p>\n<h3 id=\"3-5-实时-Otter\"><a href=\"#3-5-实时-Otter\" class=\"headerlink\" title=\"3.5 [实时]-Otter\"></a>3.5 [实时]-Otter</h3><p>otter是在canal基础上又重新实现了可配置的消费者，使用otter的话，刚才说过的消费者就不需要写了，而otter提供了一个web界面，可以自定义同步任务及map表。非常适合mysql库之间的同步。而且通过retl_buff表的监控，也可以实现一些全量数据的同步。</p>\n<p>但是otter也有一些不好的地方，比如界面上的参数并不是所有的都有用，文档写的一般，不是很清晰。但是想想省了好多事，还是非常好的一款中间件。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/otter\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/otter</a></p>\n<h3 id=\"3-6-实时-Databus\"><a href=\"#3-6-实时-Databus\" class=\"headerlink\" title=\"3.6 [实时]-Databus\"></a>3.6 [实时]-Databus</h3><p>Databus是LinkedIn开源的一款低延迟的分布式数据库同步系统（a source-agnostic distributed change data capture system），它提供可靠的数据捕获、流转和数据处理功能。Databus将数据库作为唯一真实数据来源，并将变更从事务或提交日志中提取出来，然后通知相关的衍生数据库或缓存。 Databus传输层端到端的延迟是微秒级别的，这意味着每台服务器每秒可以处理数千次数据吞吐变更事件,同时还支持无限回溯能力和丰富的变更订阅功能，</p>\n<p>项目地址: <a href=\"https://github.com/linkedin/databus\" target=\"_blank\" rel=\"noopener\">https://github.com/linkedin/databus</a></p>\n<h3 id=\"3-7-实时-MySQL主从同步\"><a href=\"#3-7-实时-MySQL主从同步\" class=\"headerlink\" title=\"3.7 [实时]-MySQL主从同步\"></a>3.7 [实时]-MySQL主从同步</h3><p><strong>1.asynchronous 异步复制</strong></p>\n<p>原理：在异步复制中，master写数据到binlog且sync，无需等待slave。slave request binlog后写入relay-log并flush disk。</p>\n<p>优点：复制的性能最好</p>\n<p>缺点：master挂掉后，slave可能会丢失事务</p>\n<p>代表：MySQL原生的复制</p>\n<p><img src=\"https://yqfile.alicdn.com/f30dd5a58ea24c87365127b3951a067a3c23134d.jpeg\" alt=\"异步复制\"></p>\n<p><strong>2.fully synchronous 全同步复制</strong></p>\n<p>原理：在全同步复制中，master写数据到binlog且sync，所有slave request binlog后写入relay-log并flush disk，并且回放完日志再commit。</p>\n<p>优点：数据不会丢失</p>\n<p>缺点：会阻塞master session，性能太差，非常依赖网络</p>\n<p>代表：MySQL-Cluster</p>\n<p><img src=\"https://yqfile.alicdn.com/99ecf19b4f839b8a6df909c5584a5a0144f090fa.jpeg\" alt=\"全同步复制\"></p>\n<p><strong>3.semi synchronous 半同步复制</strong></p>\n<p>原理: 在半同步复制中，master写数据到binlog且sync，且commit，然后一直等待ACK。当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）</p>\n<p>优点：会有数据丢失风险（低）</p>\n<p>缺点：会阻塞master session，性能差，非常依赖网络</p>\n<p>代表：after commit, 原生的半同步</p>\n<p>重点：由于master是在三段提交的最后commit阶段完成后才等待，所以master的其他session是可以看到这个提交事务的，所以这时候master上的数据和slave不一致，master crash后，slave数据丢失。</p>\n<p><img src=\"https://yqfile.alicdn.com/7f465154accff14368ff16d0b011dfc1b82cbac6.jpeg\" alt=\"半同步复制\"></p>\n<p><strong>4.lossless replication 无损复制</strong></p>\n<p>原理: 在半同步复制中，master写数据到binlog且sync，然后一直等待ACK. 当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）</p>\n<p>优点：数据零丢失（前提是让其一直是lossless replication），性能好</p>\n<p>缺点：会阻塞master session，非常依赖网络</p>\n<p>代表：after sync, 原生的半同步</p>\n<p>重点：由于master是在三段提交的第二阶段sync binlog完成后才等待, 所以master的其他session是看不见这个提交事务的，所以这时候master上的数据和slave一致，master crash后，slave没有丢失数据。</p>\n<p><img src=\"https://yqfile.alicdn.com/6c77a9f51c3a9cdb0e783607752ebcbad01cbbf3.jpeg\" alt=\"无损复制\"></p>\n<h2 id=\"4-延迟同步如何解决？\"><a href=\"#4-延迟同步如何解决？\" class=\"headerlink\" title=\"4.延迟同步如何解决？\"></a>4.延迟同步如何解决？</h2><h3 id=\"4-1-主从同步的原理\"><a href=\"#4-1-主从同步的原理\" class=\"headerlink\" title=\"4.1 主从同步的原理\"></a>4.1 主从同步的原理</h3><p>主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。master可以并发，Slave_SQL_Running线程不可以并发。</p>\n<h3 id=\"4-2-延迟怎么产生的\"><a href=\"#4-2-延迟怎么产生的\" class=\"headerlink\" title=\"4.2 延迟怎么产生的\"></a>4.2 延迟怎么产生的</h3><p>当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。</p>\n<p>首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高。</p>\n<p>次要原因：读写binlog带来的性能影响，网络传输延迟。</p>\n<h3 id=\"4-3-同步延迟解决方案\"><a href=\"#4-3-同步延迟解决方案\" class=\"headerlink\" title=\"4.3 同步延迟解决方案\"></a>4.3 同步延迟解决方案</h3><p><strong>一、架构方面</strong></p>\n<p>1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。</p>\n<p>2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。</p>\n<p>3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。</p>\n<p>4.不同业务的mysql物理上放在不同机器，分散压力。</p>\n<p>5.使用比主库更好的硬件设备作为slave</p>\n<p>总结，mysql压力小，延迟自然会变小。</p>\n<p><strong>二、硬件方面</strong></p>\n<p>1.采用好服务器，比如4u比2u性能明显好，2u比1u性能明显好。</p>\n<p>2.存储用ssd或者盘阵或者san，提升随机写的性能。</p>\n<p>3.主从间保证处在同一个交换机下面，并且是万兆环境。</p>\n<p>总结，硬件强劲，延迟自然会变小。一句话，缩小延迟的解决方案就是花钱和花时间。</p>\n<p><strong>三、主从同步加速</strong></p>\n<p>1、sync_binlog在slave端设置为0</p>\n<p>2、–logs-slave-updates 从服务器从主服务器接收到的更新不记入它的二进制日志。</p>\n<p>3、直接禁用slave端的binlog</p>\n<p>4、slave端，如果使用的存储引擎是innodb，innodb_flush_log_at_trx_commit =2</p>\n<p><strong>四、文件系统属性优化</strong></p>\n<p>master端修改linux、Unix文件系统中文件的etime属性， 由于每当读文件时OS都会将读取操作发生的时间回写到磁盘上，对于读操作频繁的数据库文件来说这是没必要的，只会增加磁盘系统的负担影响I/O性能。可以通过设置文件系统的mount属性，组织操作系统写atime信息，在linux上的操作为：<br>打开/etc/fstab，加上noatime参数 /dev/sdb1 /data reiserfs noatime 1 2 然后重新mount文件系统 #mount -oremount /data</p>\n<h2 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h2><p>MySQL的读写分离的几种选择；<a href=\"https://www.cnblogs.com/fyc119/p/7529902.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/fyc119/p/7529902.html</a></p>\n<p>mysql的读写分离Amoeba：<a href=\"http://blog.51cto.com/freeze/860111\" target=\"_blank\" rel=\"noopener\">http://blog.51cto.com/freeze/860111</a></p>\n<p>Amoeba搞定mysql主从读写分离: <a href=\"http://blog.chinaunix.net/uid-20639775-id-154600.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-20639775-id-154600.html</a></p>\n<p>MySQL主从延时这么长，要怎么优化？: <a href=\"https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ</a></p>\n<p>mysql数据库从库同步延迟的问题：<a href=\"https://blog.csdn.net/caomiao2006/article/details/51011373\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caomiao2006/article/details/51011373</a></p>\n<p>MySQL 主从同步延迟的原因及解决办法：<a href=\"https://blog.csdn.net/Soar_Away/article/details/72615012\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Soar_Away/article/details/72615012</a></p>\n<p>数据同步工具: <a href=\"https://blog.csdn.net/frog4/article/details/79624664\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/frog4/article/details/79624664</a></p>\n<p>Databus简介: <a href=\"https://blog.csdn.net/acm_lkl/article/details/78645406\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/acm_lkl/article/details/78645406</a></p>\n<p>DataBus&amp;Canal对比: <a href=\"http://www.cnblogs.com/xunshao/p/9762377.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/xunshao/p/9762377.html</a></p>\n<p>MySQL无损复制： <a href=\"https://yq.aliyun.com/articles/59258\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/59258</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-读写分离方案\"><a href=\"#1-读写分离方案\" class=\"headerlink\" title=\"1.读写分离方案\"></a>1.读写分离方案</h2><p>目前要实现mysql的主从读写分离，主要有以下几种方案：<br>","more":"</p>\n<h3 id=\"1-1-修改源码\"><a href=\"#1-1-修改源码\" class=\"headerlink\" title=\"1.1 修改源码\"></a>1.1 修改源码</h3><p>通过程序实现，网上很多现成的代码，比较复杂，如果添加从服务器要更改多台服务器的代码。</p>\n<h3 id=\"1-2-自研\"><a href=\"#1-2-自研\" class=\"headerlink\" title=\"1.2 自研\"></a>1.2 自研</h3><p>自己开发接口实现，这种方案门槛高，开发成本高，不是一般的小公司能承担得起。</p>\n<h3 id=\"1-3-中间件\"><a href=\"#1-3-中间件\" class=\"headerlink\" title=\"1.3 中间件\"></a>1.3 中间件</h3><p>由于mysql-proxy的主从读写分离是通过lua脚本来实现，目前lua的脚本的开发跟不上节奏，而写没有完美的现成的脚本，因此导致用于生产环境的话风险比较大，据网上很多人说mysql-proxy的性能不高。阿里开源项目Amoeba具有负载均衡、高可用性、sql过滤、读写分离、可路由相关的query到目标数据库，并且安装配置非常简单。</p>\n<h2 id=\"2-读写分离中间件\"><a href=\"#2-读写分离中间件\" class=\"headerlink\" title=\"2.读写分离中间件\"></a>2.读写分离中间件</h2><h3 id=\"2-1-活跃中的项目\"><a href=\"#2-1-活跃中的项目\" class=\"headerlink\" title=\"2.1 活跃中的项目\"></a>2.1 活跃中的项目</h3><h4 id=\"2-1-1-活跃-MySQL-Router-官方\"><a href=\"#2-1-1-活跃-MySQL-Router-官方\" class=\"headerlink\" title=\"2.1.1 [活跃]-MySQL-Router(官方)\"></a>2.1.1 [活跃]-MySQL-Router(官方)</h4><p>官网地址: <a href=\"https://dev.mysql.com/doc/mysql-router/8.0/en/\" target=\"_blank\" rel=\"noopener\">https://dev.mysql.com/doc/mysql-router/8.0/en/</a></p>\n<p>由MySQL官方提供，MySQL Router用于取代MySQL Proxy，建议MySQL Router与应用程序部署在一台机器。应用程序像访问MySQL一样访问MySQL Proxy，由MySQL Proxy将数据转发给后端的MySQL。支持各种操作系统。</p>\n<p><img src=\"https://image-static.segmentfault.com/290/493/2904939003-5a074a6f6e7ea_articlex\" alt=\"架构图\"></p>\n<p>使用MySQL-Router实现应用程序的高可用: <a href=\"https://segmentfault.com/a/1190000011970688\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000011970688</a></p>\n<h4 id=\"2-1-2-活跃-MySQL-Cluster-官方\"><a href=\"#2-1-2-活跃-MySQL-Cluster-官方\" class=\"headerlink\" title=\"2.1.2 [活跃]-MySQL-Cluster(官方)\"></a>2.1.2 [活跃]-MySQL-Cluster(官方)</h4><p>MySQL Cluster 是MySQL 官方集群部署方案，它的历史较久。支持通过自动分片支持读写扩展，通过实时备份冗余数据，是可用性最高的方案，声称可做到99.999%的可用性。MySQL-Cluster 的稳定性也不是太好。</p>\n<p><img src=\"http://www.2cto.com/uploadfile/Collfiles/20150402/2015040210055875.png\" alt=\"MySQL-Cluster\"></p>\n<p>实战体验几种MySQLCluster方案: <a href=\"https://www.2cto.com/database/201504/387166.html\" target=\"_blank\" rel=\"noopener\">https://www.2cto.com/database/201504/387166.html</a></p>\n<h4 id=\"2-1-3-活跃-MaxScale-MariaDB\"><a href=\"#2-1-3-活跃-MaxScale-MariaDB\" class=\"headerlink\" title=\"2.1.3 [活跃]-MaxScale(MariaDB)\"></a>2.1.3 [活跃]-MaxScale(MariaDB)</h4><p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。</p>\n<p>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>MaxScale是mariadb开发的一个MySQL数据中间件，配置好MySQL的主从复制架构后，可以实现读写分离，把读操作分散到从服务器中，并且对多个服务器实现负载均衡。MaxScale是插件式结构，允许用户开发适合自己的插件。MaxScale 使用 C 语言开发，利用 Linux 下的异步 I/O 功能。使用 epoll 作为事件驱动框架。</p>\n<p>MaxScale有两种方式实现读/写分离。一种是基于connect的，类似于Haproxy，不解析SQL语句，可以通过PHP Yii框架或Java Mybatis框架实现。在此方式中，用Maxscale做多台slave的负载均衡，并且支持主从同步延迟检测功能。</p>\n<p><img src=\"https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115910151-347833274.png\" alt=\"负载均衡\"></p>\n<p><img src=\"https://images2017.cnblogs.com/blog/883511/201709/883511-20170925115734901-1106073519.png\" alt=\"读写分离\"></p>\n<p>官网地址: <a href=\"https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/\" target=\"_blank\" rel=\"noopener\">https://mariadb.com/kb/en/mariadb-enterprise/mariadb-maxscale-20/</a></p>\n<p>利用Maxscale实现MySQL读写分离：<a href=\"https://www.cnblogs.com/darren-lee/p/7591416.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/darren-lee/p/7591416.html</a></p>\n<h4 id=\"2-1-4-活跃-Galera-Cluster-MariaDB\"><a href=\"#2-1-4-活跃-Galera-Cluster-MariaDB\" class=\"headerlink\" title=\"2.1.4 [活跃]-Galera-Cluster(MariaDB)\"></a>2.1.4 [活跃]-Galera-Cluster(MariaDB)</h4><p>Mariadb Galera Cluster是一款优秀的中间件软件，同样可以实现读写分离，负载均衡等功能，并且稳定性要大大超过MySQL-Proxy，建议大家用来替代MySQL-Proxy，甚至MySQL-Cluster。</p>\n<p>浅谈MariaDB Galera Cluster架构: <a href=\"https://www.cnblogs.com/vadim/p/6930566.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/vadim/p/6930566.html</a></p>\n<h3 id=\"2-2-停滞或未开源的项目\"><a href=\"#2-2-停滞或未开源的项目\" class=\"headerlink\" title=\"2.2 停滞或未开源的项目\"></a>2.2 停滞或未开源的项目</h3><h4 id=\"2-2-1-停滞-MySQL-Proxy-官方\"><a href=\"#2-2-1-停滞-MySQL-Proxy-官方\" class=\"headerlink\" title=\"2.2.1 [停滞]-MySQL-Proxy(官方)\"></a>2.2.1 [停滞]-MySQL-Proxy(官方)</h4><p>mysql官方提供的mysql中间件服务，上游可接入若干个mysql-client，后端可连接若干个mysql-server。它使用mysql协议，任何使用mysql-client的上游无需修改任何代码，即可迁移至mysql-proxy上。MySQL Proxy强大的一项功能是实现“读写分离（Read/Write Splitting）”。基本的原理是让主数据库处理事务性查询，而从数据库处理SELECT查询。数据库复制被用来把事务性查询导致的变更同步到集群中的从数据库。</p>\n<p>MySQL-Proxy实现读写分离提高并发负载案例：<a href=\"http://blog.jobbole.com/94606/\" target=\"_blank\" rel=\"noopener\">http://blog.jobbole.com/94606/</a></p>\n<p>MySQL-Proxy实际上非常不稳定，在高并发或有错误连接的情况下，进程很容易自动关闭，因此打开–keepalive参数让进程自动恢复是个比较好的办法，但还是不能从根本上解决问题，因此通常最稳妥的做法是在每个从服务器上安装一个MySQL-Proxy供自身使用，虽然比较低效但却能保证稳定性；</p>\n<h4 id=\"2-2-2-停滞-Atlas-MySQL-Proxy增强版\"><a href=\"#2-2-2-停滞-Atlas-MySQL-Proxy增强版\" class=\"headerlink\" title=\"2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)\"></a>2.2.2 [停滞]-Atlas(MySQL-Proxy增强版)</h4><p>Atlas是由 Qihoo 360公司Web平台部基础架构团队开发维护的一个基于MySQL协议的数据中间层项目。它在MySQL官方推出的MySQL-Proxy 0.8.2版本的基础上，修改了大量bug，添加了很多功能特性。由于团队精力有限, 不再主要维护，很多Issue很难再继续满足。</p>\n<p>项目地址: <a href=\"https://github.com/Qihoo360/Atlas\" target=\"_blank\" rel=\"noopener\">https://github.com/Qihoo360/Atlas</a></p>\n<h4 id=\"2-2-3-停滞-DBProxy-Atlas美团版\"><a href=\"#2-2-3-停滞-DBProxy-Atlas美团版\" class=\"headerlink\" title=\"2.2.3 [停滞]-DBProxy(Atlas美团版)\"></a>2.2.3 [停滞]-DBProxy(Atlas美团版)</h4><p>项目地址: <a href=\"https://github.com/Meituan-Dianping/DBProxy\" target=\"_blank\" rel=\"noopener\">https://github.com/Meituan-Dianping/DBProxy</a></p>\n<p>DBProxy是由美团点评公司技术工程部DBA团队（北京）开发维护的一个基于MySQL协议的数据中间层。它在奇虎360公司开源的Atlas基础上，修改了部分bug，并且添加了很多特性。最后提交时间2016年。</p>\n<h4 id=\"2-2-4-未开源-MTAtlas-Atlas美团版\"><a href=\"#2-2-4-未开源-MTAtlas-Atlas美团版\" class=\"headerlink\" title=\"2.2.4 [未开源]-MTAtlas(Atlas美团版)\"></a>2.2.4 [未开源]-MTAtlas(Atlas美团版)</h4><p>原美团DBA团队在开源Atlas基础上做的一系列升级改造。在读写分离、单库分表的基础上，完成了分库分表的功能开发。</p>\n<h4 id=\"2-2-5-未开源-ArkProxy-极数云舟\"><a href=\"#2-2-5-未开源-ArkProxy-极数云舟\" class=\"headerlink\" title=\"2.2.5 [未开源]-ArkProxy(极数云舟)\"></a>2.2.5 [未开源]-ArkProxy(极数云舟)</h4><p>极数云舟(<a href=\"http://www.cloud-ark.com\" target=\"_blank\" rel=\"noopener\">http://www.cloud-ark.com</a>) 公司开发的数据库中间件，核心特性包括:透明读写分离,兼容性,友好性,权重分发,消息压缩,从库接入,用户连接数限制及统计,丰富的参数配置,连接池,失败重试。</p>\n<p><img src=\"http://www.cloud-ark.com/static/product_img/Arkproxy.png\" alt=\"ArkProxy\"></p>\n<h4 id=\"2-2-6-停滞-Amoeba-阿里\"><a href=\"#2-2-6-停滞-Amoeba-阿里\" class=\"headerlink\" title=\"2.2.6 [停滞]-Amoeba(阿里)\"></a>2.2.6 [停滞]-Amoeba(阿里)</h4><p>Amoeba是淘宝的得力作品。支持读写分离，表和库级别的读写分离，数据库水平分割，垂直分割，还有集群。mysql-proxy 只是轻量级的读写分离程序，虽然C写的，但是驱动是需要lua的脚本跑，而且在高并发下经常挂掉。程序还忽略了一些字符设定，如果数据库不是同一编码还会出现乱码,amoeba就不存在。</p>\n<p>Amoeba致力于MySQL的分布式数据库前端代理层，它主要在应用层访问MySQL的 时候充当SQL路由功能，专注于分布式数据库代理层（Database Proxy）开发。座落与 Client、DB Server(s)之间,对客户端透明。具有负载均衡、高可用性、SQL 过滤、读写分离、可路由相关的到目标数据库、可并发请求多台数据库合并结果。</p>\n<p>Amoeba作者陈思儒离职去盛大之后，阿里巴巴内部考虑到Amoeba的稳定性、性能和功能支持，以及其他因素，重新设立了一个项目组并且更换名称为Cobar，现在Cobar已经开源了，详情见： <a href=\"http://www.mysqlops.com/2012/06/19/cobar-alibaba.html\" target=\"_blank\" rel=\"noopener\">http://www.mysqlops.com/2012/06/19/cobar-alibaba.html</a></p>\n<p>项目地址：<a href=\"https://sourceforge.net/projects/amoeba/\" target=\"_blank\" rel=\"noopener\">https://sourceforge.net/projects/amoeba/</a></p>\n<h2 id=\"3-数据同步工具\"><a href=\"#3-数据同步工具\" class=\"headerlink\" title=\"3.数据同步工具\"></a>3.数据同步工具</h2><h3 id=\"3-1-离线-DataX\"><a href=\"#3-1-离线-DataX\" class=\"headerlink\" title=\"3.1 [离线]-DataX\"></a>3.1 [离线]-DataX</h3><p>阿里的Datax是比较优秀的产品，基于python，提供各种数据库的读写插件，多线程执行，使用起来也很简单，定义好配置json文件执行脚本就可以了，非常适合离线数据，增量数据可以使用一些编码的方式实现，但是也仅仅针对insert数据比较有效，update数据就不适合。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/DataX\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/DataX</a></p>\n<h3 id=\"3-2-离线-Sqoop\"><a href=\"#3-2-离线-Sqoop\" class=\"headerlink\" title=\"3.2 [离线]-Sqoop\"></a>3.2 [离线]-Sqoop</h3><p>Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。Sqoop在数据库的支持的丰富性上不如DataX，但是如果你用hadoop，用sqoop是更好的选择，因为做Apache的顶级项目，他背后的支持远远比阿里一家公司靠谱的多。</p>\n<p>官网：<a href=\"http://sqoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://sqoop.apache.org/</a></p>\n<h3 id=\"3-3-离线-Kettle\"><a href=\"#3-3-离线-Kettle\" class=\"headerlink\" title=\"3.3 [离线]-Kettle\"></a>3.3 [离线]-Kettle</h3><p>Kettle是一款国外开源的ETL工具，纯java编写，可以在Window、Linux、Unix上运行，数据抽取高效稳定。Kettle作为传统ETL工具，目前也都已经有了nosql数据库的支持，而且kettle还有图形界面可以用，使用起来简单多了。而且本来就是专门做ETL的，是Pentaho指定的ETL组件，对于数据清洗等处理数据的环节支持更好。但是数据效率一般，而且在生产环境也很少弄台windows机器，适合小项目，数据量比较小的同步。</p>\n<p>Kettle 中文名称叫水壶，该项目的主程序员MATT 希望把各种数据放到一个壶里，然后以一种指定的格式流出。</p>\n<p>官网：<a href=\"https://community.hitachivantara.com/docs/DOC-1009855\" target=\"_blank\" rel=\"noopener\">https://community.hitachivantara.com/docs/DOC-1009855</a></p>\n<h3 id=\"3-4-实时-Canal\"><a href=\"#3-4-实时-Canal\" class=\"headerlink\" title=\"3.4 [实时]-Canal\"></a>3.4 [实时]-Canal</h3><p>Canal是基于mysql的binlog进行数据同步的中间件。简单来说，Canal 会将自己伪装成 MySQL 从节点（Slave），并从主节点（Master）获取 Binlog，解析和贮存后供下游消费端使用。Canal 包含两个组成部分：服务端和客户端。服务端负责连接至不同的 MySQL 实例，并为每个实例维护一个事件消息队列；客户端则可以订阅这些队列中的数据变更事件，处理并存储到数据仓库中。</p>\n<p>使用的话，安装好canal，配置好数据库参数，再编写一个客户端消费canal传过来的数据就可以了。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/canal\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/canal</a></p>\n<h3 id=\"3-5-实时-Otter\"><a href=\"#3-5-实时-Otter\" class=\"headerlink\" title=\"3.5 [实时]-Otter\"></a>3.5 [实时]-Otter</h3><p>otter是在canal基础上又重新实现了可配置的消费者，使用otter的话，刚才说过的消费者就不需要写了，而otter提供了一个web界面，可以自定义同步任务及map表。非常适合mysql库之间的同步。而且通过retl_buff表的监控，也可以实现一些全量数据的同步。</p>\n<p>但是otter也有一些不好的地方，比如界面上的参数并不是所有的都有用，文档写的一般，不是很清晰。但是想想省了好多事，还是非常好的一款中间件。</p>\n<p>github地址：<a href=\"https://github.com/alibaba/otter\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/otter</a></p>\n<h3 id=\"3-6-实时-Databus\"><a href=\"#3-6-实时-Databus\" class=\"headerlink\" title=\"3.6 [实时]-Databus\"></a>3.6 [实时]-Databus</h3><p>Databus是LinkedIn开源的一款低延迟的分布式数据库同步系统（a source-agnostic distributed change data capture system），它提供可靠的数据捕获、流转和数据处理功能。Databus将数据库作为唯一真实数据来源，并将变更从事务或提交日志中提取出来，然后通知相关的衍生数据库或缓存。 Databus传输层端到端的延迟是微秒级别的，这意味着每台服务器每秒可以处理数千次数据吞吐变更事件,同时还支持无限回溯能力和丰富的变更订阅功能，</p>\n<p>项目地址: <a href=\"https://github.com/linkedin/databus\" target=\"_blank\" rel=\"noopener\">https://github.com/linkedin/databus</a></p>\n<h3 id=\"3-7-实时-MySQL主从同步\"><a href=\"#3-7-实时-MySQL主从同步\" class=\"headerlink\" title=\"3.7 [实时]-MySQL主从同步\"></a>3.7 [实时]-MySQL主从同步</h3><p><strong>1.asynchronous 异步复制</strong></p>\n<p>原理：在异步复制中，master写数据到binlog且sync，无需等待slave。slave request binlog后写入relay-log并flush disk。</p>\n<p>优点：复制的性能最好</p>\n<p>缺点：master挂掉后，slave可能会丢失事务</p>\n<p>代表：MySQL原生的复制</p>\n<p><img src=\"https://yqfile.alicdn.com/f30dd5a58ea24c87365127b3951a067a3c23134d.jpeg\" alt=\"异步复制\"></p>\n<p><strong>2.fully synchronous 全同步复制</strong></p>\n<p>原理：在全同步复制中，master写数据到binlog且sync，所有slave request binlog后写入relay-log并flush disk，并且回放完日志再commit。</p>\n<p>优点：数据不会丢失</p>\n<p>缺点：会阻塞master session，性能太差，非常依赖网络</p>\n<p>代表：MySQL-Cluster</p>\n<p><img src=\"https://yqfile.alicdn.com/99ecf19b4f839b8a6df909c5584a5a0144f090fa.jpeg\" alt=\"全同步复制\"></p>\n<p><strong>3.semi synchronous 半同步复制</strong></p>\n<p>原理: 在半同步复制中，master写数据到binlog且sync，且commit，然后一直等待ACK。当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）</p>\n<p>优点：会有数据丢失风险（低）</p>\n<p>缺点：会阻塞master session，性能差，非常依赖网络</p>\n<p>代表：after commit, 原生的半同步</p>\n<p>重点：由于master是在三段提交的最后commit阶段完成后才等待，所以master的其他session是可以看到这个提交事务的，所以这时候master上的数据和slave不一致，master crash后，slave数据丢失。</p>\n<p><img src=\"https://yqfile.alicdn.com/7f465154accff14368ff16d0b011dfc1b82cbac6.jpeg\" alt=\"半同步复制\"></p>\n<p><strong>4.lossless replication 无损复制</strong></p>\n<p>原理: 在半同步复制中，master写数据到binlog且sync，然后一直等待ACK. 当至少一个slave request bilog后写入到relay-log并flush disk，就返回ack（不需要回放完日志）</p>\n<p>优点：数据零丢失（前提是让其一直是lossless replication），性能好</p>\n<p>缺点：会阻塞master session，非常依赖网络</p>\n<p>代表：after sync, 原生的半同步</p>\n<p>重点：由于master是在三段提交的第二阶段sync binlog完成后才等待, 所以master的其他session是看不见这个提交事务的，所以这时候master上的数据和slave一致，master crash后，slave没有丢失数据。</p>\n<p><img src=\"https://yqfile.alicdn.com/6c77a9f51c3a9cdb0e783607752ebcbad01cbbf3.jpeg\" alt=\"无损复制\"></p>\n<h2 id=\"4-延迟同步如何解决？\"><a href=\"#4-延迟同步如何解决？\" class=\"headerlink\" title=\"4.延迟同步如何解决？\"></a>4.延迟同步如何解决？</h2><h3 id=\"4-1-主从同步的原理\"><a href=\"#4-1-主从同步的原理\" class=\"headerlink\" title=\"4.1 主从同步的原理\"></a>4.1 主从同步的原理</h3><p>主库针对写操作，顺序写binlog，从库单线程去主库顺序读”写操作的binlog”，从库取到binlog在本地原样执行（随机写），来保证主从数据逻辑上一致。mysql的主从复制都是单线程的操作，主库对所有DDL和DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率比较高，下一步，问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。master可以并发，Slave_SQL_Running线程不可以并发。</p>\n<h3 id=\"4-2-延迟怎么产生的\"><a href=\"#4-2-延迟怎么产生的\" class=\"headerlink\" title=\"4.2 延迟怎么产生的\"></a>4.2 延迟怎么产生的</h3><p>当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。</p>\n<p>首要原因：数据库在业务上读写压力太大，CPU计算负荷大，网卡负荷大，硬盘随机IO太高。</p>\n<p>次要原因：读写binlog带来的性能影响，网络传输延迟。</p>\n<h3 id=\"4-3-同步延迟解决方案\"><a href=\"#4-3-同步延迟解决方案\" class=\"headerlink\" title=\"4.3 同步延迟解决方案\"></a>4.3 同步延迟解决方案</h3><p><strong>一、架构方面</strong></p>\n<p>1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。</p>\n<p>2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。</p>\n<p>3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。</p>\n<p>4.不同业务的mysql物理上放在不同机器，分散压力。</p>\n<p>5.使用比主库更好的硬件设备作为slave</p>\n<p>总结，mysql压力小，延迟自然会变小。</p>\n<p><strong>二、硬件方面</strong></p>\n<p>1.采用好服务器，比如4u比2u性能明显好，2u比1u性能明显好。</p>\n<p>2.存储用ssd或者盘阵或者san，提升随机写的性能。</p>\n<p>3.主从间保证处在同一个交换机下面，并且是万兆环境。</p>\n<p>总结，硬件强劲，延迟自然会变小。一句话，缩小延迟的解决方案就是花钱和花时间。</p>\n<p><strong>三、主从同步加速</strong></p>\n<p>1、sync_binlog在slave端设置为0</p>\n<p>2、–logs-slave-updates 从服务器从主服务器接收到的更新不记入它的二进制日志。</p>\n<p>3、直接禁用slave端的binlog</p>\n<p>4、slave端，如果使用的存储引擎是innodb，innodb_flush_log_at_trx_commit =2</p>\n<p><strong>四、文件系统属性优化</strong></p>\n<p>master端修改linux、Unix文件系统中文件的etime属性， 由于每当读文件时OS都会将读取操作发生的时间回写到磁盘上，对于读操作频繁的数据库文件来说这是没必要的，只会增加磁盘系统的负担影响I/O性能。可以通过设置文件系统的mount属性，组织操作系统写atime信息，在linux上的操作为：<br>打开/etc/fstab，加上noatime参数 /dev/sdb1 /data reiserfs noatime 1 2 然后重新mount文件系统 #mount -oremount /data</p>\n<h2 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h2><p>MySQL的读写分离的几种选择；<a href=\"https://www.cnblogs.com/fyc119/p/7529902.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/fyc119/p/7529902.html</a></p>\n<p>mysql的读写分离Amoeba：<a href=\"http://blog.51cto.com/freeze/860111\" target=\"_blank\" rel=\"noopener\">http://blog.51cto.com/freeze/860111</a></p>\n<p>Amoeba搞定mysql主从读写分离: <a href=\"http://blog.chinaunix.net/uid-20639775-id-154600.html\" target=\"_blank\" rel=\"noopener\">http://blog.chinaunix.net/uid-20639775-id-154600.html</a></p>\n<p>MySQL主从延时这么长，要怎么优化？: <a href=\"https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/pP2f7CYbT7ftM0tvk9c4mQ</a></p>\n<p>mysql数据库从库同步延迟的问题：<a href=\"https://blog.csdn.net/caomiao2006/article/details/51011373\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caomiao2006/article/details/51011373</a></p>\n<p>MySQL 主从同步延迟的原因及解决办法：<a href=\"https://blog.csdn.net/Soar_Away/article/details/72615012\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Soar_Away/article/details/72615012</a></p>\n<p>数据同步工具: <a href=\"https://blog.csdn.net/frog4/article/details/79624664\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/frog4/article/details/79624664</a></p>\n<p>Databus简介: <a href=\"https://blog.csdn.net/acm_lkl/article/details/78645406\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/acm_lkl/article/details/78645406</a></p>\n<p>DataBus&amp;Canal对比: <a href=\"http://www.cnblogs.com/xunshao/p/9762377.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/xunshao/p/9762377.html</a></p>\n<p>MySQL无损复制： <a href=\"https://yq.aliyun.com/articles/59258\" target=\"_blank\" rel=\"noopener\">https://yq.aliyun.com/articles/59258</a></p>"},{"layout":"lay_post","title":"NoSQL方案选型","date":"2018-11-29T16:00:00.000Z","author":"lvyafei","_content":"\n## 1.关系型数据库缺点\n\n### 1.1.大数据场景下 I/O 较高\n\n因为数据是按 行存储，即使只针对其中 某一列 进行运算，关系型数据库也会对 整行数据 进行扫描，从存储设备中 读入内存，导致 I/O 较高\n<!-- more -->\n\n### 1.2.结构化存储 不够灵活\n\n存储的是 行记录，无法存储 灵活的数据结构\n\n### 1.3.表结构 schema 扩展不方便\n\n如要需要修改 表结构，需要执行执行 DDL（data definition language）语句修改，修改期间会导致 锁表，部分服务不可用\n\n### 1.4.全文搜索 功能较弱\n\n关系型数据库只能够进行 子字符串 的 匹配查询，当表的数据逐渐变大的时候，即使在有 索引 的情况下，like 扫表查询的匹配会 非常慢\n\n### 1.5.难以 存储 和 处理 复杂 关系型数据\n\n传统的关系数据库，并不擅长处理 数据点之间 的关系\n\nNoSQL 在许多方面性能大大优于 非关系型 数据库的同时，往往也伴随一些特性的缺失。比较常见的是 事务功能 的缺失。\n\n针对传统 关系型数据库 的不足，下面介绍常见的 5 大类 NoSQL 解决方案：\n\n## 2.NoSQL方案类型\n\n### 2.1 列式数据库\n\n列式数据库 是以 列相关存储架构 进行数据存储的数据库，主要适合于 批量数据处理 和 即时查询。相对应的是 行式数据库，数据以 行相关的存储架构 进行空间分配，主要适合于 小批量 的 数据处理，常用于 联机事务型数据处理。\n\n**基于列式数据库的 列存储特性，可以解决某些特定场景下 关系型数据库 高 I/O 的问题。**\n\n**HBase**\n\n运行于 HDFS 文件系统之上，为 Hadoop 提供类似于 BigTable 规模的服务。因此，它可以 容错地 存储 海量稀疏 的数据\n\n**BigTable**\n\n基于 Google 文件系统（Google File System，GFS）的数据存储系统，用于存储 大规模结构化数据，适用于云计算\n\n<font color=red>**优点：**</font>\n\n1.高效的储存空间利用率\n\n2.查询效率高\n\n3.适合做聚合操作\n\n4.适合大量的数据而不是小数据\n\n<font color=blue>**缺点：**</font>\n\n1.不适合扫描 小量数据\n\n2.不适合 随机的更新\n\n3.不适合做含有删除和更新的 实时操作\n\n4.单行数据 支持 ACID 的 事务操作，多行数据 的 事务操作，不支持事务的 正常回滚，支持 （Isolation）隔离性、(Durability）持久性，不能保证 (Atomicity）原子性、（Consistency）一致性\n\n### 2.2 K-V数据库\n\n使用 键值（key-value）存储的数据库，其数据按照 键值对 的形式进行 组织、索引 和 存储。\n\n**KV 存储非常适合不涉及过多 数据关系 业务的数据。它能够有效减少 读写磁盘 的次数，比 SQL 数据库存储 拥有更好的 读写性能，能够解决 关系型数据库 无法存储 数据结构 的问题。**\n\n**Redis**\n\nRedis 是一个使用 ANSI C 编写的 开源、支持网络、基于内存、可选持久性 的 键值对存储 数据库。Redis 是目前最流行的 键值对存储 数据库之一\n\n**Cassandra**\n\nApache Cassandra（社区内一般简称为 C*）是一套 开源的分布式 NoSQL 数据库系统。它最初由 Facebook 开发，用于储存 收件箱 等简单格式数据，集 Google BigTable 的 数据模型 与 Amazon Dynamo 的 完全分布式 架构于一身。Cassandra 是一种流行的 分布式结构化 数据存储方案\n\n**Memcached**\n\nMemcached 是一个 开放源代码、高性能、分配的 内存对象缓存系统。用于加速动态 web 应用程序，减轻关系型数据库负载。它可以应对 任意多个连接，使用 非阻塞的网络 IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个 Hash 表，Memcached 自管理这些 Hash 表。\n\n**LevelDB**\n\nLevelDB 是一个由 Google 所研发的 键／值对（Key/Value Pair）嵌入式 数据库管理系统 编程库，以开源的 BSD 许可证发布。\n\n<font color=red>**优点：</font>\n\n1.性能极高\n\n2.丰富的数据类型\n\n3.丰富的特性\n\n<font color=blue>**缺点：</font>\n\n事务 不能支持 原子性 和 持久性（A 和 D），只支持 隔离性 和 一致性（I 和 C）。\n\n### 2.3 文档型数据库\n\n文档数据库 用于将 半结构化数据 存储为 文档 的一种数据库。文档数据库通常以 JSON 或 XML 格式存储数据。\n\n**由于文档数据库的 no-schema 特性，可以 存储 和 读取 任意数据。**\n\n**MongoDB**\n\nMongoDB 是一个基于 分布式文件存储 的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的 高性能 数据存储解决方案。MongoDB 是一个介于 关系数据库 和 非关系数据库 之间的产品，是非关系数据库当中功能 最丰富，最像关系数据库的 NoSQL。\n\n**CouchDB**\n\nCouchDB 是用 Erlang 开发的 面向文档 的 分布式 数据库，用于存储 半结构化 的数据，比较类似 lucene 的 index 结构。CouchDB 支持 RESTful API，它使用 JSON 作为 存储格式，JavaScript 作为 查询语言，MapReduce 和 HTTP 作为 API 的 NoSQL 数据库。其中一个显著的功能就是 多主复制 功能。除此之外，CouchDB 构建在强大的 B- 树储存引擎 之上。\n\n<font color=red>**优点：</font>\n\n1.新增字段简单不需要像关系型数据库一样，先执行 DDL 语句 修改表结构，程序代码 直接读写 即可。\n\n2.容易兼容 历史数据。对于历史数据，即使没有新增的字段，也不会导致错误，只会返回 空值，此时 代码兼容处理 即可。\n\n3.容易存储复杂数据。JSON 是一种强大的 描述语言，能够描述复杂的 数据结构\n\n<font color=blue>**缺点：</font>\n\n1.Atomicity（原子性）：仅支持 单行/文档级原子性，不支持 多行、多文档、多语句原子性。\n\n2.Isolation（隔离性）：隔离级别仅支持 已提交读（Read committed）级别，可能导致 不可重复读，幻读 的问题。\n\n3.不支持 复杂查询。例如 join 查询，如果需要 join 查询，需要 多次操作数据库。\n\n### 2.4 全文搜索引擎\n\n全文搜索引擎 的技术原理称为 倒排索引（inverted index），是一种 索引方法，其基本原理是建立 单词 到 文档 的索引。与之相对是，是 正排索引，其基本原理是建立 文档 到 单词 的索引。\n\n**全文搜索引擎的出现，正是解决关系型数据库 全文搜索较弱 的问题。**\n\n**ElasticSearch**\n\nElasticSearch 是一个基于 Apache Lucene 的 搜索引擎。它提供了一个 分布式，多租户 对全文搜索引擎。ElasticSearch 是用 Java 开发的，对外提供 RESTful Web 接口。根据 DB-Engines 排名，ElasticSearch 是最受欢迎的 企业搜索引擎。\n\n**Solr**\n\nSolr 是 Apache Lucene 项目的 开源企业搜索平台。其主要功能包括 全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及 富文本（比如 Word、PDF）处理等等。Solr 是高度 可扩展 的，并提供了 分布式搜索 和 索引复制\n\n<font color=red>**优点：</font>\n\n1.查询效率高，适用于对 海量数据 进行 近实时 的处理。\n\n2.可扩展性\n\n3.基于 集群 环境可以方便 横向扩展，可以承载 PB 级的数据。\n\n4.支持 高可用，ElasticSearch 集群弹性灵活，可以发现新的或失败的节点，重组 和 重新平衡 数据，确保数据是 安全 和 可访问的\n\n<font color=blue>**缺点：</font>\n\n1.事务的 ACID 支持不足，单一文档 的数据是支持 ACID 的。对于 多个文档 的 事务操作，不支持事务的 正常回滚。支持（Isolation）隔离性（基于 乐观锁机制）和（Durability）持久性，不支持（Atomicity）原子性，（Consistency）一致性。\n\n2.对类似数据库中，通过 外键 进行 多表关联的复杂操作支持较弱。\n\n3.读写 有一定 延时，写入的数据，最快 1s 中能被检索到。\n\n4.更新 性能较低，底层实现是 先删数据，再 插入新数据。\n\n5.内存占用大，因为 Lucene 将 索引部分 加载到 内存 中。\n\n### 2.5 图形数据库\n\n图形数据库 应用 图形理论 存储 实体 之间的 关系信息。最常见例子就是 社会网络中人与人之间的关系。关系型数据库 用于存储这种 关系型数据 的效果并不好，其查询 复杂、缓慢、超出预期。\n\n**图形数据库 的独特设计弥补了这个缺陷，解决 关系型 数据库 存储 和 处理复杂关系型数据 功能较弱的问题。**\n\n**Neo4j**\n\nNeo4j 是一个 高性能的，NOSQL 图形数据库，它将 结构化数据 存储在 “图形网络上” 而不是 “表中”。它是一个 嵌入式的、基于磁盘的、具备完全的 事务特性 的 Java 持久化引擎。Neo4j 也可以被看作是一个 高性能的图引擎。程序员工作在一个 面向对象的、灵活的网络结构 下而不是 严格、静态 的 表中。\n\n**ArangoDB**\n\nArangoDB 是一个 原生多模型 数据库系统。数据库系统支持 三个 重要的 数据模型（键/值，文档，图形）。ArangoDB 包含一个 数据库核心 和 统一查询语言 AQL（ArangoDB 查询语言）。查询语言是 声明性的，允许在 单个查询 中 组合 不同的 数据访问模式。ArangoDB 是一个 NoSQL 数据库系统，但 AQL 在很多方面与 SQL 都类似。\n\n<font color=red>**优点：</font>\n\n1.高性能表现\n\n2.设计的灵活性\n\n3.开发的敏捷性\n\n4.完全支持ACID\n\n<font color=blue>**缺点：</font>\n\n1.节点，关系 和它们的 属性 的数量被 限制。\n\n不支持 拆分。\n\n## 3.关系数据库 or NoSQL\n\n关于 关系型数据库 和 NoSQL 数据库 的选型，往往需要考虑几个指标：数据量、并发量、实时性、一致性要求、读写分布、数据类型、安全性、运维成本。\n\n|系统类型|数据库选型|\n|------|------|\n|企业内部管理系统|例如运营系统，数据量少，并发量小，首选考虑 关系型数据库|\n|互联网大流量系统|例如电商单品页，后台考虑选 关系型数据库，前台考虑选 内存型数据库|\n|日志型系统|原始数据 考虑选 列式数据库，日志搜索 考虑选 倒排索引|\n|搜索型系统|例如站内搜索，非通用搜索，商品搜索，后台考虑选 关系型数据库，前台考虑选 倒排索引|\n|事务型系统|例如库存管理，交易，记账，考虑选 关系型数据库 + 缓存数据库 + 一致性型协议|\n|离线计算|例如大量数据分析，考虑选 列式数据库 或者 关系型数据库 都可以|\n|实时计算|例如实时监控，可以考虑选 内存型数据库 或者 列式数据库|\n\n## 4.参考资料\n\n参考：https://blog.csdn.net/baidu_22254181/article/details/82594116","source":"_posts/2018-11-30-NoSQL方案选型.md","raw":"---\nlayout: lay_post\ntitle: \"NoSQL方案选型\"\ndate: 2018-11-30\ncategories: 中间件\ntags: NoSQL\nauthor: lvyafei\n---\n\n## 1.关系型数据库缺点\n\n### 1.1.大数据场景下 I/O 较高\n\n因为数据是按 行存储，即使只针对其中 某一列 进行运算，关系型数据库也会对 整行数据 进行扫描，从存储设备中 读入内存，导致 I/O 较高\n<!-- more -->\n\n### 1.2.结构化存储 不够灵活\n\n存储的是 行记录，无法存储 灵活的数据结构\n\n### 1.3.表结构 schema 扩展不方便\n\n如要需要修改 表结构，需要执行执行 DDL（data definition language）语句修改，修改期间会导致 锁表，部分服务不可用\n\n### 1.4.全文搜索 功能较弱\n\n关系型数据库只能够进行 子字符串 的 匹配查询，当表的数据逐渐变大的时候，即使在有 索引 的情况下，like 扫表查询的匹配会 非常慢\n\n### 1.5.难以 存储 和 处理 复杂 关系型数据\n\n传统的关系数据库，并不擅长处理 数据点之间 的关系\n\nNoSQL 在许多方面性能大大优于 非关系型 数据库的同时，往往也伴随一些特性的缺失。比较常见的是 事务功能 的缺失。\n\n针对传统 关系型数据库 的不足，下面介绍常见的 5 大类 NoSQL 解决方案：\n\n## 2.NoSQL方案类型\n\n### 2.1 列式数据库\n\n列式数据库 是以 列相关存储架构 进行数据存储的数据库，主要适合于 批量数据处理 和 即时查询。相对应的是 行式数据库，数据以 行相关的存储架构 进行空间分配，主要适合于 小批量 的 数据处理，常用于 联机事务型数据处理。\n\n**基于列式数据库的 列存储特性，可以解决某些特定场景下 关系型数据库 高 I/O 的问题。**\n\n**HBase**\n\n运行于 HDFS 文件系统之上，为 Hadoop 提供类似于 BigTable 规模的服务。因此，它可以 容错地 存储 海量稀疏 的数据\n\n**BigTable**\n\n基于 Google 文件系统（Google File System，GFS）的数据存储系统，用于存储 大规模结构化数据，适用于云计算\n\n<font color=red>**优点：**</font>\n\n1.高效的储存空间利用率\n\n2.查询效率高\n\n3.适合做聚合操作\n\n4.适合大量的数据而不是小数据\n\n<font color=blue>**缺点：**</font>\n\n1.不适合扫描 小量数据\n\n2.不适合 随机的更新\n\n3.不适合做含有删除和更新的 实时操作\n\n4.单行数据 支持 ACID 的 事务操作，多行数据 的 事务操作，不支持事务的 正常回滚，支持 （Isolation）隔离性、(Durability）持久性，不能保证 (Atomicity）原子性、（Consistency）一致性\n\n### 2.2 K-V数据库\n\n使用 键值（key-value）存储的数据库，其数据按照 键值对 的形式进行 组织、索引 和 存储。\n\n**KV 存储非常适合不涉及过多 数据关系 业务的数据。它能够有效减少 读写磁盘 的次数，比 SQL 数据库存储 拥有更好的 读写性能，能够解决 关系型数据库 无法存储 数据结构 的问题。**\n\n**Redis**\n\nRedis 是一个使用 ANSI C 编写的 开源、支持网络、基于内存、可选持久性 的 键值对存储 数据库。Redis 是目前最流行的 键值对存储 数据库之一\n\n**Cassandra**\n\nApache Cassandra（社区内一般简称为 C*）是一套 开源的分布式 NoSQL 数据库系统。它最初由 Facebook 开发，用于储存 收件箱 等简单格式数据，集 Google BigTable 的 数据模型 与 Amazon Dynamo 的 完全分布式 架构于一身。Cassandra 是一种流行的 分布式结构化 数据存储方案\n\n**Memcached**\n\nMemcached 是一个 开放源代码、高性能、分配的 内存对象缓存系统。用于加速动态 web 应用程序，减轻关系型数据库负载。它可以应对 任意多个连接，使用 非阻塞的网络 IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个 Hash 表，Memcached 自管理这些 Hash 表。\n\n**LevelDB**\n\nLevelDB 是一个由 Google 所研发的 键／值对（Key/Value Pair）嵌入式 数据库管理系统 编程库，以开源的 BSD 许可证发布。\n\n<font color=red>**优点：</font>\n\n1.性能极高\n\n2.丰富的数据类型\n\n3.丰富的特性\n\n<font color=blue>**缺点：</font>\n\n事务 不能支持 原子性 和 持久性（A 和 D），只支持 隔离性 和 一致性（I 和 C）。\n\n### 2.3 文档型数据库\n\n文档数据库 用于将 半结构化数据 存储为 文档 的一种数据库。文档数据库通常以 JSON 或 XML 格式存储数据。\n\n**由于文档数据库的 no-schema 特性，可以 存储 和 读取 任意数据。**\n\n**MongoDB**\n\nMongoDB 是一个基于 分布式文件存储 的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的 高性能 数据存储解决方案。MongoDB 是一个介于 关系数据库 和 非关系数据库 之间的产品，是非关系数据库当中功能 最丰富，最像关系数据库的 NoSQL。\n\n**CouchDB**\n\nCouchDB 是用 Erlang 开发的 面向文档 的 分布式 数据库，用于存储 半结构化 的数据，比较类似 lucene 的 index 结构。CouchDB 支持 RESTful API，它使用 JSON 作为 存储格式，JavaScript 作为 查询语言，MapReduce 和 HTTP 作为 API 的 NoSQL 数据库。其中一个显著的功能就是 多主复制 功能。除此之外，CouchDB 构建在强大的 B- 树储存引擎 之上。\n\n<font color=red>**优点：</font>\n\n1.新增字段简单不需要像关系型数据库一样，先执行 DDL 语句 修改表结构，程序代码 直接读写 即可。\n\n2.容易兼容 历史数据。对于历史数据，即使没有新增的字段，也不会导致错误，只会返回 空值，此时 代码兼容处理 即可。\n\n3.容易存储复杂数据。JSON 是一种强大的 描述语言，能够描述复杂的 数据结构\n\n<font color=blue>**缺点：</font>\n\n1.Atomicity（原子性）：仅支持 单行/文档级原子性，不支持 多行、多文档、多语句原子性。\n\n2.Isolation（隔离性）：隔离级别仅支持 已提交读（Read committed）级别，可能导致 不可重复读，幻读 的问题。\n\n3.不支持 复杂查询。例如 join 查询，如果需要 join 查询，需要 多次操作数据库。\n\n### 2.4 全文搜索引擎\n\n全文搜索引擎 的技术原理称为 倒排索引（inverted index），是一种 索引方法，其基本原理是建立 单词 到 文档 的索引。与之相对是，是 正排索引，其基本原理是建立 文档 到 单词 的索引。\n\n**全文搜索引擎的出现，正是解决关系型数据库 全文搜索较弱 的问题。**\n\n**ElasticSearch**\n\nElasticSearch 是一个基于 Apache Lucene 的 搜索引擎。它提供了一个 分布式，多租户 对全文搜索引擎。ElasticSearch 是用 Java 开发的，对外提供 RESTful Web 接口。根据 DB-Engines 排名，ElasticSearch 是最受欢迎的 企业搜索引擎。\n\n**Solr**\n\nSolr 是 Apache Lucene 项目的 开源企业搜索平台。其主要功能包括 全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及 富文本（比如 Word、PDF）处理等等。Solr 是高度 可扩展 的，并提供了 分布式搜索 和 索引复制\n\n<font color=red>**优点：</font>\n\n1.查询效率高，适用于对 海量数据 进行 近实时 的处理。\n\n2.可扩展性\n\n3.基于 集群 环境可以方便 横向扩展，可以承载 PB 级的数据。\n\n4.支持 高可用，ElasticSearch 集群弹性灵活，可以发现新的或失败的节点，重组 和 重新平衡 数据，确保数据是 安全 和 可访问的\n\n<font color=blue>**缺点：</font>\n\n1.事务的 ACID 支持不足，单一文档 的数据是支持 ACID 的。对于 多个文档 的 事务操作，不支持事务的 正常回滚。支持（Isolation）隔离性（基于 乐观锁机制）和（Durability）持久性，不支持（Atomicity）原子性，（Consistency）一致性。\n\n2.对类似数据库中，通过 外键 进行 多表关联的复杂操作支持较弱。\n\n3.读写 有一定 延时，写入的数据，最快 1s 中能被检索到。\n\n4.更新 性能较低，底层实现是 先删数据，再 插入新数据。\n\n5.内存占用大，因为 Lucene 将 索引部分 加载到 内存 中。\n\n### 2.5 图形数据库\n\n图形数据库 应用 图形理论 存储 实体 之间的 关系信息。最常见例子就是 社会网络中人与人之间的关系。关系型数据库 用于存储这种 关系型数据 的效果并不好，其查询 复杂、缓慢、超出预期。\n\n**图形数据库 的独特设计弥补了这个缺陷，解决 关系型 数据库 存储 和 处理复杂关系型数据 功能较弱的问题。**\n\n**Neo4j**\n\nNeo4j 是一个 高性能的，NOSQL 图形数据库，它将 结构化数据 存储在 “图形网络上” 而不是 “表中”。它是一个 嵌入式的、基于磁盘的、具备完全的 事务特性 的 Java 持久化引擎。Neo4j 也可以被看作是一个 高性能的图引擎。程序员工作在一个 面向对象的、灵活的网络结构 下而不是 严格、静态 的 表中。\n\n**ArangoDB**\n\nArangoDB 是一个 原生多模型 数据库系统。数据库系统支持 三个 重要的 数据模型（键/值，文档，图形）。ArangoDB 包含一个 数据库核心 和 统一查询语言 AQL（ArangoDB 查询语言）。查询语言是 声明性的，允许在 单个查询 中 组合 不同的 数据访问模式。ArangoDB 是一个 NoSQL 数据库系统，但 AQL 在很多方面与 SQL 都类似。\n\n<font color=red>**优点：</font>\n\n1.高性能表现\n\n2.设计的灵活性\n\n3.开发的敏捷性\n\n4.完全支持ACID\n\n<font color=blue>**缺点：</font>\n\n1.节点，关系 和它们的 属性 的数量被 限制。\n\n不支持 拆分。\n\n## 3.关系数据库 or NoSQL\n\n关于 关系型数据库 和 NoSQL 数据库 的选型，往往需要考虑几个指标：数据量、并发量、实时性、一致性要求、读写分布、数据类型、安全性、运维成本。\n\n|系统类型|数据库选型|\n|------|------|\n|企业内部管理系统|例如运营系统，数据量少，并发量小，首选考虑 关系型数据库|\n|互联网大流量系统|例如电商单品页，后台考虑选 关系型数据库，前台考虑选 内存型数据库|\n|日志型系统|原始数据 考虑选 列式数据库，日志搜索 考虑选 倒排索引|\n|搜索型系统|例如站内搜索，非通用搜索，商品搜索，后台考虑选 关系型数据库，前台考虑选 倒排索引|\n|事务型系统|例如库存管理，交易，记账，考虑选 关系型数据库 + 缓存数据库 + 一致性型协议|\n|离线计算|例如大量数据分析，考虑选 列式数据库 或者 关系型数据库 都可以|\n|实时计算|例如实时监控，可以考虑选 内存型数据库 或者 列式数据库|\n\n## 4.参考资料\n\n参考：https://blog.csdn.net/baidu_22254181/article/details/82594116","slug":"2018-11-30-NoSQL方案选型","published":1,"updated":"2018-12-01T08:24:08.246Z","comments":1,"photos":[],"link":"","_id":"cjskffof2005z4glmmnm381ca","content":"<h2 id=\"1-关系型数据库缺点\"><a href=\"#1-关系型数据库缺点\" class=\"headerlink\" title=\"1.关系型数据库缺点\"></a>1.关系型数据库缺点</h2><h3 id=\"1-1-大数据场景下-I-O-较高\"><a href=\"#1-1-大数据场景下-I-O-较高\" class=\"headerlink\" title=\"1.1.大数据场景下 I/O 较高\"></a>1.1.大数据场景下 I/O 较高</h3><p>因为数据是按 行存储，即使只针对其中 某一列 进行运算，关系型数据库也会对 整行数据 进行扫描，从存储设备中 读入内存，导致 I/O 较高<br><a id=\"more\"></a></p>\n<h3 id=\"1-2-结构化存储-不够灵活\"><a href=\"#1-2-结构化存储-不够灵活\" class=\"headerlink\" title=\"1.2.结构化存储 不够灵活\"></a>1.2.结构化存储 不够灵活</h3><p>存储的是 行记录，无法存储 灵活的数据结构</p>\n<h3 id=\"1-3-表结构-schema-扩展不方便\"><a href=\"#1-3-表结构-schema-扩展不方便\" class=\"headerlink\" title=\"1.3.表结构 schema 扩展不方便\"></a>1.3.表结构 schema 扩展不方便</h3><p>如要需要修改 表结构，需要执行执行 DDL（data definition language）语句修改，修改期间会导致 锁表，部分服务不可用</p>\n<h3 id=\"1-4-全文搜索-功能较弱\"><a href=\"#1-4-全文搜索-功能较弱\" class=\"headerlink\" title=\"1.4.全文搜索 功能较弱\"></a>1.4.全文搜索 功能较弱</h3><p>关系型数据库只能够进行 子字符串 的 匹配查询，当表的数据逐渐变大的时候，即使在有 索引 的情况下，like 扫表查询的匹配会 非常慢</p>\n<h3 id=\"1-5-难以-存储-和-处理-复杂-关系型数据\"><a href=\"#1-5-难以-存储-和-处理-复杂-关系型数据\" class=\"headerlink\" title=\"1.5.难以 存储 和 处理 复杂 关系型数据\"></a>1.5.难以 存储 和 处理 复杂 关系型数据</h3><p>传统的关系数据库，并不擅长处理 数据点之间 的关系</p>\n<p>NoSQL 在许多方面性能大大优于 非关系型 数据库的同时，往往也伴随一些特性的缺失。比较常见的是 事务功能 的缺失。</p>\n<p>针对传统 关系型数据库 的不足，下面介绍常见的 5 大类 NoSQL 解决方案：</p>\n<h2 id=\"2-NoSQL方案类型\"><a href=\"#2-NoSQL方案类型\" class=\"headerlink\" title=\"2.NoSQL方案类型\"></a>2.NoSQL方案类型</h2><h3 id=\"2-1-列式数据库\"><a href=\"#2-1-列式数据库\" class=\"headerlink\" title=\"2.1 列式数据库\"></a>2.1 列式数据库</h3><p>列式数据库 是以 列相关存储架构 进行数据存储的数据库，主要适合于 批量数据处理 和 即时查询。相对应的是 行式数据库，数据以 行相关的存储架构 进行空间分配，主要适合于 小批量 的 数据处理，常用于 联机事务型数据处理。</p>\n<p><strong>基于列式数据库的 列存储特性，可以解决某些特定场景下 关系型数据库 高 I/O 的问题。</strong></p>\n<p><strong>HBase</strong></p>\n<p>运行于 HDFS 文件系统之上，为 Hadoop 提供类似于 BigTable 规模的服务。因此，它可以 容错地 存储 海量稀疏 的数据</p>\n<p><strong>BigTable</strong></p>\n<p>基于 Google 文件系统（Google File System，GFS）的数据存储系统，用于存储 大规模结构化数据，适用于云计算</p>\n<font color=\"red\"><strong>优点：</strong></font>\n\n<p>1.高效的储存空间利用率</p>\n<p>2.查询效率高</p>\n<p>3.适合做聚合操作</p>\n<p>4.适合大量的数据而不是小数据</p>\n<font color=\"blue\"><strong>缺点：</strong></font>\n\n<p>1.不适合扫描 小量数据</p>\n<p>2.不适合 随机的更新</p>\n<p>3.不适合做含有删除和更新的 实时操作</p>\n<p>4.单行数据 支持 ACID 的 事务操作，多行数据 的 事务操作，不支持事务的 正常回滚，支持 （Isolation）隔离性、(Durability）持久性，不能保证 (Atomicity）原子性、（Consistency）一致性</p>\n<h3 id=\"2-2-K-V数据库\"><a href=\"#2-2-K-V数据库\" class=\"headerlink\" title=\"2.2 K-V数据库\"></a>2.2 K-V数据库</h3><p>使用 键值（key-value）存储的数据库，其数据按照 键值对 的形式进行 组织、索引 和 存储。</p>\n<p><strong>KV 存储非常适合不涉及过多 数据关系 业务的数据。它能够有效减少 读写磁盘 的次数，比 SQL 数据库存储 拥有更好的 读写性能，能够解决 关系型数据库 无法存储 数据结构 的问题。</strong></p>\n<p><strong>Redis</strong></p>\n<p>Redis 是一个使用 ANSI C 编写的 开源、支持网络、基于内存、可选持久性 的 键值对存储 数据库。Redis 是目前最流行的 键值对存储 数据库之一</p>\n<p><strong>Cassandra</strong></p>\n<p>Apache Cassandra（社区内一般简称为 C*）是一套 开源的分布式 NoSQL 数据库系统。它最初由 Facebook 开发，用于储存 收件箱 等简单格式数据，集 Google BigTable 的 数据模型 与 Amazon Dynamo 的 完全分布式 架构于一身。Cassandra 是一种流行的 分布式结构化 数据存储方案</p>\n<p><strong>Memcached</strong></p>\n<p>Memcached 是一个 开放源代码、高性能、分配的 内存对象缓存系统。用于加速动态 web 应用程序，减轻关系型数据库负载。它可以应对 任意多个连接，使用 非阻塞的网络 IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个 Hash 表，Memcached 自管理这些 Hash 表。</p>\n<p><strong>LevelDB</strong></p>\n<p>LevelDB 是一个由 Google 所研发的 键／值对（Key/Value Pair）嵌入式 数据库管理系统 编程库，以开源的 BSD 许可证发布。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.性能极高</p>\n<p>2.丰富的数据类型</p>\n<p>3.丰富的特性</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>事务 不能支持 原子性 和 持久性（A 和 D），只支持 隔离性 和 一致性（I 和 C）。</p>\n<h3 id=\"2-3-文档型数据库\"><a href=\"#2-3-文档型数据库\" class=\"headerlink\" title=\"2.3 文档型数据库\"></a>2.3 文档型数据库</h3><p>文档数据库 用于将 半结构化数据 存储为 文档 的一种数据库。文档数据库通常以 JSON 或 XML 格式存储数据。</p>\n<p><strong>由于文档数据库的 no-schema 特性，可以 存储 和 读取 任意数据。</strong></p>\n<p><strong>MongoDB</strong></p>\n<p>MongoDB 是一个基于 分布式文件存储 的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的 高性能 数据存储解决方案。MongoDB 是一个介于 关系数据库 和 非关系数据库 之间的产品，是非关系数据库当中功能 最丰富，最像关系数据库的 NoSQL。</p>\n<p><strong>CouchDB</strong></p>\n<p>CouchDB 是用 Erlang 开发的 面向文档 的 分布式 数据库，用于存储 半结构化 的数据，比较类似 lucene 的 index 结构。CouchDB 支持 RESTful API，它使用 JSON 作为 存储格式，JavaScript 作为 查询语言，MapReduce 和 HTTP 作为 API 的 NoSQL 数据库。其中一个显著的功能就是 多主复制 功能。除此之外，CouchDB 构建在强大的 B- 树储存引擎 之上。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.新增字段简单不需要像关系型数据库一样，先执行 DDL 语句 修改表结构，程序代码 直接读写 即可。</p>\n<p>2.容易兼容 历史数据。对于历史数据，即使没有新增的字段，也不会导致错误，只会返回 空值，此时 代码兼容处理 即可。</p>\n<p>3.容易存储复杂数据。JSON 是一种强大的 描述语言，能够描述复杂的 数据结构</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.Atomicity（原子性）：仅支持 单行/文档级原子性，不支持 多行、多文档、多语句原子性。</p>\n<p>2.Isolation（隔离性）：隔离级别仅支持 已提交读（Read committed）级别，可能导致 不可重复读，幻读 的问题。</p>\n<p>3.不支持 复杂查询。例如 join 查询，如果需要 join 查询，需要 多次操作数据库。</p>\n<h3 id=\"2-4-全文搜索引擎\"><a href=\"#2-4-全文搜索引擎\" class=\"headerlink\" title=\"2.4 全文搜索引擎\"></a>2.4 全文搜索引擎</h3><p>全文搜索引擎 的技术原理称为 倒排索引（inverted index），是一种 索引方法，其基本原理是建立 单词 到 文档 的索引。与之相对是，是 正排索引，其基本原理是建立 文档 到 单词 的索引。</p>\n<p><strong>全文搜索引擎的出现，正是解决关系型数据库 全文搜索较弱 的问题。</strong></p>\n<p><strong>ElasticSearch</strong></p>\n<p>ElasticSearch 是一个基于 Apache Lucene 的 搜索引擎。它提供了一个 分布式，多租户 对全文搜索引擎。ElasticSearch 是用 Java 开发的，对外提供 RESTful Web 接口。根据 DB-Engines 排名，ElasticSearch 是最受欢迎的 企业搜索引擎。</p>\n<p><strong>Solr</strong></p>\n<p>Solr 是 Apache Lucene 项目的 开源企业搜索平台。其主要功能包括 全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及 富文本（比如 Word、PDF）处理等等。Solr 是高度 可扩展 的，并提供了 分布式搜索 和 索引复制</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.查询效率高，适用于对 海量数据 进行 近实时 的处理。</p>\n<p>2.可扩展性</p>\n<p>3.基于 集群 环境可以方便 横向扩展，可以承载 PB 级的数据。</p>\n<p>4.支持 高可用，ElasticSearch 集群弹性灵活，可以发现新的或失败的节点，重组 和 重新平衡 数据，确保数据是 安全 和 可访问的</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.事务的 ACID 支持不足，单一文档 的数据是支持 ACID 的。对于 多个文档 的 事务操作，不支持事务的 正常回滚。支持（Isolation）隔离性（基于 乐观锁机制）和（Durability）持久性，不支持（Atomicity）原子性，（Consistency）一致性。</p>\n<p>2.对类似数据库中，通过 外键 进行 多表关联的复杂操作支持较弱。</p>\n<p>3.读写 有一定 延时，写入的数据，最快 1s 中能被检索到。</p>\n<p>4.更新 性能较低，底层实现是 先删数据，再 插入新数据。</p>\n<p>5.内存占用大，因为 Lucene 将 索引部分 加载到 内存 中。</p>\n<h3 id=\"2-5-图形数据库\"><a href=\"#2-5-图形数据库\" class=\"headerlink\" title=\"2.5 图形数据库\"></a>2.5 图形数据库</h3><p>图形数据库 应用 图形理论 存储 实体 之间的 关系信息。最常见例子就是 社会网络中人与人之间的关系。关系型数据库 用于存储这种 关系型数据 的效果并不好，其查询 复杂、缓慢、超出预期。</p>\n<p><strong>图形数据库 的独特设计弥补了这个缺陷，解决 关系型 数据库 存储 和 处理复杂关系型数据 功能较弱的问题。</strong></p>\n<p><strong>Neo4j</strong></p>\n<p>Neo4j 是一个 高性能的，NOSQL 图形数据库，它将 结构化数据 存储在 “图形网络上” 而不是 “表中”。它是一个 嵌入式的、基于磁盘的、具备完全的 事务特性 的 Java 持久化引擎。Neo4j 也可以被看作是一个 高性能的图引擎。程序员工作在一个 面向对象的、灵活的网络结构 下而不是 严格、静态 的 表中。</p>\n<p><strong>ArangoDB</strong></p>\n<p>ArangoDB 是一个 原生多模型 数据库系统。数据库系统支持 三个 重要的 数据模型（键/值，文档，图形）。ArangoDB 包含一个 数据库核心 和 统一查询语言 AQL（ArangoDB 查询语言）。查询语言是 声明性的，允许在 单个查询 中 组合 不同的 数据访问模式。ArangoDB 是一个 NoSQL 数据库系统，但 AQL 在很多方面与 SQL 都类似。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.高性能表现</p>\n<p>2.设计的灵活性</p>\n<p>3.开发的敏捷性</p>\n<p>4.完全支持ACID</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.节点，关系 和它们的 属性 的数量被 限制。</p>\n<p>不支持 拆分。</p>\n<h2 id=\"3-关系数据库-or-NoSQL\"><a href=\"#3-关系数据库-or-NoSQL\" class=\"headerlink\" title=\"3.关系数据库 or NoSQL\"></a>3.关系数据库 or NoSQL</h2><p>关于 关系型数据库 和 NoSQL 数据库 的选型，往往需要考虑几个指标：数据量、并发量、实时性、一致性要求、读写分布、数据类型、安全性、运维成本。</p>\n<table>\n<thead>\n<tr>\n<th>系统类型</th>\n<th>数据库选型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>企业内部管理系统</td>\n<td>例如运营系统，数据量少，并发量小，首选考虑 关系型数据库</td>\n</tr>\n<tr>\n<td>互联网大流量系统</td>\n<td>例如电商单品页，后台考虑选 关系型数据库，前台考虑选 内存型数据库</td>\n</tr>\n<tr>\n<td>日志型系统</td>\n<td>原始数据 考虑选 列式数据库，日志搜索 考虑选 倒排索引</td>\n</tr>\n<tr>\n<td>搜索型系统</td>\n<td>例如站内搜索，非通用搜索，商品搜索，后台考虑选 关系型数据库，前台考虑选 倒排索引</td>\n</tr>\n<tr>\n<td>事务型系统</td>\n<td>例如库存管理，交易，记账，考虑选 关系型数据库 + 缓存数据库 + 一致性型协议</td>\n</tr>\n<tr>\n<td>离线计算</td>\n<td>例如大量数据分析，考虑选 列式数据库 或者 关系型数据库 都可以</td>\n</tr>\n<tr>\n<td>实时计算</td>\n<td>例如实时监控，可以考虑选 内存型数据库 或者 列式数据库</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><p>参考：<a href=\"https://blog.csdn.net/baidu_22254181/article/details/82594116\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baidu_22254181/article/details/82594116</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-关系型数据库缺点\"><a href=\"#1-关系型数据库缺点\" class=\"headerlink\" title=\"1.关系型数据库缺点\"></a>1.关系型数据库缺点</h2><h3 id=\"1-1-大数据场景下-I-O-较高\"><a href=\"#1-1-大数据场景下-I-O-较高\" class=\"headerlink\" title=\"1.1.大数据场景下 I/O 较高\"></a>1.1.大数据场景下 I/O 较高</h3><p>因为数据是按 行存储，即使只针对其中 某一列 进行运算，关系型数据库也会对 整行数据 进行扫描，从存储设备中 读入内存，导致 I/O 较高<br>","more":"</p>\n<h3 id=\"1-2-结构化存储-不够灵活\"><a href=\"#1-2-结构化存储-不够灵活\" class=\"headerlink\" title=\"1.2.结构化存储 不够灵活\"></a>1.2.结构化存储 不够灵活</h3><p>存储的是 行记录，无法存储 灵活的数据结构</p>\n<h3 id=\"1-3-表结构-schema-扩展不方便\"><a href=\"#1-3-表结构-schema-扩展不方便\" class=\"headerlink\" title=\"1.3.表结构 schema 扩展不方便\"></a>1.3.表结构 schema 扩展不方便</h3><p>如要需要修改 表结构，需要执行执行 DDL（data definition language）语句修改，修改期间会导致 锁表，部分服务不可用</p>\n<h3 id=\"1-4-全文搜索-功能较弱\"><a href=\"#1-4-全文搜索-功能较弱\" class=\"headerlink\" title=\"1.4.全文搜索 功能较弱\"></a>1.4.全文搜索 功能较弱</h3><p>关系型数据库只能够进行 子字符串 的 匹配查询，当表的数据逐渐变大的时候，即使在有 索引 的情况下，like 扫表查询的匹配会 非常慢</p>\n<h3 id=\"1-5-难以-存储-和-处理-复杂-关系型数据\"><a href=\"#1-5-难以-存储-和-处理-复杂-关系型数据\" class=\"headerlink\" title=\"1.5.难以 存储 和 处理 复杂 关系型数据\"></a>1.5.难以 存储 和 处理 复杂 关系型数据</h3><p>传统的关系数据库，并不擅长处理 数据点之间 的关系</p>\n<p>NoSQL 在许多方面性能大大优于 非关系型 数据库的同时，往往也伴随一些特性的缺失。比较常见的是 事务功能 的缺失。</p>\n<p>针对传统 关系型数据库 的不足，下面介绍常见的 5 大类 NoSQL 解决方案：</p>\n<h2 id=\"2-NoSQL方案类型\"><a href=\"#2-NoSQL方案类型\" class=\"headerlink\" title=\"2.NoSQL方案类型\"></a>2.NoSQL方案类型</h2><h3 id=\"2-1-列式数据库\"><a href=\"#2-1-列式数据库\" class=\"headerlink\" title=\"2.1 列式数据库\"></a>2.1 列式数据库</h3><p>列式数据库 是以 列相关存储架构 进行数据存储的数据库，主要适合于 批量数据处理 和 即时查询。相对应的是 行式数据库，数据以 行相关的存储架构 进行空间分配，主要适合于 小批量 的 数据处理，常用于 联机事务型数据处理。</p>\n<p><strong>基于列式数据库的 列存储特性，可以解决某些特定场景下 关系型数据库 高 I/O 的问题。</strong></p>\n<p><strong>HBase</strong></p>\n<p>运行于 HDFS 文件系统之上，为 Hadoop 提供类似于 BigTable 规模的服务。因此，它可以 容错地 存储 海量稀疏 的数据</p>\n<p><strong>BigTable</strong></p>\n<p>基于 Google 文件系统（Google File System，GFS）的数据存储系统，用于存储 大规模结构化数据，适用于云计算</p>\n<font color=\"red\"><strong>优点：</strong></font>\n\n<p>1.高效的储存空间利用率</p>\n<p>2.查询效率高</p>\n<p>3.适合做聚合操作</p>\n<p>4.适合大量的数据而不是小数据</p>\n<font color=\"blue\"><strong>缺点：</strong></font>\n\n<p>1.不适合扫描 小量数据</p>\n<p>2.不适合 随机的更新</p>\n<p>3.不适合做含有删除和更新的 实时操作</p>\n<p>4.单行数据 支持 ACID 的 事务操作，多行数据 的 事务操作，不支持事务的 正常回滚，支持 （Isolation）隔离性、(Durability）持久性，不能保证 (Atomicity）原子性、（Consistency）一致性</p>\n<h3 id=\"2-2-K-V数据库\"><a href=\"#2-2-K-V数据库\" class=\"headerlink\" title=\"2.2 K-V数据库\"></a>2.2 K-V数据库</h3><p>使用 键值（key-value）存储的数据库，其数据按照 键值对 的形式进行 组织、索引 和 存储。</p>\n<p><strong>KV 存储非常适合不涉及过多 数据关系 业务的数据。它能够有效减少 读写磁盘 的次数，比 SQL 数据库存储 拥有更好的 读写性能，能够解决 关系型数据库 无法存储 数据结构 的问题。</strong></p>\n<p><strong>Redis</strong></p>\n<p>Redis 是一个使用 ANSI C 编写的 开源、支持网络、基于内存、可选持久性 的 键值对存储 数据库。Redis 是目前最流行的 键值对存储 数据库之一</p>\n<p><strong>Cassandra</strong></p>\n<p>Apache Cassandra（社区内一般简称为 C*）是一套 开源的分布式 NoSQL 数据库系统。它最初由 Facebook 开发，用于储存 收件箱 等简单格式数据，集 Google BigTable 的 数据模型 与 Amazon Dynamo 的 完全分布式 架构于一身。Cassandra 是一种流行的 分布式结构化 数据存储方案</p>\n<p><strong>Memcached</strong></p>\n<p>Memcached 是一个 开放源代码、高性能、分配的 内存对象缓存系统。用于加速动态 web 应用程序，减轻关系型数据库负载。它可以应对 任意多个连接，使用 非阻塞的网络 IO。由于它的工作机制是在内存中开辟一块空间，然后建立一个 Hash 表，Memcached 自管理这些 Hash 表。</p>\n<p><strong>LevelDB</strong></p>\n<p>LevelDB 是一个由 Google 所研发的 键／值对（Key/Value Pair）嵌入式 数据库管理系统 编程库，以开源的 BSD 许可证发布。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.性能极高</p>\n<p>2.丰富的数据类型</p>\n<p>3.丰富的特性</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>事务 不能支持 原子性 和 持久性（A 和 D），只支持 隔离性 和 一致性（I 和 C）。</p>\n<h3 id=\"2-3-文档型数据库\"><a href=\"#2-3-文档型数据库\" class=\"headerlink\" title=\"2.3 文档型数据库\"></a>2.3 文档型数据库</h3><p>文档数据库 用于将 半结构化数据 存储为 文档 的一种数据库。文档数据库通常以 JSON 或 XML 格式存储数据。</p>\n<p><strong>由于文档数据库的 no-schema 特性，可以 存储 和 读取 任意数据。</strong></p>\n<p><strong>MongoDB</strong></p>\n<p>MongoDB 是一个基于 分布式文件存储 的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的 高性能 数据存储解决方案。MongoDB 是一个介于 关系数据库 和 非关系数据库 之间的产品，是非关系数据库当中功能 最丰富，最像关系数据库的 NoSQL。</p>\n<p><strong>CouchDB</strong></p>\n<p>CouchDB 是用 Erlang 开发的 面向文档 的 分布式 数据库，用于存储 半结构化 的数据，比较类似 lucene 的 index 结构。CouchDB 支持 RESTful API，它使用 JSON 作为 存储格式，JavaScript 作为 查询语言，MapReduce 和 HTTP 作为 API 的 NoSQL 数据库。其中一个显著的功能就是 多主复制 功能。除此之外，CouchDB 构建在强大的 B- 树储存引擎 之上。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.新增字段简单不需要像关系型数据库一样，先执行 DDL 语句 修改表结构，程序代码 直接读写 即可。</p>\n<p>2.容易兼容 历史数据。对于历史数据，即使没有新增的字段，也不会导致错误，只会返回 空值，此时 代码兼容处理 即可。</p>\n<p>3.容易存储复杂数据。JSON 是一种强大的 描述语言，能够描述复杂的 数据结构</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.Atomicity（原子性）：仅支持 单行/文档级原子性，不支持 多行、多文档、多语句原子性。</p>\n<p>2.Isolation（隔离性）：隔离级别仅支持 已提交读（Read committed）级别，可能导致 不可重复读，幻读 的问题。</p>\n<p>3.不支持 复杂查询。例如 join 查询，如果需要 join 查询，需要 多次操作数据库。</p>\n<h3 id=\"2-4-全文搜索引擎\"><a href=\"#2-4-全文搜索引擎\" class=\"headerlink\" title=\"2.4 全文搜索引擎\"></a>2.4 全文搜索引擎</h3><p>全文搜索引擎 的技术原理称为 倒排索引（inverted index），是一种 索引方法，其基本原理是建立 单词 到 文档 的索引。与之相对是，是 正排索引，其基本原理是建立 文档 到 单词 的索引。</p>\n<p><strong>全文搜索引擎的出现，正是解决关系型数据库 全文搜索较弱 的问题。</strong></p>\n<p><strong>ElasticSearch</strong></p>\n<p>ElasticSearch 是一个基于 Apache Lucene 的 搜索引擎。它提供了一个 分布式，多租户 对全文搜索引擎。ElasticSearch 是用 Java 开发的，对外提供 RESTful Web 接口。根据 DB-Engines 排名，ElasticSearch 是最受欢迎的 企业搜索引擎。</p>\n<p><strong>Solr</strong></p>\n<p>Solr 是 Apache Lucene 项目的 开源企业搜索平台。其主要功能包括 全文检索、命中标示、分面搜索、动态聚类、数据库集成，以及 富文本（比如 Word、PDF）处理等等。Solr 是高度 可扩展 的，并提供了 分布式搜索 和 索引复制</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.查询效率高，适用于对 海量数据 进行 近实时 的处理。</p>\n<p>2.可扩展性</p>\n<p>3.基于 集群 环境可以方便 横向扩展，可以承载 PB 级的数据。</p>\n<p>4.支持 高可用，ElasticSearch 集群弹性灵活，可以发现新的或失败的节点，重组 和 重新平衡 数据，确保数据是 安全 和 可访问的</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.事务的 ACID 支持不足，单一文档 的数据是支持 ACID 的。对于 多个文档 的 事务操作，不支持事务的 正常回滚。支持（Isolation）隔离性（基于 乐观锁机制）和（Durability）持久性，不支持（Atomicity）原子性，（Consistency）一致性。</p>\n<p>2.对类似数据库中，通过 外键 进行 多表关联的复杂操作支持较弱。</p>\n<p>3.读写 有一定 延时，写入的数据，最快 1s 中能被检索到。</p>\n<p>4.更新 性能较低，底层实现是 先删数据，再 插入新数据。</p>\n<p>5.内存占用大，因为 Lucene 将 索引部分 加载到 内存 中。</p>\n<h3 id=\"2-5-图形数据库\"><a href=\"#2-5-图形数据库\" class=\"headerlink\" title=\"2.5 图形数据库\"></a>2.5 图形数据库</h3><p>图形数据库 应用 图形理论 存储 实体 之间的 关系信息。最常见例子就是 社会网络中人与人之间的关系。关系型数据库 用于存储这种 关系型数据 的效果并不好，其查询 复杂、缓慢、超出预期。</p>\n<p><strong>图形数据库 的独特设计弥补了这个缺陷，解决 关系型 数据库 存储 和 处理复杂关系型数据 功能较弱的问题。</strong></p>\n<p><strong>Neo4j</strong></p>\n<p>Neo4j 是一个 高性能的，NOSQL 图形数据库，它将 结构化数据 存储在 “图形网络上” 而不是 “表中”。它是一个 嵌入式的、基于磁盘的、具备完全的 事务特性 的 Java 持久化引擎。Neo4j 也可以被看作是一个 高性能的图引擎。程序员工作在一个 面向对象的、灵活的网络结构 下而不是 严格、静态 的 表中。</p>\n<p><strong>ArangoDB</strong></p>\n<p>ArangoDB 是一个 原生多模型 数据库系统。数据库系统支持 三个 重要的 数据模型（键/值，文档，图形）。ArangoDB 包含一个 数据库核心 和 统一查询语言 AQL（ArangoDB 查询语言）。查询语言是 声明性的，允许在 单个查询 中 组合 不同的 数据访问模式。ArangoDB 是一个 NoSQL 数据库系统，但 AQL 在很多方面与 SQL 都类似。</p>\n<font color=\"red\">**优点：</font>\n\n<p>1.高性能表现</p>\n<p>2.设计的灵活性</p>\n<p>3.开发的敏捷性</p>\n<p>4.完全支持ACID</p>\n<font color=\"blue\">**缺点：</font>\n\n<p>1.节点，关系 和它们的 属性 的数量被 限制。</p>\n<p>不支持 拆分。</p>\n<h2 id=\"3-关系数据库-or-NoSQL\"><a href=\"#3-关系数据库-or-NoSQL\" class=\"headerlink\" title=\"3.关系数据库 or NoSQL\"></a>3.关系数据库 or NoSQL</h2><p>关于 关系型数据库 和 NoSQL 数据库 的选型，往往需要考虑几个指标：数据量、并发量、实时性、一致性要求、读写分布、数据类型、安全性、运维成本。</p>\n<table>\n<thead>\n<tr>\n<th>系统类型</th>\n<th>数据库选型</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>企业内部管理系统</td>\n<td>例如运营系统，数据量少，并发量小，首选考虑 关系型数据库</td>\n</tr>\n<tr>\n<td>互联网大流量系统</td>\n<td>例如电商单品页，后台考虑选 关系型数据库，前台考虑选 内存型数据库</td>\n</tr>\n<tr>\n<td>日志型系统</td>\n<td>原始数据 考虑选 列式数据库，日志搜索 考虑选 倒排索引</td>\n</tr>\n<tr>\n<td>搜索型系统</td>\n<td>例如站内搜索，非通用搜索，商品搜索，后台考虑选 关系型数据库，前台考虑选 倒排索引</td>\n</tr>\n<tr>\n<td>事务型系统</td>\n<td>例如库存管理，交易，记账，考虑选 关系型数据库 + 缓存数据库 + 一致性型协议</td>\n</tr>\n<tr>\n<td>离线计算</td>\n<td>例如大量数据分析，考虑选 列式数据库 或者 关系型数据库 都可以</td>\n</tr>\n<tr>\n<td>实时计算</td>\n<td>例如实时监控，可以考虑选 内存型数据库 或者 列式数据库</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><p>参考：<a href=\"https://blog.csdn.net/baidu_22254181/article/details/82594116\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baidu_22254181/article/details/82594116</a></p>"},{"layout":"lay_post","title":"Mycat中间件指南","date":"2018-12-03T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. Mycat概述\n\nMycat 是什么？从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了 MySQL 协议的的Server，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。\n<!--more-->\n\n### 1.1 Mycat原理\n\nMycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。\n\n### 1.2 Mycat应用场景\n\nMycat 发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景：\n\n+ 单纯的读写分离，此时配置最为简单，支持读写分离，主从切换；\n\n+ 分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片；\n\n+ 多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化；\n\n+ 报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计；\n\n+ 替代 Hbase，分析大数据；\n\n+ 作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择。\n\n### 1.3 Mycat中的概念\n\n#### 1.3.1 逻辑库(schema)\n\n通常对实际应用来说，并不需要知道中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。\n\n#### 1.3.2 逻辑表(table)\n\n既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。\n\n+ 1.分片表\n\n分片表，是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。\n\n+ 2.非分片表\n\n一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。\n\n+ 3.ER表\n\n关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关系，Mycat 中的 ER 表即是来源于此。根据这一思路，提出了基于 E-R 关系的数据分片策略，子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据 Join 不会跨库操作。\n\n表分组（Table Group）是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的重要一条规则。\n\n+ 4.全局表\n\n一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性：变动不频繁、数据量总体变化不大、数据规模不大，很少有超过数十万条记录。对于这类的表，在分片的情况下，当业务表因为规模而进行分片以后，业务表与这些附属的字典表之间的关联，就成了比较棘手的问题，所以 Mycat 中通过数据冗余来解决这类表的 join，即所有的分片都有一份数据的拷贝，所有将字典表或者符合字典表特性的一些表定义为全局表。\n\n数据冗余是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的另外一条重要规则。\n\n#### 1.3.3 分片节点(dataNode)\n\n数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点（dataNode）。\n\n#### 1.3.4 节点主机(dataHost)\n\n数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。\n\n#### 1.3.5 分片规则(rule)\n\n前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。\n\n#### 1.3.6 全局序列号(sequence)\n\n数据切分后，原有的关系数据库中的主键约束在分布式条件下将无法使用，因此需要引入外部机制保证数据唯一性标识，这种保证全局性的数据唯一标识的机制就是全局序列号（sequence）。\n\n## 2. Mycat配置\n\n### 2.1 schema.xml\n\nSchema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。弄懂这些配置，是正确使用 MyCat 的前提。这里就一层层对该文件进行解析。\n\n```xml\n<schema name=\"TESTDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn2\">\n\t<table name=\"travelrecord\" dataNode=\"dn1,dn2,dn3\" rule=\"auto-sharding-long\" ></table>\n</schema>\n<schema name=\"USERDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t<table name=\"company\" dataNode=\"dn10,dn11,dn12\" rule=\"auto-sharding-long\" ></table>\n</schema>\n```\n**schema**：该标签用于定义 MyCat 实例中的逻辑库，MyCat 可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用 schema 标签来划分这些不同的逻辑库。如果不配置 schema 标签，所有的表配置，会属于同一个默认的逻辑库。\n\n**table**：该标签定义了 MyCat 中的逻辑表，所有需要拆分的表都需要在这个标签中定义。\n\n**childTable**：该标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。\n\n**dataNode**：该标签定义了 MyCat 中的数据节点，也就是我们通常说所的数据分片。一个 dataNode 标签就是一个独立的数据分片。\n\n**dataHost**：该标签在 mycat 逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。\n\n**heartbeat**：该标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。\n\n### 2.2 server.xml\n\nserver.xml 几乎保存了所有 mycat 需要的系统配置信息。其在代码内直接的映射类为 SystemConfig 类。\n\n```xml\n<user name=\"test\">\n\t<property name=\"password\">test</property>\n\t<property name=\"schemas\">TESTDB</property>\n\t<property name=\"readOnly\">true</property>\n\t<property name=\"benchmark\">11111</property>\n\t<property name=\"usingDecrypt\">1</property>\n\t<privileges check=\"false\">\n\t<schema name=\"TESTDB\" dml=\"0010\" showTables=\"custome/mysql\">\n\t\t<table name=\"tbl_user\" dml=\"0110\"></table>\n\t\t<table name=\"tbl_dynamic\" dml=\"1111\"></table>\n\t</schema>\n\t</privileges>\n</user>\n```\n\n**user**：这个标签主要用于定义登录 mycat 的用户和权限。\n\n**system**：该标签内嵌套的所有 property 标签都与系统配置有关，请注意，下面我会省去标签 property 直接使用这个标签的 name 属性内的值来介绍这个属性的作用。\n\n### 2.3 rule.xml\n\nrule.xml 里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。这个文件里面主要有 tableRule 和 function 这两个标签。在具体使用过程中可以按照需求添加 tableRule 和 function。\n\n```xml\n<tableRule name=\"rule1\">\n\t<rule>\n\t\t<columns>id</columns>\n\t\t<algorithm>func1</algorithm>\n\t</rule>\n</tableRule>\n<function name=\"hash-int\" class=\"io.mycat.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n</function>\n```\n\n**tableRule**：该标签定义表规则。\n\n**function**：该标签用于路由算法的配置\n\n## 3. Mycat分库分表\n\n*当你找到某个合适的业务字段作为分片字段以后，不必纠结于“牺牲了按主键查询记录的性能”，因为在这种情况下，MyCAT 提供了“主键到分片”的内存缓存机制，热点数据按照主键查询，丝毫不损失性能。*\n\n### 3.1 Mycat全局表\n\n如果你的业务中有些数据类似于数据字典，比如配置文件的配置，常用业务的配置或者数据量不大很少变动的表，这些表往往不是特别大，而且大部分的业务场景都会用到，那么这种表适合于 Mycat 全局表，无须对数据进行切分，只要在所有的分片上保存一份数据即可。\n\n```xml\n<table name=\"t_area\" primaryKey=\"id\" type=\"global\" dataNode=\"dn1,dn2\" />\n```\n\n### 3.2 ER分片表\n\n有一类业务，例如订单（order）跟订单明细（order_detail）,明细表会依赖于订单，也就是说会存在表的主从关系，这类似业务的切分可以抽象出合适的切分规则，比如根据用户 ID 切分,其他相关的表都依赖于用户 ID，再或者根据订单 ID 切分，总之部分业务总会可以抽象出父子关系的表。这类表适用于 ER 分片表。\n\n子表的记录与所关联的父表记录存放在同一个数据分片上，避免数据 Join 跨库操作\n\n```xml\n<table name=\"order\" dataNode=\"dn$1-32\" rule=\"mod-long\">\n\t<childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"order_id\" parentKey=\"order_id\" />\n</table>\n```\n\n### 3.3 多对多关联\n\n有一类业务场景是 “主表 A+关系表+主表 B”，举例来说就是商户会员+订单+商户，对应这类业务，如何切分？目前总的原则是需要从业务角度\n来看，关系表更偏向哪个表，即“A 的关系”还是“B 的关系”，来决定关系表跟从那个方向存储，未来 Mycat版本中将考虑将中间表进行双向复制，以实现从 A-关系表 以及 B-关系表的双向关联查。\n\n### 3.4 常用分片规则\n\n|分类|说明|\n| -- | -- |\n|io.mycat.route.function.PartitionByFileMap|分片枚举|\n|io.mycat.route.function.PartitionByLong|固定分片hash算法|\n|io.mycat.route.function.AutoPartitionByLong|范围约定|\n|io.mycat.route.function.PartitionByMod|取模|\n|io.mycat.route.function.PartitionByDate|按日期（天）分片|\n|io.mycat.route.function.PartitionByPattern|取模范围约束|\n|io.mycat.route.function.PartitionByPrefixPattern|截取数字做hash求模范围约束|\n|io.mycat.route.function.PartitionDirectBySubString|应用指定|\n|io.mycat.route.function.PartitionByString|截取数字hash解析|\n|io.mycat.route.function.PartitionByMurmurHash|一致性 hash|\n|io.mycat.route.function.LatestMonthPartion|按单月小时拆分|\n|io.mycat.route.function.PartitionByRangeMod|范围求模分片|\n|io.mycat.route.function.PartitionByRangeDateHash|日期范围hash分片|\n|io.mycat.route.function.PartitionByHotDate|冷热数据分片|\n|io.mycat.route.function.PartitionByMonth|自然月分片|\n|io.mycat.route.function.PartitionByCRC32PreSlot|有状态分片算法|\n\n### 3.5 数据扩容方案\n\n#### 3.5.1 离线扩容缩容\n\n1、 复制 schema.xml、 rule.xml 并重命名为 newSchema.xml、 newRule.xml 放于 conf 目录下。\n\n2、 修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配置参数（表的节点数、数据源、路由规则）。\n\n3、 修改 conf 目录下的 migrateTables.properties 配置文件， 告诉工具哪些表需要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移。\n\n4、 修改 bin 目录下的 dataMigrate.sh 脚本文件。\n\n5、 停止 mycat 服务（如果可以确保扩容缩容过程中不会有写操作， 也可以不停止 mycat 服务）。\n\n6、 通过 crt 等工具进入 mycat 根目录， 执行 bin/ dataMigrate.sh 脚本， 开始扩容/缩容过程。\n\n7、 扩容缩容成功后， 将 newSchema.xml 和 newRule.xml 重命名为 schema.xml 和 rule.xml 并替换掉原文件， 重启 mycat 服务， 整个扩容缩容过程完成。\n\n## 4. Mycat读写分离\n\n对于MySQL来说，标准的读写分离是主从模式，一个写节点Master后面跟着多个读节点，读节点的数量取决于系统的压力。\n\n### 4.1 MySQL主从模式种类\n\n![主从复制方式](/images/Mycat/主从复制方式.png)\n\nMySQL 主从复制的原理如下：\n\n第一步是在主库上记录二进制日志（稍后介绍如何设置）。在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL 会按事务提交的顺序 而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。下一步，备库将主库的二进制日志复制到其本地的中继日志中。首先,备库会启动一个工作线程，称为I/O线程,I/O线程跟主库建立一个普通的客户端连接，然后在主库上启 动一个特殊的二进制转储(binhg dump、线程（该线程没有对应的 SQL 命令），这个二进制转储线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库，它将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会 被唤醒，备库 I/O 线程会将接收到的事件记录到中继日志中。\n\n备库的SQL线程执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当SQL线程追赶上I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL线程执行的事件也可以通过配置选项来决定是否写入其自己的二进制日志中。这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行。也就是说 I/o 线程能够独立于 SQL 线程之外工作。但这种架构也限制了复制的过程，其中最重要 的一点是在主库上并发运行的査询在备库只能串行化执行，因\n为只有一个 SQL 线程来重 放中继日志中的事件。\n\n进行同步复制，这将大大改善MySQL主从同步的数据延迟问题，配合Mycat分片，可以更好的将一个超级大表的数据同步的时延降低到最低。即使是并发复制机制、仍然无法避免主从数据库的数据瞬间不同步的问题，因此又有了一种增强的方案，即galera for mysql、percona-cluster或者mariadb cluster等集群机制，他们是一种多主同步复制的模式，可以在任意节点上进行读写、自动控制成员，自动删除故障节点、自动加入节点、真正给予行级别的并发复制等强大能力。\n\n**MySQL主从同步的监控**\n\nMySQL有主从同步的状态信息，可以通过命令以下获取：\n\n**show slave status**：获知当前是否主从同步正常工作。其中Seconds_Behind_Master字段从字面理解，它表示当前MySQL主从数据的同步延迟，单位是秒，但这个指标从DBA的角度并不能简单的理解为延迟多少秒，但对于应用来说，简单的认为是主从同步的时间差就可以了，另外，当主从同步停止以后，重新启动同步，这个数值可能会是几万秒，取决于主从同步停止的时间长短，我们可以认为数据此时有很多天没有同步了，而这个数值越接近零，则说明主从同步延迟最小。\n\n我们可以采集这个指标并汇聚曲线图，来分析我们的数据库的同步延迟曲线，然后根据此曲线，给出一个合理的阀值，主从同步的时延小于阀值时，我们认为从库是同步的，此时可以安全的从从库读取数据。Mycat 未来将支持这种优化，让应用更加可靠的读取到预期的从库数据。\n\n### 4.2 MySQL高可用方案\n\n1.主从复制+读写分离\n\n![mysql高可用方案1](/images/Mycat/mysql高可用方案1.png)\n\n对于数据实时性要求不是特别严格的应用，只需要通过廉价的 pc server 来扩展 Slave 的数量，将读压力分散到多台 Slave 的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。\n\n2.MySQL Cluster\n\n![mysql高可用方案2](/images/Mycat/mysql高可用方案2.png)\n\nMySQL Cluster 由一组计算机构成，每台计算机上均运行着多种进程，包括 MySQL 服务器，NDB Cluster的数据节点，管理服务器，以及（可能）专门的数据访问程序。NDB”是一种“内存中”的存储引擎，它具有可用性高和数据一致性好的特点。MySQL Cluster 要实现完全冗余和容错，至少需要 4 台物理主机，其中两个为管理节点。MySQL Cluster使用不那么广泛，除了自身构架因素、适用的业务有限之外，另一个重要的原因是其安装配置管理相对复杂繁琐，总共有几十个操作步骤，需要 DBA 花费几个小时才能搭建或完成。重启 MySQLCluster 数据库的管理操作之前需要执行 46 个手动命令，需要耗费 DBA 2.5 小时的时间，而依靠 MySQLCluster Manager 只需一个命令即可完成，但 MySQL Cluster Manager 仅作为商用 MySQL Cluster 运营商级版本 (CGE) 数据库的一部分提供，需要购买。其官方的说明，若应用中的 SQL 操作为主键数据库访问，包含一些JOIN 操作而非对整个表执行常规扫描和 JOIN 而返回数万行数据，则适合 Cluster，否则不合适，从这一条限制来看，表明大多数业务场景并不合适 MySQL Cluster，业内有资深人士也凭评价：NDB 不适合大多数业务场景，而且有安全问题。\n\n3.HeartBeat+双主复制\n\n![mysql高可用方案3](/images/Mycat/mysql高可用方案3.png)\n\nheartbeat 是 Linux-HA 工程的一个组件,heartbeat 最核心的包括两个部分：心跳监测和资源接管。在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运 行在对方主机上的资源或者服务。\n\n4.HeartBeat+DRBD+MySQL\n\n![mysql高可用方案4](/images/Mycat/mysql高可用方案4.png)\n\nDRBD 是通过网络来实现块设备的数据镜像同步的一款开源 Cluster 软件，它自动完成网络中两个不同服务器上的磁盘同步，相对于 binlog 日志同步，它是更底层的磁盘同步，理论上 DRDB 适合很多文件型系统的高可用。\n\n5.Lvs+Keepalived+双主复制\n\n![mysql高可用方案5](/images/Mycat/mysql高可用方案5.png)\n\nLvs 是一个虚拟的服务器集群系统，可以实现 LINUX 平台下的简单负载均衡。keepalived 是一个类似于layer3, 4 & 5 交换机制的软件，主要用于主机与备机的故障转移，这是一种适用面很广的负载均衡和高可用方\n案，最常用于 Web 系统。\n\n6.Galera Cluster\n\n![mysql高可用方案6](/images/Mycat/mysql高可用方案6.png)\n\n这种 gluster 模式可以说是全新的一种高可用方案，前面也提到其优点，它的缺点不多，不支持 XA，不支持Lock Table，只能用 InnoDB 引擎。\n\n### 4.3 Mycat读写分离支持\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t\t<!-- can have multi read hosts -->\n\t\t<readHost host=\"hostS1\" url=\"localhost2:3306\" user=\"root\" password=\"123456\"weight=\"1\" />\n\t</writeHost>\n</dataHost>\n```\n\n或者\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost:3307\" user=\"root\" password=\"123456\">\n\t</writeHost>\n</dataHost>\n```\n\n以上两种取模第一种当写挂了读不可用，第二种可以继续使用，事务内部的一切操作都会走写节点，所以读操作不要加事务，如果读延时较大，使用根据主从延时的读写分离，或者强制走写节点。\n\n当你是1主3从的模式的时候，可以把第一个从节点配置为writeHost 2，第2个和第三个从节点则配置为writeHost 1的readHost:\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\" >\n\t\t<readHost host=\"hostS2\" url=\"localhost3:3306\" user=\"root\" password=\"123456\" />\n\t\t<readHost host=\"hostS3\" url=\"localhos4t:3306\" user=\"root\" password=\"123456\" />\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost2:3306\" user=\"root\" password=\"123456\" />\n</dataHost>\n```\n\n**根据主从延时切换**：\n\n1.4开始支持MySQL主从复制状态绑定的读写分离机制，让读更加安全可靠，配置如下：\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"2\" slaveThreshold=\"100\">\n\t<heartbeat>show slave status</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost:3316\" user=\"root\" password=\"123456\" />\n</dataHost>\n```\n\nMyCAT心跳检查语句配置为 show slave status,dataHost 上定义两个新属性： switchType=\"2\" 与slaveThreshold=\"100\"，此时意味着开启 MySQL 主从复制状态绑定的读写分离与切换机制，Mycat心跳机制通过检测 show slave status中的\"Seconds_Behind_Master\", \"Slave_IO_Running\",\"Slave_SQL_Running\" 三个字段来确定当前主从同步的状态以及Seconds_Behind_Master主从复制时延,当Seconds_Behind_Master > slaveThreshold时，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的 Seconds_Behind_Master 是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。\n\n1.4.1开始支持MySQL 集群模式，让读更加安全可靠,配置如下：\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"3\">\n\t<heartbeat> show status like ‘wsrep%’ </heartbeat>\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\"password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\"url=\"localhost:3316\"user=\"root\"password=\"123456\" ></writeHost>\n</dataHost>\n```\n\nMyCAT 心跳检查语句配置为 show status like ‘wsrep%’,dataHost 上定义两个新属性： switchType=\"3\"此时意味着开启MySQL集群复制状态状态绑定的读写分离与切换机制，Mycat心跳机制通过检测集群复制时延时，如果延时过大或者集群出现节点问题不会负载改节点。\n\nswitchType字典值：\n\n-1：表示不自动切换\n\n1：默认值，自动切换\n\n2：基于MySQL主从同步的状态决定是否切换，心跳语句为show slave status\n\n3：基于MySQL galary cluster的切换机制(适合集群)（1.4.1）,心跳语句为 show status like ‘wsrep%’\n\n### 4.4 Mycat高可用方案\n\nMycat 作为一个代理层中间件，Mycat 系统的高可用涉及到 Mycat 本身的高可用以及后端 MySQL 的高可用，前面章节所讲的 MySQL 高可用方案都可以在此用来确保 Mycat 所连接的后端 MySQL 服务的高可用性。在\n大多数情况下，建议采用标准的 MySQL 主从复制高可用性配置并交付给 Mycat 来完成后端 MySQL 节点的主从自动切换。\n\n![mycat高可用方案](/images/Mycat/mycat高可用方案.png)\n\n## 5. Mycat系统架构\n\n<center>系统架构</center>\n\n![arc](/images/Mycat/arc.png)\n\n<center>最佳实践</center>\n\n![最佳实践](/images/Mycat/最佳实践.jpg)\n\n## 6. 参考资料\n\nMycat权威指南：http://www.mycat.io/document/mycat-definitive-guide.pdf\n\nMycal社区：http://www.mycat.io/","source":"_posts/2018-12-04-Mycat中间件指南.md","raw":"---\nlayout: lay_post\ntitle: \"Mycat中间件指南\"\ndate: 2018-12-04\ncategories: 中间件\ntags: Mycat\nauthor: lvyafei\n---\n\n## 1. Mycat概述\n\nMycat 是什么？从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了 MySQL 协议的的Server，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。\n<!--more-->\n\n### 1.1 Mycat原理\n\nMycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。\n\n### 1.2 Mycat应用场景\n\nMycat 发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景：\n\n+ 单纯的读写分离，此时配置最为简单，支持读写分离，主从切换；\n\n+ 分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片；\n\n+ 多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化；\n\n+ 报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计；\n\n+ 替代 Hbase，分析大数据；\n\n+ 作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择。\n\n### 1.3 Mycat中的概念\n\n#### 1.3.1 逻辑库(schema)\n\n通常对实际应用来说，并不需要知道中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。\n\n#### 1.3.2 逻辑表(table)\n\n既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。\n\n+ 1.分片表\n\n分片表，是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。\n\n+ 2.非分片表\n\n一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。\n\n+ 3.ER表\n\n关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关系，Mycat 中的 ER 表即是来源于此。根据这一思路，提出了基于 E-R 关系的数据分片策略，子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据 Join 不会跨库操作。\n\n表分组（Table Group）是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的重要一条规则。\n\n+ 4.全局表\n\n一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性：变动不频繁、数据量总体变化不大、数据规模不大，很少有超过数十万条记录。对于这类的表，在分片的情况下，当业务表因为规模而进行分片以后，业务表与这些附属的字典表之间的关联，就成了比较棘手的问题，所以 Mycat 中通过数据冗余来解决这类表的 join，即所有的分片都有一份数据的拷贝，所有将字典表或者符合字典表特性的一些表定义为全局表。\n\n数据冗余是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的另外一条重要规则。\n\n#### 1.3.3 分片节点(dataNode)\n\n数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点（dataNode）。\n\n#### 1.3.4 节点主机(dataHost)\n\n数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。\n\n#### 1.3.5 分片规则(rule)\n\n前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。\n\n#### 1.3.6 全局序列号(sequence)\n\n数据切分后，原有的关系数据库中的主键约束在分布式条件下将无法使用，因此需要引入外部机制保证数据唯一性标识，这种保证全局性的数据唯一标识的机制就是全局序列号（sequence）。\n\n## 2. Mycat配置\n\n### 2.1 schema.xml\n\nSchema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。弄懂这些配置，是正确使用 MyCat 的前提。这里就一层层对该文件进行解析。\n\n```xml\n<schema name=\"TESTDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\" dataNode=\"dn2\">\n\t<table name=\"travelrecord\" dataNode=\"dn1,dn2,dn3\" rule=\"auto-sharding-long\" ></table>\n</schema>\n<schema name=\"USERDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t<table name=\"company\" dataNode=\"dn10,dn11,dn12\" rule=\"auto-sharding-long\" ></table>\n</schema>\n```\n**schema**：该标签用于定义 MyCat 实例中的逻辑库，MyCat 可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用 schema 标签来划分这些不同的逻辑库。如果不配置 schema 标签，所有的表配置，会属于同一个默认的逻辑库。\n\n**table**：该标签定义了 MyCat 中的逻辑表，所有需要拆分的表都需要在这个标签中定义。\n\n**childTable**：该标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。\n\n**dataNode**：该标签定义了 MyCat 中的数据节点，也就是我们通常说所的数据分片。一个 dataNode 标签就是一个独立的数据分片。\n\n**dataHost**：该标签在 mycat 逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。\n\n**heartbeat**：该标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。\n\n### 2.2 server.xml\n\nserver.xml 几乎保存了所有 mycat 需要的系统配置信息。其在代码内直接的映射类为 SystemConfig 类。\n\n```xml\n<user name=\"test\">\n\t<property name=\"password\">test</property>\n\t<property name=\"schemas\">TESTDB</property>\n\t<property name=\"readOnly\">true</property>\n\t<property name=\"benchmark\">11111</property>\n\t<property name=\"usingDecrypt\">1</property>\n\t<privileges check=\"false\">\n\t<schema name=\"TESTDB\" dml=\"0010\" showTables=\"custome/mysql\">\n\t\t<table name=\"tbl_user\" dml=\"0110\"></table>\n\t\t<table name=\"tbl_dynamic\" dml=\"1111\"></table>\n\t</schema>\n\t</privileges>\n</user>\n```\n\n**user**：这个标签主要用于定义登录 mycat 的用户和权限。\n\n**system**：该标签内嵌套的所有 property 标签都与系统配置有关，请注意，下面我会省去标签 property 直接使用这个标签的 name 属性内的值来介绍这个属性的作用。\n\n### 2.3 rule.xml\n\nrule.xml 里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。这个文件里面主要有 tableRule 和 function 这两个标签。在具体使用过程中可以按照需求添加 tableRule 和 function。\n\n```xml\n<tableRule name=\"rule1\">\n\t<rule>\n\t\t<columns>id</columns>\n\t\t<algorithm>func1</algorithm>\n\t</rule>\n</tableRule>\n<function name=\"hash-int\" class=\"io.mycat.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n</function>\n```\n\n**tableRule**：该标签定义表规则。\n\n**function**：该标签用于路由算法的配置\n\n## 3. Mycat分库分表\n\n*当你找到某个合适的业务字段作为分片字段以后，不必纠结于“牺牲了按主键查询记录的性能”，因为在这种情况下，MyCAT 提供了“主键到分片”的内存缓存机制，热点数据按照主键查询，丝毫不损失性能。*\n\n### 3.1 Mycat全局表\n\n如果你的业务中有些数据类似于数据字典，比如配置文件的配置，常用业务的配置或者数据量不大很少变动的表，这些表往往不是特别大，而且大部分的业务场景都会用到，那么这种表适合于 Mycat 全局表，无须对数据进行切分，只要在所有的分片上保存一份数据即可。\n\n```xml\n<table name=\"t_area\" primaryKey=\"id\" type=\"global\" dataNode=\"dn1,dn2\" />\n```\n\n### 3.2 ER分片表\n\n有一类业务，例如订单（order）跟订单明细（order_detail）,明细表会依赖于订单，也就是说会存在表的主从关系，这类似业务的切分可以抽象出合适的切分规则，比如根据用户 ID 切分,其他相关的表都依赖于用户 ID，再或者根据订单 ID 切分，总之部分业务总会可以抽象出父子关系的表。这类表适用于 ER 分片表。\n\n子表的记录与所关联的父表记录存放在同一个数据分片上，避免数据 Join 跨库操作\n\n```xml\n<table name=\"order\" dataNode=\"dn$1-32\" rule=\"mod-long\">\n\t<childTable name=\"order_detail\" primaryKey=\"id\" joinKey=\"order_id\" parentKey=\"order_id\" />\n</table>\n```\n\n### 3.3 多对多关联\n\n有一类业务场景是 “主表 A+关系表+主表 B”，举例来说就是商户会员+订单+商户，对应这类业务，如何切分？目前总的原则是需要从业务角度\n来看，关系表更偏向哪个表，即“A 的关系”还是“B 的关系”，来决定关系表跟从那个方向存储，未来 Mycat版本中将考虑将中间表进行双向复制，以实现从 A-关系表 以及 B-关系表的双向关联查。\n\n### 3.4 常用分片规则\n\n|分类|说明|\n| -- | -- |\n|io.mycat.route.function.PartitionByFileMap|分片枚举|\n|io.mycat.route.function.PartitionByLong|固定分片hash算法|\n|io.mycat.route.function.AutoPartitionByLong|范围约定|\n|io.mycat.route.function.PartitionByMod|取模|\n|io.mycat.route.function.PartitionByDate|按日期（天）分片|\n|io.mycat.route.function.PartitionByPattern|取模范围约束|\n|io.mycat.route.function.PartitionByPrefixPattern|截取数字做hash求模范围约束|\n|io.mycat.route.function.PartitionDirectBySubString|应用指定|\n|io.mycat.route.function.PartitionByString|截取数字hash解析|\n|io.mycat.route.function.PartitionByMurmurHash|一致性 hash|\n|io.mycat.route.function.LatestMonthPartion|按单月小时拆分|\n|io.mycat.route.function.PartitionByRangeMod|范围求模分片|\n|io.mycat.route.function.PartitionByRangeDateHash|日期范围hash分片|\n|io.mycat.route.function.PartitionByHotDate|冷热数据分片|\n|io.mycat.route.function.PartitionByMonth|自然月分片|\n|io.mycat.route.function.PartitionByCRC32PreSlot|有状态分片算法|\n\n### 3.5 数据扩容方案\n\n#### 3.5.1 离线扩容缩容\n\n1、 复制 schema.xml、 rule.xml 并重命名为 newSchema.xml、 newRule.xml 放于 conf 目录下。\n\n2、 修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配置参数（表的节点数、数据源、路由规则）。\n\n3、 修改 conf 目录下的 migrateTables.properties 配置文件， 告诉工具哪些表需要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移。\n\n4、 修改 bin 目录下的 dataMigrate.sh 脚本文件。\n\n5、 停止 mycat 服务（如果可以确保扩容缩容过程中不会有写操作， 也可以不停止 mycat 服务）。\n\n6、 通过 crt 等工具进入 mycat 根目录， 执行 bin/ dataMigrate.sh 脚本， 开始扩容/缩容过程。\n\n7、 扩容缩容成功后， 将 newSchema.xml 和 newRule.xml 重命名为 schema.xml 和 rule.xml 并替换掉原文件， 重启 mycat 服务， 整个扩容缩容过程完成。\n\n## 4. Mycat读写分离\n\n对于MySQL来说，标准的读写分离是主从模式，一个写节点Master后面跟着多个读节点，读节点的数量取决于系统的压力。\n\n### 4.1 MySQL主从模式种类\n\n![主从复制方式](/images/Mycat/主从复制方式.png)\n\nMySQL 主从复制的原理如下：\n\n第一步是在主库上记录二进制日志（稍后介绍如何设置）。在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL 会按事务提交的顺序 而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。下一步，备库将主库的二进制日志复制到其本地的中继日志中。首先,备库会启动一个工作线程，称为I/O线程,I/O线程跟主库建立一个普通的客户端连接，然后在主库上启 动一个特殊的二进制转储(binhg dump、线程（该线程没有对应的 SQL 命令），这个二进制转储线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库，它将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会 被唤醒，备库 I/O 线程会将接收到的事件记录到中继日志中。\n\n备库的SQL线程执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当SQL线程追赶上I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL线程执行的事件也可以通过配置选项来决定是否写入其自己的二进制日志中。这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行。也就是说 I/o 线程能够独立于 SQL 线程之外工作。但这种架构也限制了复制的过程，其中最重要 的一点是在主库上并发运行的査询在备库只能串行化执行，因\n为只有一个 SQL 线程来重 放中继日志中的事件。\n\n进行同步复制，这将大大改善MySQL主从同步的数据延迟问题，配合Mycat分片，可以更好的将一个超级大表的数据同步的时延降低到最低。即使是并发复制机制、仍然无法避免主从数据库的数据瞬间不同步的问题，因此又有了一种增强的方案，即galera for mysql、percona-cluster或者mariadb cluster等集群机制，他们是一种多主同步复制的模式，可以在任意节点上进行读写、自动控制成员，自动删除故障节点、自动加入节点、真正给予行级别的并发复制等强大能力。\n\n**MySQL主从同步的监控**\n\nMySQL有主从同步的状态信息，可以通过命令以下获取：\n\n**show slave status**：获知当前是否主从同步正常工作。其中Seconds_Behind_Master字段从字面理解，它表示当前MySQL主从数据的同步延迟，单位是秒，但这个指标从DBA的角度并不能简单的理解为延迟多少秒，但对于应用来说，简单的认为是主从同步的时间差就可以了，另外，当主从同步停止以后，重新启动同步，这个数值可能会是几万秒，取决于主从同步停止的时间长短，我们可以认为数据此时有很多天没有同步了，而这个数值越接近零，则说明主从同步延迟最小。\n\n我们可以采集这个指标并汇聚曲线图，来分析我们的数据库的同步延迟曲线，然后根据此曲线，给出一个合理的阀值，主从同步的时延小于阀值时，我们认为从库是同步的，此时可以安全的从从库读取数据。Mycat 未来将支持这种优化，让应用更加可靠的读取到预期的从库数据。\n\n### 4.2 MySQL高可用方案\n\n1.主从复制+读写分离\n\n![mysql高可用方案1](/images/Mycat/mysql高可用方案1.png)\n\n对于数据实时性要求不是特别严格的应用，只需要通过廉价的 pc server 来扩展 Slave 的数量，将读压力分散到多台 Slave 的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。\n\n2.MySQL Cluster\n\n![mysql高可用方案2](/images/Mycat/mysql高可用方案2.png)\n\nMySQL Cluster 由一组计算机构成，每台计算机上均运行着多种进程，包括 MySQL 服务器，NDB Cluster的数据节点，管理服务器，以及（可能）专门的数据访问程序。NDB”是一种“内存中”的存储引擎，它具有可用性高和数据一致性好的特点。MySQL Cluster 要实现完全冗余和容错，至少需要 4 台物理主机，其中两个为管理节点。MySQL Cluster使用不那么广泛，除了自身构架因素、适用的业务有限之外，另一个重要的原因是其安装配置管理相对复杂繁琐，总共有几十个操作步骤，需要 DBA 花费几个小时才能搭建或完成。重启 MySQLCluster 数据库的管理操作之前需要执行 46 个手动命令，需要耗费 DBA 2.5 小时的时间，而依靠 MySQLCluster Manager 只需一个命令即可完成，但 MySQL Cluster Manager 仅作为商用 MySQL Cluster 运营商级版本 (CGE) 数据库的一部分提供，需要购买。其官方的说明，若应用中的 SQL 操作为主键数据库访问，包含一些JOIN 操作而非对整个表执行常规扫描和 JOIN 而返回数万行数据，则适合 Cluster，否则不合适，从这一条限制来看，表明大多数业务场景并不合适 MySQL Cluster，业内有资深人士也凭评价：NDB 不适合大多数业务场景，而且有安全问题。\n\n3.HeartBeat+双主复制\n\n![mysql高可用方案3](/images/Mycat/mysql高可用方案3.png)\n\nheartbeat 是 Linux-HA 工程的一个组件,heartbeat 最核心的包括两个部分：心跳监测和资源接管。在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运 行在对方主机上的资源或者服务。\n\n4.HeartBeat+DRBD+MySQL\n\n![mysql高可用方案4](/images/Mycat/mysql高可用方案4.png)\n\nDRBD 是通过网络来实现块设备的数据镜像同步的一款开源 Cluster 软件，它自动完成网络中两个不同服务器上的磁盘同步，相对于 binlog 日志同步，它是更底层的磁盘同步，理论上 DRDB 适合很多文件型系统的高可用。\n\n5.Lvs+Keepalived+双主复制\n\n![mysql高可用方案5](/images/Mycat/mysql高可用方案5.png)\n\nLvs 是一个虚拟的服务器集群系统，可以实现 LINUX 平台下的简单负载均衡。keepalived 是一个类似于layer3, 4 & 5 交换机制的软件，主要用于主机与备机的故障转移，这是一种适用面很广的负载均衡和高可用方\n案，最常用于 Web 系统。\n\n6.Galera Cluster\n\n![mysql高可用方案6](/images/Mycat/mysql高可用方案6.png)\n\n这种 gluster 模式可以说是全新的一种高可用方案，前面也提到其优点，它的缺点不多，不支持 XA，不支持Lock Table，只能用 InnoDB 引擎。\n\n### 4.3 Mycat读写分离支持\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t\t<!-- can have multi read hosts -->\n\t\t<readHost host=\"hostS1\" url=\"localhost2:3306\" user=\"root\" password=\"123456\"weight=\"1\" />\n\t</writeHost>\n</dataHost>\n```\n\n或者\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost:3307\" user=\"root\" password=\"123456\">\n\t</writeHost>\n</dataHost>\n```\n\n以上两种取模第一种当写挂了读不可用，第二种可以继续使用，事务内部的一切操作都会走写节点，所以读操作不要加事务，如果读延时较大，使用根据主从延时的读写分离，或者强制走写节点。\n\n当你是1主3从的模式的时候，可以把第一个从节点配置为writeHost 2，第2个和第三个从节点则配置为writeHost 1的readHost:\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"1\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t<heartbeat>select user()</heartbeat>\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\" >\n\t\t<readHost host=\"hostS2\" url=\"localhost3:3306\" user=\"root\" password=\"123456\" />\n\t\t<readHost host=\"hostS3\" url=\"localhos4t:3306\" user=\"root\" password=\"123456\" />\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost2:3306\" user=\"root\" password=\"123456\" />\n</dataHost>\n```\n\n**根据主从延时切换**：\n\n1.4开始支持MySQL主从复制状态绑定的读写分离机制，让读更加安全可靠，配置如下：\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"2\" slaveThreshold=\"100\">\n\t<heartbeat>show slave status</heartbeat>\n\t<!-- can have multi write hosts -->\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\" url=\"localhost:3316\" user=\"root\" password=\"123456\" />\n</dataHost>\n```\n\nMyCAT心跳检查语句配置为 show slave status,dataHost 上定义两个新属性： switchType=\"2\" 与slaveThreshold=\"100\"，此时意味着开启 MySQL 主从复制状态绑定的读写分离与切换机制，Mycat心跳机制通过检测 show slave status中的\"Seconds_Behind_Master\", \"Slave_IO_Running\",\"Slave_SQL_Running\" 三个字段来确定当前主从同步的状态以及Seconds_Behind_Master主从复制时延,当Seconds_Behind_Master > slaveThreshold时，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的 Seconds_Behind_Master 是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。\n\n1.4.1开始支持MySQL 集群模式，让读更加安全可靠,配置如下：\n\n```xml\n<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"3\">\n\t<heartbeat> show status like ‘wsrep%’ </heartbeat>\n\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\"password=\"123456\">\n\t</writeHost>\n\t<writeHost host=\"hostS1\"url=\"localhost:3316\"user=\"root\"password=\"123456\" ></writeHost>\n</dataHost>\n```\n\nMyCAT 心跳检查语句配置为 show status like ‘wsrep%’,dataHost 上定义两个新属性： switchType=\"3\"此时意味着开启MySQL集群复制状态状态绑定的读写分离与切换机制，Mycat心跳机制通过检测集群复制时延时，如果延时过大或者集群出现节点问题不会负载改节点。\n\nswitchType字典值：\n\n-1：表示不自动切换\n\n1：默认值，自动切换\n\n2：基于MySQL主从同步的状态决定是否切换，心跳语句为show slave status\n\n3：基于MySQL galary cluster的切换机制(适合集群)（1.4.1）,心跳语句为 show status like ‘wsrep%’\n\n### 4.4 Mycat高可用方案\n\nMycat 作为一个代理层中间件，Mycat 系统的高可用涉及到 Mycat 本身的高可用以及后端 MySQL 的高可用，前面章节所讲的 MySQL 高可用方案都可以在此用来确保 Mycat 所连接的后端 MySQL 服务的高可用性。在\n大多数情况下，建议采用标准的 MySQL 主从复制高可用性配置并交付给 Mycat 来完成后端 MySQL 节点的主从自动切换。\n\n![mycat高可用方案](/images/Mycat/mycat高可用方案.png)\n\n## 5. Mycat系统架构\n\n<center>系统架构</center>\n\n![arc](/images/Mycat/arc.png)\n\n<center>最佳实践</center>\n\n![最佳实践](/images/Mycat/最佳实践.jpg)\n\n## 6. 参考资料\n\nMycat权威指南：http://www.mycat.io/document/mycat-definitive-guide.pdf\n\nMycal社区：http://www.mycat.io/","slug":"2018-12-04-Mycat中间件指南","published":1,"updated":"2018-12-04T13:27:34.977Z","comments":1,"photos":[],"link":"","_id":"cjskffof200624glm6wco1h12","content":"<h2 id=\"1-Mycat概述\"><a href=\"#1-Mycat概述\" class=\"headerlink\" title=\"1. Mycat概述\"></a>1. Mycat概述</h2><p>Mycat 是什么？从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了 MySQL 协议的的Server，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。<br><a id=\"more\"></a></p>\n<h3 id=\"1-1-Mycat原理\"><a href=\"#1-1-Mycat原理\" class=\"headerlink\" title=\"1.1 Mycat原理\"></a>1.1 Mycat原理</h3><p>Mycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。</p>\n<h3 id=\"1-2-Mycat应用场景\"><a href=\"#1-2-Mycat应用场景\" class=\"headerlink\" title=\"1.2 Mycat应用场景\"></a>1.2 Mycat应用场景</h3><p>Mycat 发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景：</p>\n<ul>\n<li><p>单纯的读写分离，此时配置最为简单，支持读写分离，主从切换；</p>\n</li>\n<li><p>分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片；</p>\n</li>\n<li><p>多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化；</p>\n</li>\n<li><p>报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计；</p>\n</li>\n<li><p>替代 Hbase，分析大数据；</p>\n</li>\n<li><p>作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择。</p>\n</li>\n</ul>\n<h3 id=\"1-3-Mycat中的概念\"><a href=\"#1-3-Mycat中的概念\" class=\"headerlink\" title=\"1.3 Mycat中的概念\"></a>1.3 Mycat中的概念</h3><h4 id=\"1-3-1-逻辑库-schema\"><a href=\"#1-3-1-逻辑库-schema\" class=\"headerlink\" title=\"1.3.1 逻辑库(schema)\"></a>1.3.1 逻辑库(schema)</h4><p>通常对实际应用来说，并不需要知道中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。</p>\n<h4 id=\"1-3-2-逻辑表-table\"><a href=\"#1-3-2-逻辑表-table\" class=\"headerlink\" title=\"1.3.2 逻辑表(table)\"></a>1.3.2 逻辑表(table)</h4><p>既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。</p>\n<ul>\n<li>1.分片表</li>\n</ul>\n<p>分片表，是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。</p>\n<ul>\n<li>2.非分片表</li>\n</ul>\n<p>一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。</p>\n<ul>\n<li>3.ER表</li>\n</ul>\n<p>关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关系，Mycat 中的 ER 表即是来源于此。根据这一思路，提出了基于 E-R 关系的数据分片策略，子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据 Join 不会跨库操作。</p>\n<p>表分组（Table Group）是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的重要一条规则。</p>\n<ul>\n<li>4.全局表</li>\n</ul>\n<p>一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性：变动不频繁、数据量总体变化不大、数据规模不大，很少有超过数十万条记录。对于这类的表，在分片的情况下，当业务表因为规模而进行分片以后，业务表与这些附属的字典表之间的关联，就成了比较棘手的问题，所以 Mycat 中通过数据冗余来解决这类表的 join，即所有的分片都有一份数据的拷贝，所有将字典表或者符合字典表特性的一些表定义为全局表。</p>\n<p>数据冗余是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的另外一条重要规则。</p>\n<h4 id=\"1-3-3-分片节点-dataNode\"><a href=\"#1-3-3-分片节点-dataNode\" class=\"headerlink\" title=\"1.3.3 分片节点(dataNode)\"></a>1.3.3 分片节点(dataNode)</h4><p>数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点（dataNode）。</p>\n<h4 id=\"1-3-4-节点主机-dataHost\"><a href=\"#1-3-4-节点主机-dataHost\" class=\"headerlink\" title=\"1.3.4 节点主机(dataHost)\"></a>1.3.4 节点主机(dataHost)</h4><p>数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。</p>\n<h4 id=\"1-3-5-分片规则-rule\"><a href=\"#1-3-5-分片规则-rule\" class=\"headerlink\" title=\"1.3.5 分片规则(rule)\"></a>1.3.5 分片规则(rule)</h4><p>前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。</p>\n<h4 id=\"1-3-6-全局序列号-sequence\"><a href=\"#1-3-6-全局序列号-sequence\" class=\"headerlink\" title=\"1.3.6 全局序列号(sequence)\"></a>1.3.6 全局序列号(sequence)</h4><p>数据切分后，原有的关系数据库中的主键约束在分布式条件下将无法使用，因此需要引入外部机制保证数据唯一性标识，这种保证全局性的数据唯一标识的机制就是全局序列号（sequence）。</p>\n<h2 id=\"2-Mycat配置\"><a href=\"#2-Mycat配置\" class=\"headerlink\" title=\"2. Mycat配置\"></a>2. Mycat配置</h2><h3 id=\"2-1-schema-xml\"><a href=\"#2-1-schema-xml\" class=\"headerlink\" title=\"2.1 schema.xml\"></a>2.1 schema.xml</h3><p>Schema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。弄懂这些配置，是正确使用 MyCat 的前提。这里就一层层对该文件进行解析。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"TESTDB\"</span> <span class=\"attr\">checkSQLschema</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">sqlMaxLimit</span>=<span class=\"string\">\"100\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn2\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"travelrecord\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn1,dn2,dn3\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"auto-sharding-long\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"USERDB\"</span> <span class=\"attr\">checkSQLschema</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">sqlMaxLimit</span>=<span class=\"string\">\"100\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"company\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn10,dn11,dn12\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"auto-sharding-long\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>schema</strong>：该标签用于定义 MyCat 实例中的逻辑库，MyCat 可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用 schema 标签来划分这些不同的逻辑库。如果不配置 schema 标签，所有的表配置，会属于同一个默认的逻辑库。</p>\n<p><strong>table</strong>：该标签定义了 MyCat 中的逻辑表，所有需要拆分的表都需要在这个标签中定义。</p>\n<p><strong>childTable</strong>：该标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。</p>\n<p><strong>dataNode</strong>：该标签定义了 MyCat 中的数据节点，也就是我们通常说所的数据分片。一个 dataNode 标签就是一个独立的数据分片。</p>\n<p><strong>dataHost</strong>：该标签在 mycat 逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。</p>\n<p><strong>heartbeat</strong>：该标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。</p>\n<h3 id=\"2-2-server-xml\"><a href=\"#2-2-server-xml\" class=\"headerlink\" title=\"2.2 server.xml\"></a>2.2 server.xml</h3><p>server.xml 几乎保存了所有 mycat 需要的系统配置信息。其在代码内直接的映射类为 SystemConfig 类。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">user</span> <span class=\"attr\">name</span>=<span class=\"string\">\"test\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"password\"</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"schemas\"</span>&gt;</span>TESTDB<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"readOnly\"</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"benchmark\"</span>&gt;</span>11111<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usingDecrypt\"</span>&gt;</span>1<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">privileges</span> <span class=\"attr\">check</span>=<span class=\"string\">\"false\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"TESTDB\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"0010\"</span> <span class=\"attr\">showTables</span>=<span class=\"string\">\"custome/mysql\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tbl_user\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"0110\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tbl_dynamic\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"1111\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">privileges</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">user</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>user</strong>：这个标签主要用于定义登录 mycat 的用户和权限。</p>\n<p><strong>system</strong>：该标签内嵌套的所有 property 标签都与系统配置有关，请注意，下面我会省去标签 property 直接使用这个标签的 name 属性内的值来介绍这个属性的作用。</p>\n<h3 id=\"2-3-rule-xml\"><a href=\"#2-3-rule-xml\" class=\"headerlink\" title=\"2.3 rule.xml\"></a>2.3 rule.xml</h3><p>rule.xml 里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。这个文件里面主要有 tableRule 和 function 这两个标签。在具体使用过程中可以按照需求添加 tableRule 和 function。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tableRule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"rule1\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">columns</span>&gt;</span>id<span class=\"tag\">&lt;/<span class=\"name\">columns</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">algorithm</span>&gt;</span>func1<span class=\"tag\">&lt;/<span class=\"name\">algorithm</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tableRule</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">function</span> <span class=\"attr\">name</span>=<span class=\"string\">\"hash-int\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"io.mycat.route.function.PartitionByFileMap\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"mapFile\"</span>&gt;</span>partition-hash-int.txt<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">function</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>tableRule</strong>：该标签定义表规则。</p>\n<p><strong>function</strong>：该标签用于路由算法的配置</p>\n<h2 id=\"3-Mycat分库分表\"><a href=\"#3-Mycat分库分表\" class=\"headerlink\" title=\"3. Mycat分库分表\"></a>3. Mycat分库分表</h2><p><em>当你找到某个合适的业务字段作为分片字段以后，不必纠结于“牺牲了按主键查询记录的性能”，因为在这种情况下，MyCAT 提供了“主键到分片”的内存缓存机制，热点数据按照主键查询，丝毫不损失性能。</em></p>\n<h3 id=\"3-1-Mycat全局表\"><a href=\"#3-1-Mycat全局表\" class=\"headerlink\" title=\"3.1 Mycat全局表\"></a>3.1 Mycat全局表</h3><p>如果你的业务中有些数据类似于数据字典，比如配置文件的配置，常用业务的配置或者数据量不大很少变动的表，这些表往往不是特别大，而且大部分的业务场景都会用到，那么这种表适合于 Mycat 全局表，无须对数据进行切分，只要在所有的分片上保存一份数据即可。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"t_area\"</span> <span class=\"attr\">primaryKey</span>=<span class=\"string\">\"id\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"global\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn1,dn2\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-ER分片表\"><a href=\"#3-2-ER分片表\" class=\"headerlink\" title=\"3.2 ER分片表\"></a>3.2 ER分片表</h3><p>有一类业务，例如订单（order）跟订单明细（order_detail）,明细表会依赖于订单，也就是说会存在表的主从关系，这类似业务的切分可以抽象出合适的切分规则，比如根据用户 ID 切分,其他相关的表都依赖于用户 ID，再或者根据订单 ID 切分，总之部分业务总会可以抽象出父子关系的表。这类表适用于 ER 分片表。</p>\n<p>子表的记录与所关联的父表记录存放在同一个数据分片上，避免数据 Join 跨库操作</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"order\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn$1-32\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"mod-long\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">childTable</span> <span class=\"attr\">name</span>=<span class=\"string\">\"order_detail\"</span> <span class=\"attr\">primaryKey</span>=<span class=\"string\">\"id\"</span> <span class=\"attr\">joinKey</span>=<span class=\"string\">\"order_id\"</span> <span class=\"attr\">parentKey</span>=<span class=\"string\">\"order_id\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-3-多对多关联\"><a href=\"#3-3-多对多关联\" class=\"headerlink\" title=\"3.3 多对多关联\"></a>3.3 多对多关联</h3><p>有一类业务场景是 “主表 A+关系表+主表 B”，举例来说就是商户会员+订单+商户，对应这类业务，如何切分？目前总的原则是需要从业务角度<br>来看，关系表更偏向哪个表，即“A 的关系”还是“B 的关系”，来决定关系表跟从那个方向存储，未来 Mycat版本中将考虑将中间表进行双向复制，以实现从 A-关系表 以及 B-关系表的双向关联查。</p>\n<h3 id=\"3-4-常用分片规则\"><a href=\"#3-4-常用分片规则\" class=\"headerlink\" title=\"3.4 常用分片规则\"></a>3.4 常用分片规则</h3><table>\n<thead>\n<tr>\n<th>分类</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>io.mycat.route.function.PartitionByFileMap</td>\n<td>分片枚举</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByLong</td>\n<td>固定分片hash算法</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.AutoPartitionByLong</td>\n<td>范围约定</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMod</td>\n<td>取模</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByDate</td>\n<td>按日期（天）分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByPattern</td>\n<td>取模范围约束</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByPrefixPattern</td>\n<td>截取数字做hash求模范围约束</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionDirectBySubString</td>\n<td>应用指定</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByString</td>\n<td>截取数字hash解析</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMurmurHash</td>\n<td>一致性 hash</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.LatestMonthPartion</td>\n<td>按单月小时拆分</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByRangeMod</td>\n<td>范围求模分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByRangeDateHash</td>\n<td>日期范围hash分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByHotDate</td>\n<td>冷热数据分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMonth</td>\n<td>自然月分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByCRC32PreSlot</td>\n<td>有状态分片算法</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"3-5-数据扩容方案\"><a href=\"#3-5-数据扩容方案\" class=\"headerlink\" title=\"3.5 数据扩容方案\"></a>3.5 数据扩容方案</h3><h4 id=\"3-5-1-离线扩容缩容\"><a href=\"#3-5-1-离线扩容缩容\" class=\"headerlink\" title=\"3.5.1 离线扩容缩容\"></a>3.5.1 离线扩容缩容</h4><p>1、 复制 schema.xml、 rule.xml 并重命名为 newSchema.xml、 newRule.xml 放于 conf 目录下。</p>\n<p>2、 修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配置参数（表的节点数、数据源、路由规则）。</p>\n<p>3、 修改 conf 目录下的 migrateTables.properties 配置文件， 告诉工具哪些表需要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移。</p>\n<p>4、 修改 bin 目录下的 dataMigrate.sh 脚本文件。</p>\n<p>5、 停止 mycat 服务（如果可以确保扩容缩容过程中不会有写操作， 也可以不停止 mycat 服务）。</p>\n<p>6、 通过 crt 等工具进入 mycat 根目录， 执行 bin/ dataMigrate.sh 脚本， 开始扩容/缩容过程。</p>\n<p>7、 扩容缩容成功后， 将 newSchema.xml 和 newRule.xml 重命名为 schema.xml 和 rule.xml 并替换掉原文件， 重启 mycat 服务， 整个扩容缩容过程完成。</p>\n<h2 id=\"4-Mycat读写分离\"><a href=\"#4-Mycat读写分离\" class=\"headerlink\" title=\"4. Mycat读写分离\"></a>4. Mycat读写分离</h2><p>对于MySQL来说，标准的读写分离是主从模式，一个写节点Master后面跟着多个读节点，读节点的数量取决于系统的压力。</p>\n<h3 id=\"4-1-MySQL主从模式种类\"><a href=\"#4-1-MySQL主从模式种类\" class=\"headerlink\" title=\"4.1 MySQL主从模式种类\"></a>4.1 MySQL主从模式种类</h3><p><img src=\"/images/Mycat/主从复制方式.png\" alt=\"主从复制方式\"></p>\n<p>MySQL 主从复制的原理如下：</p>\n<p>第一步是在主库上记录二进制日志（稍后介绍如何设置）。在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL 会按事务提交的顺序 而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。下一步，备库将主库的二进制日志复制到其本地的中继日志中。首先,备库会启动一个工作线程，称为I/O线程,I/O线程跟主库建立一个普通的客户端连接，然后在主库上启 动一个特殊的二进制转储(binhg dump、线程（该线程没有对应的 SQL 命令），这个二进制转储线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库，它将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会 被唤醒，备库 I/O 线程会将接收到的事件记录到中继日志中。</p>\n<p>备库的SQL线程执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当SQL线程追赶上I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL线程执行的事件也可以通过配置选项来决定是否写入其自己的二进制日志中。这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行。也就是说 I/o 线程能够独立于 SQL 线程之外工作。但这种架构也限制了复制的过程，其中最重要 的一点是在主库上并发运行的査询在备库只能串行化执行，因<br>为只有一个 SQL 线程来重 放中继日志中的事件。</p>\n<p>进行同步复制，这将大大改善MySQL主从同步的数据延迟问题，配合Mycat分片，可以更好的将一个超级大表的数据同步的时延降低到最低。即使是并发复制机制、仍然无法避免主从数据库的数据瞬间不同步的问题，因此又有了一种增强的方案，即galera for mysql、percona-cluster或者mariadb cluster等集群机制，他们是一种多主同步复制的模式，可以在任意节点上进行读写、自动控制成员，自动删除故障节点、自动加入节点、真正给予行级别的并发复制等强大能力。</p>\n<p><strong>MySQL主从同步的监控</strong></p>\n<p>MySQL有主从同步的状态信息，可以通过命令以下获取：</p>\n<p><strong>show slave status</strong>：获知当前是否主从同步正常工作。其中Seconds_Behind_Master字段从字面理解，它表示当前MySQL主从数据的同步延迟，单位是秒，但这个指标从DBA的角度并不能简单的理解为延迟多少秒，但对于应用来说，简单的认为是主从同步的时间差就可以了，另外，当主从同步停止以后，重新启动同步，这个数值可能会是几万秒，取决于主从同步停止的时间长短，我们可以认为数据此时有很多天没有同步了，而这个数值越接近零，则说明主从同步延迟最小。</p>\n<p>我们可以采集这个指标并汇聚曲线图，来分析我们的数据库的同步延迟曲线，然后根据此曲线，给出一个合理的阀值，主从同步的时延小于阀值时，我们认为从库是同步的，此时可以安全的从从库读取数据。Mycat 未来将支持这种优化，让应用更加可靠的读取到预期的从库数据。</p>\n<h3 id=\"4-2-MySQL高可用方案\"><a href=\"#4-2-MySQL高可用方案\" class=\"headerlink\" title=\"4.2 MySQL高可用方案\"></a>4.2 MySQL高可用方案</h3><p>1.主从复制+读写分离</p>\n<p><img src=\"/images/Mycat/mysql高可用方案1.png\" alt=\"mysql高可用方案1\"></p>\n<p>对于数据实时性要求不是特别严格的应用，只需要通过廉价的 pc server 来扩展 Slave 的数量，将读压力分散到多台 Slave 的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。</p>\n<p>2.MySQL Cluster</p>\n<p><img src=\"/images/Mycat/mysql高可用方案2.png\" alt=\"mysql高可用方案2\"></p>\n<p>MySQL Cluster 由一组计算机构成，每台计算机上均运行着多种进程，包括 MySQL 服务器，NDB Cluster的数据节点，管理服务器，以及（可能）专门的数据访问程序。NDB”是一种“内存中”的存储引擎，它具有可用性高和数据一致性好的特点。MySQL Cluster 要实现完全冗余和容错，至少需要 4 台物理主机，其中两个为管理节点。MySQL Cluster使用不那么广泛，除了自身构架因素、适用的业务有限之外，另一个重要的原因是其安装配置管理相对复杂繁琐，总共有几十个操作步骤，需要 DBA 花费几个小时才能搭建或完成。重启 MySQLCluster 数据库的管理操作之前需要执行 46 个手动命令，需要耗费 DBA 2.5 小时的时间，而依靠 MySQLCluster Manager 只需一个命令即可完成，但 MySQL Cluster Manager 仅作为商用 MySQL Cluster 运营商级版本 (CGE) 数据库的一部分提供，需要购买。其官方的说明，若应用中的 SQL 操作为主键数据库访问，包含一些JOIN 操作而非对整个表执行常规扫描和 JOIN 而返回数万行数据，则适合 Cluster，否则不合适，从这一条限制来看，表明大多数业务场景并不合适 MySQL Cluster，业内有资深人士也凭评价：NDB 不适合大多数业务场景，而且有安全问题。</p>\n<p>3.HeartBeat+双主复制</p>\n<p><img src=\"/images/Mycat/mysql高可用方案3.png\" alt=\"mysql高可用方案3\"></p>\n<p>heartbeat 是 Linux-HA 工程的一个组件,heartbeat 最核心的包括两个部分：心跳监测和资源接管。在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运 行在对方主机上的资源或者服务。</p>\n<p>4.HeartBeat+DRBD+MySQL</p>\n<p><img src=\"/images/Mycat/mysql高可用方案4.png\" alt=\"mysql高可用方案4\"></p>\n<p>DRBD 是通过网络来实现块设备的数据镜像同步的一款开源 Cluster 软件，它自动完成网络中两个不同服务器上的磁盘同步，相对于 binlog 日志同步，它是更底层的磁盘同步，理论上 DRDB 适合很多文件型系统的高可用。</p>\n<p>5.Lvs+Keepalived+双主复制</p>\n<p><img src=\"/images/Mycat/mysql高可用方案5.png\" alt=\"mysql高可用方案5\"></p>\n<p>Lvs 是一个虚拟的服务器集群系统，可以实现 LINUX 平台下的简单负载均衡。keepalived 是一个类似于layer3, 4 &amp; 5 交换机制的软件，主要用于主机与备机的故障转移，这是一种适用面很广的负载均衡和高可用方<br>案，最常用于 Web 系统。</p>\n<p>6.Galera Cluster</p>\n<p><img src=\"/images/Mycat/mysql高可用方案6.png\" alt=\"mysql高可用方案6\"></p>\n<p>这种 gluster 模式可以说是全新的一种高可用方案，前面也提到其优点，它的缺点不多，不支持 XA，不支持Lock Table，只能用 InnoDB 引擎。</p>\n<h3 id=\"4-3-Mycat读写分离支持\"><a href=\"#4-3-Mycat读写分离支持\" class=\"headerlink\" title=\"4.3 Mycat读写分离支持\"></a>4.3 Mycat读写分离支持</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"comment\">&lt;!-- can have multi read hosts --&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost2:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span><span class=\"attr\">weight</span>=<span class=\"string\">\"1\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>或者</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3307\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>以上两种取模第一种当写挂了读不可用，第二种可以继续使用，事务内部的一切操作都会走写节点，所以读操作不要加事务，如果读延时较大，使用根据主从延时的读写分离，或者强制走写节点。</p>\n<p>当你是1主3从的模式的时候，可以把第一个从节点配置为writeHost 2，第2个和第三个从节点则配置为writeHost 1的readHost:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> &gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS2\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost3:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS3\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhos4t:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost2:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>根据主从延时切换</strong>：</p>\n<p>1.4开始支持MySQL主从复制状态绑定的读写分离机制，让读更加安全可靠，配置如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span> <span class=\"attr\">switchType</span>=<span class=\"string\">\"2\"</span> <span class=\"attr\">slaveThreshold</span>=<span class=\"string\">\"100\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>show slave status<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3316\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>MyCAT心跳检查语句配置为 show slave status,dataHost 上定义两个新属性： switchType=”2” 与slaveThreshold=”100”，此时意味着开启 MySQL 主从复制状态绑定的读写分离与切换机制，Mycat心跳机制通过检测 show slave status中的”Seconds_Behind_Master”, “Slave_IO_Running”,”Slave_SQL_Running” 三个字段来确定当前主从同步的状态以及Seconds_Behind_Master主从复制时延,当Seconds_Behind_Master &gt; slaveThreshold时，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的 Seconds_Behind_Master 是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。</p>\n<p>1.4.1开始支持MySQL 集群模式，让读更加安全可靠,配置如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span> <span class=\"attr\">switchType</span>=<span class=\"string\">\"3\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span> show status like ‘wsrep%’ <span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span><span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span><span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3316\"</span><span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span><span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>MyCAT 心跳检查语句配置为 show status like ‘wsrep%’,dataHost 上定义两个新属性： switchType=”3”此时意味着开启MySQL集群复制状态状态绑定的读写分离与切换机制，Mycat心跳机制通过检测集群复制时延时，如果延时过大或者集群出现节点问题不会负载改节点。</p>\n<p>switchType字典值：</p>\n<p>-1：表示不自动切换</p>\n<p>1：默认值，自动切换</p>\n<p>2：基于MySQL主从同步的状态决定是否切换，心跳语句为show slave status</p>\n<p>3：基于MySQL galary cluster的切换机制(适合集群)（1.4.1）,心跳语句为 show status like ‘wsrep%’</p>\n<h3 id=\"4-4-Mycat高可用方案\"><a href=\"#4-4-Mycat高可用方案\" class=\"headerlink\" title=\"4.4 Mycat高可用方案\"></a>4.4 Mycat高可用方案</h3><p>Mycat 作为一个代理层中间件，Mycat 系统的高可用涉及到 Mycat 本身的高可用以及后端 MySQL 的高可用，前面章节所讲的 MySQL 高可用方案都可以在此用来确保 Mycat 所连接的后端 MySQL 服务的高可用性。在<br>大多数情况下，建议采用标准的 MySQL 主从复制高可用性配置并交付给 Mycat 来完成后端 MySQL 节点的主从自动切换。</p>\n<p><img src=\"/images/Mycat/mycat高可用方案.png\" alt=\"mycat高可用方案\"></p>\n<h2 id=\"5-Mycat系统架构\"><a href=\"#5-Mycat系统架构\" class=\"headerlink\" title=\"5. Mycat系统架构\"></a>5. Mycat系统架构</h2><center>系统架构</center>\n\n<p><img src=\"/images/Mycat/arc.png\" alt=\"arc\"></p>\n<center>最佳实践</center>\n\n<p><img src=\"/images/Mycat/最佳实践.jpg\" alt=\"最佳实践\"></p>\n<h2 id=\"6-参考资料\"><a href=\"#6-参考资料\" class=\"headerlink\" title=\"6. 参考资料\"></a>6. 参考资料</h2><p>Mycat权威指南：<a href=\"http://www.mycat.io/document/mycat-definitive-guide.pdf\" target=\"_blank\" rel=\"noopener\">http://www.mycat.io/document/mycat-definitive-guide.pdf</a></p>\n<p>Mycal社区：<a href=\"http://www.mycat.io/\" target=\"_blank\" rel=\"noopener\">http://www.mycat.io/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-Mycat概述\"><a href=\"#1-Mycat概述\" class=\"headerlink\" title=\"1. Mycat概述\"></a>1. Mycat概述</h2><p>Mycat 是什么？从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了 MySQL 协议的的Server，前端用户可以把它看作是一个数据库代理，用 MySQL 客户端工具和命令行访问，而其后端可以用MySQL 原生（Native）协议与多个 MySQL 服务器通信，也可以用 JDBC 协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为 N 个小表，存储在后端 MySQL 服务器里或者其他数据库里。<br>","more":"</p>\n<h3 id=\"1-1-Mycat原理\"><a href=\"#1-1-Mycat原理\" class=\"headerlink\" title=\"1.1 Mycat原理\"></a>1.1 Mycat原理</h3><p>Mycat 的原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的 SQL 语句，首先对 SQL 语句做了一些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此 SQL 发往后端的真实数据库，并将返回的结果做适当的处理，最终再返回给用户。</p>\n<h3 id=\"1-2-Mycat应用场景\"><a href=\"#1-2-Mycat应用场景\" class=\"headerlink\" title=\"1.2 Mycat应用场景\"></a>1.2 Mycat应用场景</h3><p>Mycat 发展到现在，适用的场景已经很丰富，而且不断有新用户给出新的创新性的方案，以下是几个典型的应用场景：</p>\n<ul>\n<li><p>单纯的读写分离，此时配置最为简单，支持读写分离，主从切换；</p>\n</li>\n<li><p>分表分库，对于超过 1000 万的表进行分片，最大支持 1000 亿的单表分片；</p>\n</li>\n<li><p>多租户应用，每个应用一个库，但应用程序只连接 Mycat，从而不改造程序本身，实现多租户化；</p>\n</li>\n<li><p>报表系统，借助于 Mycat 的分表能力，处理大规模报表的统计；</p>\n</li>\n<li><p>替代 Hbase，分析大数据；</p>\n</li>\n<li><p>作为海量数据实时查询的一种简单有效方案，比如 100 亿条频繁查询的记录需要在 3 秒内查询出来结果，除了基于主键的查询，还可能存在范围查询或其他属性查询，此时 Mycat 可能是最简单有效的选择。</p>\n</li>\n</ul>\n<h3 id=\"1-3-Mycat中的概念\"><a href=\"#1-3-Mycat中的概念\" class=\"headerlink\" title=\"1.3 Mycat中的概念\"></a>1.3 Mycat中的概念</h3><h4 id=\"1-3-1-逻辑库-schema\"><a href=\"#1-3-1-逻辑库-schema\" class=\"headerlink\" title=\"1.3.1 逻辑库(schema)\"></a>1.3.1 逻辑库(schema)</h4><p>通常对实际应用来说，并不需要知道中间件的存在，业务开发人员只需要知道数据库的概念，所以数据库中间件可以被看做是一个或多个数据库集群构成的逻辑库。</p>\n<h4 id=\"1-3-2-逻辑表-table\"><a href=\"#1-3-2-逻辑表-table\" class=\"headerlink\" title=\"1.3.2 逻辑表(table)\"></a>1.3.2 逻辑表(table)</h4><p>既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。</p>\n<ul>\n<li>1.分片表</li>\n</ul>\n<p>分片表，是指那些原有的很大数据的表，需要切分到多个数据库的表，这样，每个分片都有一部分数据，所有分片构成了完整的数据。</p>\n<ul>\n<li>2.非分片表</li>\n</ul>\n<p>一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的，非分片是相对分片表来说的，就是那些不需要进行数据切分的表。</p>\n<ul>\n<li>3.ER表</li>\n</ul>\n<p>关系型数据库是基于实体关系模型（Entity-Relationship Model)之上，通过其描述了真实世界中事物与关系，Mycat 中的 ER 表即是来源于此。根据这一思路，提出了基于 E-R 关系的数据分片策略，子表的记录与所关联的父表记录存放在同一个数据分片上，即子表依赖于父表，通过表分组（Table Group）保证数据 Join 不会跨库操作。</p>\n<p>表分组（Table Group）是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的重要一条规则。</p>\n<ul>\n<li>4.全局表</li>\n</ul>\n<p>一个真实的业务系统中，往往存在大量的类似字典表的表，这些表基本上很少变动，字典表具有以下几个特性：变动不频繁、数据量总体变化不大、数据规模不大，很少有超过数十万条记录。对于这类的表，在分片的情况下，当业务表因为规模而进行分片以后，业务表与这些附属的字典表之间的关联，就成了比较棘手的问题，所以 Mycat 中通过数据冗余来解决这类表的 join，即所有的分片都有一份数据的拷贝，所有将字典表或者符合字典表特性的一些表定义为全局表。</p>\n<p>数据冗余是解决跨分片数据 join 的一种很好的思路，也是数据切分规划的另外一条重要规则。</p>\n<h4 id=\"1-3-3-分片节点-dataNode\"><a href=\"#1-3-3-分片节点-dataNode\" class=\"headerlink\" title=\"1.3.3 分片节点(dataNode)\"></a>1.3.3 分片节点(dataNode)</h4><p>数据切分后，一个大表被分到不同的分片数据库上面，每个表分片所在的数据库就是分片节点（dataNode）。</p>\n<h4 id=\"1-3-4-节点主机-dataHost\"><a href=\"#1-3-4-节点主机-dataHost\" class=\"headerlink\" title=\"1.3.4 节点主机(dataHost)\"></a>1.3.4 节点主机(dataHost)</h4><p>数据切分后，每个分片节点（dataNode）不一定都会独占一台机器，同一机器上面可以有多个分片数据库，这样一个或多个分片节点（dataNode）所在的机器就是节点主机（dataHost）,为了规避单节点主机并发数限制，尽量将读写压力高的分片节点（dataNode）均衡的放在不同的节点主机（dataHost）。</p>\n<h4 id=\"1-3-5-分片规则-rule\"><a href=\"#1-3-5-分片规则-rule\" class=\"headerlink\" title=\"1.3.5 分片规则(rule)\"></a>1.3.5 分片规则(rule)</h4><p>前面讲了数据切分，一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。</p>\n<h4 id=\"1-3-6-全局序列号-sequence\"><a href=\"#1-3-6-全局序列号-sequence\" class=\"headerlink\" title=\"1.3.6 全局序列号(sequence)\"></a>1.3.6 全局序列号(sequence)</h4><p>数据切分后，原有的关系数据库中的主键约束在分布式条件下将无法使用，因此需要引入外部机制保证数据唯一性标识，这种保证全局性的数据唯一标识的机制就是全局序列号（sequence）。</p>\n<h2 id=\"2-Mycat配置\"><a href=\"#2-Mycat配置\" class=\"headerlink\" title=\"2. Mycat配置\"></a>2. Mycat配置</h2><h3 id=\"2-1-schema-xml\"><a href=\"#2-1-schema-xml\" class=\"headerlink\" title=\"2.1 schema.xml\"></a>2.1 schema.xml</h3><p>Schema.xml 作为 MyCat 中重要的配置文件之一，管理着 MyCat 的逻辑库、表、分片规则、DataNode 以及 DataSource。弄懂这些配置，是正确使用 MyCat 的前提。这里就一层层对该文件进行解析。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"TESTDB\"</span> <span class=\"attr\">checkSQLschema</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">sqlMaxLimit</span>=<span class=\"string\">\"100\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn2\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"travelrecord\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn1,dn2,dn3\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"auto-sharding-long\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"USERDB\"</span> <span class=\"attr\">checkSQLschema</span>=<span class=\"string\">\"false\"</span> <span class=\"attr\">sqlMaxLimit</span>=<span class=\"string\">\"100\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"company\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn10,dn11,dn12\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"auto-sharding-long\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>schema</strong>：该标签用于定义 MyCat 实例中的逻辑库，MyCat 可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用 schema 标签来划分这些不同的逻辑库。如果不配置 schema 标签，所有的表配置，会属于同一个默认的逻辑库。</p>\n<p><strong>table</strong>：该标签定义了 MyCat 中的逻辑表，所有需要拆分的表都需要在这个标签中定义。</p>\n<p><strong>childTable</strong>：该标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。</p>\n<p><strong>dataNode</strong>：该标签定义了 MyCat 中的数据节点，也就是我们通常说所的数据分片。一个 dataNode 标签就是一个独立的数据分片。</p>\n<p><strong>dataHost</strong>：该标签在 mycat 逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。</p>\n<p><strong>heartbeat</strong>：该标签内指明用于和后端数据库进行心跳检查的语句。例如,MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。</p>\n<h3 id=\"2-2-server-xml\"><a href=\"#2-2-server-xml\" class=\"headerlink\" title=\"2.2 server.xml\"></a>2.2 server.xml</h3><p>server.xml 几乎保存了所有 mycat 需要的系统配置信息。其在代码内直接的映射类为 SystemConfig 类。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">user</span> <span class=\"attr\">name</span>=<span class=\"string\">\"test\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"password\"</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"schemas\"</span>&gt;</span>TESTDB<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"readOnly\"</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"benchmark\"</span>&gt;</span>11111<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"usingDecrypt\"</span>&gt;</span>1<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">privileges</span> <span class=\"attr\">check</span>=<span class=\"string\">\"false\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">schema</span> <span class=\"attr\">name</span>=<span class=\"string\">\"TESTDB\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"0010\"</span> <span class=\"attr\">showTables</span>=<span class=\"string\">\"custome/mysql\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tbl_user\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"0110\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"tbl_dynamic\"</span> <span class=\"attr\">dml</span>=<span class=\"string\">\"1111\"</span>&gt;</span><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">schema</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">privileges</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">user</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>user</strong>：这个标签主要用于定义登录 mycat 的用户和权限。</p>\n<p><strong>system</strong>：该标签内嵌套的所有 property 标签都与系统配置有关，请注意，下面我会省去标签 property 直接使用这个标签的 name 属性内的值来介绍这个属性的作用。</p>\n<h3 id=\"2-3-rule-xml\"><a href=\"#2-3-rule-xml\" class=\"headerlink\" title=\"2.3 rule.xml\"></a>2.3 rule.xml</h3><p>rule.xml 里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。这个文件里面主要有 tableRule 和 function 这两个标签。在具体使用过程中可以按照需求添加 tableRule 和 function。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">tableRule</span> <span class=\"attr\">name</span>=<span class=\"string\">\"rule1\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">columns</span>&gt;</span>id<span class=\"tag\">&lt;/<span class=\"name\">columns</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">algorithm</span>&gt;</span>func1<span class=\"tag\">&lt;/<span class=\"name\">algorithm</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">rule</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">tableRule</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">function</span> <span class=\"attr\">name</span>=<span class=\"string\">\"hash-int\"</span> <span class=\"attr\">class</span>=<span class=\"string\">\"io.mycat.route.function.PartitionByFileMap\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">property</span> <span class=\"attr\">name</span>=<span class=\"string\">\"mapFile\"</span>&gt;</span>partition-hash-int.txt<span class=\"tag\">&lt;/<span class=\"name\">property</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">function</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>tableRule</strong>：该标签定义表规则。</p>\n<p><strong>function</strong>：该标签用于路由算法的配置</p>\n<h2 id=\"3-Mycat分库分表\"><a href=\"#3-Mycat分库分表\" class=\"headerlink\" title=\"3. Mycat分库分表\"></a>3. Mycat分库分表</h2><p><em>当你找到某个合适的业务字段作为分片字段以后，不必纠结于“牺牲了按主键查询记录的性能”，因为在这种情况下，MyCAT 提供了“主键到分片”的内存缓存机制，热点数据按照主键查询，丝毫不损失性能。</em></p>\n<h3 id=\"3-1-Mycat全局表\"><a href=\"#3-1-Mycat全局表\" class=\"headerlink\" title=\"3.1 Mycat全局表\"></a>3.1 Mycat全局表</h3><p>如果你的业务中有些数据类似于数据字典，比如配置文件的配置，常用业务的配置或者数据量不大很少变动的表，这些表往往不是特别大，而且大部分的业务场景都会用到，那么这种表适合于 Mycat 全局表，无须对数据进行切分，只要在所有的分片上保存一份数据即可。</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"t_area\"</span> <span class=\"attr\">primaryKey</span>=<span class=\"string\">\"id\"</span> <span class=\"attr\">type</span>=<span class=\"string\">\"global\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn1,dn2\"</span> /&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-ER分片表\"><a href=\"#3-2-ER分片表\" class=\"headerlink\" title=\"3.2 ER分片表\"></a>3.2 ER分片表</h3><p>有一类业务，例如订单（order）跟订单明细（order_detail）,明细表会依赖于订单，也就是说会存在表的主从关系，这类似业务的切分可以抽象出合适的切分规则，比如根据用户 ID 切分,其他相关的表都依赖于用户 ID，再或者根据订单 ID 切分，总之部分业务总会可以抽象出父子关系的表。这类表适用于 ER 分片表。</p>\n<p>子表的记录与所关联的父表记录存放在同一个数据分片上，避免数据 Join 跨库操作</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">table</span> <span class=\"attr\">name</span>=<span class=\"string\">\"order\"</span> <span class=\"attr\">dataNode</span>=<span class=\"string\">\"dn$1-32\"</span> <span class=\"attr\">rule</span>=<span class=\"string\">\"mod-long\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">childTable</span> <span class=\"attr\">name</span>=<span class=\"string\">\"order_detail\"</span> <span class=\"attr\">primaryKey</span>=<span class=\"string\">\"id\"</span> <span class=\"attr\">joinKey</span>=<span class=\"string\">\"order_id\"</span> <span class=\"attr\">parentKey</span>=<span class=\"string\">\"order_id\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">table</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"3-3-多对多关联\"><a href=\"#3-3-多对多关联\" class=\"headerlink\" title=\"3.3 多对多关联\"></a>3.3 多对多关联</h3><p>有一类业务场景是 “主表 A+关系表+主表 B”，举例来说就是商户会员+订单+商户，对应这类业务，如何切分？目前总的原则是需要从业务角度<br>来看，关系表更偏向哪个表，即“A 的关系”还是“B 的关系”，来决定关系表跟从那个方向存储，未来 Mycat版本中将考虑将中间表进行双向复制，以实现从 A-关系表 以及 B-关系表的双向关联查。</p>\n<h3 id=\"3-4-常用分片规则\"><a href=\"#3-4-常用分片规则\" class=\"headerlink\" title=\"3.4 常用分片规则\"></a>3.4 常用分片规则</h3><table>\n<thead>\n<tr>\n<th>分类</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>io.mycat.route.function.PartitionByFileMap</td>\n<td>分片枚举</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByLong</td>\n<td>固定分片hash算法</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.AutoPartitionByLong</td>\n<td>范围约定</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMod</td>\n<td>取模</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByDate</td>\n<td>按日期（天）分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByPattern</td>\n<td>取模范围约束</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByPrefixPattern</td>\n<td>截取数字做hash求模范围约束</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionDirectBySubString</td>\n<td>应用指定</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByString</td>\n<td>截取数字hash解析</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMurmurHash</td>\n<td>一致性 hash</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.LatestMonthPartion</td>\n<td>按单月小时拆分</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByRangeMod</td>\n<td>范围求模分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByRangeDateHash</td>\n<td>日期范围hash分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByHotDate</td>\n<td>冷热数据分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByMonth</td>\n<td>自然月分片</td>\n</tr>\n<tr>\n<td>io.mycat.route.function.PartitionByCRC32PreSlot</td>\n<td>有状态分片算法</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"3-5-数据扩容方案\"><a href=\"#3-5-数据扩容方案\" class=\"headerlink\" title=\"3.5 数据扩容方案\"></a>3.5 数据扩容方案</h3><h4 id=\"3-5-1-离线扩容缩容\"><a href=\"#3-5-1-离线扩容缩容\" class=\"headerlink\" title=\"3.5.1 离线扩容缩容\"></a>3.5.1 离线扩容缩容</h4><p>1、 复制 schema.xml、 rule.xml 并重命名为 newSchema.xml、 newRule.xml 放于 conf 目录下。</p>\n<p>2、 修改 newSchema.xml 和 newRule.xml 配置文件为扩容缩容后的 mycat 配置参数（表的节点数、数据源、路由规则）。</p>\n<p>3、 修改 conf 目录下的 migrateTables.properties 配置文件， 告诉工具哪些表需要进行扩容或缩容,没有出现在此配置文件的 schema 表不会进行数据迁移。</p>\n<p>4、 修改 bin 目录下的 dataMigrate.sh 脚本文件。</p>\n<p>5、 停止 mycat 服务（如果可以确保扩容缩容过程中不会有写操作， 也可以不停止 mycat 服务）。</p>\n<p>6、 通过 crt 等工具进入 mycat 根目录， 执行 bin/ dataMigrate.sh 脚本， 开始扩容/缩容过程。</p>\n<p>7、 扩容缩容成功后， 将 newSchema.xml 和 newRule.xml 重命名为 schema.xml 和 rule.xml 并替换掉原文件， 重启 mycat 服务， 整个扩容缩容过程完成。</p>\n<h2 id=\"4-Mycat读写分离\"><a href=\"#4-Mycat读写分离\" class=\"headerlink\" title=\"4. Mycat读写分离\"></a>4. Mycat读写分离</h2><p>对于MySQL来说，标准的读写分离是主从模式，一个写节点Master后面跟着多个读节点，读节点的数量取决于系统的压力。</p>\n<h3 id=\"4-1-MySQL主从模式种类\"><a href=\"#4-1-MySQL主从模式种类\" class=\"headerlink\" title=\"4.1 MySQL主从模式种类\"></a>4.1 MySQL主从模式种类</h3><p><img src=\"/images/Mycat/主从复制方式.png\" alt=\"主从复制方式\"></p>\n<p>MySQL 主从复制的原理如下：</p>\n<p>第一步是在主库上记录二进制日志（稍后介绍如何设置）。在每次准备提交事务完成数据更新前，主库将数据更新的事件记录到二进制日志中。MySQL 会按事务提交的顺序 而非每条语句的执行顺序来记录二进制日志。在记录二进制日志后，主库会告诉存储引擎可以提交事务了。下一步，备库将主库的二进制日志复制到其本地的中继日志中。首先,备库会启动一个工作线程，称为I/O线程,I/O线程跟主库建立一个普通的客户端连接，然后在主库上启 动一个特殊的二进制转储(binhg dump、线程（该线程没有对应的 SQL 命令），这个二进制转储线程会读取主库上二进制日志中的事件。它不会对事件进行轮询。如果该线程追赶上了主库，它将进入睡眠状态，直到主库发送信号量通知其有新的事件产生时才会 被唤醒，备库 I/O 线程会将接收到的事件记录到中继日志中。</p>\n<p>备库的SQL线程执行最后一步，该线程从中继日志中读取事件并在备库执行，从而实现备库数据的更新。当SQL线程追赶上I/O 线程时，中继日志通常已经在系统缓存中，所以中继日志的开销很低。SQL线程执行的事件也可以通过配置选项来决定是否写入其自己的二进制日志中。这种复制架构实现了获取事件和重放事件的解耦，允许这两个过程异步进行。也就是说 I/o 线程能够独立于 SQL 线程之外工作。但这种架构也限制了复制的过程，其中最重要 的一点是在主库上并发运行的査询在备库只能串行化执行，因<br>为只有一个 SQL 线程来重 放中继日志中的事件。</p>\n<p>进行同步复制，这将大大改善MySQL主从同步的数据延迟问题，配合Mycat分片，可以更好的将一个超级大表的数据同步的时延降低到最低。即使是并发复制机制、仍然无法避免主从数据库的数据瞬间不同步的问题，因此又有了一种增强的方案，即galera for mysql、percona-cluster或者mariadb cluster等集群机制，他们是一种多主同步复制的模式，可以在任意节点上进行读写、自动控制成员，自动删除故障节点、自动加入节点、真正给予行级别的并发复制等强大能力。</p>\n<p><strong>MySQL主从同步的监控</strong></p>\n<p>MySQL有主从同步的状态信息，可以通过命令以下获取：</p>\n<p><strong>show slave status</strong>：获知当前是否主从同步正常工作。其中Seconds_Behind_Master字段从字面理解，它表示当前MySQL主从数据的同步延迟，单位是秒，但这个指标从DBA的角度并不能简单的理解为延迟多少秒，但对于应用来说，简单的认为是主从同步的时间差就可以了，另外，当主从同步停止以后，重新启动同步，这个数值可能会是几万秒，取决于主从同步停止的时间长短，我们可以认为数据此时有很多天没有同步了，而这个数值越接近零，则说明主从同步延迟最小。</p>\n<p>我们可以采集这个指标并汇聚曲线图，来分析我们的数据库的同步延迟曲线，然后根据此曲线，给出一个合理的阀值，主从同步的时延小于阀值时，我们认为从库是同步的，此时可以安全的从从库读取数据。Mycat 未来将支持这种优化，让应用更加可靠的读取到预期的从库数据。</p>\n<h3 id=\"4-2-MySQL高可用方案\"><a href=\"#4-2-MySQL高可用方案\" class=\"headerlink\" title=\"4.2 MySQL高可用方案\"></a>4.2 MySQL高可用方案</h3><p>1.主从复制+读写分离</p>\n<p><img src=\"/images/Mycat/mysql高可用方案1.png\" alt=\"mysql高可用方案1\"></p>\n<p>对于数据实时性要求不是特别严格的应用，只需要通过廉价的 pc server 来扩展 Slave 的数量，将读压力分散到多台 Slave 的机器上面，即可通过分散单台数据库服务器的读压力来解决数据库端的读性能瓶颈，毕竟在大多数数据库应用系统中的读压力还是要比写压力大很多。这在很大程度上解决了目前很多中小型网站的数据库压力瓶颈问题，甚至有些大型网站也在使用类似方案解决数据库瓶颈。</p>\n<p>2.MySQL Cluster</p>\n<p><img src=\"/images/Mycat/mysql高可用方案2.png\" alt=\"mysql高可用方案2\"></p>\n<p>MySQL Cluster 由一组计算机构成，每台计算机上均运行着多种进程，包括 MySQL 服务器，NDB Cluster的数据节点，管理服务器，以及（可能）专门的数据访问程序。NDB”是一种“内存中”的存储引擎，它具有可用性高和数据一致性好的特点。MySQL Cluster 要实现完全冗余和容错，至少需要 4 台物理主机，其中两个为管理节点。MySQL Cluster使用不那么广泛，除了自身构架因素、适用的业务有限之外，另一个重要的原因是其安装配置管理相对复杂繁琐，总共有几十个操作步骤，需要 DBA 花费几个小时才能搭建或完成。重启 MySQLCluster 数据库的管理操作之前需要执行 46 个手动命令，需要耗费 DBA 2.5 小时的时间，而依靠 MySQLCluster Manager 只需一个命令即可完成，但 MySQL Cluster Manager 仅作为商用 MySQL Cluster 运营商级版本 (CGE) 数据库的一部分提供，需要购买。其官方的说明，若应用中的 SQL 操作为主键数据库访问，包含一些JOIN 操作而非对整个表执行常规扫描和 JOIN 而返回数万行数据，则适合 Cluster，否则不合适，从这一条限制来看，表明大多数业务场景并不合适 MySQL Cluster，业内有资深人士也凭评价：NDB 不适合大多数业务场景，而且有安全问题。</p>\n<p>3.HeartBeat+双主复制</p>\n<p><img src=\"/images/Mycat/mysql高可用方案3.png\" alt=\"mysql高可用方案3\"></p>\n<p>heartbeat 是 Linux-HA 工程的一个组件,heartbeat 最核心的包括两个部分：心跳监测和资源接管。在指定的时间内未收到对方发送的报文，那么就认为对方失效，这时需启动资源接管模块来接管运 行在对方主机上的资源或者服务。</p>\n<p>4.HeartBeat+DRBD+MySQL</p>\n<p><img src=\"/images/Mycat/mysql高可用方案4.png\" alt=\"mysql高可用方案4\"></p>\n<p>DRBD 是通过网络来实现块设备的数据镜像同步的一款开源 Cluster 软件，它自动完成网络中两个不同服务器上的磁盘同步，相对于 binlog 日志同步，它是更底层的磁盘同步，理论上 DRDB 适合很多文件型系统的高可用。</p>\n<p>5.Lvs+Keepalived+双主复制</p>\n<p><img src=\"/images/Mycat/mysql高可用方案5.png\" alt=\"mysql高可用方案5\"></p>\n<p>Lvs 是一个虚拟的服务器集群系统，可以实现 LINUX 平台下的简单负载均衡。keepalived 是一个类似于layer3, 4 &amp; 5 交换机制的软件，主要用于主机与备机的故障转移，这是一种适用面很广的负载均衡和高可用方<br>案，最常用于 Web 系统。</p>\n<p>6.Galera Cluster</p>\n<p><img src=\"/images/Mycat/mysql高可用方案6.png\" alt=\"mysql高可用方案6\"></p>\n<p>这种 gluster 模式可以说是全新的一种高可用方案，前面也提到其优点，它的缺点不多，不支持 XA，不支持Lock Table，只能用 InnoDB 引擎。</p>\n<h3 id=\"4-3-Mycat读写分离支持\"><a href=\"#4-3-Mycat读写分离支持\" class=\"headerlink\" title=\"4.3 Mycat读写分离支持\"></a>4.3 Mycat读写分离支持</h3><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t\t<span class=\"comment\">&lt;!-- can have multi read hosts --&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost2:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span><span class=\"attr\">weight</span>=<span class=\"string\">\"1\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>或者</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3307\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>以上两种取模第一种当写挂了读不可用，第二种可以继续使用，事务内部的一切操作都会走写节点，所以读操作不要加事务，如果读延时较大，使用根据主从延时的读写分离，或者强制走写节点。</p>\n<p>当你是1主3从的模式的时候，可以把第一个从节点配置为writeHost 2，第2个和第三个从节点则配置为writeHost 1的readHost:</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"1\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>select user()<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> &gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS2\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost3:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\">\t\t<span class=\"tag\">&lt;<span class=\"name\">readHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS3\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhos4t:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost2:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p><strong>根据主从延时切换</strong>：</p>\n<p>1.4开始支持MySQL主从复制状态绑定的读写分离机制，让读更加安全可靠，配置如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span> <span class=\"attr\">switchType</span>=<span class=\"string\">\"2\"</span> <span class=\"attr\">slaveThreshold</span>=<span class=\"string\">\"100\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span>show slave status<span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"comment\">&lt;!-- can have multi write hosts --&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3316\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span> <span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> /&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>MyCAT心跳检查语句配置为 show slave status,dataHost 上定义两个新属性： switchType=”2” 与slaveThreshold=”100”，此时意味着开启 MySQL 主从复制状态绑定的读写分离与切换机制，Mycat心跳机制通过检测 show slave status中的”Seconds_Behind_Master”, “Slave_IO_Running”,”Slave_SQL_Running” 三个字段来确定当前主从同步的状态以及Seconds_Behind_Master主从复制时延,当Seconds_Behind_Master &gt; slaveThreshold时，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的 Seconds_Behind_Master 是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。</p>\n<p>1.4.1开始支持MySQL 集群模式，让读更加安全可靠,配置如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dataHost</span> <span class=\"attr\">name</span>=<span class=\"string\">\"localhost1\"</span> <span class=\"attr\">maxCon</span>=<span class=\"string\">\"1000\"</span> <span class=\"attr\">minCon</span>=<span class=\"string\">\"10\"</span> <span class=\"attr\">balance</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">writeType</span>=<span class=\"string\">\"0\"</span> <span class=\"attr\">dbType</span>=<span class=\"string\">\"mysql\"</span> <span class=\"attr\">dbDriver</span>=<span class=\"string\">\"native\"</span> <span class=\"attr\">switchType</span>=<span class=\"string\">\"3\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">heartbeat</span>&gt;</span> show status like ‘wsrep%’ <span class=\"tag\">&lt;/<span class=\"name\">heartbeat</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostM1\"</span> <span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3306\"</span> <span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span><span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">writeHost</span> <span class=\"attr\">host</span>=<span class=\"string\">\"hostS1\"</span><span class=\"attr\">url</span>=<span class=\"string\">\"localhost:3316\"</span><span class=\"attr\">user</span>=<span class=\"string\">\"root\"</span><span class=\"attr\">password</span>=<span class=\"string\">\"123456\"</span> &gt;</span><span class=\"tag\">&lt;/<span class=\"name\">writeHost</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">dataHost</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<p>MyCAT 心跳检查语句配置为 show status like ‘wsrep%’,dataHost 上定义两个新属性： switchType=”3”此时意味着开启MySQL集群复制状态状态绑定的读写分离与切换机制，Mycat心跳机制通过检测集群复制时延时，如果延时过大或者集群出现节点问题不会负载改节点。</p>\n<p>switchType字典值：</p>\n<p>-1：表示不自动切换</p>\n<p>1：默认值，自动切换</p>\n<p>2：基于MySQL主从同步的状态决定是否切换，心跳语句为show slave status</p>\n<p>3：基于MySQL galary cluster的切换机制(适合集群)（1.4.1）,心跳语句为 show status like ‘wsrep%’</p>\n<h3 id=\"4-4-Mycat高可用方案\"><a href=\"#4-4-Mycat高可用方案\" class=\"headerlink\" title=\"4.4 Mycat高可用方案\"></a>4.4 Mycat高可用方案</h3><p>Mycat 作为一个代理层中间件，Mycat 系统的高可用涉及到 Mycat 本身的高可用以及后端 MySQL 的高可用，前面章节所讲的 MySQL 高可用方案都可以在此用来确保 Mycat 所连接的后端 MySQL 服务的高可用性。在<br>大多数情况下，建议采用标准的 MySQL 主从复制高可用性配置并交付给 Mycat 来完成后端 MySQL 节点的主从自动切换。</p>\n<p><img src=\"/images/Mycat/mycat高可用方案.png\" alt=\"mycat高可用方案\"></p>\n<h2 id=\"5-Mycat系统架构\"><a href=\"#5-Mycat系统架构\" class=\"headerlink\" title=\"5. Mycat系统架构\"></a>5. Mycat系统架构</h2><center>系统架构</center>\n\n<p><img src=\"/images/Mycat/arc.png\" alt=\"arc\"></p>\n<center>最佳实践</center>\n\n<p><img src=\"/images/Mycat/最佳实践.jpg\" alt=\"最佳实践\"></p>\n<h2 id=\"6-参考资料\"><a href=\"#6-参考资料\" class=\"headerlink\" title=\"6. 参考资料\"></a>6. 参考资料</h2><p>Mycat权威指南：<a href=\"http://www.mycat.io/document/mycat-definitive-guide.pdf\" target=\"_blank\" rel=\"noopener\">http://www.mycat.io/document/mycat-definitive-guide.pdf</a></p>\n<p>Mycal社区：<a href=\"http://www.mycat.io/\" target=\"_blank\" rel=\"noopener\">http://www.mycat.io/</a></p>"},{"layout":"lay_post","title":"mongoDB架构与集群","date":"2018-11-29T16:00:00.000Z","author":"lvyafei","_content":"\n## 1.mongoDB-集群架构\n\n1.单机部署、2.复本集（主备）部署、3.分片部署、4.复本集与分片混合部署。\n\n1.Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。\n<!-- more -->\n\n2.Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。\n\n![混合集群](/images/mongodb/混合集群.png)\n\n![混合集群-写数据](/images/mongodb/混合集群-写数据.png)\n\n![混合集群-读数据](/images/mongodb/混合集群-读数据.png)\n\n![复本-写](/images/mongodb/复本-写.png)\n\n![复本-读](/images/mongodb/复本-读.png)\n\n![config-server](/images/mongodb/config-server.png)\n\n![shared-key](/images/mongodb/shared-key.png)\n\n## 2.深入剖析MongoDB架构\n\n### 2.1 MongoDB数据文件内部结构\n\nMongoDB在数据存储上按命名空间来划分，一个Collection是一个命名空间，一个索引也是一个命名空间。\n同一个命名空间的数据被分成很多个Extent，Extent之间使用双向链表连接。\n在每一个Extent中，保存了具体每一行的数据，这些数据也是通过双向链接来连接的。\n每一行数据存储空间不仅包括数据占用空间，还可能包含一部分附加空间，这使得在数据Update变大后可以不移动位置。\n索引以BTree结构实现。\n\n![MongoDB数据文件内部结构](http://static.open-open.com/lib/uploadImg/20120929/20120929201958_374.jpg)\n\n### 2.2 在MongoDB中实现事务 \n\n众所周知， MongoDB只支持对单行记录的原子性修改，并不支持对多行数据的原子操作。但是通过上图中的不可思议的操作步骤，实际上你也可以自己实现该事务。 其步骤如下： \n\n第1步：先记录一条事务记录，将要修改的多行记录的修改值写到里面，并设置其状态为init（如果这时候操作中断，那么在重新启动时，会判断到它处于init状态，从而将其保存的多行修改操作应用到具体的行上）。\n第2步：然后更新具体要修改的行，将刚才写的事务记录的标识写到它的tran字段中。\n第3步：将事务记录的状态从 init变成pending（如果在这时候操作中断，那么在重新启动时，会判断到它的状态是pending，这时查看其所有对应的多条要修改的记录，如果 其tran值不为空，那么就进行第4步；如果值为空，说明第4步已经执行过了，直接将其状态从pending变成 commited就行）。\n第4步：将需要修改的多条记录的相应值加以修改，并且unset掉之前的tran字段。\n第5步：将事务记录那一条的状态从pending变成commited，事务至此完成。\n其实上面的步骤并不罕见，在支持事务的DBMS中，其事务原子性提交的保证大多都与上面类似。而事务记录的tran那条记录，就类似于这些DBMS中的redolog。 \n\n![MongoDB中实现事务](http://static.open-open.com/lib/uploadImg/20120929/20120929202006_566.jpg)\n\n### 2.3 MongoDB数据同步\n\n本流程可简要描述如下： \n\n红色箭头表示写操作可以写到Primary上，然后异步同步到多个Secondary上。\n蓝色箭头表示读操作可以从Primary或Secondary任意一个中读取。\n各个Primary与Secondary之间一直保持心跳同步检测，用于判断Replica Sets的状态。\n\n![MongoDB数据同步](http://static.open-open.com/lib/uploadImg/20120929/20120929202014_618.jpg)\n\n### 2.4 分片机制\n\nMongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制。\n有多个分片节点保存这些chunk，每个节点保存一部分的chunk。\n每一个分片节点都是一个Replica Sets，这样保证数据的安全性。\n当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk。\n当chunk在分片节点中分布不均衡时，会引发chunk迁移操作。\n\n![分片机制](http://static.open-open.com/lib/uploadImg/20120929/20120929202022_314.jpg)\n\n### 2.5 服务器角色\n\n前面讲了分片的机制，下面是具体在分片时几种节点的角色： \n\n客户端访问路由节点mongos来进行数据读写。\nconfig服务器保存了两个映射关系，一个是key值的区间对应哪一个chunk的映射关系，另一个是chunk存在哪一个分片节点的映射关系。\n路由节点通过config服务器获取数据信息，通过这些信息，找到真正存放数据的分片节点进行对应操作。\n路由节点还会在写操作时判断当前chunk是否超出限定大小。如果超出，就分列成两个chunk。\n对于按分片key进行的查询和update操作来说，路由节点会查到具体的chunk然后再进行相关的工作。\n对于不按分片key进行的查询和update操作来说，mongos会对所有下属节点发送请求然后再对返回结果进行合并。\n\n![服务器角色](http://static.open-open.com/lib/uploadImg/20120929/20120929202032_511.jpg)\n\n## 3.参考资料\n\n参考：https://blog.csdn.net/zhaowen25/article/details/41871383\n\n参考：http://www.open-open.com/lib/view/open1348919251822.html\n","source":"_posts/2018-11-30-mongoDB架构与集群.md","raw":"---\nlayout: lay_post\ntitle: \"mongoDB架构与集群\"\ndate: 2018-11-30\ncategories: 中间件\ntags: [NoSQL,mongoDB]\nauthor: lvyafei\n---\n\n## 1.mongoDB-集群架构\n\n1.单机部署、2.复本集（主备）部署、3.分片部署、4.复本集与分片混合部署。\n\n1.Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。\n<!-- more -->\n\n2.Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。\n\n![混合集群](/images/mongodb/混合集群.png)\n\n![混合集群-写数据](/images/mongodb/混合集群-写数据.png)\n\n![混合集群-读数据](/images/mongodb/混合集群-读数据.png)\n\n![复本-写](/images/mongodb/复本-写.png)\n\n![复本-读](/images/mongodb/复本-读.png)\n\n![config-server](/images/mongodb/config-server.png)\n\n![shared-key](/images/mongodb/shared-key.png)\n\n## 2.深入剖析MongoDB架构\n\n### 2.1 MongoDB数据文件内部结构\n\nMongoDB在数据存储上按命名空间来划分，一个Collection是一个命名空间，一个索引也是一个命名空间。\n同一个命名空间的数据被分成很多个Extent，Extent之间使用双向链表连接。\n在每一个Extent中，保存了具体每一行的数据，这些数据也是通过双向链接来连接的。\n每一行数据存储空间不仅包括数据占用空间，还可能包含一部分附加空间，这使得在数据Update变大后可以不移动位置。\n索引以BTree结构实现。\n\n![MongoDB数据文件内部结构](http://static.open-open.com/lib/uploadImg/20120929/20120929201958_374.jpg)\n\n### 2.2 在MongoDB中实现事务 \n\n众所周知， MongoDB只支持对单行记录的原子性修改，并不支持对多行数据的原子操作。但是通过上图中的不可思议的操作步骤，实际上你也可以自己实现该事务。 其步骤如下： \n\n第1步：先记录一条事务记录，将要修改的多行记录的修改值写到里面，并设置其状态为init（如果这时候操作中断，那么在重新启动时，会判断到它处于init状态，从而将其保存的多行修改操作应用到具体的行上）。\n第2步：然后更新具体要修改的行，将刚才写的事务记录的标识写到它的tran字段中。\n第3步：将事务记录的状态从 init变成pending（如果在这时候操作中断，那么在重新启动时，会判断到它的状态是pending，这时查看其所有对应的多条要修改的记录，如果 其tran值不为空，那么就进行第4步；如果值为空，说明第4步已经执行过了，直接将其状态从pending变成 commited就行）。\n第4步：将需要修改的多条记录的相应值加以修改，并且unset掉之前的tran字段。\n第5步：将事务记录那一条的状态从pending变成commited，事务至此完成。\n其实上面的步骤并不罕见，在支持事务的DBMS中，其事务原子性提交的保证大多都与上面类似。而事务记录的tran那条记录，就类似于这些DBMS中的redolog。 \n\n![MongoDB中实现事务](http://static.open-open.com/lib/uploadImg/20120929/20120929202006_566.jpg)\n\n### 2.3 MongoDB数据同步\n\n本流程可简要描述如下： \n\n红色箭头表示写操作可以写到Primary上，然后异步同步到多个Secondary上。\n蓝色箭头表示读操作可以从Primary或Secondary任意一个中读取。\n各个Primary与Secondary之间一直保持心跳同步检测，用于判断Replica Sets的状态。\n\n![MongoDB数据同步](http://static.open-open.com/lib/uploadImg/20120929/20120929202014_618.jpg)\n\n### 2.4 分片机制\n\nMongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制。\n有多个分片节点保存这些chunk，每个节点保存一部分的chunk。\n每一个分片节点都是一个Replica Sets，这样保证数据的安全性。\n当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk。\n当chunk在分片节点中分布不均衡时，会引发chunk迁移操作。\n\n![分片机制](http://static.open-open.com/lib/uploadImg/20120929/20120929202022_314.jpg)\n\n### 2.5 服务器角色\n\n前面讲了分片的机制，下面是具体在分片时几种节点的角色： \n\n客户端访问路由节点mongos来进行数据读写。\nconfig服务器保存了两个映射关系，一个是key值的区间对应哪一个chunk的映射关系，另一个是chunk存在哪一个分片节点的映射关系。\n路由节点通过config服务器获取数据信息，通过这些信息，找到真正存放数据的分片节点进行对应操作。\n路由节点还会在写操作时判断当前chunk是否超出限定大小。如果超出，就分列成两个chunk。\n对于按分片key进行的查询和update操作来说，路由节点会查到具体的chunk然后再进行相关的工作。\n对于不按分片key进行的查询和update操作来说，mongos会对所有下属节点发送请求然后再对返回结果进行合并。\n\n![服务器角色](http://static.open-open.com/lib/uploadImg/20120929/20120929202032_511.jpg)\n\n## 3.参考资料\n\n参考：https://blog.csdn.net/zhaowen25/article/details/41871383\n\n参考：http://www.open-open.com/lib/view/open1348919251822.html\n","slug":"2018-11-30-mongoDB架构与集群","published":1,"updated":"2018-12-03T12:56:00.646Z","comments":1,"photos":[],"link":"","_id":"cjskffof200664glmt91nr1sr","content":"<h2 id=\"1-mongoDB-集群架构\"><a href=\"#1-mongoDB-集群架构\" class=\"headerlink\" title=\"1.mongoDB-集群架构\"></a>1.mongoDB-集群架构</h2><p>1.单机部署、2.复本集（主备）部署、3.分片部署、4.复本集与分片混合部署。</p>\n<p>1.Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。<br><a id=\"more\"></a></p>\n<p>2.Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。</p>\n<p><img src=\"/images/mongodb/混合集群.png\" alt=\"混合集群\"></p>\n<p><img src=\"/images/mongodb/混合集群-写数据.png\" alt=\"混合集群-写数据\"></p>\n<p><img src=\"/images/mongodb/混合集群-读数据.png\" alt=\"混合集群-读数据\"></p>\n<p><img src=\"/images/mongodb/复本-写.png\" alt=\"复本-写\"></p>\n<p><img src=\"/images/mongodb/复本-读.png\" alt=\"复本-读\"></p>\n<p><img src=\"/images/mongodb/config-server.png\" alt=\"config-server\"></p>\n<p><img src=\"/images/mongodb/shared-key.png\" alt=\"shared-key\"></p>\n<h2 id=\"2-深入剖析MongoDB架构\"><a href=\"#2-深入剖析MongoDB架构\" class=\"headerlink\" title=\"2.深入剖析MongoDB架构\"></a>2.深入剖析MongoDB架构</h2><h3 id=\"2-1-MongoDB数据文件内部结构\"><a href=\"#2-1-MongoDB数据文件内部结构\" class=\"headerlink\" title=\"2.1 MongoDB数据文件内部结构\"></a>2.1 MongoDB数据文件内部结构</h3><p>MongoDB在数据存储上按命名空间来划分，一个Collection是一个命名空间，一个索引也是一个命名空间。<br>同一个命名空间的数据被分成很多个Extent，Extent之间使用双向链表连接。<br>在每一个Extent中，保存了具体每一行的数据，这些数据也是通过双向链接来连接的。<br>每一行数据存储空间不仅包括数据占用空间，还可能包含一部分附加空间，这使得在数据Update变大后可以不移动位置。<br>索引以BTree结构实现。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929201958_374.jpg\" alt=\"MongoDB数据文件内部结构\"></p>\n<h3 id=\"2-2-在MongoDB中实现事务\"><a href=\"#2-2-在MongoDB中实现事务\" class=\"headerlink\" title=\"2.2 在MongoDB中实现事务\"></a>2.2 在MongoDB中实现事务</h3><p>众所周知， MongoDB只支持对单行记录的原子性修改，并不支持对多行数据的原子操作。但是通过上图中的不可思议的操作步骤，实际上你也可以自己实现该事务。 其步骤如下： </p>\n<p>第1步：先记录一条事务记录，将要修改的多行记录的修改值写到里面，并设置其状态为init（如果这时候操作中断，那么在重新启动时，会判断到它处于init状态，从而将其保存的多行修改操作应用到具体的行上）。<br>第2步：然后更新具体要修改的行，将刚才写的事务记录的标识写到它的tran字段中。<br>第3步：将事务记录的状态从 init变成pending（如果在这时候操作中断，那么在重新启动时，会判断到它的状态是pending，这时查看其所有对应的多条要修改的记录，如果 其tran值不为空，那么就进行第4步；如果值为空，说明第4步已经执行过了，直接将其状态从pending变成 commited就行）。<br>第4步：将需要修改的多条记录的相应值加以修改，并且unset掉之前的tran字段。<br>第5步：将事务记录那一条的状态从pending变成commited，事务至此完成。<br>其实上面的步骤并不罕见，在支持事务的DBMS中，其事务原子性提交的保证大多都与上面类似。而事务记录的tran那条记录，就类似于这些DBMS中的redolog。 </p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202006_566.jpg\" alt=\"MongoDB中实现事务\"></p>\n<h3 id=\"2-3-MongoDB数据同步\"><a href=\"#2-3-MongoDB数据同步\" class=\"headerlink\" title=\"2.3 MongoDB数据同步\"></a>2.3 MongoDB数据同步</h3><p>本流程可简要描述如下： </p>\n<p>红色箭头表示写操作可以写到Primary上，然后异步同步到多个Secondary上。<br>蓝色箭头表示读操作可以从Primary或Secondary任意一个中读取。<br>各个Primary与Secondary之间一直保持心跳同步检测，用于判断Replica Sets的状态。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202014_618.jpg\" alt=\"MongoDB数据同步\"></p>\n<h3 id=\"2-4-分片机制\"><a href=\"#2-4-分片机制\" class=\"headerlink\" title=\"2.4 分片机制\"></a>2.4 分片机制</h3><p>MongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制。<br>有多个分片节点保存这些chunk，每个节点保存一部分的chunk。<br>每一个分片节点都是一个Replica Sets，这样保证数据的安全性。<br>当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk。<br>当chunk在分片节点中分布不均衡时，会引发chunk迁移操作。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202022_314.jpg\" alt=\"分片机制\"></p>\n<h3 id=\"2-5-服务器角色\"><a href=\"#2-5-服务器角色\" class=\"headerlink\" title=\"2.5 服务器角色\"></a>2.5 服务器角色</h3><p>前面讲了分片的机制，下面是具体在分片时几种节点的角色： </p>\n<p>客户端访问路由节点mongos来进行数据读写。<br>config服务器保存了两个映射关系，一个是key值的区间对应哪一个chunk的映射关系，另一个是chunk存在哪一个分片节点的映射关系。<br>路由节点通过config服务器获取数据信息，通过这些信息，找到真正存放数据的分片节点进行对应操作。<br>路由节点还会在写操作时判断当前chunk是否超出限定大小。如果超出，就分列成两个chunk。<br>对于按分片key进行的查询和update操作来说，路由节点会查到具体的chunk然后再进行相关的工作。<br>对于不按分片key进行的查询和update操作来说，mongos会对所有下属节点发送请求然后再对返回结果进行合并。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202032_511.jpg\" alt=\"服务器角色\"></p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><p>参考：<a href=\"https://blog.csdn.net/zhaowen25/article/details/41871383\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhaowen25/article/details/41871383</a></p>\n<p>参考：<a href=\"http://www.open-open.com/lib/view/open1348919251822.html\" target=\"_blank\" rel=\"noopener\">http://www.open-open.com/lib/view/open1348919251822.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-mongoDB-集群架构\"><a href=\"#1-mongoDB-集群架构\" class=\"headerlink\" title=\"1.mongoDB-集群架构\"></a>1.mongoDB-集群架构</h2><p>1.单机部署、2.复本集（主备）部署、3.分片部署、4.复本集与分片混合部署。</p>\n<p>1.Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。<br>","more":"</p>\n<p>2.Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。</p>\n<p><img src=\"/images/mongodb/混合集群.png\" alt=\"混合集群\"></p>\n<p><img src=\"/images/mongodb/混合集群-写数据.png\" alt=\"混合集群-写数据\"></p>\n<p><img src=\"/images/mongodb/混合集群-读数据.png\" alt=\"混合集群-读数据\"></p>\n<p><img src=\"/images/mongodb/复本-写.png\" alt=\"复本-写\"></p>\n<p><img src=\"/images/mongodb/复本-读.png\" alt=\"复本-读\"></p>\n<p><img src=\"/images/mongodb/config-server.png\" alt=\"config-server\"></p>\n<p><img src=\"/images/mongodb/shared-key.png\" alt=\"shared-key\"></p>\n<h2 id=\"2-深入剖析MongoDB架构\"><a href=\"#2-深入剖析MongoDB架构\" class=\"headerlink\" title=\"2.深入剖析MongoDB架构\"></a>2.深入剖析MongoDB架构</h2><h3 id=\"2-1-MongoDB数据文件内部结构\"><a href=\"#2-1-MongoDB数据文件内部结构\" class=\"headerlink\" title=\"2.1 MongoDB数据文件内部结构\"></a>2.1 MongoDB数据文件内部结构</h3><p>MongoDB在数据存储上按命名空间来划分，一个Collection是一个命名空间，一个索引也是一个命名空间。<br>同一个命名空间的数据被分成很多个Extent，Extent之间使用双向链表连接。<br>在每一个Extent中，保存了具体每一行的数据，这些数据也是通过双向链接来连接的。<br>每一行数据存储空间不仅包括数据占用空间，还可能包含一部分附加空间，这使得在数据Update变大后可以不移动位置。<br>索引以BTree结构实现。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929201958_374.jpg\" alt=\"MongoDB数据文件内部结构\"></p>\n<h3 id=\"2-2-在MongoDB中实现事务\"><a href=\"#2-2-在MongoDB中实现事务\" class=\"headerlink\" title=\"2.2 在MongoDB中实现事务\"></a>2.2 在MongoDB中实现事务</h3><p>众所周知， MongoDB只支持对单行记录的原子性修改，并不支持对多行数据的原子操作。但是通过上图中的不可思议的操作步骤，实际上你也可以自己实现该事务。 其步骤如下： </p>\n<p>第1步：先记录一条事务记录，将要修改的多行记录的修改值写到里面，并设置其状态为init（如果这时候操作中断，那么在重新启动时，会判断到它处于init状态，从而将其保存的多行修改操作应用到具体的行上）。<br>第2步：然后更新具体要修改的行，将刚才写的事务记录的标识写到它的tran字段中。<br>第3步：将事务记录的状态从 init变成pending（如果在这时候操作中断，那么在重新启动时，会判断到它的状态是pending，这时查看其所有对应的多条要修改的记录，如果 其tran值不为空，那么就进行第4步；如果值为空，说明第4步已经执行过了，直接将其状态从pending变成 commited就行）。<br>第4步：将需要修改的多条记录的相应值加以修改，并且unset掉之前的tran字段。<br>第5步：将事务记录那一条的状态从pending变成commited，事务至此完成。<br>其实上面的步骤并不罕见，在支持事务的DBMS中，其事务原子性提交的保证大多都与上面类似。而事务记录的tran那条记录，就类似于这些DBMS中的redolog。 </p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202006_566.jpg\" alt=\"MongoDB中实现事务\"></p>\n<h3 id=\"2-3-MongoDB数据同步\"><a href=\"#2-3-MongoDB数据同步\" class=\"headerlink\" title=\"2.3 MongoDB数据同步\"></a>2.3 MongoDB数据同步</h3><p>本流程可简要描述如下： </p>\n<p>红色箭头表示写操作可以写到Primary上，然后异步同步到多个Secondary上。<br>蓝色箭头表示读操作可以从Primary或Secondary任意一个中读取。<br>各个Primary与Secondary之间一直保持心跳同步检测，用于判断Replica Sets的状态。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202014_618.jpg\" alt=\"MongoDB数据同步\"></p>\n<h3 id=\"2-4-分片机制\"><a href=\"#2-4-分片机制\" class=\"headerlink\" title=\"2.4 分片机制\"></a>2.4 分片机制</h3><p>MongoDB的分片是指定一个分片key来进行，数据按范围分成不同的chunk，每个chunk的大小有限制。<br>有多个分片节点保存这些chunk，每个节点保存一部分的chunk。<br>每一个分片节点都是一个Replica Sets，这样保证数据的安全性。<br>当一个chunk超过其限制的最大体积时，会分裂成两个小的chunk。<br>当chunk在分片节点中分布不均衡时，会引发chunk迁移操作。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202022_314.jpg\" alt=\"分片机制\"></p>\n<h3 id=\"2-5-服务器角色\"><a href=\"#2-5-服务器角色\" class=\"headerlink\" title=\"2.5 服务器角色\"></a>2.5 服务器角色</h3><p>前面讲了分片的机制，下面是具体在分片时几种节点的角色： </p>\n<p>客户端访问路由节点mongos来进行数据读写。<br>config服务器保存了两个映射关系，一个是key值的区间对应哪一个chunk的映射关系，另一个是chunk存在哪一个分片节点的映射关系。<br>路由节点通过config服务器获取数据信息，通过这些信息，找到真正存放数据的分片节点进行对应操作。<br>路由节点还会在写操作时判断当前chunk是否超出限定大小。如果超出，就分列成两个chunk。<br>对于按分片key进行的查询和update操作来说，路由节点会查到具体的chunk然后再进行相关的工作。<br>对于不按分片key进行的查询和update操作来说，mongos会对所有下属节点发送请求然后再对返回结果进行合并。</p>\n<p><img src=\"http://static.open-open.com/lib/uploadImg/20120929/20120929202032_511.jpg\" alt=\"服务器角色\"></p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><p>参考：<a href=\"https://blog.csdn.net/zhaowen25/article/details/41871383\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zhaowen25/article/details/41871383</a></p>\n<p>参考：<a href=\"http://www.open-open.com/lib/view/open1348919251822.html\" target=\"_blank\" rel=\"noopener\">http://www.open-open.com/lib/view/open1348919251822.html</a></p>"},{"layout":"lay_post","title":"编译/解释语言、静态/动态语言、静态类型/动态类型语言","date":"2018-12-24T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. 前言\n\n编程语言根据不同角度有多种分类：\n根据运行时程序是否为机器码可以分：编译语言、解释语言。\n根据运行时代码可以根据某些条件改变自身结构可以分：静态语言、动态语言。\n根据运行期间才去做数据类型检查可以分：静态类型语言，动态类型语言。\n<!--more-->\n\n## 2. 编译语言 & 解释语言\n\n**编译型语言**\n\n![编译语言](/images/编程语言/编译语言.png)\n需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。\n\n优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。\n缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。\n代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift\n\n**解释型语言**\n\n![解释语言](/images/编程语言/解释语言.png)\n解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。\n\n优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。\n缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。\n代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby\n\n**混合型语言**\n\n![混合语言](/images/编程语言/混合语言.png)\n既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。\n\n比如C#，C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行。\nJava先生成字节码再在Java虚拟机中解释执行。\n\n严格来说混合型语言属于解释型语言。C#更接近编译型语言。\n\n## 3. 静态语言 & 动态语言\n\n**动态语言**\n\n![动态语言](/images/编程语言/动态语言.png)\n是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。动态语言说的是运行是改变结构，改变的是代码结构。\n主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。\n\n**静态语言**\n\n与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。\n\n## 4. 静态类型语言 & 动态类型语言\n\n**动态类型语言**\n\n![动态类型语言](/images/编程语言/动态类型语言.png)\n是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。\n主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。\n\n**静态类型语言**\n\n静态类型语言的数据类型是在编译期间（或运行之前）确定的，编写代码的时候要明确确定变量的数据类型。\n主要语言：C、C++、C#、Java、Object-C。\n\n## 5.参考资料\n\n动态语言和静态语言的区别：\nhttps://blog.csdn.net/lvxiangan/article/details/78391281\n\n深度解析PYTHON动态语言：\nhttps://www.cnblogs.com/jiaoyu121/p/6959310.html\n","source":"_posts/2018-12-25-编译解释语言-静态动态语言-静态类型动态类型语言.md","raw":"---\nlayout: lay_post\ntitle: \"编译/解释语言、静态/动态语言、静态类型/动态类型语言\"\ndate: 2018-12-25\ncategories: 其它\ntags: [编程语言]\nauthor: lvyafei\n---\n\n## 1. 前言\n\n编程语言根据不同角度有多种分类：\n根据运行时程序是否为机器码可以分：编译语言、解释语言。\n根据运行时代码可以根据某些条件改变自身结构可以分：静态语言、动态语言。\n根据运行期间才去做数据类型检查可以分：静态类型语言，动态类型语言。\n<!--more-->\n\n## 2. 编译语言 & 解释语言\n\n**编译型语言**\n\n![编译语言](/images/编程语言/编译语言.png)\n需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。\n\n优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。\n缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。\n代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift\n\n**解释型语言**\n\n![解释语言](/images/编程语言/解释语言.png)\n解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。\n\n优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。\n缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。\n代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby\n\n**混合型语言**\n\n![混合语言](/images/编程语言/混合语言.png)\n既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。\n\n比如C#，C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行。\nJava先生成字节码再在Java虚拟机中解释执行。\n\n严格来说混合型语言属于解释型语言。C#更接近编译型语言。\n\n## 3. 静态语言 & 动态语言\n\n**动态语言**\n\n![动态语言](/images/编程语言/动态语言.png)\n是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。动态语言说的是运行是改变结构，改变的是代码结构。\n主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。\n\n**静态语言**\n\n与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。\n\n## 4. 静态类型语言 & 动态类型语言\n\n**动态类型语言**\n\n![动态类型语言](/images/编程语言/动态类型语言.png)\n是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。\n主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。\n\n**静态类型语言**\n\n静态类型语言的数据类型是在编译期间（或运行之前）确定的，编写代码的时候要明确确定变量的数据类型。\n主要语言：C、C++、C#、Java、Object-C。\n\n## 5.参考资料\n\n动态语言和静态语言的区别：\nhttps://blog.csdn.net/lvxiangan/article/details/78391281\n\n深度解析PYTHON动态语言：\nhttps://www.cnblogs.com/jiaoyu121/p/6959310.html\n","slug":"2018-12-25-编译解释语言-静态动态语言-静态类型动态类型语言","published":1,"updated":"2019-02-25T14:16:48.058Z","comments":1,"photos":[],"link":"","_id":"cjskffofi00694glm9d7jvqyd","content":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>编程语言根据不同角度有多种分类：<br>根据运行时程序是否为机器码可以分：编译语言、解释语言。<br>根据运行时代码可以根据某些条件改变自身结构可以分：静态语言、动态语言。<br>根据运行期间才去做数据类型检查可以分：静态类型语言，动态类型语言。<br><a id=\"more\"></a></p>\n<h2 id=\"2-编译语言-amp-解释语言\"><a href=\"#2-编译语言-amp-解释语言\" class=\"headerlink\" title=\"2. 编译语言 &amp; 解释语言\"></a>2. 编译语言 &amp; 解释语言</h2><p><strong>编译型语言</strong></p>\n<p><img src=\"/images/编程语言/编译语言.png\" alt=\"编译语言\"><br>需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。</p>\n<p>优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。<br>缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。<br>代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift</p>\n<p><strong>解释型语言</strong></p>\n<p><img src=\"/images/编程语言/解释语言.png\" alt=\"解释语言\"><br>解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。</p>\n<p>优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。<br>缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。<br>代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby</p>\n<p><strong>混合型语言</strong></p>\n<p><img src=\"/images/编程语言/混合语言.png\" alt=\"混合语言\"><br>既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。</p>\n<p>比如C#，C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行。<br>Java先生成字节码再在Java虚拟机中解释执行。</p>\n<p>严格来说混合型语言属于解释型语言。C#更接近编译型语言。</p>\n<h2 id=\"3-静态语言-amp-动态语言\"><a href=\"#3-静态语言-amp-动态语言\" class=\"headerlink\" title=\"3. 静态语言 &amp; 动态语言\"></a>3. 静态语言 &amp; 动态语言</h2><p><strong>动态语言</strong></p>\n<p><img src=\"/images/编程语言/动态语言.png\" alt=\"动态语言\"><br>是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。动态语言说的是运行是改变结构，改变的是代码结构。<br>主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。</p>\n<p><strong>静态语言</strong></p>\n<p>与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。</p>\n<h2 id=\"4-静态类型语言-amp-动态类型语言\"><a href=\"#4-静态类型语言-amp-动态类型语言\" class=\"headerlink\" title=\"4. 静态类型语言 &amp; 动态类型语言\"></a>4. 静态类型语言 &amp; 动态类型语言</h2><p><strong>动态类型语言</strong></p>\n<p><img src=\"/images/编程语言/动态类型语言.png\" alt=\"动态类型语言\"><br>是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。<br>主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。</p>\n<p><strong>静态类型语言</strong></p>\n<p>静态类型语言的数据类型是在编译期间（或运行之前）确定的，编写代码的时候要明确确定变量的数据类型。<br>主要语言：C、C++、C#、Java、Object-C。</p>\n<h2 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h2><p>动态语言和静态语言的区别：<br><a href=\"https://blog.csdn.net/lvxiangan/article/details/78391281\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lvxiangan/article/details/78391281</a></p>\n<p>深度解析PYTHON动态语言：<br><a href=\"https://www.cnblogs.com/jiaoyu121/p/6959310.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jiaoyu121/p/6959310.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>编程语言根据不同角度有多种分类：<br>根据运行时程序是否为机器码可以分：编译语言、解释语言。<br>根据运行时代码可以根据某些条件改变自身结构可以分：静态语言、动态语言。<br>根据运行期间才去做数据类型检查可以分：静态类型语言，动态类型语言。<br>","more":"</p>\n<h2 id=\"2-编译语言-amp-解释语言\"><a href=\"#2-编译语言-amp-解释语言\" class=\"headerlink\" title=\"2. 编译语言 &amp; 解释语言\"></a>2. 编译语言 &amp; 解释语言</h2><p><strong>编译型语言</strong></p>\n<p><img src=\"/images/编程语言/编译语言.png\" alt=\"编译语言\"><br>需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。</p>\n<p>优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。<br>缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。<br>代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift</p>\n<p><strong>解释型语言</strong></p>\n<p><img src=\"/images/编程语言/解释语言.png\" alt=\"解释语言\"><br>解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。</p>\n<p>优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。<br>缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。<br>代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby</p>\n<p><strong>混合型语言</strong></p>\n<p><img src=\"/images/编程语言/混合语言.png\" alt=\"混合语言\"><br>既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。</p>\n<p>比如C#，C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行。<br>Java先生成字节码再在Java虚拟机中解释执行。</p>\n<p>严格来说混合型语言属于解释型语言。C#更接近编译型语言。</p>\n<h2 id=\"3-静态语言-amp-动态语言\"><a href=\"#3-静态语言-amp-动态语言\" class=\"headerlink\" title=\"3. 静态语言 &amp; 动态语言\"></a>3. 静态语言 &amp; 动态语言</h2><p><strong>动态语言</strong></p>\n<p><img src=\"/images/编程语言/动态语言.png\" alt=\"动态语言\"><br>是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。动态语言说的是运行是改变结构，改变的是代码结构。<br>主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。</p>\n<p><strong>静态语言</strong></p>\n<p>与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。</p>\n<h2 id=\"4-静态类型语言-amp-动态类型语言\"><a href=\"#4-静态类型语言-amp-动态类型语言\" class=\"headerlink\" title=\"4. 静态类型语言 &amp; 动态类型语言\"></a>4. 静态类型语言 &amp; 动态类型语言</h2><p><strong>动态类型语言</strong></p>\n<p><img src=\"/images/编程语言/动态类型语言.png\" alt=\"动态类型语言\"><br>是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。<br>主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。</p>\n<p><strong>静态类型语言</strong></p>\n<p>静态类型语言的数据类型是在编译期间（或运行之前）确定的，编写代码的时候要明确确定变量的数据类型。<br>主要语言：C、C++、C#、Java、Object-C。</p>\n<h2 id=\"5-参考资料\"><a href=\"#5-参考资料\" class=\"headerlink\" title=\"5.参考资料\"></a>5.参考资料</h2><p>动态语言和静态语言的区别：<br><a href=\"https://blog.csdn.net/lvxiangan/article/details/78391281\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lvxiangan/article/details/78391281</a></p>\n<p>深度解析PYTHON动态语言：<br><a href=\"https://www.cnblogs.com/jiaoyu121/p/6959310.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jiaoyu121/p/6959310.html</a></p>"},{"layout":"lay_post","title":"密码学入门","date":"2019-01-21T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. 前言\n\n在如今的信息安全领域，有各种各样的加密算法凝聚了计算机科学家门的智慧。从宏观上来看，这些加密算法可以归结为三大类：哈希算法、对称加密算法、非对称加密算法。\n<!--more-->\n\n## 2.书籍\n\n![图解密码技术](/images/密码学/图解密码技术.jpg)\n\n## 3. 文章\n\n漫画：什么是加密算法？\n\nhttps://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ","source":"_posts/2019-01-22-密码学入门.md","raw":"---\nlayout: lay_post\ntitle: \"密码学入门\"\ndate: 2019-01-22\ncategories: 密码学\ntags: [加密解密]\nauthor: lvyafei\n---\n\n## 1. 前言\n\n在如今的信息安全领域，有各种各样的加密算法凝聚了计算机科学家门的智慧。从宏观上来看，这些加密算法可以归结为三大类：哈希算法、对称加密算法、非对称加密算法。\n<!--more-->\n\n## 2.书籍\n\n![图解密码技术](/images/密码学/图解密码技术.jpg)\n\n## 3. 文章\n\n漫画：什么是加密算法？\n\nhttps://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ","slug":"2019-01-22-密码学入门","published":1,"updated":"2019-02-25T14:16:48.058Z","comments":1,"photos":[],"link":"","_id":"cjskffofi006d4glmk62d7svo","content":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>在如今的信息安全领域，有各种各样的加密算法凝聚了计算机科学家门的智慧。从宏观上来看，这些加密算法可以归结为三大类：哈希算法、对称加密算法、非对称加密算法。<br><a id=\"more\"></a></p>\n<h2 id=\"2-书籍\"><a href=\"#2-书籍\" class=\"headerlink\" title=\"2.书籍\"></a>2.书籍</h2><p><img src=\"/images/密码学/图解密码技术.jpg\" alt=\"图解密码技术\"></p>\n<h2 id=\"3-文章\"><a href=\"#3-文章\" class=\"headerlink\" title=\"3. 文章\"></a>3. 文章</h2><p>漫画：什么是加密算法？</p>\n<p><a href=\"https://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>在如今的信息安全领域，有各种各样的加密算法凝聚了计算机科学家门的智慧。从宏观上来看，这些加密算法可以归结为三大类：哈希算法、对称加密算法、非对称加密算法。<br>","more":"</p>\n<h2 id=\"2-书籍\"><a href=\"#2-书籍\" class=\"headerlink\" title=\"2.书籍\"></a>2.书籍</h2><p><img src=\"/images/密码学/图解密码技术.jpg\" alt=\"图解密码技术\"></p>\n<h2 id=\"3-文章\"><a href=\"#3-文章\" class=\"headerlink\" title=\"3. 文章\"></a>3. 文章</h2><p>漫画：什么是加密算法？</p>\n<p><a href=\"https://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/mszEors5SK2rThqXF79PuQ</a></p>"},{"layout":"lay_post","title":"Java优秀框架源码学习","date":"2019-01-20T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. 前言\n\n通过研究优秀的框架源码，可以洞察到设计者的思想，对提高自身开发水平有很大的帮助。为设计新的系统打下良好的基础，站在巨人肩膀可以看得更远。\n<!--more-->\n\n## 2. Spring源码\n\nSpring是java开发中使用频率最高的框架，包含大量的设计模式，是系统架构师必备的设计参考。\n\n源码地址：https://github.com/spring-projects/spring-framework\n\n源码编译：项目管理使用gradle，配置好gradle环境变量,并在idea中配置gradel的目录，即可编译。\n\n## 3. RocketMQ源码\n\nRocketMQ是消息中间件的代表，消息中间件是分布式领域中不可缺少的一环，故障的处理、性能的优化都离不开对源码的深入掌握，对自研分布式系统模块有很大的参考意义，底层的通信使用netty,使用javassist来做动态编程，对底层技术的使用有很大的参考意义。\n\n源码地址：https://github.com/apache/rocketmq\n\n源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:\n\n```shell\nmvn -Prelease-all -DskipTests clean install -U\n```\n\n## 4. Flink源码\n\nFlink作为stream,batch计算的融合，是大数据领域中处理流、批数据的优秀项目，掌握源码对了解分布式任务系统的设计，以及流式数据处理有很大帮助，通过比较与storm等框架的优劣，也能看出系统设计的最佳原则。\n\n源码地址：https://github.com/apache/flink\n\n源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:\n\n```shell\nmvn clean package -DskipTests\n```\n\n## 5.其它\n\n想要设计一套优秀的系统、框架。都离不开对已有框架的研究和学习，Java领域中优秀的不局限于以上3个框架，好的底层框架比如Netty,JAVA开发的基础JDK的设计，以及Java领域以外的优秀框架，比如C++领域中高性能低延时的设计。都是需要不断的学习与积累，没有终点，只有在学习的路上。不断学习思考才能与时俱进。","source":"_posts/2019-01-21-Java优秀框架源码学习.md","raw":"---\nlayout: lay_post\ntitle: \"Java优秀框架源码学习\"\ndate: 2019-01-21\ncategories: 源码研究\ntags: [JAVA框架]\nauthor: lvyafei\n---\n\n## 1. 前言\n\n通过研究优秀的框架源码，可以洞察到设计者的思想，对提高自身开发水平有很大的帮助。为设计新的系统打下良好的基础，站在巨人肩膀可以看得更远。\n<!--more-->\n\n## 2. Spring源码\n\nSpring是java开发中使用频率最高的框架，包含大量的设计模式，是系统架构师必备的设计参考。\n\n源码地址：https://github.com/spring-projects/spring-framework\n\n源码编译：项目管理使用gradle，配置好gradle环境变量,并在idea中配置gradel的目录，即可编译。\n\n## 3. RocketMQ源码\n\nRocketMQ是消息中间件的代表，消息中间件是分布式领域中不可缺少的一环，故障的处理、性能的优化都离不开对源码的深入掌握，对自研分布式系统模块有很大的参考意义，底层的通信使用netty,使用javassist来做动态编程，对底层技术的使用有很大的参考意义。\n\n源码地址：https://github.com/apache/rocketmq\n\n源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:\n\n```shell\nmvn -Prelease-all -DskipTests clean install -U\n```\n\n## 4. Flink源码\n\nFlink作为stream,batch计算的融合，是大数据领域中处理流、批数据的优秀项目，掌握源码对了解分布式任务系统的设计，以及流式数据处理有很大帮助，通过比较与storm等框架的优劣，也能看出系统设计的最佳原则。\n\n源码地址：https://github.com/apache/flink\n\n源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:\n\n```shell\nmvn clean package -DskipTests\n```\n\n## 5.其它\n\n想要设计一套优秀的系统、框架。都离不开对已有框架的研究和学习，Java领域中优秀的不局限于以上3个框架，好的底层框架比如Netty,JAVA开发的基础JDK的设计，以及Java领域以外的优秀框架，比如C++领域中高性能低延时的设计。都是需要不断的学习与积累，没有终点，只有在学习的路上。不断学习思考才能与时俱进。","slug":"2019-01-21-Java优秀框架源码学习","published":1,"updated":"2019-02-25T14:16:48.058Z","comments":1,"photos":[],"link":"","_id":"cjskffofy006f4glmoe8diwf4","content":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>通过研究优秀的框架源码，可以洞察到设计者的思想，对提高自身开发水平有很大的帮助。为设计新的系统打下良好的基础，站在巨人肩膀可以看得更远。<br><a id=\"more\"></a></p>\n<h2 id=\"2-Spring源码\"><a href=\"#2-Spring源码\" class=\"headerlink\" title=\"2. Spring源码\"></a>2. Spring源码</h2><p>Spring是java开发中使用频率最高的框架，包含大量的设计模式，是系统架构师必备的设计参考。</p>\n<p>源码地址：<a href=\"https://github.com/spring-projects/spring-framework\" target=\"_blank\" rel=\"noopener\">https://github.com/spring-projects/spring-framework</a></p>\n<p>源码编译：项目管理使用gradle，配置好gradle环境变量,并在idea中配置gradel的目录，即可编译。</p>\n<h2 id=\"3-RocketMQ源码\"><a href=\"#3-RocketMQ源码\" class=\"headerlink\" title=\"3. RocketMQ源码\"></a>3. RocketMQ源码</h2><p>RocketMQ是消息中间件的代表，消息中间件是分布式领域中不可缺少的一环，故障的处理、性能的优化都离不开对源码的深入掌握，对自研分布式系统模块有很大的参考意义，底层的通信使用netty,使用javassist来做动态编程，对底层技术的使用有很大的参考意义。</p>\n<p>源码地址：<a href=\"https://github.com/apache/rocketmq\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq</a></p>\n<p>源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn -Prelease-all -DskipTests clean install -U</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-Flink源码\"><a href=\"#4-Flink源码\" class=\"headerlink\" title=\"4. Flink源码\"></a>4. Flink源码</h2><p>Flink作为stream,batch计算的融合，是大数据领域中处理流、批数据的优秀项目，掌握源码对了解分布式任务系统的设计，以及流式数据处理有很大帮助，通过比较与storm等框架的优劣，也能看出系统设计的最佳原则。</p>\n<p>源码地址：<a href=\"https://github.com/apache/flink\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/flink</a></p>\n<p>源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean package -DskipTests</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-其它\"><a href=\"#5-其它\" class=\"headerlink\" title=\"5.其它\"></a>5.其它</h2><p>想要设计一套优秀的系统、框架。都离不开对已有框架的研究和学习，Java领域中优秀的不局限于以上3个框架，好的底层框架比如Netty,JAVA开发的基础JDK的设计，以及Java领域以外的优秀框架，比如C++领域中高性能低延时的设计。都是需要不断的学习与积累，没有终点，只有在学习的路上。不断学习思考才能与时俱进。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>通过研究优秀的框架源码，可以洞察到设计者的思想，对提高自身开发水平有很大的帮助。为设计新的系统打下良好的基础，站在巨人肩膀可以看得更远。<br>","more":"</p>\n<h2 id=\"2-Spring源码\"><a href=\"#2-Spring源码\" class=\"headerlink\" title=\"2. Spring源码\"></a>2. Spring源码</h2><p>Spring是java开发中使用频率最高的框架，包含大量的设计模式，是系统架构师必备的设计参考。</p>\n<p>源码地址：<a href=\"https://github.com/spring-projects/spring-framework\" target=\"_blank\" rel=\"noopener\">https://github.com/spring-projects/spring-framework</a></p>\n<p>源码编译：项目管理使用gradle，配置好gradle环境变量,并在idea中配置gradel的目录，即可编译。</p>\n<h2 id=\"3-RocketMQ源码\"><a href=\"#3-RocketMQ源码\" class=\"headerlink\" title=\"3. RocketMQ源码\"></a>3. RocketMQ源码</h2><p>RocketMQ是消息中间件的代表，消息中间件是分布式领域中不可缺少的一环，故障的处理、性能的优化都离不开对源码的深入掌握，对自研分布式系统模块有很大的参考意义，底层的通信使用netty,使用javassist来做动态编程，对底层技术的使用有很大的参考意义。</p>\n<p>源码地址：<a href=\"https://github.com/apache/rocketmq\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/rocketmq</a></p>\n<p>源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn -Prelease-all -DskipTests clean install -U</span><br></pre></td></tr></table></figure>\n<h2 id=\"4-Flink源码\"><a href=\"#4-Flink源码\" class=\"headerlink\" title=\"4. Flink源码\"></a>4. Flink源码</h2><p>Flink作为stream,batch计算的融合，是大数据领域中处理流、批数据的优秀项目，掌握源码对了解分布式任务系统的设计，以及流式数据处理有很大帮助，通过比较与storm等框架的优劣，也能看出系统设计的最佳原则。</p>\n<p>源码地址：<a href=\"https://github.com/apache/flink\" target=\"_blank\" rel=\"noopener\">https://github.com/apache/flink</a></p>\n<p>源码编译：项目管理使用maven，在idea中配置好maven的目录，使用以下命令进行编译:</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mvn clean package -DskipTests</span><br></pre></td></tr></table></figure>\n<h2 id=\"5-其它\"><a href=\"#5-其它\" class=\"headerlink\" title=\"5.其它\"></a>5.其它</h2><p>想要设计一套优秀的系统、框架。都离不开对已有框架的研究和学习，Java领域中优秀的不局限于以上3个框架，好的底层框架比如Netty,JAVA开发的基础JDK的设计，以及Java领域以外的优秀框架，比如C++领域中高性能低延时的设计。都是需要不断的学习与积累，没有终点，只有在学习的路上。不断学习思考才能与时俱进。</p>"},{"layout":"lay_post","title":"TiDB数据库指南","date":"2018-12-02T16:00:00.000Z","author":"lvyafei","_content":"\n## 1.TiDB 系统架构\n\nTiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。\n<!--more-->\n\n![整体架构](/images/TiDB/整体架构.png)\n\n![整体架构1](/images/TiDB/整体架构1.png)\n\nTiDB 具备如下特性：\n\n+ 高度兼容 MySQL\n\n大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。\n\n+ 水平弹性扩展\n\n通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。\n\n无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。\n\n+ 高可用\n\n高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。\n\n**TiDB 高可用:**TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。\n\n**PD高可用:**PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。\n\n**TiKV高可用:**TiKV 是一个集群，通过 Raft 协议保持数据的一致性（副本数量可配置，默认保存三副本），并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 结点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内（默认 30 分钟）无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点上。\n\n+ 分布式事务\n\nTiDB 100% 支持标准的 ACID 事务。\n\n+ 真正金融级高可用\n\n相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。\n\n+ 一站式 HTAP 解决方案\n\nTiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP & OLAP，无需传统繁琐的 ETL 过程。\n\n+ 云原生 SQL 数据库\n\nTiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。\n\n## 2.TiKV Server 存储层\n\n![存储层](/images/TiDB/存储层.png)\n\nTiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。\n\n+ 1.水平扩展\n\n对于一个 KV 系统，将数据分散在多台机器上有两种比较典型的方案：一种是按照 Key 做 Hash，根据 Hash 值选择对应的存储节点；另一种是分 Range，某一段连续的 Key 都保存在一个存储节点上。TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，我们将每一段叫做一个 Region，并且我们会尽量保持每个 Region 中保存的数据不超过一定的大小(这个大小可以配置，目前默认是 64mb)。每一个 Region 都可以用 StartKey 到 EndKey 这样一个左闭右开区间来描述。\n\n+ 2.事务\n\nTiKV 的事务采用的是 Percolator 模型，并且做了大量的优化。TiKV 的事务采用乐观锁(TiKV通过实现MVCC来处理并发问题)，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。\n\n## 3.TiDB Server 运算层\n\n![运算层](/images/TiDB/运算层.png)\n\nTiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。\n\n用户的 SQL 请求会直接或者通过 Load Balancer 发送到 tidb-server，tidb-server 会解析 MySQL Protocol Packet，获取请求内容，然后做语法解析、查询计划制定和优化、执行查询计划获取和处理数据。数据全部存储在 TiKV 集群中，所以在这个过程中 tidb-server 需要和 tikv-server 交互，获取数据。最后 tidb-server 需要将查询结果返回给用户。\n\n## 4.PD Server 调度层\n\nPlacement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。\n\nPD 不断的通过 Store 或者 Leader 的心跳包收集信息，获得整个集群的详细数据，并且根据这些信息以及调度策略生成调度操作序列，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。\n\n## 5.TiSpark 数据分析层\n\nTiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。\n\n## 6.扩容缩容(存储层)\n\nTiDB 集群扩容缩容方案： https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/\n\nTiDB 集群扩容缩容方案(使用TiDB Ansible)： https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/\n\n## 7.数据同步(Binlog同步)\n\nTiDB-Binlog 是一个用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。TiDB-Binlog 支持以下功能场景：\n\n**数据同步**：同步 TiDB 集群数据到其他数据库。\n\n**实时备份和恢复**：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。\n\n**TiDB-Binlog 的整体架构**：\n\n![TiDB-Binlog](https://www.pingcap.com/images/docs-cn/tidb_binlog_cluster_architecture.png)\n\nTiDB-Binlog 集群主要分为 Pump 和 Drainer 两个组件：\n\n**Pump**：用于实时记录 TiDB 产生的 Binlog，并将 Binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。\n\n**Drainer**：从各个 Pump 中收集 Binlog 进行归并，再将 Binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。\n\n主要特性: 1.多个 Pump 形成一个集群，可以水平扩容；2.TiDB 通过内置的 Pump Client 将 Binlog 分发到各个 Pump；3.Pump 负责存储 Binlog，并将 Binlog 按顺序提供给 Drainer；4.Drainer 负责读取各个 Pump 的 Binlog，归并排序后发送到下游。\n\nDrainer支持的db-type： \"mysql\", \"pb\", \"kafka\", \"flash\", \"tidb\"。\n\n## 8.参考资料\n\nTiDB官网: https://www.pingcap.com/docs-cn/","source":"_posts/2018-12-03-TiDB数据库指南.md","raw":"---\nlayout: lay_post\ntitle: \"TiDB数据库指南\"\ndate: 2018-12-03\ncategories: 中间件\ntags: TiDB\nauthor: lvyafei\n---\n\n## 1.TiDB 系统架构\n\nTiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。\n<!--more-->\n\n![整体架构](/images/TiDB/整体架构.png)\n\n![整体架构1](/images/TiDB/整体架构1.png)\n\nTiDB 具备如下特性：\n\n+ 高度兼容 MySQL\n\n大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。\n\n+ 水平弹性扩展\n\n通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。\n\n无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。\n\n+ 高可用\n\n高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。\n\n**TiDB 高可用:**TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。\n\n**PD高可用:**PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。\n\n**TiKV高可用:**TiKV 是一个集群，通过 Raft 协议保持数据的一致性（副本数量可配置，默认保存三副本），并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 结点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内（默认 30 分钟）无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点上。\n\n+ 分布式事务\n\nTiDB 100% 支持标准的 ACID 事务。\n\n+ 真正金融级高可用\n\n相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。\n\n+ 一站式 HTAP 解决方案\n\nTiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP & OLAP，无需传统繁琐的 ETL 过程。\n\n+ 云原生 SQL 数据库\n\nTiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。\n\n## 2.TiKV Server 存储层\n\n![存储层](/images/TiDB/存储层.png)\n\nTiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。\n\n+ 1.水平扩展\n\n对于一个 KV 系统，将数据分散在多台机器上有两种比较典型的方案：一种是按照 Key 做 Hash，根据 Hash 值选择对应的存储节点；另一种是分 Range，某一段连续的 Key 都保存在一个存储节点上。TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，我们将每一段叫做一个 Region，并且我们会尽量保持每个 Region 中保存的数据不超过一定的大小(这个大小可以配置，目前默认是 64mb)。每一个 Region 都可以用 StartKey 到 EndKey 这样一个左闭右开区间来描述。\n\n+ 2.事务\n\nTiKV 的事务采用的是 Percolator 模型，并且做了大量的优化。TiKV 的事务采用乐观锁(TiKV通过实现MVCC来处理并发问题)，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。\n\n## 3.TiDB Server 运算层\n\n![运算层](/images/TiDB/运算层.png)\n\nTiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。\n\n用户的 SQL 请求会直接或者通过 Load Balancer 发送到 tidb-server，tidb-server 会解析 MySQL Protocol Packet，获取请求内容，然后做语法解析、查询计划制定和优化、执行查询计划获取和处理数据。数据全部存储在 TiKV 集群中，所以在这个过程中 tidb-server 需要和 tikv-server 交互，获取数据。最后 tidb-server 需要将查询结果返回给用户。\n\n## 4.PD Server 调度层\n\nPlacement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。\n\nPD 不断的通过 Store 或者 Leader 的心跳包收集信息，获得整个集群的详细数据，并且根据这些信息以及调度策略生成调度操作序列，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。\n\n## 5.TiSpark 数据分析层\n\nTiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。\n\n## 6.扩容缩容(存储层)\n\nTiDB 集群扩容缩容方案： https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/\n\nTiDB 集群扩容缩容方案(使用TiDB Ansible)： https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/\n\n## 7.数据同步(Binlog同步)\n\nTiDB-Binlog 是一个用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。TiDB-Binlog 支持以下功能场景：\n\n**数据同步**：同步 TiDB 集群数据到其他数据库。\n\n**实时备份和恢复**：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。\n\n**TiDB-Binlog 的整体架构**：\n\n![TiDB-Binlog](https://www.pingcap.com/images/docs-cn/tidb_binlog_cluster_architecture.png)\n\nTiDB-Binlog 集群主要分为 Pump 和 Drainer 两个组件：\n\n**Pump**：用于实时记录 TiDB 产生的 Binlog，并将 Binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。\n\n**Drainer**：从各个 Pump 中收集 Binlog 进行归并，再将 Binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。\n\n主要特性: 1.多个 Pump 形成一个集群，可以水平扩容；2.TiDB 通过内置的 Pump Client 将 Binlog 分发到各个 Pump；3.Pump 负责存储 Binlog，并将 Binlog 按顺序提供给 Drainer；4.Drainer 负责读取各个 Pump 的 Binlog，归并排序后发送到下游。\n\nDrainer支持的db-type： \"mysql\", \"pb\", \"kafka\", \"flash\", \"tidb\"。\n\n## 8.参考资料\n\nTiDB官网: https://www.pingcap.com/docs-cn/","slug":"2018-12-03-TiDB数据库指南","published":1,"updated":"2018-12-23T06:50:48.828Z","comments":1,"photos":[],"link":"","_id":"cjskffofy006i4glmz2iemp4f","content":"<h2 id=\"1-TiDB-系统架构\"><a href=\"#1-TiDB-系统架构\" class=\"headerlink\" title=\"1.TiDB 系统架构\"></a>1.TiDB 系统架构</h2><p>TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。<br><a id=\"more\"></a></p>\n<p><img src=\"/images/TiDB/整体架构.png\" alt=\"整体架构\"></p>\n<p><img src=\"/images/TiDB/整体架构1.png\" alt=\"整体架构1\"></p>\n<p>TiDB 具备如下特性：</p>\n<ul>\n<li>高度兼容 MySQL</li>\n</ul>\n<p>大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。</p>\n<ul>\n<li>水平弹性扩展</li>\n</ul>\n<p>通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。</p>\n<p>无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。</p>\n<ul>\n<li>高可用</li>\n</ul>\n<p>高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。</p>\n<p><strong>TiDB 高可用:</strong>TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。</p>\n<p><strong>PD高可用:</strong>PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。</p>\n<p><strong>TiKV高可用:</strong>TiKV 是一个集群，通过 Raft 协议保持数据的一致性（副本数量可配置，默认保存三副本），并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 结点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内（默认 30 分钟）无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点上。</p>\n<ul>\n<li>分布式事务</li>\n</ul>\n<p>TiDB 100% 支持标准的 ACID 事务。</p>\n<ul>\n<li>真正金融级高可用</li>\n</ul>\n<p>相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。</p>\n<ul>\n<li>一站式 HTAP 解决方案</li>\n</ul>\n<p>TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP &amp; OLAP，无需传统繁琐的 ETL 过程。</p>\n<ul>\n<li>云原生 SQL 数据库</li>\n</ul>\n<p>TiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。</p>\n<h2 id=\"2-TiKV-Server-存储层\"><a href=\"#2-TiKV-Server-存储层\" class=\"headerlink\" title=\"2.TiKV Server 存储层\"></a>2.TiKV Server 存储层</h2><p><img src=\"/images/TiDB/存储层.png\" alt=\"存储层\"></p>\n<p>TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。</p>\n<ul>\n<li>1.水平扩展</li>\n</ul>\n<p>对于一个 KV 系统，将数据分散在多台机器上有两种比较典型的方案：一种是按照 Key 做 Hash，根据 Hash 值选择对应的存储节点；另一种是分 Range，某一段连续的 Key 都保存在一个存储节点上。TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，我们将每一段叫做一个 Region，并且我们会尽量保持每个 Region 中保存的数据不超过一定的大小(这个大小可以配置，目前默认是 64mb)。每一个 Region 都可以用 StartKey 到 EndKey 这样一个左闭右开区间来描述。</p>\n<ul>\n<li>2.事务</li>\n</ul>\n<p>TiKV 的事务采用的是 Percolator 模型，并且做了大量的优化。TiKV 的事务采用乐观锁(TiKV通过实现MVCC来处理并发问题)，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。</p>\n<h2 id=\"3-TiDB-Server-运算层\"><a href=\"#3-TiDB-Server-运算层\" class=\"headerlink\" title=\"3.TiDB Server 运算层\"></a>3.TiDB Server 运算层</h2><p><img src=\"/images/TiDB/运算层.png\" alt=\"运算层\"></p>\n<p>TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。</p>\n<p>用户的 SQL 请求会直接或者通过 Load Balancer 发送到 tidb-server，tidb-server 会解析 MySQL Protocol Packet，获取请求内容，然后做语法解析、查询计划制定和优化、执行查询计划获取和处理数据。数据全部存储在 TiKV 集群中，所以在这个过程中 tidb-server 需要和 tikv-server 交互，获取数据。最后 tidb-server 需要将查询结果返回给用户。</p>\n<h2 id=\"4-PD-Server-调度层\"><a href=\"#4-PD-Server-调度层\" class=\"headerlink\" title=\"4.PD Server 调度层\"></a>4.PD Server 调度层</h2><p>Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。</p>\n<p>PD 不断的通过 Store 或者 Leader 的心跳包收集信息，获得整个集群的详细数据，并且根据这些信息以及调度策略生成调度操作序列，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。</p>\n<h2 id=\"5-TiSpark-数据分析层\"><a href=\"#5-TiSpark-数据分析层\" class=\"headerlink\" title=\"5.TiSpark 数据分析层\"></a>5.TiSpark 数据分析层</h2><p>TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。</p>\n<h2 id=\"6-扩容缩容-存储层\"><a href=\"#6-扩容缩容-存储层\" class=\"headerlink\" title=\"6.扩容缩容(存储层)\"></a>6.扩容缩容(存储层)</h2><p>TiDB 集群扩容缩容方案： <a href=\"https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/</a></p>\n<p>TiDB 集群扩容缩容方案(使用TiDB Ansible)： <a href=\"https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/</a></p>\n<h2 id=\"7-数据同步-Binlog同步\"><a href=\"#7-数据同步-Binlog同步\" class=\"headerlink\" title=\"7.数据同步(Binlog同步)\"></a>7.数据同步(Binlog同步)</h2><p>TiDB-Binlog 是一个用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。TiDB-Binlog 支持以下功能场景：</p>\n<p><strong>数据同步</strong>：同步 TiDB 集群数据到其他数据库。</p>\n<p><strong>实时备份和恢复</strong>：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。</p>\n<p><strong>TiDB-Binlog 的整体架构</strong>：</p>\n<p><img src=\"https://www.pingcap.com/images/docs-cn/tidb_binlog_cluster_architecture.png\" alt=\"TiDB-Binlog\"></p>\n<p>TiDB-Binlog 集群主要分为 Pump 和 Drainer 两个组件：</p>\n<p><strong>Pump</strong>：用于实时记录 TiDB 产生的 Binlog，并将 Binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。</p>\n<p><strong>Drainer</strong>：从各个 Pump 中收集 Binlog 进行归并，再将 Binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。</p>\n<p>主要特性: 1.多个 Pump 形成一个集群，可以水平扩容；2.TiDB 通过内置的 Pump Client 将 Binlog 分发到各个 Pump；3.Pump 负责存储 Binlog，并将 Binlog 按顺序提供给 Drainer；4.Drainer 负责读取各个 Pump 的 Binlog，归并排序后发送到下游。</p>\n<p>Drainer支持的db-type： “mysql”, “pb”, “kafka”, “flash”, “tidb”。</p>\n<h2 id=\"8-参考资料\"><a href=\"#8-参考资料\" class=\"headerlink\" title=\"8.参考资料\"></a>8.参考资料</h2><p>TiDB官网: <a href=\"https://www.pingcap.com/docs-cn/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-TiDB-系统架构\"><a href=\"#1-TiDB-系统架构\" class=\"headerlink\" title=\"1.TiDB 系统架构\"></a>1.TiDB 系统架构</h2><p>TiDB 是 PingCAP 公司设计的开源分布式 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为 OLTP (Online Transactional Processing) 和 OLAP (Online Analytical Processing) 场景提供一站式的解决方案。<br>","more":"</p>\n<p><img src=\"/images/TiDB/整体架构.png\" alt=\"整体架构\"></p>\n<p><img src=\"/images/TiDB/整体架构1.png\" alt=\"整体架构1\"></p>\n<p>TiDB 具备如下特性：</p>\n<ul>\n<li>高度兼容 MySQL</li>\n</ul>\n<p>大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。</p>\n<ul>\n<li>水平弹性扩展</li>\n</ul>\n<p>通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。</p>\n<p>无限水平扩展是 TiDB 的一大特点，这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例（推荐至少部署 3 个 TiKV， 3 个 PD，2 个 TiDB），随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。</p>\n<ul>\n<li>高可用</li>\n</ul>\n<p>高可用是 TiDB 的另一大特点，TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。下面分别说明这三个组件的可用性、单个实例失效后的后果以及如何恢复。</p>\n<p><strong>TiDB 高可用:</strong>TiDB 是无状态的，推荐至少部署两个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的 Session，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。单个实例失效后，可以重启这个实例或者部署一个新的实例。</p>\n<p><strong>PD高可用:</strong>PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是3秒钟。推荐至少部署三个 PD 实例，单个实例失效后，重启这个实例或者添加新的实例。</p>\n<p><strong>TiKV高可用:</strong>TiKV 是一个集群，通过 Raft 协议保持数据的一致性（副本数量可配置，默认保存三副本），并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 结点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内（默认 30 分钟）无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点上。</p>\n<ul>\n<li>分布式事务</li>\n</ul>\n<p>TiDB 100% 支持标准的 ACID 事务。</p>\n<ul>\n<li>真正金融级高可用</li>\n</ul>\n<p>相比于传统主从 (M-S) 复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。</p>\n<ul>\n<li>一站式 HTAP 解决方案</li>\n</ul>\n<p>TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP 解决方案，一份存储同时处理 OLTP &amp; OLAP，无需传统繁琐的 ETL 过程。</p>\n<ul>\n<li>云原生 SQL 数据库</li>\n</ul>\n<p>TiDB 是为云而设计的数据库，支持公有云、私有云和混合云，使部署、配置和维护变得十分简单。</p>\n<h2 id=\"2-TiKV-Server-存储层\"><a href=\"#2-TiKV-Server-存储层\" class=\"headerlink\" title=\"2.TiKV Server 存储层\"></a>2.TiKV Server 存储层</h2><p><img src=\"/images/TiDB/存储层.png\" alt=\"存储层\"></p>\n<p>TiKV Server 负责存储数据，从外部看 TiKV 是一个分布式的提供事务的 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和容灾。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 调度，这里也是以 Region 为单位进行调度。</p>\n<ul>\n<li>1.水平扩展</li>\n</ul>\n<p>对于一个 KV 系统，将数据分散在多台机器上有两种比较典型的方案：一种是按照 Key 做 Hash，根据 Hash 值选择对应的存储节点；另一种是分 Range，某一段连续的 Key 都保存在一个存储节点上。TiKV 选择了第二种方式，将整个 Key-Value 空间分成很多段，每一段是一系列连续的 Key，我们将每一段叫做一个 Region，并且我们会尽量保持每个 Region 中保存的数据不超过一定的大小(这个大小可以配置，目前默认是 64mb)。每一个 Region 都可以用 StartKey 到 EndKey 这样一个左闭右开区间来描述。</p>\n<ul>\n<li>2.事务</li>\n</ul>\n<p>TiKV 的事务采用的是 Percolator 模型，并且做了大量的优化。TiKV 的事务采用乐观锁(TiKV通过实现MVCC来处理并发问题)，事务的执行过程中，不会检测写写冲突，只有在提交过程中，才会做冲突检测，冲突的双方中比较早完成提交的会写入成功，另一方会尝试重新执行整个事务。当业务的写入冲突不严重的情况下，这种模型性能会很好，比如随机更新表中某一行的数据，并且表很大。但是如果业务的写入冲突严重，性能就会很差，举一个极端的例子，就是计数器，多个客户端同时修改少量行，导致冲突严重的，造成大量的无效重试。</p>\n<h2 id=\"3-TiDB-Server-运算层\"><a href=\"#3-TiDB-Server-运算层\" class=\"headerlink\" title=\"3.TiDB Server 运算层\"></a>3.TiDB Server 运算层</h2><p><img src=\"/images/TiDB/运算层.png\" alt=\"运算层\"></p>\n<p>TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。</p>\n<p>用户的 SQL 请求会直接或者通过 Load Balancer 发送到 tidb-server，tidb-server 会解析 MySQL Protocol Packet，获取请求内容，然后做语法解析、查询计划制定和优化、执行查询计划获取和处理数据。数据全部存储在 TiKV 集群中，所以在这个过程中 tidb-server 需要和 tikv-server 交互，获取数据。最后 tidb-server 需要将查询结果返回给用户。</p>\n<h2 id=\"4-PD-Server-调度层\"><a href=\"#4-PD-Server-调度层\" class=\"headerlink\" title=\"4.PD Server 调度层\"></a>4.PD Server 调度层</h2><p>Placement Driver (简称 PD) 是整个集群的管理模块，其主要工作有三个：一是存储集群的元信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。PD 是一个集群，需要部署奇数个节点，一般线上推荐至少部署 3 个节点。</p>\n<p>PD 不断的通过 Store 或者 Leader 的心跳包收集信息，获得整个集群的详细数据，并且根据这些信息以及调度策略生成调度操作序列，每次收到 Region Leader 发来的心跳包时，PD 都会检查是否有对这个 Region 待进行的操作，通过心跳包的回复消息，将需要进行的操作返回给 Region Leader，并在后面的心跳包中监测执行结果。注意这里的操作只是给 Region Leader 的建议，并不保证一定能得到执行，具体是否会执行以及什么时候执行，由 Region Leader 自己根据当前自身状态来定。</p>\n<h2 id=\"5-TiSpark-数据分析层\"><a href=\"#5-TiSpark-数据分析层\" class=\"headerlink\" title=\"5.TiSpark 数据分析层\"></a>5.TiSpark 数据分析层</h2><p>TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。</p>\n<h2 id=\"6-扩容缩容-存储层\"><a href=\"#6-扩容缩容-存储层\" class=\"headerlink\" title=\"6.扩容缩容(存储层)\"></a>6.扩容缩容(存储层)</h2><p>TiDB 集群扩容缩容方案： <a href=\"https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/op-guide/horizontal-scale/</a></p>\n<p>TiDB 集群扩容缩容方案(使用TiDB Ansible)： <a href=\"https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/op-guide/ansible-deployment-scale/</a></p>\n<h2 id=\"7-数据同步-Binlog同步\"><a href=\"#7-数据同步-Binlog同步\" class=\"headerlink\" title=\"7.数据同步(Binlog同步)\"></a>7.数据同步(Binlog同步)</h2><p>TiDB-Binlog 是一个用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。TiDB-Binlog 支持以下功能场景：</p>\n<p><strong>数据同步</strong>：同步 TiDB 集群数据到其他数据库。</p>\n<p><strong>实时备份和恢复</strong>：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。</p>\n<p><strong>TiDB-Binlog 的整体架构</strong>：</p>\n<p><img src=\"https://www.pingcap.com/images/docs-cn/tidb_binlog_cluster_architecture.png\" alt=\"TiDB-Binlog\"></p>\n<p>TiDB-Binlog 集群主要分为 Pump 和 Drainer 两个组件：</p>\n<p><strong>Pump</strong>：用于实时记录 TiDB 产生的 Binlog，并将 Binlog 按照事务的提交时间进行排序，再提供给 Drainer 进行消费。</p>\n<p><strong>Drainer</strong>：从各个 Pump 中收集 Binlog 进行归并，再将 Binlog 转化成 SQL 或者指定格式的数据，最终同步到下游。</p>\n<p>主要特性: 1.多个 Pump 形成一个集群，可以水平扩容；2.TiDB 通过内置的 Pump Client 将 Binlog 分发到各个 Pump；3.Pump 负责存储 Binlog，并将 Binlog 按顺序提供给 Drainer；4.Drainer 负责读取各个 Pump 的 Binlog，归并排序后发送到下游。</p>\n<p>Drainer支持的db-type： “mysql”, “pb”, “kafka”, “flash”, “tidb”。</p>\n<h2 id=\"8-参考资料\"><a href=\"#8-参考资料\" class=\"headerlink\" title=\"8.参考资料\"></a>8.参考资料</h2><p>TiDB官网: <a href=\"https://www.pingcap.com/docs-cn/\" target=\"_blank\" rel=\"noopener\">https://www.pingcap.com/docs-cn/</a></p>"},{"layout":"lay_post","title":"MySQL分库分表方案选型","date":"2018-11-30T16:00:00.000Z","author":"lvyafei","_content":"\n## 1.分库分表方案\n\n针对MySQL的分库分表，可以从不同层次切入。常见的切入层有：\n\n编码层 -》 框架层 -》 驱动层 -》代理层 -》实现层\n<!--more-->\n\n### 1.1 编码层(不推荐)\n\n在代码层面动态切换数据源，例如Spring中的AbstractRoutingDataSource，缺点也是显而易见的，需要编写大量的代码，照顾到每个分支。当涉及跨库查询、聚合，需要循环计算结果并合并的场景，工作量巨大。不建议使用该种方案。\n\n### 1.2 框架层(不推荐)\n\n这种情况适合公司ORM框架统一的情况，修改或增强现有ORM框架的功能，在SQL中增加一些自定义原语或者hint来实现。主要做法是通过实现一些拦截器（比如Mybatis的Interceptor接口），增加一些自定义解析来控制数据的流向，效果虽然较好，但会改变一些现有的编程经验。很多情况要修改框架源码，不推荐。\n\n### 1.3 驱动层(ShardingJDBC)\n\n基于在编码层和框架层切入的各种缺点，真正的数据库中间件起码要从驱动层开始。重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。\n\n常用的方案为：TDDL、ShardingJDBC等。\n\nMysql Connector/J的Failover协议 (具体指“load balancing”、“replication”、“farbic”等）， 也是直接在驱动上进行修改。\n\n![驱动层方案](/images/分库分表/驱动层方案.png)\n\n### 1.4 代理层(MyCat)\n\n代理层的数据库中间件，将自己伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。\n\n常用的方案为：MySQL Router、MyCat等\n\n![代理层方案](/images/分库分表/代理层方案.png)\n\n### 1.5 实现层(Mysql-Cluster,Galera-Cluster)\n\nSQL特殊版本支持，如Mysql-Cluster本身就支持各种特性，Mariadb-Galera-Cluster支持对等双主，Greenplum支持分片等。\n\n### 1.6 驱动层与代理层比较\n\n#### 1.6.1 驱动层的特点\n\n1.仅支持JAVA，支持丰富的DB\n\n![驱动层特点](/images/分库分表/驱动层特点.png)\n\n2.占用较多的数据库连接\n\n驱动层中间件要维护很多数据库连接。比如一个分了10个 库 的表，每个java中的Connection要维护10个数据库连接。如果项目过多，则会出现连接爆炸。像Postgres这种每个连接对应一个进程的数据库，压力会很大。\n\n3.数据聚合在业务实例执行\n\n数据聚合，比如count sum等，是通过多次查询，然后在业务实例的内存中进行聚合。路由表存在于业务方实例内存中，通过轮询或者被动通知的途径更新路由表即可。\n\n4.集中式管理\n\n所有集群的配置管理都集中在一个地方，运维负担小，DBA即可完成相关操作。\n\n**驱动层的典型实现**\n\n![驱动层典型实现](/images/分库分表/驱动层典型实现.png)\n\n#### 1.6.2 代理层的特点\n\n1.异构支持，DB支持有限\n\n与驱动层相反，代理层中间件仅支持一种后端关系型数据库，但支持多种开发语言。如果你的系统是异构的，并且都有同样的SLA要求，则推荐使用此方案。\n\n![代理层特点](/images/分库分表/代理层特点.png)\n\n2.运维负担大\n\n代理层需要维护数据库连接数量有限（MySQL Router那种粘性连接除外）。但作为一个独立的服务，既要考虑单独部署，又要考虑高可用，会增加很多额外节点，更别提用了影子节点的公司了。\n另外，代理层是请求唯一的入口，稳定性要求极高，一旦有高耗内存的聚合查询把节点搞崩溃了，都是灾难性的事故。\n\n**代理层典型实现**\n\n![代理层典型实现](/images/分库分表/代理层典型实现.png)\n\n### 1.7 使用限制\n\n1.确保数据均衡\n\n拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。\n\n2.不能深分页\n\n不带切分键的深分页，会取出所有库所取页数之前的所有数据在内存排序计算。容易造成内存溢出。 \n\n3.减少子查询\n\n子查询会造成SQL解析紊乱，解析错误的情况，尽量减少SQL的子查询。\n\n4.事务最小原则\n\n尽量缩小单机事务涉及的库范围，即尽可能减少夸库操作，将同类操作的库/表分在一起。\n\n5.数据均衡原则\n\n拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。\n\n6.特殊函数\n\ndistinct、having、union、in、or等，一般不被支持。或者被支持，使用之后会增加风险，需要改造。\n\n## 2.分库分表中间件\n\n### 2.1 活跃中的项目\n\n#### 2.1.1 [活跃]-ProxySQL(轻量级)\n\nProxySQL是一个可以实现MySQL读写分离的轻量级工具。ProxySQL的特点：将所有配置保存写入到SQLit表中。支持动态加载配置，即一般可以在线修改配置，但有少部分参数还是需要重启来生效。支持query cache。支持对query的路由，可以针对某个语句进行分配去哪个实例执行。故障切换。过滤危险的SQL。不支持分表，可以分库，但是利用规则配置实现分表。\n\n![ProxySQL](https://images2015.cnblogs.com/blog/609710/201706/609710-20170615165724071-1793246218.png)\n\nMHA+ProxySQL实现读写分离高可用：https://www.cnblogs.com/gomysql/p/7018797.html\n\n项目地址: https://github.com/sysown/proxysql\n\n官网：https://proxysql.com/\n\n#### 2.1.2 [活跃]-Ctrip DAL(携程)\n\nCtrip DAL是携程框架部开发的数据库访问框架，支持代码生成和水平扩展。其由携程技术中心框架部DAL团队开发，历经3年不断打磨，并在长期的实际使用中基于大量的用户反馈不断优化。\n\nCtrip DAL支持流行的分库分表操作，支持Java和C#，支持Mysql和MS SqlServer。使用该框架可以在有效地保护企业已有数据库投资的同时，迅速，可靠的为企业提供数据库访问层的横向扩展能力。整个框架包括代码生成器和客户端。工作模式是使用代码生成器在线生成代码和配置，通过DAL客户端完成数据库操作。生成器具有丰富的向导指引，操作简单清晰，即可以批量生成标准DAO，也可以在方法级别定制数据库访问。\n\n![Ctrip-DAL](https://github.com/ctripcorp/dal/raw/master/doc/codegen_work_model.png)\n\n项目地址: https://github.com/ctripcorp/dal\n\n#### 2.1.3 [活跃]-Vitess(Youtube)\n\n这个中间件是Youtube生产在使用的，但是架构很复杂。 与以往中间件不同，使用Vitess应用改动比较大要 使用他提供语言的API接口，我们可以借鉴他其中的一些设计思想。Vitess 是一个用于 MySql 扩展的数据库解决方案。它以能够像运行在专用硬件上那样有效地运行于云体系。它集 MySql 数据库的很多重要特性和 NoSQL 数据库的可扩展性于一体。Vitess 已经成功侍服了 2011 年以来所有的 YouTube 数据库流量。\n\n![Vitess](https://img-blog.csdn.net/20150826095203562)\n\n理解VITESS: https://www.cnblogs.com/zhangwushang/p/8523015.html\n\n官网：https://vitess.io/\n\n项目地址：https://github.com/vitessio/vitess\n\n#### 2.1.4 [活跃]-Heisenberg(Cobar增强版)\n\nheisenberg 是百度的熊照同学(id:brucexx)编写的一款基于MySQL协议之上的分库分表中间件服务器，支持各种灵活（velocity脚本自定义）的分库分表规则，做到应用和分库分表相隔离，并且为mysql进行dbproxy,减少了db的连接IO压力，并且可做到读写分离以及replication的手工切换。\n\n改编自cobar, 结合了cobar和TDDL的优势，让其分片策略变为分库表策略，节约了大量连接，其优点： 分库分表与应用脱离，分库表如同使用单库表一样 减少db 连接数压力 热重启配置 可水平扩容 遵守Mysql原生协议 读写分离 无语言限制，mysqlclient,c,java等都可以使用 Heisenberg服务器通过管理命令可以查看，如连接数，线程池，结点等，并可以调整 采用velocity的分库分表脚本进行自定义分库表，相当的灵活。\n\n![Heisenberg](http://dl2.iteye.com/upload/attachment/0095/7149/b468edd2-ebdd-3c77-a033-b172909ee46f.jpg)\n\n项目地址: https://github.com/brucexx/heisenberg\n\n#### 2.1.5 [活跃]-Mycat(Cobar增强版)\n\n2013 年阿里的 Cobar 在社区使用过程中发现存在一些比较严重的问题，及其使用限制，经过 Mycat 发起人第一次改良，第一代改良版——Mycat 诞生。 Mycat 开源以后，一些 Cobar 的用户参与了 Mycat 的开发，最终 Mycat 发展成为一个由众多软件公司的实力派架构师和资深开发人员维护的社区型开源软件。\n\n![Mycat](http://5b0988e595225.cdn.sohucs.com/images/20180929/fc684917d1cd4292a5d62574699e71fb.jpeg)\n\n项目地址: https://github.com/MyCATApache/Mycat-Server\n\n利用MyCAT实现MySQL的读写分离和主从切换：https://blog.csdn.net/leonpenn/article/details/77278360\n\n官网：http://mycat.io/\n\n项目地址：https://github.com/MyCATApache/Mycat-Server\n\n#### 2.1.6 [活跃]-Sharding-JDBC(当当)\n\nSharding-JDBC是当当应用框架ddframe中,从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架,是继dubbox、elastic-job之后ddframe开源的第三个项目。Sharding-JDBC直接分装jdbc协议,可理解为增强版的JDBC驱动,旧代码迁移成本几乎为零,定位为轻量级java框架,使用客户端直连数据库,以jar包形式提供服务,无proxy层。\n\n![Sharding-JDBC](http://aliyunzixunbucket.oss-cn-beijing.aliyuncs.com/jpg/0d31edabc368a0bd0013de4cbc444232.jpg)\n\n项目地址: https://github.com/sharding-sphere/sharding-sphere\n\n### 2.2 停滞或未开源的项目\n\n#### 2.2.1 [停滞]-kingshard(Go语言)\n\n一个由Go开发高性能MySQL Proxy项目，kingshard在满足基本的读写分离的功能上，致力于简化MySQL分库分表操作,能够让DBA通过kingshard轻松平滑地实现MySQL数据库扩容。\n\n![架构图](https://image-static.segmentfault.com/322/105/3221059488-56fe2b2e4e675_articlex)\n\nsharding方式:range方式、hash方式\n\n**分表方案采用两级映射的方式：**\n\n1.kingshard将该表分成512张子表，例如：test_0000,test_0001,...test_511。\n\n2.将shardKey通过hash或range方式定位到其要操作的记录在哪张子表上。\n\n3.子表落在哪个node上通过配置文件设置。\n\n**基于kingshard的子表迁移方案:**\n\n1.通过自动数据迁移工具开始数据迁移。\n\n2.数据差异小于某一临界值，阻塞老子表写操作（read-only）\n\n3.等待新子表数据同步完毕\n\n4.更改kingshard配置文件中的对应子表的路由规则。\n\n5.删除老节点上的子表。\n\n参考网址: https://segmentfault.com/a/1190000003001545\n\n项目地址: https://github.com/flike/kingshard\n\n#### 2.2.2 [停滞]-MySQL Fabric(官方)\n\n为了实现和方便管理MySQL 分片以及实现高可用部署，Oracle在2014年5月推出了一套为各方寄予厚望的MySQL产品 -- MySQL Fabric, 用来管理MySQL 服务，提供扩展性和容易使用的系统，Fabric当前实现了两个特性：高可用和使用数据分片实现可扩展性和负载均衡，这两个特性能单独使用或结合使用。\n\n![MySQL Fabric](http://www.2cto.com/uploadfile/Collfiles/20140823/2014082309170262.jpg)\n\nMySQLFabric概述: https://www.cnblogs.com/huaxingtianxia/p/7095193.html\n\nMySQL原生HA方案 – Fabric体验之旅: https://www.csdn.net/article/2014-08-20/2821300\n\n官网: https://downloads.mysql.com/archives/utilities/\n\n#### 2.2.3 [停滞]-Oceanus(58同城)\n\n58同城数据库中间件。Oceanus致力于打造一个功能简单、可依赖、易于上手、易于扩展、易于集成的解决方案，甚至是平台化系统。拥抱开源，提供各类插件机制集成其他开源项目，新手可以在几分钟内上手编程，分库分表逻辑不再与业务紧密耦合，扩容有标准模式，减少意外错误的发生。最后更新时间2015年。\n\n项目地址：https://github.com/58code/Oceanus\n\n![oceanus](http://dl2.iteye.com/upload/attachment/0106/3405/f18c03c4-ea5b-395a-9ca5-50c4f31e721f.png)\n\n#### 2.2.4 [停滞]-TSharding(蘑菇街)\n\nTSharding 是应用于蘑菇街交易平台的一个简易 sharding 组件，也是一个 Mybatis 分库分表组件。\n\n![TSharding](http://static.oschina.net/uploads/space/2016/0817/105311_VhyZ_2720166.png)\n\n项目地址: https://github.com/baihui212/tsharding\n\n#### 2.2.5 [未开源]-DDB(网易)\n\nDDB（Distributed database）是网易杭研院立项最早，应用最为广泛的后台产品之一，也是国内最早出现的基于现有database之上开发的分布式数据库中间件，目前依然在为网易易信，云音乐，云阅读等大型互联网产品提供稳定的数据库服务。\n\n![DDB](http://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhboMzgaQTMiblcE1O5vfEDiaUaFSSTawRvPxUPG1zMrXNwJAWPH0TibQaC8wkicBuib9Nct9fn4D44B1g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n网易分库分表数据库DDB：https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg\n\n#### 2.2.6 [停滞]-TDDL(阿里)\n\n淘宝根据自身业务需求研发了TDDL（Taobao Distributed Data Layer）框架，主要用于解决分库分表场景下的访问路由（持久层与数据访问层的配合）以及异构数据库之间的数据同步，它是一个基于集中式配置的JDBC DataSource实现，具有分库分表、Master/Salve、动态数据源配置等功能。就目前而言，许多大厂也在出一些更加优秀和社区支持更广泛的DAL层产品，比如Hibernate Shards、Ibatis-Sharding等。项目最后一次更新为2012年。\n\n![TDDL](https://img-blog.csdn.net/20160601111503650)\n\n![TDDL分库分表策略](https://img-blog.csdn.net/20160601111544711)\n\nTDDL：来自淘宝的分布式数据层：https://blog.csdn.net/diu_brother/article/details/51554555\n\n官网: https://github.com/alibaba/tb_tddl\n\n#### 2.2.7 [未开源]-MTDDL(美团点评)\n\nMTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。\n\nMTDDL——美团点评分布式数据访问层中间件：https://tech.meituan.com/mtddl.html\n\n#### 2.2.8 [停滞]-Zebra(美团点评)\n\nZebra是美团点评内部使用的数据库访问层中间件，它具有以下的功能点：配置集中管理，动态刷新。支持读写分离、分库分表。丰富的监控信息在CAT上展现\n\n项目地址: https://github.com/Meituan-Dianping/Zebra\n\n#### 2.2.9 [停滞]-Cobar(阿里)\n\nCobar是提供分布式数据库服务的中间件，由阿里中间件团队开发，是阿里巴巴B2B前台应用访问数据库的统一入口，Cobar的分布式方案是分库和分表，可以按照业务需求将数据库中耦合度较低的表分到不同的分库中，也可以按照具体表的增长速度和数据量水平切分到不同的分库中，Cobar可以实现应用层与物理分库的双向透明，从而实现应用程序访问分布式数据库与访问单库无差别。 Cobar还可以配合MySQL的心跳和binlog实现备机的自动切换，保证数据节点的可靠性，从而实现高可用性。\n\n![Cobar](https://images0.cnblogs.com/blog/316027/201412/171250029067744.jpg)\n\n项目地址: https://github.com/alibaba/cobar\n\n#### 2.2.10 [未开源]-OneProxy(代理层)\n\nOneProxy是由原支付宝首席架构师楼方鑫开发，目前由楼方鑫创立的杭州平民软件公司（@平民架构）提供技术支持。目前已有多家公司在生成环境中使用，其中包括了支付、电商等行业。\n\n![OneProxy](https://images2015.cnblogs.com/blog/711446/201606/711446-20160620135708787-1432694302.jpg)\n\nOneProxy的主要功能有：1. 垂直分库 2. 水平分表 3. Proxy集群 4. 读高可用 5. 读写分离（master不参与读）6. 读写分离（master参与读）7. 写高可用 8. 读写随机\n\nOneProxy使用手册-致力于打造透明的数据层: https://www.cnblogs.com/youge-OneSQL/articles/4208583.html\n\n官网：http://www.onexsoft.com/\n\n### 2.3 其他数据库项目\n\n#### 2.3.1 [活跃]-Greenplum(PostgreSQL)\n\nGreenPlum建立在PostgreSQL的基础上，把许许多多的PostgreSQL节点组织在一起，实现了一个强大的分布式数据库。集群包括两类角色：master和segment。\n\nGreenPlum数据库默认会采用Hash Distribution：如果创建表时没有指定Distribution Key，则会选择Primary Key作为Distribution Key。如果Primary Key也不存在，就会选择表的第一列作为Distribution Key。和大多数的分布式系统一样，GreenPlum也支持垂直和水平两种扩容方式，垂直扩容又被称为presharding模式。\n\n![Greenplum](https://nos.netease.com/cloud-website-bucket/20180703130100fab02779-312a-465a-ba31-75a275194d70.jpg)\n\n【GreenPlum】GreenPlum服务来了!: https://sq.163yun.com/blog/article/172464991000825856\n\n官网: https://greenplum.org/\n\n#### 2.3.2 [活跃]-MariaDB Spider(Mariadb)\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\n\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\nSpider是MariaDB内置的一个可插拔用于MariaDB/MySQL数据库分片的存储引擎，充当应用服务器和远程后端DB之间的代理（中间件），它可以轻松实现MySQL的横向和纵向扩展，突破单台MySQL的限制，支持范围分区、列表分区、哈希分区，支持XA分布式事务，支持跨库join。通过Spider，您可以跨多个数据库后端有效访问数据，让您的应用程序一行代码不改，即可轻松实现分库分表！\n\n![MariaDB-Spider](http://img.mp.itc.cn/upload/20170420/527be525b8294adea707a05822d8d1c0_th.jpeg)\n\nMariaDB Spider：实现MySQL横纵向扩展的小能手: https://www.sohu.com/a/135228509_487514\n\n官网: https://mariadb.com/kb/en/library/spider/\n\n## 3.扩容方案如何做？\n\n### 3.1 水平分库扩展的问题\n\n水平分库常用的分库策略是采用取模的方式，对userId或业务ID,当业务快速的发展，用户量数据大量上升，当前容量不足以支撑，就需要对数据库进行水平扩容，再增加新库来分解。新库加入之后，原先sharding到3个库的数据，就可以sharding到4个库里面了。\n\n不过此时由于分片规则进行了变化(uid%3 变为uid%4)，大部分的数据，无法命中在原有的数据库上了，需要重新分配，大量数据需要迁移。比如之前uid1通过uid1%3 分配在A库上，新加入库D之后，算法改为uid1%4 了，此时有可能就分配在B库上面了。如果你了解过一致性哈希的原理，就会发现新增一个节点，大概会有90%的数据需要迁移，这个对DB同学的压力还是蛮大的，那么如何应对？\n\n### 3.2 方案一：停服迁移\n\n停服迁移是最常见的一种方案了，一般如下流程:1.预估停服时间，发布停服公告。2.停服，通过事先做好的数据迁移工具，按照新的分片规则，进行迁移。3.修改分片规则。4.启动服务。\n\n缺点：\n\n1.停服，伤害用户体验，同时也降低了服务器的可用性\n\n2.必须在制定时间内完成迁移，如果失败，需要择日再次进行。同时增加了开发人员的压力，容易发生大的事故\n\n3.数据量的巨大的时候，迁移需要大量时间\n\n### 3.3 方案二：升级从库\n\n线上数据库，我们为了保持其高可用，一般都会每台主库配一台从库，读写在主库，然后主从同步到从库。\n\n升级从库方案步骤：\n\n1.修改分片配置，做好新库和老库的映射。\n\n2.同步配置，从库升级为主库\n\n3.解除主从关系\n\n4.冗余数据清理\n\n5.为新的数据节点搭建新的从库\n\n示意图如下:\n\n![原来的架构](/images/分库分表/从库变主库.png)\n\n![从库升级主库](/images/分库分表/从库变主库1.png)\n\n![主库添加从库](/images/分库分表/从库变主库2.png)\n\n### 3.4 方案三：双写迁移\n\n原理和上述相同，做分裂扩容，只是数据的同步方式不同了\n\n双写迁移方案步骤：\n\n1.增加新库写链接\n\n双写的核心原理，就是对需要扩容的数据库上，增加新库，并对现有的分片上增加写链接，同时写两份数据。因为新库的数据为空，所以数据的CRUD对其没有影响，在上层的逻辑层，还是以老库的数据为主。\n\n2.新老库数据迁移\n\n通过工具，把老库的数据迁移到新库里面，此时可以选择同步分裂后的数据（1/2）来同步，也可以全同步，一般建议全同步，最终做数据校检的时候好处理。\n\n3.数据校检\n\n按照理想环境情况下，数据迁移之后，因为是双写操作，所以两边的数据是一致的，特别是insert和update，一致性情况很高。但真实环境中会有网络延迟等情况，对于delete情况并不是很理想，此时就需要做好数据校检了，数据校检可以多做几遍，直到数据几乎一致，尽量以旧库的数据为准。\n\n4.分片配置修改\n\n数据同步完毕，就可以把新库的分片映射重新处理了，还是按照老库分裂的方式来进行，u之前uid%2=0,变为uid%4=0和uid%4=2的。uid%2=1，变为uid%4=1和uid%4=3的。\n\n示意图如下：\n\n![双写迁移](/images/分库分表/双写迁移.png)\n\n![双写迁移1](/images/分库分表/双写迁移1.png)\n\n![双写迁移2](/images/分库分表/双写迁移2.png)\n\n## 4.参考资料\n\n分库分表？选型和流程要慎重，否则会失控：https://juejin.im/post/5bf778ef5188251b8a26ed8b\n\nMySQL分库分表方案: https://www.cnblogs.com/sunny3096/p/8595058.html\n\n分布式数据中间件TDDL、Amoeba、Cobar、MyCAT架构比较: https://blog.csdn.net/kobejayandy/article/details/60869530\n\n假如让你来设计数据库中间件: https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA \n\n数据库中间件Atlas调研笔记: https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA\n\n数据库中间件TDDL调研笔记: https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w\n\n数据库中间件cobar调研笔记: https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ\n\nmysql-proxy数据库中间件架构: https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ\n\n水平分库如何做到平滑扩展： https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A\n\nmysql中间件研究(Atlas,Cobar,TDDL): https://www.guokr.com/blog/475765/\n\nmycat分布式mysql中间件（mysql中间件研究): http://songwie.com/articlelist/44","source":"_posts/2018-12-01-MySQL分库分表方案选型.md","raw":"---\nlayout: lay_post\ntitle: \"MySQL分库分表方案选型\"\ndate: 2018-12-01\ncategories: 中间件\ntags: MySQL\nauthor: lvyafei\n---\n\n## 1.分库分表方案\n\n针对MySQL的分库分表，可以从不同层次切入。常见的切入层有：\n\n编码层 -》 框架层 -》 驱动层 -》代理层 -》实现层\n<!--more-->\n\n### 1.1 编码层(不推荐)\n\n在代码层面动态切换数据源，例如Spring中的AbstractRoutingDataSource，缺点也是显而易见的，需要编写大量的代码，照顾到每个分支。当涉及跨库查询、聚合，需要循环计算结果并合并的场景，工作量巨大。不建议使用该种方案。\n\n### 1.2 框架层(不推荐)\n\n这种情况适合公司ORM框架统一的情况，修改或增强现有ORM框架的功能，在SQL中增加一些自定义原语或者hint来实现。主要做法是通过实现一些拦截器（比如Mybatis的Interceptor接口），增加一些自定义解析来控制数据的流向，效果虽然较好，但会改变一些现有的编程经验。很多情况要修改框架源码，不推荐。\n\n### 1.3 驱动层(ShardingJDBC)\n\n基于在编码层和框架层切入的各种缺点，真正的数据库中间件起码要从驱动层开始。重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。\n\n常用的方案为：TDDL、ShardingJDBC等。\n\nMysql Connector/J的Failover协议 (具体指“load balancing”、“replication”、“farbic”等）， 也是直接在驱动上进行修改。\n\n![驱动层方案](/images/分库分表/驱动层方案.png)\n\n### 1.4 代理层(MyCat)\n\n代理层的数据库中间件，将自己伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。\n\n常用的方案为：MySQL Router、MyCat等\n\n![代理层方案](/images/分库分表/代理层方案.png)\n\n### 1.5 实现层(Mysql-Cluster,Galera-Cluster)\n\nSQL特殊版本支持，如Mysql-Cluster本身就支持各种特性，Mariadb-Galera-Cluster支持对等双主，Greenplum支持分片等。\n\n### 1.6 驱动层与代理层比较\n\n#### 1.6.1 驱动层的特点\n\n1.仅支持JAVA，支持丰富的DB\n\n![驱动层特点](/images/分库分表/驱动层特点.png)\n\n2.占用较多的数据库连接\n\n驱动层中间件要维护很多数据库连接。比如一个分了10个 库 的表，每个java中的Connection要维护10个数据库连接。如果项目过多，则会出现连接爆炸。像Postgres这种每个连接对应一个进程的数据库，压力会很大。\n\n3.数据聚合在业务实例执行\n\n数据聚合，比如count sum等，是通过多次查询，然后在业务实例的内存中进行聚合。路由表存在于业务方实例内存中，通过轮询或者被动通知的途径更新路由表即可。\n\n4.集中式管理\n\n所有集群的配置管理都集中在一个地方，运维负担小，DBA即可完成相关操作。\n\n**驱动层的典型实现**\n\n![驱动层典型实现](/images/分库分表/驱动层典型实现.png)\n\n#### 1.6.2 代理层的特点\n\n1.异构支持，DB支持有限\n\n与驱动层相反，代理层中间件仅支持一种后端关系型数据库，但支持多种开发语言。如果你的系统是异构的，并且都有同样的SLA要求，则推荐使用此方案。\n\n![代理层特点](/images/分库分表/代理层特点.png)\n\n2.运维负担大\n\n代理层需要维护数据库连接数量有限（MySQL Router那种粘性连接除外）。但作为一个独立的服务，既要考虑单独部署，又要考虑高可用，会增加很多额外节点，更别提用了影子节点的公司了。\n另外，代理层是请求唯一的入口，稳定性要求极高，一旦有高耗内存的聚合查询把节点搞崩溃了，都是灾难性的事故。\n\n**代理层典型实现**\n\n![代理层典型实现](/images/分库分表/代理层典型实现.png)\n\n### 1.7 使用限制\n\n1.确保数据均衡\n\n拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。\n\n2.不能深分页\n\n不带切分键的深分页，会取出所有库所取页数之前的所有数据在内存排序计算。容易造成内存溢出。 \n\n3.减少子查询\n\n子查询会造成SQL解析紊乱，解析错误的情况，尽量减少SQL的子查询。\n\n4.事务最小原则\n\n尽量缩小单机事务涉及的库范围，即尽可能减少夸库操作，将同类操作的库/表分在一起。\n\n5.数据均衡原则\n\n拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。\n\n6.特殊函数\n\ndistinct、having、union、in、or等，一般不被支持。或者被支持，使用之后会增加风险，需要改造。\n\n## 2.分库分表中间件\n\n### 2.1 活跃中的项目\n\n#### 2.1.1 [活跃]-ProxySQL(轻量级)\n\nProxySQL是一个可以实现MySQL读写分离的轻量级工具。ProxySQL的特点：将所有配置保存写入到SQLit表中。支持动态加载配置，即一般可以在线修改配置，但有少部分参数还是需要重启来生效。支持query cache。支持对query的路由，可以针对某个语句进行分配去哪个实例执行。故障切换。过滤危险的SQL。不支持分表，可以分库，但是利用规则配置实现分表。\n\n![ProxySQL](https://images2015.cnblogs.com/blog/609710/201706/609710-20170615165724071-1793246218.png)\n\nMHA+ProxySQL实现读写分离高可用：https://www.cnblogs.com/gomysql/p/7018797.html\n\n项目地址: https://github.com/sysown/proxysql\n\n官网：https://proxysql.com/\n\n#### 2.1.2 [活跃]-Ctrip DAL(携程)\n\nCtrip DAL是携程框架部开发的数据库访问框架，支持代码生成和水平扩展。其由携程技术中心框架部DAL团队开发，历经3年不断打磨，并在长期的实际使用中基于大量的用户反馈不断优化。\n\nCtrip DAL支持流行的分库分表操作，支持Java和C#，支持Mysql和MS SqlServer。使用该框架可以在有效地保护企业已有数据库投资的同时，迅速，可靠的为企业提供数据库访问层的横向扩展能力。整个框架包括代码生成器和客户端。工作模式是使用代码生成器在线生成代码和配置，通过DAL客户端完成数据库操作。生成器具有丰富的向导指引，操作简单清晰，即可以批量生成标准DAO，也可以在方法级别定制数据库访问。\n\n![Ctrip-DAL](https://github.com/ctripcorp/dal/raw/master/doc/codegen_work_model.png)\n\n项目地址: https://github.com/ctripcorp/dal\n\n#### 2.1.3 [活跃]-Vitess(Youtube)\n\n这个中间件是Youtube生产在使用的，但是架构很复杂。 与以往中间件不同，使用Vitess应用改动比较大要 使用他提供语言的API接口，我们可以借鉴他其中的一些设计思想。Vitess 是一个用于 MySql 扩展的数据库解决方案。它以能够像运行在专用硬件上那样有效地运行于云体系。它集 MySql 数据库的很多重要特性和 NoSQL 数据库的可扩展性于一体。Vitess 已经成功侍服了 2011 年以来所有的 YouTube 数据库流量。\n\n![Vitess](https://img-blog.csdn.net/20150826095203562)\n\n理解VITESS: https://www.cnblogs.com/zhangwushang/p/8523015.html\n\n官网：https://vitess.io/\n\n项目地址：https://github.com/vitessio/vitess\n\n#### 2.1.4 [活跃]-Heisenberg(Cobar增强版)\n\nheisenberg 是百度的熊照同学(id:brucexx)编写的一款基于MySQL协议之上的分库分表中间件服务器，支持各种灵活（velocity脚本自定义）的分库分表规则，做到应用和分库分表相隔离，并且为mysql进行dbproxy,减少了db的连接IO压力，并且可做到读写分离以及replication的手工切换。\n\n改编自cobar, 结合了cobar和TDDL的优势，让其分片策略变为分库表策略，节约了大量连接，其优点： 分库分表与应用脱离，分库表如同使用单库表一样 减少db 连接数压力 热重启配置 可水平扩容 遵守Mysql原生协议 读写分离 无语言限制，mysqlclient,c,java等都可以使用 Heisenberg服务器通过管理命令可以查看，如连接数，线程池，结点等，并可以调整 采用velocity的分库分表脚本进行自定义分库表，相当的灵活。\n\n![Heisenberg](http://dl2.iteye.com/upload/attachment/0095/7149/b468edd2-ebdd-3c77-a033-b172909ee46f.jpg)\n\n项目地址: https://github.com/brucexx/heisenberg\n\n#### 2.1.5 [活跃]-Mycat(Cobar增强版)\n\n2013 年阿里的 Cobar 在社区使用过程中发现存在一些比较严重的问题，及其使用限制，经过 Mycat 发起人第一次改良，第一代改良版——Mycat 诞生。 Mycat 开源以后，一些 Cobar 的用户参与了 Mycat 的开发，最终 Mycat 发展成为一个由众多软件公司的实力派架构师和资深开发人员维护的社区型开源软件。\n\n![Mycat](http://5b0988e595225.cdn.sohucs.com/images/20180929/fc684917d1cd4292a5d62574699e71fb.jpeg)\n\n项目地址: https://github.com/MyCATApache/Mycat-Server\n\n利用MyCAT实现MySQL的读写分离和主从切换：https://blog.csdn.net/leonpenn/article/details/77278360\n\n官网：http://mycat.io/\n\n项目地址：https://github.com/MyCATApache/Mycat-Server\n\n#### 2.1.6 [活跃]-Sharding-JDBC(当当)\n\nSharding-JDBC是当当应用框架ddframe中,从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架,是继dubbox、elastic-job之后ddframe开源的第三个项目。Sharding-JDBC直接分装jdbc协议,可理解为增强版的JDBC驱动,旧代码迁移成本几乎为零,定位为轻量级java框架,使用客户端直连数据库,以jar包形式提供服务,无proxy层。\n\n![Sharding-JDBC](http://aliyunzixunbucket.oss-cn-beijing.aliyuncs.com/jpg/0d31edabc368a0bd0013de4cbc444232.jpg)\n\n项目地址: https://github.com/sharding-sphere/sharding-sphere\n\n### 2.2 停滞或未开源的项目\n\n#### 2.2.1 [停滞]-kingshard(Go语言)\n\n一个由Go开发高性能MySQL Proxy项目，kingshard在满足基本的读写分离的功能上，致力于简化MySQL分库分表操作,能够让DBA通过kingshard轻松平滑地实现MySQL数据库扩容。\n\n![架构图](https://image-static.segmentfault.com/322/105/3221059488-56fe2b2e4e675_articlex)\n\nsharding方式:range方式、hash方式\n\n**分表方案采用两级映射的方式：**\n\n1.kingshard将该表分成512张子表，例如：test_0000,test_0001,...test_511。\n\n2.将shardKey通过hash或range方式定位到其要操作的记录在哪张子表上。\n\n3.子表落在哪个node上通过配置文件设置。\n\n**基于kingshard的子表迁移方案:**\n\n1.通过自动数据迁移工具开始数据迁移。\n\n2.数据差异小于某一临界值，阻塞老子表写操作（read-only）\n\n3.等待新子表数据同步完毕\n\n4.更改kingshard配置文件中的对应子表的路由规则。\n\n5.删除老节点上的子表。\n\n参考网址: https://segmentfault.com/a/1190000003001545\n\n项目地址: https://github.com/flike/kingshard\n\n#### 2.2.2 [停滞]-MySQL Fabric(官方)\n\n为了实现和方便管理MySQL 分片以及实现高可用部署，Oracle在2014年5月推出了一套为各方寄予厚望的MySQL产品 -- MySQL Fabric, 用来管理MySQL 服务，提供扩展性和容易使用的系统，Fabric当前实现了两个特性：高可用和使用数据分片实现可扩展性和负载均衡，这两个特性能单独使用或结合使用。\n\n![MySQL Fabric](http://www.2cto.com/uploadfile/Collfiles/20140823/2014082309170262.jpg)\n\nMySQLFabric概述: https://www.cnblogs.com/huaxingtianxia/p/7095193.html\n\nMySQL原生HA方案 – Fabric体验之旅: https://www.csdn.net/article/2014-08-20/2821300\n\n官网: https://downloads.mysql.com/archives/utilities/\n\n#### 2.2.3 [停滞]-Oceanus(58同城)\n\n58同城数据库中间件。Oceanus致力于打造一个功能简单、可依赖、易于上手、易于扩展、易于集成的解决方案，甚至是平台化系统。拥抱开源，提供各类插件机制集成其他开源项目，新手可以在几分钟内上手编程，分库分表逻辑不再与业务紧密耦合，扩容有标准模式，减少意外错误的发生。最后更新时间2015年。\n\n项目地址：https://github.com/58code/Oceanus\n\n![oceanus](http://dl2.iteye.com/upload/attachment/0106/3405/f18c03c4-ea5b-395a-9ca5-50c4f31e721f.png)\n\n#### 2.2.4 [停滞]-TSharding(蘑菇街)\n\nTSharding 是应用于蘑菇街交易平台的一个简易 sharding 组件，也是一个 Mybatis 分库分表组件。\n\n![TSharding](http://static.oschina.net/uploads/space/2016/0817/105311_VhyZ_2720166.png)\n\n项目地址: https://github.com/baihui212/tsharding\n\n#### 2.2.5 [未开源]-DDB(网易)\n\nDDB（Distributed database）是网易杭研院立项最早，应用最为广泛的后台产品之一，也是国内最早出现的基于现有database之上开发的分布式数据库中间件，目前依然在为网易易信，云音乐，云阅读等大型互联网产品提供稳定的数据库服务。\n\n![DDB](http://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhboMzgaQTMiblcE1O5vfEDiaUaFSSTawRvPxUPG1zMrXNwJAWPH0TibQaC8wkicBuib9Nct9fn4D44B1g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n\n网易分库分表数据库DDB：https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg\n\n#### 2.2.6 [停滞]-TDDL(阿里)\n\n淘宝根据自身业务需求研发了TDDL（Taobao Distributed Data Layer）框架，主要用于解决分库分表场景下的访问路由（持久层与数据访问层的配合）以及异构数据库之间的数据同步，它是一个基于集中式配置的JDBC DataSource实现，具有分库分表、Master/Salve、动态数据源配置等功能。就目前而言，许多大厂也在出一些更加优秀和社区支持更广泛的DAL层产品，比如Hibernate Shards、Ibatis-Sharding等。项目最后一次更新为2012年。\n\n![TDDL](https://img-blog.csdn.net/20160601111503650)\n\n![TDDL分库分表策略](https://img-blog.csdn.net/20160601111544711)\n\nTDDL：来自淘宝的分布式数据层：https://blog.csdn.net/diu_brother/article/details/51554555\n\n官网: https://github.com/alibaba/tb_tddl\n\n#### 2.2.7 [未开源]-MTDDL(美团点评)\n\nMTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。\n\nMTDDL——美团点评分布式数据访问层中间件：https://tech.meituan.com/mtddl.html\n\n#### 2.2.8 [停滞]-Zebra(美团点评)\n\nZebra是美团点评内部使用的数据库访问层中间件，它具有以下的功能点：配置集中管理，动态刷新。支持读写分离、分库分表。丰富的监控信息在CAT上展现\n\n项目地址: https://github.com/Meituan-Dianping/Zebra\n\n#### 2.2.9 [停滞]-Cobar(阿里)\n\nCobar是提供分布式数据库服务的中间件，由阿里中间件团队开发，是阿里巴巴B2B前台应用访问数据库的统一入口，Cobar的分布式方案是分库和分表，可以按照业务需求将数据库中耦合度较低的表分到不同的分库中，也可以按照具体表的增长速度和数据量水平切分到不同的分库中，Cobar可以实现应用层与物理分库的双向透明，从而实现应用程序访问分布式数据库与访问单库无差别。 Cobar还可以配合MySQL的心跳和binlog实现备机的自动切换，保证数据节点的可靠性，从而实现高可用性。\n\n![Cobar](https://images0.cnblogs.com/blog/316027/201412/171250029067744.jpg)\n\n项目地址: https://github.com/alibaba/cobar\n\n#### 2.2.10 [未开源]-OneProxy(代理层)\n\nOneProxy是由原支付宝首席架构师楼方鑫开发，目前由楼方鑫创立的杭州平民软件公司（@平民架构）提供技术支持。目前已有多家公司在生成环境中使用，其中包括了支付、电商等行业。\n\n![OneProxy](https://images2015.cnblogs.com/blog/711446/201606/711446-20160620135708787-1432694302.jpg)\n\nOneProxy的主要功能有：1. 垂直分库 2. 水平分表 3. Proxy集群 4. 读高可用 5. 读写分离（master不参与读）6. 读写分离（master参与读）7. 写高可用 8. 读写随机\n\nOneProxy使用手册-致力于打造透明的数据层: https://www.cnblogs.com/youge-OneSQL/articles/4208583.html\n\n官网：http://www.onexsoft.com/\n\n### 2.3 其他数据库项目\n\n#### 2.3.1 [活跃]-Greenplum(PostgreSQL)\n\nGreenPlum建立在PostgreSQL的基础上，把许许多多的PostgreSQL节点组织在一起，实现了一个强大的分布式数据库。集群包括两类角色：master和segment。\n\nGreenPlum数据库默认会采用Hash Distribution：如果创建表时没有指定Distribution Key，则会选择Primary Key作为Distribution Key。如果Primary Key也不存在，就会选择表的第一列作为Distribution Key。和大多数的分布式系统一样，GreenPlum也支持垂直和水平两种扩容方式，垂直扩容又被称为presharding模式。\n\n![Greenplum](https://nos.netease.com/cloud-website-bucket/20180703130100fab02779-312a-465a-ba31-75a275194d70.jpg)\n\n【GreenPlum】GreenPlum服务来了!: https://sq.163yun.com/blog/article/172464991000825856\n\n官网: https://greenplum.org/\n\n#### 2.3.2 [活跃]-MariaDB Spider(Mariadb)\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\n\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\nSpider是MariaDB内置的一个可插拔用于MariaDB/MySQL数据库分片的存储引擎，充当应用服务器和远程后端DB之间的代理（中间件），它可以轻松实现MySQL的横向和纵向扩展，突破单台MySQL的限制，支持范围分区、列表分区、哈希分区，支持XA分布式事务，支持跨库join。通过Spider，您可以跨多个数据库后端有效访问数据，让您的应用程序一行代码不改，即可轻松实现分库分表！\n\n![MariaDB-Spider](http://img.mp.itc.cn/upload/20170420/527be525b8294adea707a05822d8d1c0_th.jpeg)\n\nMariaDB Spider：实现MySQL横纵向扩展的小能手: https://www.sohu.com/a/135228509_487514\n\n官网: https://mariadb.com/kb/en/library/spider/\n\n## 3.扩容方案如何做？\n\n### 3.1 水平分库扩展的问题\n\n水平分库常用的分库策略是采用取模的方式，对userId或业务ID,当业务快速的发展，用户量数据大量上升，当前容量不足以支撑，就需要对数据库进行水平扩容，再增加新库来分解。新库加入之后，原先sharding到3个库的数据，就可以sharding到4个库里面了。\n\n不过此时由于分片规则进行了变化(uid%3 变为uid%4)，大部分的数据，无法命中在原有的数据库上了，需要重新分配，大量数据需要迁移。比如之前uid1通过uid1%3 分配在A库上，新加入库D之后，算法改为uid1%4 了，此时有可能就分配在B库上面了。如果你了解过一致性哈希的原理，就会发现新增一个节点，大概会有90%的数据需要迁移，这个对DB同学的压力还是蛮大的，那么如何应对？\n\n### 3.2 方案一：停服迁移\n\n停服迁移是最常见的一种方案了，一般如下流程:1.预估停服时间，发布停服公告。2.停服，通过事先做好的数据迁移工具，按照新的分片规则，进行迁移。3.修改分片规则。4.启动服务。\n\n缺点：\n\n1.停服，伤害用户体验，同时也降低了服务器的可用性\n\n2.必须在制定时间内完成迁移，如果失败，需要择日再次进行。同时增加了开发人员的压力，容易发生大的事故\n\n3.数据量的巨大的时候，迁移需要大量时间\n\n### 3.3 方案二：升级从库\n\n线上数据库，我们为了保持其高可用，一般都会每台主库配一台从库，读写在主库，然后主从同步到从库。\n\n升级从库方案步骤：\n\n1.修改分片配置，做好新库和老库的映射。\n\n2.同步配置，从库升级为主库\n\n3.解除主从关系\n\n4.冗余数据清理\n\n5.为新的数据节点搭建新的从库\n\n示意图如下:\n\n![原来的架构](/images/分库分表/从库变主库.png)\n\n![从库升级主库](/images/分库分表/从库变主库1.png)\n\n![主库添加从库](/images/分库分表/从库变主库2.png)\n\n### 3.4 方案三：双写迁移\n\n原理和上述相同，做分裂扩容，只是数据的同步方式不同了\n\n双写迁移方案步骤：\n\n1.增加新库写链接\n\n双写的核心原理，就是对需要扩容的数据库上，增加新库，并对现有的分片上增加写链接，同时写两份数据。因为新库的数据为空，所以数据的CRUD对其没有影响，在上层的逻辑层，还是以老库的数据为主。\n\n2.新老库数据迁移\n\n通过工具，把老库的数据迁移到新库里面，此时可以选择同步分裂后的数据（1/2）来同步，也可以全同步，一般建议全同步，最终做数据校检的时候好处理。\n\n3.数据校检\n\n按照理想环境情况下，数据迁移之后，因为是双写操作，所以两边的数据是一致的，特别是insert和update，一致性情况很高。但真实环境中会有网络延迟等情况，对于delete情况并不是很理想，此时就需要做好数据校检了，数据校检可以多做几遍，直到数据几乎一致，尽量以旧库的数据为准。\n\n4.分片配置修改\n\n数据同步完毕，就可以把新库的分片映射重新处理了，还是按照老库分裂的方式来进行，u之前uid%2=0,变为uid%4=0和uid%4=2的。uid%2=1，变为uid%4=1和uid%4=3的。\n\n示意图如下：\n\n![双写迁移](/images/分库分表/双写迁移.png)\n\n![双写迁移1](/images/分库分表/双写迁移1.png)\n\n![双写迁移2](/images/分库分表/双写迁移2.png)\n\n## 4.参考资料\n\n分库分表？选型和流程要慎重，否则会失控：https://juejin.im/post/5bf778ef5188251b8a26ed8b\n\nMySQL分库分表方案: https://www.cnblogs.com/sunny3096/p/8595058.html\n\n分布式数据中间件TDDL、Amoeba、Cobar、MyCAT架构比较: https://blog.csdn.net/kobejayandy/article/details/60869530\n\n假如让你来设计数据库中间件: https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA \n\n数据库中间件Atlas调研笔记: https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA\n\n数据库中间件TDDL调研笔记: https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w\n\n数据库中间件cobar调研笔记: https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ\n\nmysql-proxy数据库中间件架构: https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ\n\n水平分库如何做到平滑扩展： https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A\n\nmysql中间件研究(Atlas,Cobar,TDDL): https://www.guokr.com/blog/475765/\n\nmycat分布式mysql中间件（mysql中间件研究): http://songwie.com/articlelist/44","slug":"2018-12-01-MySQL分库分表方案选型","published":1,"updated":"2018-12-04T13:27:34.925Z","comments":1,"photos":[],"link":"","_id":"cjskffofy006m4glm36r80gyd","content":"<h2 id=\"1-分库分表方案\"><a href=\"#1-分库分表方案\" class=\"headerlink\" title=\"1.分库分表方案\"></a>1.分库分表方案</h2><p>针对MySQL的分库分表，可以从不同层次切入。常见的切入层有：</p>\n<p>编码层 -》 框架层 -》 驱动层 -》代理层 -》实现层<br><a id=\"more\"></a></p>\n<h3 id=\"1-1-编码层-不推荐\"><a href=\"#1-1-编码层-不推荐\" class=\"headerlink\" title=\"1.1 编码层(不推荐)\"></a>1.1 编码层(不推荐)</h3><p>在代码层面动态切换数据源，例如Spring中的AbstractRoutingDataSource，缺点也是显而易见的，需要编写大量的代码，照顾到每个分支。当涉及跨库查询、聚合，需要循环计算结果并合并的场景，工作量巨大。不建议使用该种方案。</p>\n<h3 id=\"1-2-框架层-不推荐\"><a href=\"#1-2-框架层-不推荐\" class=\"headerlink\" title=\"1.2 框架层(不推荐)\"></a>1.2 框架层(不推荐)</h3><p>这种情况适合公司ORM框架统一的情况，修改或增强现有ORM框架的功能，在SQL中增加一些自定义原语或者hint来实现。主要做法是通过实现一些拦截器（比如Mybatis的Interceptor接口），增加一些自定义解析来控制数据的流向，效果虽然较好，但会改变一些现有的编程经验。很多情况要修改框架源码，不推荐。</p>\n<h3 id=\"1-3-驱动层-ShardingJDBC\"><a href=\"#1-3-驱动层-ShardingJDBC\" class=\"headerlink\" title=\"1.3 驱动层(ShardingJDBC)\"></a>1.3 驱动层(ShardingJDBC)</h3><p>基于在编码层和框架层切入的各种缺点，真正的数据库中间件起码要从驱动层开始。重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。</p>\n<p>常用的方案为：TDDL、ShardingJDBC等。</p>\n<p>Mysql Connector/J的Failover协议 (具体指“load balancing”、“replication”、“farbic”等）， 也是直接在驱动上进行修改。</p>\n<p><img src=\"/images/分库分表/驱动层方案.png\" alt=\"驱动层方案\"></p>\n<h3 id=\"1-4-代理层-MyCat\"><a href=\"#1-4-代理层-MyCat\" class=\"headerlink\" title=\"1.4 代理层(MyCat)\"></a>1.4 代理层(MyCat)</h3><p>代理层的数据库中间件，将自己伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。</p>\n<p>常用的方案为：MySQL Router、MyCat等</p>\n<p><img src=\"/images/分库分表/代理层方案.png\" alt=\"代理层方案\"></p>\n<h3 id=\"1-5-实现层-Mysql-Cluster-Galera-Cluster\"><a href=\"#1-5-实现层-Mysql-Cluster-Galera-Cluster\" class=\"headerlink\" title=\"1.5 实现层(Mysql-Cluster,Galera-Cluster)\"></a>1.5 实现层(Mysql-Cluster,Galera-Cluster)</h3><p>SQL特殊版本支持，如Mysql-Cluster本身就支持各种特性，Mariadb-Galera-Cluster支持对等双主，Greenplum支持分片等。</p>\n<h3 id=\"1-6-驱动层与代理层比较\"><a href=\"#1-6-驱动层与代理层比较\" class=\"headerlink\" title=\"1.6 驱动层与代理层比较\"></a>1.6 驱动层与代理层比较</h3><h4 id=\"1-6-1-驱动层的特点\"><a href=\"#1-6-1-驱动层的特点\" class=\"headerlink\" title=\"1.6.1 驱动层的特点\"></a>1.6.1 驱动层的特点</h4><p>1.仅支持JAVA，支持丰富的DB</p>\n<p><img src=\"/images/分库分表/驱动层特点.png\" alt=\"驱动层特点\"></p>\n<p>2.占用较多的数据库连接</p>\n<p>驱动层中间件要维护很多数据库连接。比如一个分了10个 库 的表，每个java中的Connection要维护10个数据库连接。如果项目过多，则会出现连接爆炸。像Postgres这种每个连接对应一个进程的数据库，压力会很大。</p>\n<p>3.数据聚合在业务实例执行</p>\n<p>数据聚合，比如count sum等，是通过多次查询，然后在业务实例的内存中进行聚合。路由表存在于业务方实例内存中，通过轮询或者被动通知的途径更新路由表即可。</p>\n<p>4.集中式管理</p>\n<p>所有集群的配置管理都集中在一个地方，运维负担小，DBA即可完成相关操作。</p>\n<p><strong>驱动层的典型实现</strong></p>\n<p><img src=\"/images/分库分表/驱动层典型实现.png\" alt=\"驱动层典型实现\"></p>\n<h4 id=\"1-6-2-代理层的特点\"><a href=\"#1-6-2-代理层的特点\" class=\"headerlink\" title=\"1.6.2 代理层的特点\"></a>1.6.2 代理层的特点</h4><p>1.异构支持，DB支持有限</p>\n<p>与驱动层相反，代理层中间件仅支持一种后端关系型数据库，但支持多种开发语言。如果你的系统是异构的，并且都有同样的SLA要求，则推荐使用此方案。</p>\n<p><img src=\"/images/分库分表/代理层特点.png\" alt=\"代理层特点\"></p>\n<p>2.运维负担大</p>\n<p>代理层需要维护数据库连接数量有限（MySQL Router那种粘性连接除外）。但作为一个独立的服务，既要考虑单独部署，又要考虑高可用，会增加很多额外节点，更别提用了影子节点的公司了。<br>另外，代理层是请求唯一的入口，稳定性要求极高，一旦有高耗内存的聚合查询把节点搞崩溃了，都是灾难性的事故。</p>\n<p><strong>代理层典型实现</strong></p>\n<p><img src=\"/images/分库分表/代理层典型实现.png\" alt=\"代理层典型实现\"></p>\n<h3 id=\"1-7-使用限制\"><a href=\"#1-7-使用限制\" class=\"headerlink\" title=\"1.7 使用限制\"></a>1.7 使用限制</h3><p>1.确保数据均衡</p>\n<p>拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。</p>\n<p>2.不能深分页</p>\n<p>不带切分键的深分页，会取出所有库所取页数之前的所有数据在内存排序计算。容易造成内存溢出。 </p>\n<p>3.减少子查询</p>\n<p>子查询会造成SQL解析紊乱，解析错误的情况，尽量减少SQL的子查询。</p>\n<p>4.事务最小原则</p>\n<p>尽量缩小单机事务涉及的库范围，即尽可能减少夸库操作，将同类操作的库/表分在一起。</p>\n<p>5.数据均衡原则</p>\n<p>拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。</p>\n<p>6.特殊函数</p>\n<p>distinct、having、union、in、or等，一般不被支持。或者被支持，使用之后会增加风险，需要改造。</p>\n<h2 id=\"2-分库分表中间件\"><a href=\"#2-分库分表中间件\" class=\"headerlink\" title=\"2.分库分表中间件\"></a>2.分库分表中间件</h2><h3 id=\"2-1-活跃中的项目\"><a href=\"#2-1-活跃中的项目\" class=\"headerlink\" title=\"2.1 活跃中的项目\"></a>2.1 活跃中的项目</h3><h4 id=\"2-1-1-活跃-ProxySQL-轻量级\"><a href=\"#2-1-1-活跃-ProxySQL-轻量级\" class=\"headerlink\" title=\"2.1.1 [活跃]-ProxySQL(轻量级)\"></a>2.1.1 [活跃]-ProxySQL(轻量级)</h4><p>ProxySQL是一个可以实现MySQL读写分离的轻量级工具。ProxySQL的特点：将所有配置保存写入到SQLit表中。支持动态加载配置，即一般可以在线修改配置，但有少部分参数还是需要重启来生效。支持query cache。支持对query的路由，可以针对某个语句进行分配去哪个实例执行。故障切换。过滤危险的SQL。不支持分表，可以分库，但是利用规则配置实现分表。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/609710/201706/609710-20170615165724071-1793246218.png\" alt=\"ProxySQL\"></p>\n<p>MHA+ProxySQL实现读写分离高可用：<a href=\"https://www.cnblogs.com/gomysql/p/7018797.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gomysql/p/7018797.html</a></p>\n<p>项目地址: <a href=\"https://github.com/sysown/proxysql\" target=\"_blank\" rel=\"noopener\">https://github.com/sysown/proxysql</a></p>\n<p>官网：<a href=\"https://proxysql.com/\" target=\"_blank\" rel=\"noopener\">https://proxysql.com/</a></p>\n<h4 id=\"2-1-2-活跃-Ctrip-DAL-携程\"><a href=\"#2-1-2-活跃-Ctrip-DAL-携程\" class=\"headerlink\" title=\"2.1.2 [活跃]-Ctrip DAL(携程)\"></a>2.1.2 [活跃]-Ctrip DAL(携程)</h4><p>Ctrip DAL是携程框架部开发的数据库访问框架，支持代码生成和水平扩展。其由携程技术中心框架部DAL团队开发，历经3年不断打磨，并在长期的实际使用中基于大量的用户反馈不断优化。</p>\n<p>Ctrip DAL支持流行的分库分表操作，支持Java和C#，支持Mysql和MS SqlServer。使用该框架可以在有效地保护企业已有数据库投资的同时，迅速，可靠的为企业提供数据库访问层的横向扩展能力。整个框架包括代码生成器和客户端。工作模式是使用代码生成器在线生成代码和配置，通过DAL客户端完成数据库操作。生成器具有丰富的向导指引，操作简单清晰，即可以批量生成标准DAO，也可以在方法级别定制数据库访问。</p>\n<p><img src=\"https://github.com/ctripcorp/dal/raw/master/doc/codegen_work_model.png\" alt=\"Ctrip-DAL\"></p>\n<p>项目地址: <a href=\"https://github.com/ctripcorp/dal\" target=\"_blank\" rel=\"noopener\">https://github.com/ctripcorp/dal</a></p>\n<h4 id=\"2-1-3-活跃-Vitess-Youtube\"><a href=\"#2-1-3-活跃-Vitess-Youtube\" class=\"headerlink\" title=\"2.1.3 [活跃]-Vitess(Youtube)\"></a>2.1.3 [活跃]-Vitess(Youtube)</h4><p>这个中间件是Youtube生产在使用的，但是架构很复杂。 与以往中间件不同，使用Vitess应用改动比较大要 使用他提供语言的API接口，我们可以借鉴他其中的一些设计思想。Vitess 是一个用于 MySql 扩展的数据库解决方案。它以能够像运行在专用硬件上那样有效地运行于云体系。它集 MySql 数据库的很多重要特性和 NoSQL 数据库的可扩展性于一体。Vitess 已经成功侍服了 2011 年以来所有的 YouTube 数据库流量。</p>\n<p><img src=\"https://img-blog.csdn.net/20150826095203562\" alt=\"Vitess\"></p>\n<p>理解VITESS: <a href=\"https://www.cnblogs.com/zhangwushang/p/8523015.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhangwushang/p/8523015.html</a></p>\n<p>官网：<a href=\"https://vitess.io/\" target=\"_blank\" rel=\"noopener\">https://vitess.io/</a></p>\n<p>项目地址：<a href=\"https://github.com/vitessio/vitess\" target=\"_blank\" rel=\"noopener\">https://github.com/vitessio/vitess</a></p>\n<h4 id=\"2-1-4-活跃-Heisenberg-Cobar增强版\"><a href=\"#2-1-4-活跃-Heisenberg-Cobar增强版\" class=\"headerlink\" title=\"2.1.4 [活跃]-Heisenberg(Cobar增强版)\"></a>2.1.4 [活跃]-Heisenberg(Cobar增强版)</h4><p>heisenberg 是百度的熊照同学(id:brucexx)编写的一款基于MySQL协议之上的分库分表中间件服务器，支持各种灵活（velocity脚本自定义）的分库分表规则，做到应用和分库分表相隔离，并且为mysql进行dbproxy,减少了db的连接IO压力，并且可做到读写分离以及replication的手工切换。</p>\n<p>改编自cobar, 结合了cobar和TDDL的优势，让其分片策略变为分库表策略，节约了大量连接，其优点： 分库分表与应用脱离，分库表如同使用单库表一样 减少db 连接数压力 热重启配置 可水平扩容 遵守Mysql原生协议 读写分离 无语言限制，mysqlclient,c,java等都可以使用 Heisenberg服务器通过管理命令可以查看，如连接数，线程池，结点等，并可以调整 采用velocity的分库分表脚本进行自定义分库表，相当的灵活。</p>\n<p><img src=\"http://dl2.iteye.com/upload/attachment/0095/7149/b468edd2-ebdd-3c77-a033-b172909ee46f.jpg\" alt=\"Heisenberg\"></p>\n<p>项目地址: <a href=\"https://github.com/brucexx/heisenberg\" target=\"_blank\" rel=\"noopener\">https://github.com/brucexx/heisenberg</a></p>\n<h4 id=\"2-1-5-活跃-Mycat-Cobar增强版\"><a href=\"#2-1-5-活跃-Mycat-Cobar增强版\" class=\"headerlink\" title=\"2.1.5 [活跃]-Mycat(Cobar增强版)\"></a>2.1.5 [活跃]-Mycat(Cobar增强版)</h4><p>2013 年阿里的 Cobar 在社区使用过程中发现存在一些比较严重的问题，及其使用限制，经过 Mycat 发起人第一次改良，第一代改良版——Mycat 诞生。 Mycat 开源以后，一些 Cobar 的用户参与了 Mycat 的开发，最终 Mycat 发展成为一个由众多软件公司的实力派架构师和资深开发人员维护的社区型开源软件。</p>\n<p><img src=\"http://5b0988e595225.cdn.sohucs.com/images/20180929/fc684917d1cd4292a5d62574699e71fb.jpeg\" alt=\"Mycat\"></p>\n<p>项目地址: <a href=\"https://github.com/MyCATApache/Mycat-Server\" target=\"_blank\" rel=\"noopener\">https://github.com/MyCATApache/Mycat-Server</a></p>\n<p>利用MyCAT实现MySQL的读写分离和主从切换：<a href=\"https://blog.csdn.net/leonpenn/article/details/77278360\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leonpenn/article/details/77278360</a></p>\n<p>官网：<a href=\"http://mycat.io/\" target=\"_blank\" rel=\"noopener\">http://mycat.io/</a></p>\n<p>项目地址：<a href=\"https://github.com/MyCATApache/Mycat-Server\" target=\"_blank\" rel=\"noopener\">https://github.com/MyCATApache/Mycat-Server</a></p>\n<h4 id=\"2-1-6-活跃-Sharding-JDBC-当当\"><a href=\"#2-1-6-活跃-Sharding-JDBC-当当\" class=\"headerlink\" title=\"2.1.6 [活跃]-Sharding-JDBC(当当)\"></a>2.1.6 [活跃]-Sharding-JDBC(当当)</h4><p>Sharding-JDBC是当当应用框架ddframe中,从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架,是继dubbox、elastic-job之后ddframe开源的第三个项目。Sharding-JDBC直接分装jdbc协议,可理解为增强版的JDBC驱动,旧代码迁移成本几乎为零,定位为轻量级java框架,使用客户端直连数据库,以jar包形式提供服务,无proxy层。</p>\n<p><img src=\"http://aliyunzixunbucket.oss-cn-beijing.aliyuncs.com/jpg/0d31edabc368a0bd0013de4cbc444232.jpg\" alt=\"Sharding-JDBC\"></p>\n<p>项目地址: <a href=\"https://github.com/sharding-sphere/sharding-sphere\" target=\"_blank\" rel=\"noopener\">https://github.com/sharding-sphere/sharding-sphere</a></p>\n<h3 id=\"2-2-停滞或未开源的项目\"><a href=\"#2-2-停滞或未开源的项目\" class=\"headerlink\" title=\"2.2 停滞或未开源的项目\"></a>2.2 停滞或未开源的项目</h3><h4 id=\"2-2-1-停滞-kingshard-Go语言\"><a href=\"#2-2-1-停滞-kingshard-Go语言\" class=\"headerlink\" title=\"2.2.1 [停滞]-kingshard(Go语言)\"></a>2.2.1 [停滞]-kingshard(Go语言)</h4><p>一个由Go开发高性能MySQL Proxy项目，kingshard在满足基本的读写分离的功能上，致力于简化MySQL分库分表操作,能够让DBA通过kingshard轻松平滑地实现MySQL数据库扩容。</p>\n<p><img src=\"https://image-static.segmentfault.com/322/105/3221059488-56fe2b2e4e675_articlex\" alt=\"架构图\"></p>\n<p>sharding方式:range方式、hash方式</p>\n<p><strong>分表方案采用两级映射的方式：</strong></p>\n<p>1.kingshard将该表分成512张子表，例如：test_0000,test_0001,…test_511。</p>\n<p>2.将shardKey通过hash或range方式定位到其要操作的记录在哪张子表上。</p>\n<p>3.子表落在哪个node上通过配置文件设置。</p>\n<p><strong>基于kingshard的子表迁移方案:</strong></p>\n<p>1.通过自动数据迁移工具开始数据迁移。</p>\n<p>2.数据差异小于某一临界值，阻塞老子表写操作（read-only）</p>\n<p>3.等待新子表数据同步完毕</p>\n<p>4.更改kingshard配置文件中的对应子表的路由规则。</p>\n<p>5.删除老节点上的子表。</p>\n<p>参考网址: <a href=\"https://segmentfault.com/a/1190000003001545\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000003001545</a></p>\n<p>项目地址: <a href=\"https://github.com/flike/kingshard\" target=\"_blank\" rel=\"noopener\">https://github.com/flike/kingshard</a></p>\n<h4 id=\"2-2-2-停滞-MySQL-Fabric-官方\"><a href=\"#2-2-2-停滞-MySQL-Fabric-官方\" class=\"headerlink\" title=\"2.2.2 [停滞]-MySQL Fabric(官方)\"></a>2.2.2 [停滞]-MySQL Fabric(官方)</h4><p>为了实现和方便管理MySQL 分片以及实现高可用部署，Oracle在2014年5月推出了一套为各方寄予厚望的MySQL产品 – MySQL Fabric, 用来管理MySQL 服务，提供扩展性和容易使用的系统，Fabric当前实现了两个特性：高可用和使用数据分片实现可扩展性和负载均衡，这两个特性能单独使用或结合使用。</p>\n<p><img src=\"http://www.2cto.com/uploadfile/Collfiles/20140823/2014082309170262.jpg\" alt=\"MySQL Fabric\"></p>\n<p>MySQLFabric概述: <a href=\"https://www.cnblogs.com/huaxingtianxia/p/7095193.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/huaxingtianxia/p/7095193.html</a></p>\n<p>MySQL原生HA方案 – Fabric体验之旅: <a href=\"https://www.csdn.net/article/2014-08-20/2821300\" target=\"_blank\" rel=\"noopener\">https://www.csdn.net/article/2014-08-20/2821300</a></p>\n<p>官网: <a href=\"https://downloads.mysql.com/archives/utilities/\" target=\"_blank\" rel=\"noopener\">https://downloads.mysql.com/archives/utilities/</a></p>\n<h4 id=\"2-2-3-停滞-Oceanus-58同城\"><a href=\"#2-2-3-停滞-Oceanus-58同城\" class=\"headerlink\" title=\"2.2.3 [停滞]-Oceanus(58同城)\"></a>2.2.3 [停滞]-Oceanus(58同城)</h4><p>58同城数据库中间件。Oceanus致力于打造一个功能简单、可依赖、易于上手、易于扩展、易于集成的解决方案，甚至是平台化系统。拥抱开源，提供各类插件机制集成其他开源项目，新手可以在几分钟内上手编程，分库分表逻辑不再与业务紧密耦合，扩容有标准模式，减少意外错误的发生。最后更新时间2015年。</p>\n<p>项目地址：<a href=\"https://github.com/58code/Oceanus\" target=\"_blank\" rel=\"noopener\">https://github.com/58code/Oceanus</a></p>\n<p><img src=\"http://dl2.iteye.com/upload/attachment/0106/3405/f18c03c4-ea5b-395a-9ca5-50c4f31e721f.png\" alt=\"oceanus\"></p>\n<h4 id=\"2-2-4-停滞-TSharding-蘑菇街\"><a href=\"#2-2-4-停滞-TSharding-蘑菇街\" class=\"headerlink\" title=\"2.2.4 [停滞]-TSharding(蘑菇街)\"></a>2.2.4 [停滞]-TSharding(蘑菇街)</h4><p>TSharding 是应用于蘑菇街交易平台的一个简易 sharding 组件，也是一个 Mybatis 分库分表组件。</p>\n<p><img src=\"http://static.oschina.net/uploads/space/2016/0817/105311_VhyZ_2720166.png\" alt=\"TSharding\"></p>\n<p>项目地址: <a href=\"https://github.com/baihui212/tsharding\" target=\"_blank\" rel=\"noopener\">https://github.com/baihui212/tsharding</a></p>\n<h4 id=\"2-2-5-未开源-DDB-网易\"><a href=\"#2-2-5-未开源-DDB-网易\" class=\"headerlink\" title=\"2.2.5 [未开源]-DDB(网易)\"></a>2.2.5 [未开源]-DDB(网易)</h4><p>DDB（Distributed database）是网易杭研院立项最早，应用最为广泛的后台产品之一，也是国内最早出现的基于现有database之上开发的分布式数据库中间件，目前依然在为网易易信，云音乐，云阅读等大型互联网产品提供稳定的数据库服务。</p>\n<p><img src=\"http://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhboMzgaQTMiblcE1O5vfEDiaUaFSSTawRvPxUPG1zMrXNwJAWPH0TibQaC8wkicBuib9Nct9fn4D44B1g/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\" alt=\"DDB\"></p>\n<p>网易分库分表数据库DDB：<a href=\"https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg</a></p>\n<h4 id=\"2-2-6-停滞-TDDL-阿里\"><a href=\"#2-2-6-停滞-TDDL-阿里\" class=\"headerlink\" title=\"2.2.6 [停滞]-TDDL(阿里)\"></a>2.2.6 [停滞]-TDDL(阿里)</h4><p>淘宝根据自身业务需求研发了TDDL（Taobao Distributed Data Layer）框架，主要用于解决分库分表场景下的访问路由（持久层与数据访问层的配合）以及异构数据库之间的数据同步，它是一个基于集中式配置的JDBC DataSource实现，具有分库分表、Master/Salve、动态数据源配置等功能。就目前而言，许多大厂也在出一些更加优秀和社区支持更广泛的DAL层产品，比如Hibernate Shards、Ibatis-Sharding等。项目最后一次更新为2012年。</p>\n<p><img src=\"https://img-blog.csdn.net/20160601111503650\" alt=\"TDDL\"></p>\n<p><img src=\"https://img-blog.csdn.net/20160601111544711\" alt=\"TDDL分库分表策略\"></p>\n<p>TDDL：来自淘宝的分布式数据层：<a href=\"https://blog.csdn.net/diu_brother/article/details/51554555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/diu_brother/article/details/51554555</a></p>\n<p>官网: <a href=\"https://github.com/alibaba/tb_tddl\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/tb_tddl</a></p>\n<h4 id=\"2-2-7-未开源-MTDDL-美团点评\"><a href=\"#2-2-7-未开源-MTDDL-美团点评\" class=\"headerlink\" title=\"2.2.7 [未开源]-MTDDL(美团点评)\"></a>2.2.7 [未开源]-MTDDL(美团点评)</h4><p>MTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。</p>\n<p>MTDDL——美团点评分布式数据访问层中间件：<a href=\"https://tech.meituan.com/mtddl.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/mtddl.html</a></p>\n<h4 id=\"2-2-8-停滞-Zebra-美团点评\"><a href=\"#2-2-8-停滞-Zebra-美团点评\" class=\"headerlink\" title=\"2.2.8 [停滞]-Zebra(美团点评)\"></a>2.2.8 [停滞]-Zebra(美团点评)</h4><p>Zebra是美团点评内部使用的数据库访问层中间件，它具有以下的功能点：配置集中管理，动态刷新。支持读写分离、分库分表。丰富的监控信息在CAT上展现</p>\n<p>项目地址: <a href=\"https://github.com/Meituan-Dianping/Zebra\" target=\"_blank\" rel=\"noopener\">https://github.com/Meituan-Dianping/Zebra</a></p>\n<h4 id=\"2-2-9-停滞-Cobar-阿里\"><a href=\"#2-2-9-停滞-Cobar-阿里\" class=\"headerlink\" title=\"2.2.9 [停滞]-Cobar(阿里)\"></a>2.2.9 [停滞]-Cobar(阿里)</h4><p>Cobar是提供分布式数据库服务的中间件，由阿里中间件团队开发，是阿里巴巴B2B前台应用访问数据库的统一入口，Cobar的分布式方案是分库和分表，可以按照业务需求将数据库中耦合度较低的表分到不同的分库中，也可以按照具体表的增长速度和数据量水平切分到不同的分库中，Cobar可以实现应用层与物理分库的双向透明，从而实现应用程序访问分布式数据库与访问单库无差别。 Cobar还可以配合MySQL的心跳和binlog实现备机的自动切换，保证数据节点的可靠性，从而实现高可用性。</p>\n<p><img src=\"https://images0.cnblogs.com/blog/316027/201412/171250029067744.jpg\" alt=\"Cobar\"></p>\n<p>项目地址: <a href=\"https://github.com/alibaba/cobar\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/cobar</a></p>\n<h4 id=\"2-2-10-未开源-OneProxy-代理层\"><a href=\"#2-2-10-未开源-OneProxy-代理层\" class=\"headerlink\" title=\"2.2.10 [未开源]-OneProxy(代理层)\"></a>2.2.10 [未开源]-OneProxy(代理层)</h4><p>OneProxy是由原支付宝首席架构师楼方鑫开发，目前由楼方鑫创立的杭州平民软件公司（@平民架构）提供技术支持。目前已有多家公司在生成环境中使用，其中包括了支付、电商等行业。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/711446/201606/711446-20160620135708787-1432694302.jpg\" alt=\"OneProxy\"></p>\n<p>OneProxy的主要功能有：1. 垂直分库 2. 水平分表 3. Proxy集群 4. 读高可用 5. 读写分离（master不参与读）6. 读写分离（master参与读）7. 写高可用 8. 读写随机</p>\n<p>OneProxy使用手册-致力于打造透明的数据层: <a href=\"https://www.cnblogs.com/youge-OneSQL/articles/4208583.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/youge-OneSQL/articles/4208583.html</a></p>\n<p>官网：<a href=\"http://www.onexsoft.com/\" target=\"_blank\" rel=\"noopener\">http://www.onexsoft.com/</a></p>\n<h3 id=\"2-3-其他数据库项目\"><a href=\"#2-3-其他数据库项目\" class=\"headerlink\" title=\"2.3 其他数据库项目\"></a>2.3 其他数据库项目</h3><h4 id=\"2-3-1-活跃-Greenplum-PostgreSQL\"><a href=\"#2-3-1-活跃-Greenplum-PostgreSQL\" class=\"headerlink\" title=\"2.3.1 [活跃]-Greenplum(PostgreSQL)\"></a>2.3.1 [活跃]-Greenplum(PostgreSQL)</h4><p>GreenPlum建立在PostgreSQL的基础上，把许许多多的PostgreSQL节点组织在一起，实现了一个强大的分布式数据库。集群包括两类角色：master和segment。</p>\n<p>GreenPlum数据库默认会采用Hash Distribution：如果创建表时没有指定Distribution Key，则会选择Primary Key作为Distribution Key。如果Primary Key也不存在，就会选择表的第一列作为Distribution Key。和大多数的分布式系统一样，GreenPlum也支持垂直和水平两种扩容方式，垂直扩容又被称为presharding模式。</p>\n<p><img src=\"https://nos.netease.com/cloud-website-bucket/20180703130100fab02779-312a-465a-ba31-75a275194d70.jpg\" alt=\"Greenplum\"></p>\n<p>【GreenPlum】GreenPlum服务来了!: <a href=\"https://sq.163yun.com/blog/article/172464991000825856\" target=\"_blank\" rel=\"noopener\">https://sq.163yun.com/blog/article/172464991000825856</a></p>\n<p>官网: <a href=\"https://greenplum.org/\" target=\"_blank\" rel=\"noopener\">https://greenplum.org/</a></p>\n<h4 id=\"2-3-2-活跃-MariaDB-Spider-Mariadb\"><a href=\"#2-3-2-活跃-MariaDB-Spider-Mariadb\" class=\"headerlink\" title=\"2.3.2 [活跃]-MariaDB Spider(Mariadb)\"></a>2.3.2 [活跃]-MariaDB Spider(Mariadb)</h4><p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。</p>\n<p>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>Spider是MariaDB内置的一个可插拔用于MariaDB/MySQL数据库分片的存储引擎，充当应用服务器和远程后端DB之间的代理（中间件），它可以轻松实现MySQL的横向和纵向扩展，突破单台MySQL的限制，支持范围分区、列表分区、哈希分区，支持XA分布式事务，支持跨库join。通过Spider，您可以跨多个数据库后端有效访问数据，让您的应用程序一行代码不改，即可轻松实现分库分表！</p>\n<p><img src=\"http://img.mp.itc.cn/upload/20170420/527be525b8294adea707a05822d8d1c0_th.jpeg\" alt=\"MariaDB-Spider\"></p>\n<p>MariaDB Spider：实现MySQL横纵向扩展的小能手: <a href=\"https://www.sohu.com/a/135228509_487514\" target=\"_blank\" rel=\"noopener\">https://www.sohu.com/a/135228509_487514</a></p>\n<p>官网: <a href=\"https://mariadb.com/kb/en/library/spider/\" target=\"_blank\" rel=\"noopener\">https://mariadb.com/kb/en/library/spider/</a></p>\n<h2 id=\"3-扩容方案如何做？\"><a href=\"#3-扩容方案如何做？\" class=\"headerlink\" title=\"3.扩容方案如何做？\"></a>3.扩容方案如何做？</h2><h3 id=\"3-1-水平分库扩展的问题\"><a href=\"#3-1-水平分库扩展的问题\" class=\"headerlink\" title=\"3.1 水平分库扩展的问题\"></a>3.1 水平分库扩展的问题</h3><p>水平分库常用的分库策略是采用取模的方式，对userId或业务ID,当业务快速的发展，用户量数据大量上升，当前容量不足以支撑，就需要对数据库进行水平扩容，再增加新库来分解。新库加入之后，原先sharding到3个库的数据，就可以sharding到4个库里面了。</p>\n<p>不过此时由于分片规则进行了变化(uid%3 变为uid%4)，大部分的数据，无法命中在原有的数据库上了，需要重新分配，大量数据需要迁移。比如之前uid1通过uid1%3 分配在A库上，新加入库D之后，算法改为uid1%4 了，此时有可能就分配在B库上面了。如果你了解过一致性哈希的原理，就会发现新增一个节点，大概会有90%的数据需要迁移，这个对DB同学的压力还是蛮大的，那么如何应对？</p>\n<h3 id=\"3-2-方案一：停服迁移\"><a href=\"#3-2-方案一：停服迁移\" class=\"headerlink\" title=\"3.2 方案一：停服迁移\"></a>3.2 方案一：停服迁移</h3><p>停服迁移是最常见的一种方案了，一般如下流程:1.预估停服时间，发布停服公告。2.停服，通过事先做好的数据迁移工具，按照新的分片规则，进行迁移。3.修改分片规则。4.启动服务。</p>\n<p>缺点：</p>\n<p>1.停服，伤害用户体验，同时也降低了服务器的可用性</p>\n<p>2.必须在制定时间内完成迁移，如果失败，需要择日再次进行。同时增加了开发人员的压力，容易发生大的事故</p>\n<p>3.数据量的巨大的时候，迁移需要大量时间</p>\n<h3 id=\"3-3-方案二：升级从库\"><a href=\"#3-3-方案二：升级从库\" class=\"headerlink\" title=\"3.3 方案二：升级从库\"></a>3.3 方案二：升级从库</h3><p>线上数据库，我们为了保持其高可用，一般都会每台主库配一台从库，读写在主库，然后主从同步到从库。</p>\n<p>升级从库方案步骤：</p>\n<p>1.修改分片配置，做好新库和老库的映射。</p>\n<p>2.同步配置，从库升级为主库</p>\n<p>3.解除主从关系</p>\n<p>4.冗余数据清理</p>\n<p>5.为新的数据节点搭建新的从库</p>\n<p>示意图如下:</p>\n<p><img src=\"/images/分库分表/从库变主库.png\" alt=\"原来的架构\"></p>\n<p><img src=\"/images/分库分表/从库变主库1.png\" alt=\"从库升级主库\"></p>\n<p><img src=\"/images/分库分表/从库变主库2.png\" alt=\"主库添加从库\"></p>\n<h3 id=\"3-4-方案三：双写迁移\"><a href=\"#3-4-方案三：双写迁移\" class=\"headerlink\" title=\"3.4 方案三：双写迁移\"></a>3.4 方案三：双写迁移</h3><p>原理和上述相同，做分裂扩容，只是数据的同步方式不同了</p>\n<p>双写迁移方案步骤：</p>\n<p>1.增加新库写链接</p>\n<p>双写的核心原理，就是对需要扩容的数据库上，增加新库，并对现有的分片上增加写链接，同时写两份数据。因为新库的数据为空，所以数据的CRUD对其没有影响，在上层的逻辑层，还是以老库的数据为主。</p>\n<p>2.新老库数据迁移</p>\n<p>通过工具，把老库的数据迁移到新库里面，此时可以选择同步分裂后的数据（1/2）来同步，也可以全同步，一般建议全同步，最终做数据校检的时候好处理。</p>\n<p>3.数据校检</p>\n<p>按照理想环境情况下，数据迁移之后，因为是双写操作，所以两边的数据是一致的，特别是insert和update，一致性情况很高。但真实环境中会有网络延迟等情况，对于delete情况并不是很理想，此时就需要做好数据校检了，数据校检可以多做几遍，直到数据几乎一致，尽量以旧库的数据为准。</p>\n<p>4.分片配置修改</p>\n<p>数据同步完毕，就可以把新库的分片映射重新处理了，还是按照老库分裂的方式来进行，u之前uid%2=0,变为uid%4=0和uid%4=2的。uid%2=1，变为uid%4=1和uid%4=3的。</p>\n<p>示意图如下：</p>\n<p><img src=\"/images/分库分表/双写迁移.png\" alt=\"双写迁移\"></p>\n<p><img src=\"/images/分库分表/双写迁移1.png\" alt=\"双写迁移1\"></p>\n<p><img src=\"/images/分库分表/双写迁移2.png\" alt=\"双写迁移2\"></p>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><p>分库分表？选型和流程要慎重，否则会失控：<a href=\"https://juejin.im/post/5bf778ef5188251b8a26ed8b\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5bf778ef5188251b8a26ed8b</a></p>\n<p>MySQL分库分表方案: <a href=\"https://www.cnblogs.com/sunny3096/p/8595058.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/sunny3096/p/8595058.html</a></p>\n<p>分布式数据中间件TDDL、Amoeba、Cobar、MyCAT架构比较: <a href=\"https://blog.csdn.net/kobejayandy/article/details/60869530\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kobejayandy/article/details/60869530</a></p>\n<p>假如让你来设计数据库中间件: <a href=\"https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA</a> </p>\n<p>数据库中间件Atlas调研笔记: <a href=\"https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA</a></p>\n<p>数据库中间件TDDL调研笔记: <a href=\"https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w</a></p>\n<p>数据库中间件cobar调研笔记: <a href=\"https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ</a></p>\n<p>mysql-proxy数据库中间件架构: <a href=\"https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ</a></p>\n<p>水平分库如何做到平滑扩展： <a href=\"https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A</a></p>\n<p>mysql中间件研究(Atlas,Cobar,TDDL): <a href=\"https://www.guokr.com/blog/475765/\" target=\"_blank\" rel=\"noopener\">https://www.guokr.com/blog/475765/</a></p>\n<p>mycat分布式mysql中间件（mysql中间件研究): <a href=\"http://songwie.com/articlelist/44\" target=\"_blank\" rel=\"noopener\">http://songwie.com/articlelist/44</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-分库分表方案\"><a href=\"#1-分库分表方案\" class=\"headerlink\" title=\"1.分库分表方案\"></a>1.分库分表方案</h2><p>针对MySQL的分库分表，可以从不同层次切入。常见的切入层有：</p>\n<p>编码层 -》 框架层 -》 驱动层 -》代理层 -》实现层<br>","more":"</p>\n<h3 id=\"1-1-编码层-不推荐\"><a href=\"#1-1-编码层-不推荐\" class=\"headerlink\" title=\"1.1 编码层(不推荐)\"></a>1.1 编码层(不推荐)</h3><p>在代码层面动态切换数据源，例如Spring中的AbstractRoutingDataSource，缺点也是显而易见的，需要编写大量的代码，照顾到每个分支。当涉及跨库查询、聚合，需要循环计算结果并合并的场景，工作量巨大。不建议使用该种方案。</p>\n<h3 id=\"1-2-框架层-不推荐\"><a href=\"#1-2-框架层-不推荐\" class=\"headerlink\" title=\"1.2 框架层(不推荐)\"></a>1.2 框架层(不推荐)</h3><p>这种情况适合公司ORM框架统一的情况，修改或增强现有ORM框架的功能，在SQL中增加一些自定义原语或者hint来实现。主要做法是通过实现一些拦截器（比如Mybatis的Interceptor接口），增加一些自定义解析来控制数据的流向，效果虽然较好，但会改变一些现有的编程经验。很多情况要修改框架源码，不推荐。</p>\n<h3 id=\"1-3-驱动层-ShardingJDBC\"><a href=\"#1-3-驱动层-ShardingJDBC\" class=\"headerlink\" title=\"1.3 驱动层(ShardingJDBC)\"></a>1.3 驱动层(ShardingJDBC)</h3><p>基于在编码层和框架层切入的各种缺点，真正的数据库中间件起码要从驱动层开始。重新编写了一个JDBC的驱动，在内存中维护一个路由列表，然后将请求转发到真正的数据库连接中。</p>\n<p>常用的方案为：TDDL、ShardingJDBC等。</p>\n<p>Mysql Connector/J的Failover协议 (具体指“load balancing”、“replication”、“farbic”等）， 也是直接在驱动上进行修改。</p>\n<p><img src=\"/images/分库分表/驱动层方案.png\" alt=\"驱动层方案\"></p>\n<h3 id=\"1-4-代理层-MyCat\"><a href=\"#1-4-代理层-MyCat\" class=\"headerlink\" title=\"1.4 代理层(MyCat)\"></a>1.4 代理层(MyCat)</h3><p>代理层的数据库中间件，将自己伪装成一个数据库，接受业务端的链接。然后负载业务端的请求，解析或者转发到真正的数据库中。</p>\n<p>常用的方案为：MySQL Router、MyCat等</p>\n<p><img src=\"/images/分库分表/代理层方案.png\" alt=\"代理层方案\"></p>\n<h3 id=\"1-5-实现层-Mysql-Cluster-Galera-Cluster\"><a href=\"#1-5-实现层-Mysql-Cluster-Galera-Cluster\" class=\"headerlink\" title=\"1.5 实现层(Mysql-Cluster,Galera-Cluster)\"></a>1.5 实现层(Mysql-Cluster,Galera-Cluster)</h3><p>SQL特殊版本支持，如Mysql-Cluster本身就支持各种特性，Mariadb-Galera-Cluster支持对等双主，Greenplum支持分片等。</p>\n<h3 id=\"1-6-驱动层与代理层比较\"><a href=\"#1-6-驱动层与代理层比较\" class=\"headerlink\" title=\"1.6 驱动层与代理层比较\"></a>1.6 驱动层与代理层比较</h3><h4 id=\"1-6-1-驱动层的特点\"><a href=\"#1-6-1-驱动层的特点\" class=\"headerlink\" title=\"1.6.1 驱动层的特点\"></a>1.6.1 驱动层的特点</h4><p>1.仅支持JAVA，支持丰富的DB</p>\n<p><img src=\"/images/分库分表/驱动层特点.png\" alt=\"驱动层特点\"></p>\n<p>2.占用较多的数据库连接</p>\n<p>驱动层中间件要维护很多数据库连接。比如一个分了10个 库 的表，每个java中的Connection要维护10个数据库连接。如果项目过多，则会出现连接爆炸。像Postgres这种每个连接对应一个进程的数据库，压力会很大。</p>\n<p>3.数据聚合在业务实例执行</p>\n<p>数据聚合，比如count sum等，是通过多次查询，然后在业务实例的内存中进行聚合。路由表存在于业务方实例内存中，通过轮询或者被动通知的途径更新路由表即可。</p>\n<p>4.集中式管理</p>\n<p>所有集群的配置管理都集中在一个地方，运维负担小，DBA即可完成相关操作。</p>\n<p><strong>驱动层的典型实现</strong></p>\n<p><img src=\"/images/分库分表/驱动层典型实现.png\" alt=\"驱动层典型实现\"></p>\n<h4 id=\"1-6-2-代理层的特点\"><a href=\"#1-6-2-代理层的特点\" class=\"headerlink\" title=\"1.6.2 代理层的特点\"></a>1.6.2 代理层的特点</h4><p>1.异构支持，DB支持有限</p>\n<p>与驱动层相反，代理层中间件仅支持一种后端关系型数据库，但支持多种开发语言。如果你的系统是异构的，并且都有同样的SLA要求，则推荐使用此方案。</p>\n<p><img src=\"/images/分库分表/代理层特点.png\" alt=\"代理层特点\"></p>\n<p>2.运维负担大</p>\n<p>代理层需要维护数据库连接数量有限（MySQL Router那种粘性连接除外）。但作为一个独立的服务，既要考虑单独部署，又要考虑高可用，会增加很多额外节点，更别提用了影子节点的公司了。<br>另外，代理层是请求唯一的入口，稳定性要求极高，一旦有高耗内存的聚合查询把节点搞崩溃了，都是灾难性的事故。</p>\n<p><strong>代理层典型实现</strong></p>\n<p><img src=\"/images/分库分表/代理层典型实现.png\" alt=\"代理层典型实现\"></p>\n<h3 id=\"1-7-使用限制\"><a href=\"#1-7-使用限制\" class=\"headerlink\" title=\"1.7 使用限制\"></a>1.7 使用限制</h3><p>1.确保数据均衡</p>\n<p>拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。</p>\n<p>2.不能深分页</p>\n<p>不带切分键的深分页，会取出所有库所取页数之前的所有数据在内存排序计算。容易造成内存溢出。 </p>\n<p>3.减少子查询</p>\n<p>子查询会造成SQL解析紊乱，解析错误的情况，尽量减少SQL的子查询。</p>\n<p>4.事务最小原则</p>\n<p>尽量缩小单机事务涉及的库范围，即尽可能减少夸库操作，将同类操作的库/表分在一起。</p>\n<p>5.数据均衡原则</p>\n<p>拆分数据库的数据尽量均匀，比如按省份分user库不均匀，按userid取模会比较均匀。</p>\n<p>6.特殊函数</p>\n<p>distinct、having、union、in、or等，一般不被支持。或者被支持，使用之后会增加风险，需要改造。</p>\n<h2 id=\"2-分库分表中间件\"><a href=\"#2-分库分表中间件\" class=\"headerlink\" title=\"2.分库分表中间件\"></a>2.分库分表中间件</h2><h3 id=\"2-1-活跃中的项目\"><a href=\"#2-1-活跃中的项目\" class=\"headerlink\" title=\"2.1 活跃中的项目\"></a>2.1 活跃中的项目</h3><h4 id=\"2-1-1-活跃-ProxySQL-轻量级\"><a href=\"#2-1-1-活跃-ProxySQL-轻量级\" class=\"headerlink\" title=\"2.1.1 [活跃]-ProxySQL(轻量级)\"></a>2.1.1 [活跃]-ProxySQL(轻量级)</h4><p>ProxySQL是一个可以实现MySQL读写分离的轻量级工具。ProxySQL的特点：将所有配置保存写入到SQLit表中。支持动态加载配置，即一般可以在线修改配置，但有少部分参数还是需要重启来生效。支持query cache。支持对query的路由，可以针对某个语句进行分配去哪个实例执行。故障切换。过滤危险的SQL。不支持分表，可以分库，但是利用规则配置实现分表。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/609710/201706/609710-20170615165724071-1793246218.png\" alt=\"ProxySQL\"></p>\n<p>MHA+ProxySQL实现读写分离高可用：<a href=\"https://www.cnblogs.com/gomysql/p/7018797.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gomysql/p/7018797.html</a></p>\n<p>项目地址: <a href=\"https://github.com/sysown/proxysql\" target=\"_blank\" rel=\"noopener\">https://github.com/sysown/proxysql</a></p>\n<p>官网：<a href=\"https://proxysql.com/\" target=\"_blank\" rel=\"noopener\">https://proxysql.com/</a></p>\n<h4 id=\"2-1-2-活跃-Ctrip-DAL-携程\"><a href=\"#2-1-2-活跃-Ctrip-DAL-携程\" class=\"headerlink\" title=\"2.1.2 [活跃]-Ctrip DAL(携程)\"></a>2.1.2 [活跃]-Ctrip DAL(携程)</h4><p>Ctrip DAL是携程框架部开发的数据库访问框架，支持代码生成和水平扩展。其由携程技术中心框架部DAL团队开发，历经3年不断打磨，并在长期的实际使用中基于大量的用户反馈不断优化。</p>\n<p>Ctrip DAL支持流行的分库分表操作，支持Java和C#，支持Mysql和MS SqlServer。使用该框架可以在有效地保护企业已有数据库投资的同时，迅速，可靠的为企业提供数据库访问层的横向扩展能力。整个框架包括代码生成器和客户端。工作模式是使用代码生成器在线生成代码和配置，通过DAL客户端完成数据库操作。生成器具有丰富的向导指引，操作简单清晰，即可以批量生成标准DAO，也可以在方法级别定制数据库访问。</p>\n<p><img src=\"https://github.com/ctripcorp/dal/raw/master/doc/codegen_work_model.png\" alt=\"Ctrip-DAL\"></p>\n<p>项目地址: <a href=\"https://github.com/ctripcorp/dal\" target=\"_blank\" rel=\"noopener\">https://github.com/ctripcorp/dal</a></p>\n<h4 id=\"2-1-3-活跃-Vitess-Youtube\"><a href=\"#2-1-3-活跃-Vitess-Youtube\" class=\"headerlink\" title=\"2.1.3 [活跃]-Vitess(Youtube)\"></a>2.1.3 [活跃]-Vitess(Youtube)</h4><p>这个中间件是Youtube生产在使用的，但是架构很复杂。 与以往中间件不同，使用Vitess应用改动比较大要 使用他提供语言的API接口，我们可以借鉴他其中的一些设计思想。Vitess 是一个用于 MySql 扩展的数据库解决方案。它以能够像运行在专用硬件上那样有效地运行于云体系。它集 MySql 数据库的很多重要特性和 NoSQL 数据库的可扩展性于一体。Vitess 已经成功侍服了 2011 年以来所有的 YouTube 数据库流量。</p>\n<p><img src=\"https://img-blog.csdn.net/20150826095203562\" alt=\"Vitess\"></p>\n<p>理解VITESS: <a href=\"https://www.cnblogs.com/zhangwushang/p/8523015.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhangwushang/p/8523015.html</a></p>\n<p>官网：<a href=\"https://vitess.io/\" target=\"_blank\" rel=\"noopener\">https://vitess.io/</a></p>\n<p>项目地址：<a href=\"https://github.com/vitessio/vitess\" target=\"_blank\" rel=\"noopener\">https://github.com/vitessio/vitess</a></p>\n<h4 id=\"2-1-4-活跃-Heisenberg-Cobar增强版\"><a href=\"#2-1-4-活跃-Heisenberg-Cobar增强版\" class=\"headerlink\" title=\"2.1.4 [活跃]-Heisenberg(Cobar增强版)\"></a>2.1.4 [活跃]-Heisenberg(Cobar增强版)</h4><p>heisenberg 是百度的熊照同学(id:brucexx)编写的一款基于MySQL协议之上的分库分表中间件服务器，支持各种灵活（velocity脚本自定义）的分库分表规则，做到应用和分库分表相隔离，并且为mysql进行dbproxy,减少了db的连接IO压力，并且可做到读写分离以及replication的手工切换。</p>\n<p>改编自cobar, 结合了cobar和TDDL的优势，让其分片策略变为分库表策略，节约了大量连接，其优点： 分库分表与应用脱离，分库表如同使用单库表一样 减少db 连接数压力 热重启配置 可水平扩容 遵守Mysql原生协议 读写分离 无语言限制，mysqlclient,c,java等都可以使用 Heisenberg服务器通过管理命令可以查看，如连接数，线程池，结点等，并可以调整 采用velocity的分库分表脚本进行自定义分库表，相当的灵活。</p>\n<p><img src=\"http://dl2.iteye.com/upload/attachment/0095/7149/b468edd2-ebdd-3c77-a033-b172909ee46f.jpg\" alt=\"Heisenberg\"></p>\n<p>项目地址: <a href=\"https://github.com/brucexx/heisenberg\" target=\"_blank\" rel=\"noopener\">https://github.com/brucexx/heisenberg</a></p>\n<h4 id=\"2-1-5-活跃-Mycat-Cobar增强版\"><a href=\"#2-1-5-活跃-Mycat-Cobar增强版\" class=\"headerlink\" title=\"2.1.5 [活跃]-Mycat(Cobar增强版)\"></a>2.1.5 [活跃]-Mycat(Cobar增强版)</h4><p>2013 年阿里的 Cobar 在社区使用过程中发现存在一些比较严重的问题，及其使用限制，经过 Mycat 发起人第一次改良，第一代改良版——Mycat 诞生。 Mycat 开源以后，一些 Cobar 的用户参与了 Mycat 的开发，最终 Mycat 发展成为一个由众多软件公司的实力派架构师和资深开发人员维护的社区型开源软件。</p>\n<p><img src=\"http://5b0988e595225.cdn.sohucs.com/images/20180929/fc684917d1cd4292a5d62574699e71fb.jpeg\" alt=\"Mycat\"></p>\n<p>项目地址: <a href=\"https://github.com/MyCATApache/Mycat-Server\" target=\"_blank\" rel=\"noopener\">https://github.com/MyCATApache/Mycat-Server</a></p>\n<p>利用MyCAT实现MySQL的读写分离和主从切换：<a href=\"https://blog.csdn.net/leonpenn/article/details/77278360\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/leonpenn/article/details/77278360</a></p>\n<p>官网：<a href=\"http://mycat.io/\" target=\"_blank\" rel=\"noopener\">http://mycat.io/</a></p>\n<p>项目地址：<a href=\"https://github.com/MyCATApache/Mycat-Server\" target=\"_blank\" rel=\"noopener\">https://github.com/MyCATApache/Mycat-Server</a></p>\n<h4 id=\"2-1-6-活跃-Sharding-JDBC-当当\"><a href=\"#2-1-6-活跃-Sharding-JDBC-当当\" class=\"headerlink\" title=\"2.1.6 [活跃]-Sharding-JDBC(当当)\"></a>2.1.6 [活跃]-Sharding-JDBC(当当)</h4><p>Sharding-JDBC是当当应用框架ddframe中,从关系型数据库模块dd-rdb中分离出来的数据库水平分片框架,是继dubbox、elastic-job之后ddframe开源的第三个项目。Sharding-JDBC直接分装jdbc协议,可理解为增强版的JDBC驱动,旧代码迁移成本几乎为零,定位为轻量级java框架,使用客户端直连数据库,以jar包形式提供服务,无proxy层。</p>\n<p><img src=\"http://aliyunzixunbucket.oss-cn-beijing.aliyuncs.com/jpg/0d31edabc368a0bd0013de4cbc444232.jpg\" alt=\"Sharding-JDBC\"></p>\n<p>项目地址: <a href=\"https://github.com/sharding-sphere/sharding-sphere\" target=\"_blank\" rel=\"noopener\">https://github.com/sharding-sphere/sharding-sphere</a></p>\n<h3 id=\"2-2-停滞或未开源的项目\"><a href=\"#2-2-停滞或未开源的项目\" class=\"headerlink\" title=\"2.2 停滞或未开源的项目\"></a>2.2 停滞或未开源的项目</h3><h4 id=\"2-2-1-停滞-kingshard-Go语言\"><a href=\"#2-2-1-停滞-kingshard-Go语言\" class=\"headerlink\" title=\"2.2.1 [停滞]-kingshard(Go语言)\"></a>2.2.1 [停滞]-kingshard(Go语言)</h4><p>一个由Go开发高性能MySQL Proxy项目，kingshard在满足基本的读写分离的功能上，致力于简化MySQL分库分表操作,能够让DBA通过kingshard轻松平滑地实现MySQL数据库扩容。</p>\n<p><img src=\"https://image-static.segmentfault.com/322/105/3221059488-56fe2b2e4e675_articlex\" alt=\"架构图\"></p>\n<p>sharding方式:range方式、hash方式</p>\n<p><strong>分表方案采用两级映射的方式：</strong></p>\n<p>1.kingshard将该表分成512张子表，例如：test_0000,test_0001,…test_511。</p>\n<p>2.将shardKey通过hash或range方式定位到其要操作的记录在哪张子表上。</p>\n<p>3.子表落在哪个node上通过配置文件设置。</p>\n<p><strong>基于kingshard的子表迁移方案:</strong></p>\n<p>1.通过自动数据迁移工具开始数据迁移。</p>\n<p>2.数据差异小于某一临界值，阻塞老子表写操作（read-only）</p>\n<p>3.等待新子表数据同步完毕</p>\n<p>4.更改kingshard配置文件中的对应子表的路由规则。</p>\n<p>5.删除老节点上的子表。</p>\n<p>参考网址: <a href=\"https://segmentfault.com/a/1190000003001545\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/a/1190000003001545</a></p>\n<p>项目地址: <a href=\"https://github.com/flike/kingshard\" target=\"_blank\" rel=\"noopener\">https://github.com/flike/kingshard</a></p>\n<h4 id=\"2-2-2-停滞-MySQL-Fabric-官方\"><a href=\"#2-2-2-停滞-MySQL-Fabric-官方\" class=\"headerlink\" title=\"2.2.2 [停滞]-MySQL Fabric(官方)\"></a>2.2.2 [停滞]-MySQL Fabric(官方)</h4><p>为了实现和方便管理MySQL 分片以及实现高可用部署，Oracle在2014年5月推出了一套为各方寄予厚望的MySQL产品 – MySQL Fabric, 用来管理MySQL 服务，提供扩展性和容易使用的系统，Fabric当前实现了两个特性：高可用和使用数据分片实现可扩展性和负载均衡，这两个特性能单独使用或结合使用。</p>\n<p><img src=\"http://www.2cto.com/uploadfile/Collfiles/20140823/2014082309170262.jpg\" alt=\"MySQL Fabric\"></p>\n<p>MySQLFabric概述: <a href=\"https://www.cnblogs.com/huaxingtianxia/p/7095193.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/huaxingtianxia/p/7095193.html</a></p>\n<p>MySQL原生HA方案 – Fabric体验之旅: <a href=\"https://www.csdn.net/article/2014-08-20/2821300\" target=\"_blank\" rel=\"noopener\">https://www.csdn.net/article/2014-08-20/2821300</a></p>\n<p>官网: <a href=\"https://downloads.mysql.com/archives/utilities/\" target=\"_blank\" rel=\"noopener\">https://downloads.mysql.com/archives/utilities/</a></p>\n<h4 id=\"2-2-3-停滞-Oceanus-58同城\"><a href=\"#2-2-3-停滞-Oceanus-58同城\" class=\"headerlink\" title=\"2.2.3 [停滞]-Oceanus(58同城)\"></a>2.2.3 [停滞]-Oceanus(58同城)</h4><p>58同城数据库中间件。Oceanus致力于打造一个功能简单、可依赖、易于上手、易于扩展、易于集成的解决方案，甚至是平台化系统。拥抱开源，提供各类插件机制集成其他开源项目，新手可以在几分钟内上手编程，分库分表逻辑不再与业务紧密耦合，扩容有标准模式，减少意外错误的发生。最后更新时间2015年。</p>\n<p>项目地址：<a href=\"https://github.com/58code/Oceanus\" target=\"_blank\" rel=\"noopener\">https://github.com/58code/Oceanus</a></p>\n<p><img src=\"http://dl2.iteye.com/upload/attachment/0106/3405/f18c03c4-ea5b-395a-9ca5-50c4f31e721f.png\" alt=\"oceanus\"></p>\n<h4 id=\"2-2-4-停滞-TSharding-蘑菇街\"><a href=\"#2-2-4-停滞-TSharding-蘑菇街\" class=\"headerlink\" title=\"2.2.4 [停滞]-TSharding(蘑菇街)\"></a>2.2.4 [停滞]-TSharding(蘑菇街)</h4><p>TSharding 是应用于蘑菇街交易平台的一个简易 sharding 组件，也是一个 Mybatis 分库分表组件。</p>\n<p><img src=\"http://static.oschina.net/uploads/space/2016/0817/105311_VhyZ_2720166.png\" alt=\"TSharding\"></p>\n<p>项目地址: <a href=\"https://github.com/baihui212/tsharding\" target=\"_blank\" rel=\"noopener\">https://github.com/baihui212/tsharding</a></p>\n<h4 id=\"2-2-5-未开源-DDB-网易\"><a href=\"#2-2-5-未开源-DDB-网易\" class=\"headerlink\" title=\"2.2.5 [未开源]-DDB(网易)\"></a>2.2.5 [未开源]-DDB(网易)</h4><p>DDB（Distributed database）是网易杭研院立项最早，应用最为广泛的后台产品之一，也是国内最早出现的基于现有database之上开发的分布式数据库中间件，目前依然在为网易易信，云音乐，云阅读等大型互联网产品提供稳定的数据库服务。</p>\n<p><img src=\"http://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhboMzgaQTMiblcE1O5vfEDiaUaFSSTawRvPxUPG1zMrXNwJAWPH0TibQaC8wkicBuib9Nct9fn4D44B1g/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1\" alt=\"DDB\"></p>\n<p>网易分库分表数据库DDB：<a href=\"https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/D03pO_wwPyjKpSK6BQIoJg</a></p>\n<h4 id=\"2-2-6-停滞-TDDL-阿里\"><a href=\"#2-2-6-停滞-TDDL-阿里\" class=\"headerlink\" title=\"2.2.6 [停滞]-TDDL(阿里)\"></a>2.2.6 [停滞]-TDDL(阿里)</h4><p>淘宝根据自身业务需求研发了TDDL（Taobao Distributed Data Layer）框架，主要用于解决分库分表场景下的访问路由（持久层与数据访问层的配合）以及异构数据库之间的数据同步，它是一个基于集中式配置的JDBC DataSource实现，具有分库分表、Master/Salve、动态数据源配置等功能。就目前而言，许多大厂也在出一些更加优秀和社区支持更广泛的DAL层产品，比如Hibernate Shards、Ibatis-Sharding等。项目最后一次更新为2012年。</p>\n<p><img src=\"https://img-blog.csdn.net/20160601111503650\" alt=\"TDDL\"></p>\n<p><img src=\"https://img-blog.csdn.net/20160601111544711\" alt=\"TDDL分库分表策略\"></p>\n<p>TDDL：来自淘宝的分布式数据层：<a href=\"https://blog.csdn.net/diu_brother/article/details/51554555\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/diu_brother/article/details/51554555</a></p>\n<p>官网: <a href=\"https://github.com/alibaba/tb_tddl\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/tb_tddl</a></p>\n<h4 id=\"2-2-7-未开源-MTDDL-美团点评\"><a href=\"#2-2-7-未开源-MTDDL-美团点评\" class=\"headerlink\" title=\"2.2.7 [未开源]-MTDDL(美团点评)\"></a>2.2.7 [未开源]-MTDDL(美团点评)</h4><p>MTDDL（Meituan Distributed Data Layer），美团点评分布式数据访问层中间件，旨在为全公司提供一个通用数据访问层服务，支持MySQL动态数据源、读写分离、分布式唯一主键生成器、分库分表、动态化配置等功能，并且支持从客户端角度对数据源的各方面（比如连接池、SQL等）进行监控，后续考虑支持NoSQL、Cache等多种数据源。</p>\n<p>MTDDL——美团点评分布式数据访问层中间件：<a href=\"https://tech.meituan.com/mtddl.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/mtddl.html</a></p>\n<h4 id=\"2-2-8-停滞-Zebra-美团点评\"><a href=\"#2-2-8-停滞-Zebra-美团点评\" class=\"headerlink\" title=\"2.2.8 [停滞]-Zebra(美团点评)\"></a>2.2.8 [停滞]-Zebra(美团点评)</h4><p>Zebra是美团点评内部使用的数据库访问层中间件，它具有以下的功能点：配置集中管理，动态刷新。支持读写分离、分库分表。丰富的监控信息在CAT上展现</p>\n<p>项目地址: <a href=\"https://github.com/Meituan-Dianping/Zebra\" target=\"_blank\" rel=\"noopener\">https://github.com/Meituan-Dianping/Zebra</a></p>\n<h4 id=\"2-2-9-停滞-Cobar-阿里\"><a href=\"#2-2-9-停滞-Cobar-阿里\" class=\"headerlink\" title=\"2.2.9 [停滞]-Cobar(阿里)\"></a>2.2.9 [停滞]-Cobar(阿里)</h4><p>Cobar是提供分布式数据库服务的中间件，由阿里中间件团队开发，是阿里巴巴B2B前台应用访问数据库的统一入口，Cobar的分布式方案是分库和分表，可以按照业务需求将数据库中耦合度较低的表分到不同的分库中，也可以按照具体表的增长速度和数据量水平切分到不同的分库中，Cobar可以实现应用层与物理分库的双向透明，从而实现应用程序访问分布式数据库与访问单库无差别。 Cobar还可以配合MySQL的心跳和binlog实现备机的自动切换，保证数据节点的可靠性，从而实现高可用性。</p>\n<p><img src=\"https://images0.cnblogs.com/blog/316027/201412/171250029067744.jpg\" alt=\"Cobar\"></p>\n<p>项目地址: <a href=\"https://github.com/alibaba/cobar\" target=\"_blank\" rel=\"noopener\">https://github.com/alibaba/cobar</a></p>\n<h4 id=\"2-2-10-未开源-OneProxy-代理层\"><a href=\"#2-2-10-未开源-OneProxy-代理层\" class=\"headerlink\" title=\"2.2.10 [未开源]-OneProxy(代理层)\"></a>2.2.10 [未开源]-OneProxy(代理层)</h4><p>OneProxy是由原支付宝首席架构师楼方鑫开发，目前由楼方鑫创立的杭州平民软件公司（@平民架构）提供技术支持。目前已有多家公司在生成环境中使用，其中包括了支付、电商等行业。</p>\n<p><img src=\"https://images2015.cnblogs.com/blog/711446/201606/711446-20160620135708787-1432694302.jpg\" alt=\"OneProxy\"></p>\n<p>OneProxy的主要功能有：1. 垂直分库 2. 水平分表 3. Proxy集群 4. 读高可用 5. 读写分离（master不参与读）6. 读写分离（master参与读）7. 写高可用 8. 读写随机</p>\n<p>OneProxy使用手册-致力于打造透明的数据层: <a href=\"https://www.cnblogs.com/youge-OneSQL/articles/4208583.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/youge-OneSQL/articles/4208583.html</a></p>\n<p>官网：<a href=\"http://www.onexsoft.com/\" target=\"_blank\" rel=\"noopener\">http://www.onexsoft.com/</a></p>\n<h3 id=\"2-3-其他数据库项目\"><a href=\"#2-3-其他数据库项目\" class=\"headerlink\" title=\"2.3 其他数据库项目\"></a>2.3 其他数据库项目</h3><h4 id=\"2-3-1-活跃-Greenplum-PostgreSQL\"><a href=\"#2-3-1-活跃-Greenplum-PostgreSQL\" class=\"headerlink\" title=\"2.3.1 [活跃]-Greenplum(PostgreSQL)\"></a>2.3.1 [活跃]-Greenplum(PostgreSQL)</h4><p>GreenPlum建立在PostgreSQL的基础上，把许许多多的PostgreSQL节点组织在一起，实现了一个强大的分布式数据库。集群包括两类角色：master和segment。</p>\n<p>GreenPlum数据库默认会采用Hash Distribution：如果创建表时没有指定Distribution Key，则会选择Primary Key作为Distribution Key。如果Primary Key也不存在，就会选择表的第一列作为Distribution Key。和大多数的分布式系统一样，GreenPlum也支持垂直和水平两种扩容方式，垂直扩容又被称为presharding模式。</p>\n<p><img src=\"https://nos.netease.com/cloud-website-bucket/20180703130100fab02779-312a-465a-ba31-75a275194d70.jpg\" alt=\"Greenplum\"></p>\n<p>【GreenPlum】GreenPlum服务来了!: <a href=\"https://sq.163yun.com/blog/article/172464991000825856\" target=\"_blank\" rel=\"noopener\">https://sq.163yun.com/blog/article/172464991000825856</a></p>\n<p>官网: <a href=\"https://greenplum.org/\" target=\"_blank\" rel=\"noopener\">https://greenplum.org/</a></p>\n<h4 id=\"2-3-2-活跃-MariaDB-Spider-Mariadb\"><a href=\"#2-3-2-活跃-MariaDB-Spider-Mariadb\" class=\"headerlink\" title=\"2.3.2 [活跃]-MariaDB Spider(Mariadb)\"></a>2.3.2 [活跃]-MariaDB Spider(Mariadb)</h4><p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。</p>\n<p>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>Spider是MariaDB内置的一个可插拔用于MariaDB/MySQL数据库分片的存储引擎，充当应用服务器和远程后端DB之间的代理（中间件），它可以轻松实现MySQL的横向和纵向扩展，突破单台MySQL的限制，支持范围分区、列表分区、哈希分区，支持XA分布式事务，支持跨库join。通过Spider，您可以跨多个数据库后端有效访问数据，让您的应用程序一行代码不改，即可轻松实现分库分表！</p>\n<p><img src=\"http://img.mp.itc.cn/upload/20170420/527be525b8294adea707a05822d8d1c0_th.jpeg\" alt=\"MariaDB-Spider\"></p>\n<p>MariaDB Spider：实现MySQL横纵向扩展的小能手: <a href=\"https://www.sohu.com/a/135228509_487514\" target=\"_blank\" rel=\"noopener\">https://www.sohu.com/a/135228509_487514</a></p>\n<p>官网: <a href=\"https://mariadb.com/kb/en/library/spider/\" target=\"_blank\" rel=\"noopener\">https://mariadb.com/kb/en/library/spider/</a></p>\n<h2 id=\"3-扩容方案如何做？\"><a href=\"#3-扩容方案如何做？\" class=\"headerlink\" title=\"3.扩容方案如何做？\"></a>3.扩容方案如何做？</h2><h3 id=\"3-1-水平分库扩展的问题\"><a href=\"#3-1-水平分库扩展的问题\" class=\"headerlink\" title=\"3.1 水平分库扩展的问题\"></a>3.1 水平分库扩展的问题</h3><p>水平分库常用的分库策略是采用取模的方式，对userId或业务ID,当业务快速的发展，用户量数据大量上升，当前容量不足以支撑，就需要对数据库进行水平扩容，再增加新库来分解。新库加入之后，原先sharding到3个库的数据，就可以sharding到4个库里面了。</p>\n<p>不过此时由于分片规则进行了变化(uid%3 变为uid%4)，大部分的数据，无法命中在原有的数据库上了，需要重新分配，大量数据需要迁移。比如之前uid1通过uid1%3 分配在A库上，新加入库D之后，算法改为uid1%4 了，此时有可能就分配在B库上面了。如果你了解过一致性哈希的原理，就会发现新增一个节点，大概会有90%的数据需要迁移，这个对DB同学的压力还是蛮大的，那么如何应对？</p>\n<h3 id=\"3-2-方案一：停服迁移\"><a href=\"#3-2-方案一：停服迁移\" class=\"headerlink\" title=\"3.2 方案一：停服迁移\"></a>3.2 方案一：停服迁移</h3><p>停服迁移是最常见的一种方案了，一般如下流程:1.预估停服时间，发布停服公告。2.停服，通过事先做好的数据迁移工具，按照新的分片规则，进行迁移。3.修改分片规则。4.启动服务。</p>\n<p>缺点：</p>\n<p>1.停服，伤害用户体验，同时也降低了服务器的可用性</p>\n<p>2.必须在制定时间内完成迁移，如果失败，需要择日再次进行。同时增加了开发人员的压力，容易发生大的事故</p>\n<p>3.数据量的巨大的时候，迁移需要大量时间</p>\n<h3 id=\"3-3-方案二：升级从库\"><a href=\"#3-3-方案二：升级从库\" class=\"headerlink\" title=\"3.3 方案二：升级从库\"></a>3.3 方案二：升级从库</h3><p>线上数据库，我们为了保持其高可用，一般都会每台主库配一台从库，读写在主库，然后主从同步到从库。</p>\n<p>升级从库方案步骤：</p>\n<p>1.修改分片配置，做好新库和老库的映射。</p>\n<p>2.同步配置，从库升级为主库</p>\n<p>3.解除主从关系</p>\n<p>4.冗余数据清理</p>\n<p>5.为新的数据节点搭建新的从库</p>\n<p>示意图如下:</p>\n<p><img src=\"/images/分库分表/从库变主库.png\" alt=\"原来的架构\"></p>\n<p><img src=\"/images/分库分表/从库变主库1.png\" alt=\"从库升级主库\"></p>\n<p><img src=\"/images/分库分表/从库变主库2.png\" alt=\"主库添加从库\"></p>\n<h3 id=\"3-4-方案三：双写迁移\"><a href=\"#3-4-方案三：双写迁移\" class=\"headerlink\" title=\"3.4 方案三：双写迁移\"></a>3.4 方案三：双写迁移</h3><p>原理和上述相同，做分裂扩容，只是数据的同步方式不同了</p>\n<p>双写迁移方案步骤：</p>\n<p>1.增加新库写链接</p>\n<p>双写的核心原理，就是对需要扩容的数据库上，增加新库，并对现有的分片上增加写链接，同时写两份数据。因为新库的数据为空，所以数据的CRUD对其没有影响，在上层的逻辑层，还是以老库的数据为主。</p>\n<p>2.新老库数据迁移</p>\n<p>通过工具，把老库的数据迁移到新库里面，此时可以选择同步分裂后的数据（1/2）来同步，也可以全同步，一般建议全同步，最终做数据校检的时候好处理。</p>\n<p>3.数据校检</p>\n<p>按照理想环境情况下，数据迁移之后，因为是双写操作，所以两边的数据是一致的，特别是insert和update，一致性情况很高。但真实环境中会有网络延迟等情况，对于delete情况并不是很理想，此时就需要做好数据校检了，数据校检可以多做几遍，直到数据几乎一致，尽量以旧库的数据为准。</p>\n<p>4.分片配置修改</p>\n<p>数据同步完毕，就可以把新库的分片映射重新处理了，还是按照老库分裂的方式来进行，u之前uid%2=0,变为uid%4=0和uid%4=2的。uid%2=1，变为uid%4=1和uid%4=3的。</p>\n<p>示意图如下：</p>\n<p><img src=\"/images/分库分表/双写迁移.png\" alt=\"双写迁移\"></p>\n<p><img src=\"/images/分库分表/双写迁移1.png\" alt=\"双写迁移1\"></p>\n<p><img src=\"/images/分库分表/双写迁移2.png\" alt=\"双写迁移2\"></p>\n<h2 id=\"4-参考资料\"><a href=\"#4-参考资料\" class=\"headerlink\" title=\"4.参考资料\"></a>4.参考资料</h2><p>分库分表？选型和流程要慎重，否则会失控：<a href=\"https://juejin.im/post/5bf778ef5188251b8a26ed8b\" target=\"_blank\" rel=\"noopener\">https://juejin.im/post/5bf778ef5188251b8a26ed8b</a></p>\n<p>MySQL分库分表方案: <a href=\"https://www.cnblogs.com/sunny3096/p/8595058.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/sunny3096/p/8595058.html</a></p>\n<p>分布式数据中间件TDDL、Amoeba、Cobar、MyCAT架构比较: <a href=\"https://blog.csdn.net/kobejayandy/article/details/60869530\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/kobejayandy/article/details/60869530</a></p>\n<p>假如让你来设计数据库中间件: <a href=\"https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/6kuVgdO7RBs9gs229wG3wA</a> </p>\n<p>数据库中间件Atlas调研笔记: <a href=\"https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/31WOensXaLdaAp9WRMW7PA</a></p>\n<p>数据库中间件TDDL调研笔记: <a href=\"https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/dVGSvUR9UCA-dIYVtr_G_w</a></p>\n<p>数据库中间件cobar调研笔记: <a href=\"https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/nfTKSTpCvNcvNFAdl2J7mQ</a></p>\n<p>mysql-proxy数据库中间件架构: <a href=\"https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/Ozqu2A7Sy_TGKkF6yF1rDQ</a></p>\n<p>水平分库如何做到平滑扩展： <a href=\"https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/mOh_PCVW68JCVSd19CGZ0A</a></p>\n<p>mysql中间件研究(Atlas,Cobar,TDDL): <a href=\"https://www.guokr.com/blog/475765/\" target=\"_blank\" rel=\"noopener\">https://www.guokr.com/blog/475765/</a></p>\n<p>mycat分布式mysql中间件（mysql中间件研究): <a href=\"http://songwie.com/articlelist/44\" target=\"_blank\" rel=\"noopener\">http://songwie.com/articlelist/44</a></p>"},{"layout":"lay_post","title":"分布式事务实现方案","date":"2018-12-04T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. 前言\n\n由集中式应用到分布式应用的转变，带来了诸多的变化，虽然分布式应用解决了单体应用复杂性高、可靠性差、扩展能力受限等诸多问题，但原来在单体应用中容易实现的特性，在分布式应用中不再那么轻松实现，比如事务，锁等场景。这带来了很大的挑战。通过不断的探索，每种问题都有不同程度的解决方案。\n<!--more-->\n\n>分布式系统文章集合：\n\n**消息中间件(解耦利器)**\n\n**分布式锁**\n\n**[分布式事务](/2018/12/05/2018-12-05-分布式事务实现方案)**\n\n**分布式一致性**\n\n**分布式存储**\n\n**分布式Session**\n\n**分布式计算**\n\n**分布式调度**\n\n## 2. 分布式事务的挑战\n\n事务是提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。\n\n### 2.1 数据库事务的特性\n\nACID 指数据库事务正确执行的四个基本特性的缩写，包含：\n\n**原子性(Atomicity)**：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。\n\n**一致性(Consistency)**：在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。\n\n**隔离性(Isolation)**：数据库允许多个并发事务同时对数据进行读写和修改的能力，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。**隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。**\n\n**持久性(Durability)**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\n在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。\n\n### 2.2 JTA & JTS & Spring事务\n\n### 2.3 分布式事务\n\n分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。有很多用例会跨多个子系统才能完成，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种跨系统的事务为分布式事务。\n\n## 3. 参考资料\n\n阿里分布式事务框架 GTS 全解析\nhttps://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg\n\n深入理解「分布式事务」\nhttps://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg\n\n还不理解“分布式事务”？这篇给你讲清楚：\nhttp://developer.51cto.com/art/201812/588511.htm\n\nJTA 深度历险 - 原理与实现：\nhttp://www.cnblogs.com/firstdream/p/8514222.html\n\n分布式系统核心问题(一致性)：\nhttps://blog.csdn.net/zyhlwzy/article/details/78658002\n\nCAP原则(CAP定理)、BASE理论: \nhttp://www.cnblogs.com/duanxz/p/5229352.html\n\nRocketMQ分布式消息队列设计: \nhttp://rocketmq.apache.org/docs/quick-start/\n\n=====\n\nJava常用类（一）之Object类详解\nhttps://www.cnblogs.com/zhangyinhua/p/7715486.html\n\n\njava-并发-ConcurrentHashMap高并发机制-jdk1.6\nhttps://blog.csdn.net/jianghuxiaojin/article/details/52006110\n\n\nJava并发编程总结4——ConcurrentHashMap在jdk1.8中的改进 \nhttp://www.cnblogs.com/everSeeker/p/5601861.html\n\n\n重入锁：ReentrantLock 详解\nhttps://blog.csdn.net/Somhu/article/details/78874634\n\n\nJava中Unsafe类详解\nhttps://www.cnblogs.com/thomas12112406/p/6510787.html\nhttps://www.cnblogs.com/throwable/p/9139947.html\n\nJava魔法类：sun.misc.Unsafe\nhttps://www.cnblogs.com/suxuan/p/4948608.html\n\n\n红黑树(一)之 原理和算法详细介绍\nhttps://www.cnblogs.com/skywang12345/p/3245399.html","source":"_posts/2018-12-05-分布式事务实现方案.md","raw":"---\nlayout: lay_post\ntitle: \"分布式事务实现方案\"\ndate: 2018-12-05\ncategories: 分布式\ntags: [分布式事务]\nauthor: lvyafei\n---\n\n## 1. 前言\n\n由集中式应用到分布式应用的转变，带来了诸多的变化，虽然分布式应用解决了单体应用复杂性高、可靠性差、扩展能力受限等诸多问题，但原来在单体应用中容易实现的特性，在分布式应用中不再那么轻松实现，比如事务，锁等场景。这带来了很大的挑战。通过不断的探索，每种问题都有不同程度的解决方案。\n<!--more-->\n\n>分布式系统文章集合：\n\n**消息中间件(解耦利器)**\n\n**分布式锁**\n\n**[分布式事务](/2018/12/05/2018-12-05-分布式事务实现方案)**\n\n**分布式一致性**\n\n**分布式存储**\n\n**分布式Session**\n\n**分布式计算**\n\n**分布式调度**\n\n## 2. 分布式事务的挑战\n\n事务是提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。\n\n### 2.1 数据库事务的特性\n\nACID 指数据库事务正确执行的四个基本特性的缩写，包含：\n\n**原子性(Atomicity)**：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。\n\n**一致性(Consistency)**：在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。\n\n**隔离性(Isolation)**：数据库允许多个并发事务同时对数据进行读写和修改的能力，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。**隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。**\n\n**持久性(Durability)**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。\n\n在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。\n\n### 2.2 JTA & JTS & Spring事务\n\n### 2.3 分布式事务\n\n分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。有很多用例会跨多个子系统才能完成，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种跨系统的事务为分布式事务。\n\n## 3. 参考资料\n\n阿里分布式事务框架 GTS 全解析\nhttps://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg\n\n深入理解「分布式事务」\nhttps://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg\n\n还不理解“分布式事务”？这篇给你讲清楚：\nhttp://developer.51cto.com/art/201812/588511.htm\n\nJTA 深度历险 - 原理与实现：\nhttp://www.cnblogs.com/firstdream/p/8514222.html\n\n分布式系统核心问题(一致性)：\nhttps://blog.csdn.net/zyhlwzy/article/details/78658002\n\nCAP原则(CAP定理)、BASE理论: \nhttp://www.cnblogs.com/duanxz/p/5229352.html\n\nRocketMQ分布式消息队列设计: \nhttp://rocketmq.apache.org/docs/quick-start/\n\n=====\n\nJava常用类（一）之Object类详解\nhttps://www.cnblogs.com/zhangyinhua/p/7715486.html\n\n\njava-并发-ConcurrentHashMap高并发机制-jdk1.6\nhttps://blog.csdn.net/jianghuxiaojin/article/details/52006110\n\n\nJava并发编程总结4——ConcurrentHashMap在jdk1.8中的改进 \nhttp://www.cnblogs.com/everSeeker/p/5601861.html\n\n\n重入锁：ReentrantLock 详解\nhttps://blog.csdn.net/Somhu/article/details/78874634\n\n\nJava中Unsafe类详解\nhttps://www.cnblogs.com/thomas12112406/p/6510787.html\nhttps://www.cnblogs.com/throwable/p/9139947.html\n\nJava魔法类：sun.misc.Unsafe\nhttps://www.cnblogs.com/suxuan/p/4948608.html\n\n\n红黑树(一)之 原理和算法详细介绍\nhttps://www.cnblogs.com/skywang12345/p/3245399.html","slug":"2018-12-05-分布式事务实现方案","published":1,"updated":"2019-02-25T14:16:48.058Z","comments":1,"photos":[],"link":"","_id":"cjskffogd006p4glmvjahk904","content":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>由集中式应用到分布式应用的转变，带来了诸多的变化，虽然分布式应用解决了单体应用复杂性高、可靠性差、扩展能力受限等诸多问题，但原来在单体应用中容易实现的特性，在分布式应用中不再那么轻松实现，比如事务，锁等场景。这带来了很大的挑战。通过不断的探索，每种问题都有不同程度的解决方案。<br><a id=\"more\"></a></p>\n<blockquote>\n<p>分布式系统文章集合：</p>\n</blockquote>\n<p><strong>消息中间件(解耦利器)</strong></p>\n<p><strong>分布式锁</strong></p>\n<p><strong><a href=\"/2018/12/05/2018-12-05-分布式事务实现方案\">分布式事务</a></strong></p>\n<p><strong>分布式一致性</strong></p>\n<p><strong>分布式存储</strong></p>\n<p><strong>分布式Session</strong></p>\n<p><strong>分布式计算</strong></p>\n<p><strong>分布式调度</strong></p>\n<h2 id=\"2-分布式事务的挑战\"><a href=\"#2-分布式事务的挑战\" class=\"headerlink\" title=\"2. 分布式事务的挑战\"></a>2. 分布式事务的挑战</h2><p>事务是提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。</p>\n<h3 id=\"2-1-数据库事务的特性\"><a href=\"#2-1-数据库事务的特性\" class=\"headerlink\" title=\"2.1 数据库事务的特性\"></a>2.1 数据库事务的特性</h3><p>ACID 指数据库事务正确执行的四个基本特性的缩写，包含：</p>\n<p><strong>原子性(Atomicity)</strong>：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。</p>\n<p><strong>一致性(Consistency)</strong>：在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。</p>\n<p><strong>隔离性(Isolation)</strong>：数据库允许多个并发事务同时对数据进行读写和修改的能力，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。<strong>隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</strong></p>\n<p><strong>持久性(Durability)</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>\n<p>在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。</p>\n<h3 id=\"2-2-JTA-amp-JTS-amp-Spring事务\"><a href=\"#2-2-JTA-amp-JTS-amp-Spring事务\" class=\"headerlink\" title=\"2.2 JTA &amp; JTS &amp; Spring事务\"></a>2.2 JTA &amp; JTS &amp; Spring事务</h3><h3 id=\"2-3-分布式事务\"><a href=\"#2-3-分布式事务\" class=\"headerlink\" title=\"2.3 分布式事务\"></a>2.3 分布式事务</h3><p>分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。有很多用例会跨多个子系统才能完成，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种跨系统的事务为分布式事务。</p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3. 参考资料\"></a>3. 参考资料</h2><p>阿里分布式事务框架 GTS 全解析<br><a href=\"https://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg</a></p>\n<p>深入理解「分布式事务」<br><a href=\"https://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg</a></p>\n<p>还不理解“分布式事务”？这篇给你讲清楚：<br><a href=\"http://developer.51cto.com/art/201812/588511.htm\" target=\"_blank\" rel=\"noopener\">http://developer.51cto.com/art/201812/588511.htm</a></p>\n<p>JTA 深度历险 - 原理与实现：<br><a href=\"http://www.cnblogs.com/firstdream/p/8514222.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/firstdream/p/8514222.html</a></p>\n<p>分布式系统核心问题(一致性)：<br><a href=\"https://blog.csdn.net/zyhlwzy/article/details/78658002\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zyhlwzy/article/details/78658002</a></p>\n<p>CAP原则(CAP定理)、BASE理论:<br><a href=\"http://www.cnblogs.com/duanxz/p/5229352.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/duanxz/p/5229352.html</a></p>\n<p>RocketMQ分布式消息队列设计:<br><a href=\"http://rocketmq.apache.org/docs/quick-start/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/docs/quick-start/</a></p>\n<p>=====</p>\n<p>Java常用类（一）之Object类详解<br><a href=\"https://www.cnblogs.com/zhangyinhua/p/7715486.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhangyinhua/p/7715486.html</a></p>\n<p>java-并发-ConcurrentHashMap高并发机制-jdk1.6<br><a href=\"https://blog.csdn.net/jianghuxiaojin/article/details/52006110\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jianghuxiaojin/article/details/52006110</a></p>\n<p>Java并发编程总结4——ConcurrentHashMap在jdk1.8中的改进<br><a href=\"http://www.cnblogs.com/everSeeker/p/5601861.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/everSeeker/p/5601861.html</a></p>\n<p>重入锁：ReentrantLock 详解<br><a href=\"https://blog.csdn.net/Somhu/article/details/78874634\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Somhu/article/details/78874634</a></p>\n<p>Java中Unsafe类详解<br><a href=\"https://www.cnblogs.com/thomas12112406/p/6510787.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/thomas12112406/p/6510787.html</a><br><a href=\"https://www.cnblogs.com/throwable/p/9139947.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/throwable/p/9139947.html</a></p>\n<p>Java魔法类：sun.misc.Unsafe<br><a href=\"https://www.cnblogs.com/suxuan/p/4948608.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/suxuan/p/4948608.html</a></p>\n<p>红黑树(一)之 原理和算法详细介绍<br><a href=\"https://www.cnblogs.com/skywang12345/p/3245399.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/skywang12345/p/3245399.html</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-前言\"><a href=\"#1-前言\" class=\"headerlink\" title=\"1. 前言\"></a>1. 前言</h2><p>由集中式应用到分布式应用的转变，带来了诸多的变化，虽然分布式应用解决了单体应用复杂性高、可靠性差、扩展能力受限等诸多问题，但原来在单体应用中容易实现的特性，在分布式应用中不再那么轻松实现，比如事务，锁等场景。这带来了很大的挑战。通过不断的探索，每种问题都有不同程度的解决方案。<br>","more":"</p>\n<blockquote>\n<p>分布式系统文章集合：</p>\n</blockquote>\n<p><strong>消息中间件(解耦利器)</strong></p>\n<p><strong>分布式锁</strong></p>\n<p><strong><a href=\"/2018/12/05/2018-12-05-分布式事务实现方案\">分布式事务</a></strong></p>\n<p><strong>分布式一致性</strong></p>\n<p><strong>分布式存储</strong></p>\n<p><strong>分布式Session</strong></p>\n<p><strong>分布式计算</strong></p>\n<p><strong>分布式调度</strong></p>\n<h2 id=\"2-分布式事务的挑战\"><a href=\"#2-分布式事务的挑战\" class=\"headerlink\" title=\"2. 分布式事务的挑战\"></a>2. 分布式事务的挑战</h2><p>事务是提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。</p>\n<h3 id=\"2-1-数据库事务的特性\"><a href=\"#2-1-数据库事务的特性\" class=\"headerlink\" title=\"2.1 数据库事务的特性\"></a>2.1 数据库事务的特性</h3><p>ACID 指数据库事务正确执行的四个基本特性的缩写，包含：</p>\n<p><strong>原子性(Atomicity)</strong>：整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。</p>\n<p><strong>一致性(Consistency)</strong>：在事务开始之前和事务结束以后，数据库数据的一致性约束没有被破坏。</p>\n<p><strong>隔离性(Isolation)</strong>：数据库允许多个并发事务同时对数据进行读写和修改的能力，如果一个事务要访问的数据正在被另外一个事务修改，只要另外一个事务未提交，它所访问的数据就不受未提交事务的影响。<strong>隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</strong></p>\n<p><strong>持久性(Durability)</strong>：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</p>\n<p>在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。</p>\n<h3 id=\"2-2-JTA-amp-JTS-amp-Spring事务\"><a href=\"#2-2-JTA-amp-JTS-amp-Spring事务\" class=\"headerlink\" title=\"2.2 JTA &amp; JTS &amp; Spring事务\"></a>2.2 JTA &amp; JTS &amp; Spring事务</h3><h3 id=\"2-3-分布式事务\"><a href=\"#2-3-分布式事务\" class=\"headerlink\" title=\"2.3 分布式事务\"></a>2.3 分布式事务</h3><p>分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。有很多用例会跨多个子系统才能完成，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种跨系统的事务为分布式事务。</p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3. 参考资料\"></a>3. 参考资料</h2><p>阿里分布式事务框架 GTS 全解析<br><a href=\"https://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/BqhGZDmTYLHlBCGBBOc-xg</a></p>\n<p>深入理解「分布式事务」<br><a href=\"https://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/_iGYAgx_CSxIHBMLtwbpNg</a></p>\n<p>还不理解“分布式事务”？这篇给你讲清楚：<br><a href=\"http://developer.51cto.com/art/201812/588511.htm\" target=\"_blank\" rel=\"noopener\">http://developer.51cto.com/art/201812/588511.htm</a></p>\n<p>JTA 深度历险 - 原理与实现：<br><a href=\"http://www.cnblogs.com/firstdream/p/8514222.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/firstdream/p/8514222.html</a></p>\n<p>分布式系统核心问题(一致性)：<br><a href=\"https://blog.csdn.net/zyhlwzy/article/details/78658002\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zyhlwzy/article/details/78658002</a></p>\n<p>CAP原则(CAP定理)、BASE理论:<br><a href=\"http://www.cnblogs.com/duanxz/p/5229352.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/duanxz/p/5229352.html</a></p>\n<p>RocketMQ分布式消息队列设计:<br><a href=\"http://rocketmq.apache.org/docs/quick-start/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/docs/quick-start/</a></p>\n<p>=====</p>\n<p>Java常用类（一）之Object类详解<br><a href=\"https://www.cnblogs.com/zhangyinhua/p/7715486.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zhangyinhua/p/7715486.html</a></p>\n<p>java-并发-ConcurrentHashMap高并发机制-jdk1.6<br><a href=\"https://blog.csdn.net/jianghuxiaojin/article/details/52006110\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jianghuxiaojin/article/details/52006110</a></p>\n<p>Java并发编程总结4——ConcurrentHashMap在jdk1.8中的改进<br><a href=\"http://www.cnblogs.com/everSeeker/p/5601861.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/everSeeker/p/5601861.html</a></p>\n<p>重入锁：ReentrantLock 详解<br><a href=\"https://blog.csdn.net/Somhu/article/details/78874634\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Somhu/article/details/78874634</a></p>\n<p>Java中Unsafe类详解<br><a href=\"https://www.cnblogs.com/thomas12112406/p/6510787.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/thomas12112406/p/6510787.html</a><br><a href=\"https://www.cnblogs.com/throwable/p/9139947.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/throwable/p/9139947.html</a></p>\n<p>Java魔法类：sun.misc.Unsafe<br><a href=\"https://www.cnblogs.com/suxuan/p/4948608.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/suxuan/p/4948608.html</a></p>\n<p>红黑树(一)之 原理和算法详细介绍<br><a href=\"https://www.cnblogs.com/skywang12345/p/3245399.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/skywang12345/p/3245399.html</a></p>"},{"layout":"lay_post","title":"RocketMQ中间件指南","date":"2018-12-04T16:00:00.000Z","author":"lvyafei","_content":"\n## 1. RocketMQ概述\n\n“根据我们的研究，随着使用的队列和虚拟主题的增加，ActiveMQ IO模块成为瓶颈。我们尽力通过节流，断路器或降级解决这个问题，但效果不佳。因此，我们开始关注当时流行的消息传递解决方案Kafka。不幸的是，Kafka无法满足我们的要求，特别是在低延迟和高可靠性方面，详见 http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/ ”\n<!--more-->\n\n![arc](/images/rocketmq/rmq-basic-arc.png)\n\nRocketMQ有三种方式发送消息：可靠的同步(reliable synchronous),可靠的异步(reliable asynchronous)和单向传输(one-way transmission)。\n\n### 1.1 同步发送producer.send\n\n可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nfor (int i = 0; i < 100; i++) {\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTest\",\"TagA\",(\"Hello RocketMQ \" +i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n    \n    //Call send message to deliver message to one of brokers.\n    SendResult sendResult = producer.send(msg);\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\");\nconsumer.setNamesrvAddr(\"localhost:9876\");\nconsumer.subscribe(\"TopicTest\", \"*\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyContext context) {\n        System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs);\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\n\nconsumer.start();\n```\n\n### 1.2 异步发送producer.send(msg, new SendCallback())\n\n异步传输通常用于响应时间敏感的业务场景。\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nproducer.setRetryTimesWhenSendAsyncFailed(0);\nfor (int i = 0; i < 100; i++) {\n        final int index = i;\n        //Create a message instance, specifying topic, tag and message body.\n        Message msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\",\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\n\n        producer.send(msg, new SendCallback() {\n            @Override\n            public void onSuccess(SendResult sendResult) {\n                System.out.printf(\"%-10d OK %s %n\", index,\n                    sendResult.getMsgId());\n            }\n            @Override\n            public void onException(Throwable e) {\n                System.out.printf(\"%-10d Exception %s %n\", index, e);\n                e.printStackTrace();\n            }\n        });\n}\nproducer.shutdown();\n```\n\n### 1.3 单向发送producer.sendOneway\n\n单向传输用于需要中等可靠性的情况，例如日志收集。\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nfor (int i = 0; i < 100; i++) {\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTest\",\"TagA\",(\"Hello RocketMQ \" +i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n    \n    //Call send message to deliver message to one of brokers.\n    producer.sendOneway(msg);\n}\nproducer.shutdown();\n```\n\n### 1.4 分区发送producer.send(msg, new MessageQueueSelector())\n\n发送消息:\n\n```java\nMQProducer producer = new DefaultMQProducer(\"example_group_name\");\nproducer.start();\nString[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\nfor (int i = 0; i < 100; i++) {\n    int orderId = i % 10;\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTestjjj\", tags[i % tags.length], \"KEY\" + i,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n\n    SendResult sendResult = producer.send(msg, new MessageQueueSelector() {\n    @Override\n    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\n        Integer id = (Integer) arg;\n        int index = id % mqs.size();\n        return mqs.get(index);\n    }\n    }, orderId);\n\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"example_group_name\");\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\nconsumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\");\n\nconsumer.registerMessageListener(new MessageListenerOrderly() {\n\n    AtomicLong consumeTimes = new AtomicLong(0);\n    @Override\n    public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs,ConsumeOrderlyContext context) {\n        context.setAutoCommit(false);\n        System.out.printf(Thread.currentThread().getName() + \" Receive New Messages: \" + msgs + \"%n\");\n        \n        this.consumeTimes.incrementAndGet();\n        if ((this.consumeTimes.get() % 2) == 0) {\n            return ConsumeOrderlyStatus.SUCCESS;\n        } else if ((this.consumeTimes.get() % 3) == 0) {\n            return ConsumeOrderlyStatus.ROLLBACK;\n        } else if ((this.consumeTimes.get() % 4) == 0) {\n            return ConsumeOrderlyStatus.COMMIT;\n        } else if ((this.consumeTimes.get() % 5) == 0) {\n            context.setSuspendCurrentQueueTimeMillis(3000);\n            return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;\n        }\n        return ConsumeOrderlyStatus.SUCCESS;\n    }\n});\n\nconsumer.start();\nSystem.out.printf(\"Consumer Started.%n\");\n```\n\n### 1.5 广播消费consumer.setMessageModel\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");\nproducer.start();\n\nfor (int i = 0; i < 100; i++){\n    Message msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\",\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\n    SendResult sendResult = producer.send(msg);\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"example_group_name\");\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\n\n//set to broadcast mode\nconsumer.setMessageModel(MessageModel.BROADCASTING);\nconsumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n        ConsumeConcurrentlyContext context) {\n        System.out.printf(Thread.currentThread().getName() + \" Receive New Messages: \" + msgs + \"%n\");\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\n\nconsumer.start();\nSystem.out.printf(\"Broadcast Consumer Started.%n\");\n```\n\n### 1.6 延迟发送message.setDelayTimeLevel\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\");\nproducer.start();\n\nint totalMessagesToSend = 100;\nfor (int i = 0; i < totalMessagesToSend; i++) {\n Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes());\n\n // This message will be delivered to consumer 10 seconds later.\n message.setDelayTimeLevel(3);\n producer.send(message);\n}\n\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\");\n// Subscribe topics\nconsumer.subscribe(\"TestTopic\", \"*\");\n\n// Register message listener\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n @Override\n public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> messages, ConsumeConcurrentlyContext context) {\n     for (MessageExt message : messages) {\n         // Print approximate delay time period\n         System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \"\n                 + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\");\n     }\n     return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n }\n});\n\nconsumer.start();\n```\n\n### 1.7 批量发送producer.send(new ArrayList<>())\n\n```java\nString topic = \"BatchTest\";\nList<Message> messages = new ArrayList<>();\nmessages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));\ntry {\n    producer.send(messages);\n} catch (Exception e) {\n    e.printStackTrace();\n    //handle the error\n}\n```\n\n只有在发送大批量时，复杂性才会增加，您可能不确定它是否超出了大小限制（1MiB）。\n\n### 1.8 消费过滤MessageSelector.bySql\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.start();\n\nMessage msg = new Message(\"TopicTest\",tag,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n// Set some properties.\nmsg.putUserProperty(\"a\", String.valueOf(i));\n\nSendResult sendResult = producer.send(msg);\n   \nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");\n\n// only subsribe messages have property a, also a >=0 and a <= 3\nconsumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\nconsumer.start();\n```\n\n## 2. 基于OpenMessaging收发消息\n\n### 2.1 同步发送producer.send\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    Message message = producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")));\n    SendResult sendResult = producer.send(message);\n    System.out.printf(\"Send sync message OK, msgId: %s%n\", sendResult.messageId());\n}\n```\n\n### 2.2 异步发送producer.sendAsync\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    final Promise<SendResult> result = producer.sendAsync(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n    result.addListener(new PromiseListener<SendResult>() {\n        @Override\n        public void operationCompleted(Promise<SendResult> promise) {\n            System.out.printf(\"Send async message OK, msgId: %s%n\", promise.get().messageId());\n        }\n\n        @Override\n        public void operationFailed(Promise<SendResult> promise) {\n            System.out.printf(\"Send async message Failed, error: %s%n\", promise.getThrowable().getMessage());\n        }\n    });\n}\n```\n\n### 2.3 单向发送producer.sendOneway\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    producer.sendOneway(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n    System.out.printf(\"Send oneway message OK%n\");\n}\n\nproducer.shutdown();\nmessagingAccessPoint.shutdown();\n```\n\n### 2.4 消费消息consumer.poll\n\nOMSPullConsumer:\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal PullConsumer consumer = messagingAccessPoint.createPullConsumer(\"OMS_HELLO_TOPIC\",\n    OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nconsumer.startup();\nSystem.out.printf(\"Consumer startup OK%n\");\n\nMessage message = consumer.poll();\nif (message != null) {\n    String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n    System.out.printf(\"Received one message: %s%n\", msgId);\n    consumer.ack(msgId);\n}\n\nconsumer.shutdown();\nmessagingAccessPoint.shutdown();\n```\n\n### 2.5 消费消息consumer.attachQueue\n\nOMSPushConsumer:\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal PushConsumer consumer = messagingAccessPoint.\n    createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nRuntime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n    @Override\n    public void run() {\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}));\n\nconsumer.attachQueue(\"OMS_HELLO_TOPIC\", new MessageListener() {\n    @Override\n    public void onMessage(final Message message, final ReceivedMessageContext context) {\n        System.out.printf(\"Received one message: %s%n\", message.headers().getString(MessageHeader.MESSAGE_ID));\n        context.ack();\n    }\n});\n```\n\n## 2. RocketMQ事务消息\n\nRocketMQ 事务消息设计则主要是为了解决 Producer 端的消息发送与本地事务执行的原子性问题，RocketMQ 的设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ 本身提供的存储机制，则为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计，则为事务消息在系统在发生异常时，依然能够保证事务的最终一致性达成。\n\n### 2.1 发送事务性消息\n\n事务性消息有三种状态：\n\n（1）TransactionStatus.CommitTransaction：提交事务，这意味着允许消费者使用此消息。\n\n（2）TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除而不允许使用。\n\n（3）TransactionStatus.Unknown：中间状态，表示需要MQ检查以确定状态。\n\n使用TransactionMQProducer类创建生成器客户端，并指定唯一的producerGroup，并且可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果回复MQ，最终结果状态。\n\n```java\nTransactionListener transactionListener = new TransactionListenerImpl();\nTransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\");\nExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {\n    @Override\n    public Thread newThread(Runnable r) {\n        Thread thread = new Thread(r);\n        thread.setName(\"client-transaction-msg-check-thread\");\n        return thread;\n    }\n});\n\nproducer.setExecutorService(executorService);\nproducer.setTransactionListener(transactionListener);\nproducer.start();\n\nString[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\nfor (int i = 0; i < 10; i++) {\n    try {\n        Message msg =new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n        SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n        System.out.printf(\"%s%n\", sendResult);\n\n        Thread.sleep(10);\n    } catch (MQClientException | UnsupportedEncodingException e) {\n        e.printStackTrace();\n    }\n}\n\nfor (int i = 0; i < 100000; i++) {\n    Thread.sleep(1000);\n}\nproducer.shutdown();\n```\n\n实现TransactionListener接口\n\n**executeLocalTransaction**：方法用于在发送Half消息成功时执行的本地事务。它返回三种事务状态之一。\n\n**checkLocalTransaction**：方法用于检查本地事务状态并响应MQ检查请求。它返回三种事务状态之一。\n\n```java\npublic class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n\n   private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();\n\n   @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n\n   @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }\n}\n```\n\n### 2.2 RocketMQ事务消息设计\n\n事务消息作为一种异步确保型事务，  将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示：\n\n![交互流程](/images/rocketmq/交互流程.png)\n\n1.事务发起方首先发送 prepare 消息到 MQ。\n\n2.再发送 prepare 消息成功后执行本地事务。\n\n3.根据本地事务执行结果返回 commit 或者是 rollback。\n\n4.如果消息是 rollback，MQ 将删除该 prepare 消息不进行下发，如果是 commit 消息，MQ 将会把这个消息发送给 consumer 端。\n\n<font color=red>5.如果执行本地事务过程中，执行端挂掉，或者超时，MQ 将会不停的询问其同组的其他 producer 来获取状态</font>。 \n\n6.consumer 端的消费成功机制有 MQ 保证。\n\n### 2.3 RocketMQ事务消息实现\n\nRocketMQ 事务消息在实现上充分利用了 RocketMQ 本身机制，在实现零依赖的基础上，同样实现了高性能、可扩展、全异步等一系列特性。\n\n在具体实现上，RocketMQ 通过使用 Half Topic 以及 Operation Topic 两个内部队列来存储事务消息推进状态，如下图所示：\n\n![事务消息实现](/images/rocketmq/事务消息实现.png)\n\n其中，Half Topic 对应队列中存放着 prepare 消息，Operation Topic 对应的队列则存放了 prepare message 对应的 commit/rollback 消息，消息体中则是 prepare message 对应的 offset，服务端通过比对两个队列的差值来找到尚未提交的超时事务，进行回查。\n\n在具体实现上，事务消息作为普通消息的一个应用场景，在实现过程中进行了分层抽象，从而避免了对 RocketMQ 原有存储机制的修改，如下图所示：\n\n![存储机制](/images/rocketmq/存储机制.png)\n\n从用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态即可；而在 service 层，则对事务消息的两阶段提交进行了抽象，同时针对超时事务实现了回查逻辑，通过不断扫描当前事务推进状态，来不断反向请求 Producer 端获取超时事务的执行状态，在避免事务挂起的同时，也避免了 Producer 端的单点故障。而在存储层，RocketMQ 通过 Bridge 封装了与底层队列存储的相关操作，用以操作两个对应的内部队列，用户也可以依赖其他存储介质实现自己的 service，RocketMQ 会通过 ServiceProvider 加载进来。\n\n从上述事务消息设计中可以看到，RocketMQ 事务消息较好的解决了事务的最终一致性问题，事务发起方仅需要关注本地事务执行以及实现回查接口给出事务状态判定等实现，而且在上游事务峰值高时，可以通过消息队列，避免对下游服务产生过大压力。\n\n## 3.参考资料\n\nRocketMQ官方文档： http://rocketmq.apache.org/docs/quick-start/\n\nRocketMQ 4.3正式发布，支持分布式事务： \nhttps://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&source=41#wechat_redirect","source":"_posts/2018-12-05-RocketMQ中间件指南.md","raw":"---\nlayout: lay_post\ntitle: \"RocketMQ中间件指南\"\ndate: 2018-12-05\ncategories: 中间件\ntags: MQ\nauthor: lvyafei\n---\n\n## 1. RocketMQ概述\n\n“根据我们的研究，随着使用的队列和虚拟主题的增加，ActiveMQ IO模块成为瓶颈。我们尽力通过节流，断路器或降级解决这个问题，但效果不佳。因此，我们开始关注当时流行的消息传递解决方案Kafka。不幸的是，Kafka无法满足我们的要求，特别是在低延迟和高可靠性方面，详见 http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/ ”\n<!--more-->\n\n![arc](/images/rocketmq/rmq-basic-arc.png)\n\nRocketMQ有三种方式发送消息：可靠的同步(reliable synchronous),可靠的异步(reliable asynchronous)和单向传输(one-way transmission)。\n\n### 1.1 同步发送producer.send\n\n可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nfor (int i = 0; i < 100; i++) {\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTest\",\"TagA\",(\"Hello RocketMQ \" +i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n    \n    //Call send message to deliver message to one of brokers.\n    SendResult sendResult = producer.send(msg);\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name\");\nconsumer.setNamesrvAddr(\"localhost:9876\");\nconsumer.subscribe(\"TopicTest\", \"*\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,ConsumeConcurrentlyContext context) {\n        System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs);\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\n\nconsumer.start();\n```\n\n### 1.2 异步发送producer.send(msg, new SendCallback())\n\n异步传输通常用于响应时间敏感的业务场景。\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nproducer.setRetryTimesWhenSendAsyncFailed(0);\nfor (int i = 0; i < 100; i++) {\n        final int index = i;\n        //Create a message instance, specifying topic, tag and message body.\n        Message msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\",\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\n\n        producer.send(msg, new SendCallback() {\n            @Override\n            public void onSuccess(SendResult sendResult) {\n                System.out.printf(\"%-10d OK %s %n\", index,\n                    sendResult.getMsgId());\n            }\n            @Override\n            public void onException(Throwable e) {\n                System.out.printf(\"%-10d Exception %s %n\", index, e);\n                e.printStackTrace();\n            }\n        });\n}\nproducer.shutdown();\n```\n\n### 1.3 单向发送producer.sendOneway\n\n单向传输用于需要中等可靠性的情况，例如日志收集。\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.setNamesrvAddr(\"localhost:9876\");\nproducer.start();\nfor (int i = 0; i < 100; i++) {\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTest\",\"TagA\",(\"Hello RocketMQ \" +i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n    \n    //Call send message to deliver message to one of brokers.\n    producer.sendOneway(msg);\n}\nproducer.shutdown();\n```\n\n### 1.4 分区发送producer.send(msg, new MessageQueueSelector())\n\n发送消息:\n\n```java\nMQProducer producer = new DefaultMQProducer(\"example_group_name\");\nproducer.start();\nString[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\nfor (int i = 0; i < 100; i++) {\n    int orderId = i % 10;\n    //Create a message instance, specifying topic, tag and message body.\n    Message msg = new Message(\"TopicTestjjj\", tags[i % tags.length], \"KEY\" + i,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n\n    SendResult sendResult = producer.send(msg, new MessageQueueSelector() {\n    @Override\n    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {\n        Integer id = (Integer) arg;\n        int index = id % mqs.size();\n        return mqs.get(index);\n    }\n    }, orderId);\n\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"example_group_name\");\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\nconsumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\");\n\nconsumer.registerMessageListener(new MessageListenerOrderly() {\n\n    AtomicLong consumeTimes = new AtomicLong(0);\n    @Override\n    public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs,ConsumeOrderlyContext context) {\n        context.setAutoCommit(false);\n        System.out.printf(Thread.currentThread().getName() + \" Receive New Messages: \" + msgs + \"%n\");\n        \n        this.consumeTimes.incrementAndGet();\n        if ((this.consumeTimes.get() % 2) == 0) {\n            return ConsumeOrderlyStatus.SUCCESS;\n        } else if ((this.consumeTimes.get() % 3) == 0) {\n            return ConsumeOrderlyStatus.ROLLBACK;\n        } else if ((this.consumeTimes.get() % 4) == 0) {\n            return ConsumeOrderlyStatus.COMMIT;\n        } else if ((this.consumeTimes.get() % 5) == 0) {\n            context.setSuspendCurrentQueueTimeMillis(3000);\n            return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;\n        }\n        return ConsumeOrderlyStatus.SUCCESS;\n    }\n});\n\nconsumer.start();\nSystem.out.printf(\"Consumer Started.%n\");\n```\n\n### 1.5 广播消费consumer.setMessageModel\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"ProducerGroupName\");\nproducer.start();\n\nfor (int i = 0; i < 100; i++){\n    Message msg = new Message(\"TopicTest\",\"TagA\",\"OrderID188\",\"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET));\n    SendResult sendResult = producer.send(msg);\n    System.out.printf(\"%s%n\", sendResult);\n}\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"example_group_name\");\nconsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);\n\n//set to broadcast mode\nconsumer.setMessageModel(MessageModel.BROADCASTING);\nconsumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs,\n        ConsumeConcurrentlyContext context) {\n        System.out.printf(Thread.currentThread().getName() + \" Receive New Messages: \" + msgs + \"%n\");\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\n\nconsumer.start();\nSystem.out.printf(\"Broadcast Consumer Started.%n\");\n```\n\n### 1.6 延迟发送message.setDelayTimeLevel\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\");\nproducer.start();\n\nint totalMessagesToSend = 100;\nfor (int i = 0; i < totalMessagesToSend; i++) {\n Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes());\n\n // This message will be delivered to consumer 10 seconds later.\n message.setDelayTimeLevel(3);\n producer.send(message);\n}\n\nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\");\n// Subscribe topics\nconsumer.subscribe(\"TestTopic\", \"*\");\n\n// Register message listener\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n @Override\n public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> messages, ConsumeConcurrentlyContext context) {\n     for (MessageExt message : messages) {\n         // Print approximate delay time period\n         System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \"\n                 + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\");\n     }\n     return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n }\n});\n\nconsumer.start();\n```\n\n### 1.7 批量发送producer.send(new ArrayList<>())\n\n```java\nString topic = \"BatchTest\";\nList<Message> messages = new ArrayList<>();\nmessages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));\nmessages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));\ntry {\n    producer.send(messages);\n} catch (Exception e) {\n    e.printStackTrace();\n    //handle the error\n}\n```\n\n只有在发送大批量时，复杂性才会增加，您可能不确定它是否超出了大小限制（1MiB）。\n\n### 1.8 消费过滤MessageSelector.bySql\n\n发送消息:\n\n```java\nDefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");\nproducer.start();\n\nMessage msg = new Message(\"TopicTest\",tag,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n// Set some properties.\nmsg.putUserProperty(\"a\", String.valueOf(i));\n\nSendResult sendResult = producer.send(msg);\n   \nproducer.shutdown();\n```\n\n接收消息:\n\n```java\nDefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");\n\n// only subsribe messages have property a, also a >=0 and a <= 3\nconsumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\");\n\nconsumer.registerMessageListener(new MessageListenerConcurrently() {\n    @Override\n    public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {\n        return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n    }\n});\nconsumer.start();\n```\n\n## 2. 基于OpenMessaging收发消息\n\n### 2.1 同步发送producer.send\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    Message message = producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")));\n    SendResult sendResult = producer.send(message);\n    System.out.printf(\"Send sync message OK, msgId: %s%n\", sendResult.messageId());\n}\n```\n\n### 2.2 异步发送producer.sendAsync\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    final Promise<SendResult> result = producer.sendAsync(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n    result.addListener(new PromiseListener<SendResult>() {\n        @Override\n        public void operationCompleted(Promise<SendResult> promise) {\n            System.out.printf(\"Send async message OK, msgId: %s%n\", promise.get().messageId());\n        }\n\n        @Override\n        public void operationFailed(Promise<SendResult> promise) {\n            System.out.printf(\"Send async message Failed, error: %s%n\", promise.getThrowable().getMessage());\n        }\n    });\n}\n```\n\n### 2.3 单向发送producer.sendOneway\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal Producer producer = messagingAccessPoint.createProducer();\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nproducer.startup();\nSystem.out.printf(\"Producer startup OK%n\");\n\n{\n    producer.sendOneway(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n    System.out.printf(\"Send oneway message OK%n\");\n}\n\nproducer.shutdown();\nmessagingAccessPoint.shutdown();\n```\n\n### 2.4 消费消息consumer.poll\n\nOMSPullConsumer:\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal PullConsumer consumer = messagingAccessPoint.createPullConsumer(\"OMS_HELLO_TOPIC\",\n    OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nconsumer.startup();\nSystem.out.printf(\"Consumer startup OK%n\");\n\nMessage message = consumer.poll();\nif (message != null) {\n    String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n    System.out.printf(\"Received one message: %s%n\", msgId);\n    consumer.ack(msgId);\n}\n\nconsumer.shutdown();\nmessagingAccessPoint.shutdown();\n```\n\n### 2.5 消费消息consumer.attachQueue\n\nOMSPushConsumer:\n\n```java\nfinal MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\nfinal PushConsumer consumer = messagingAccessPoint.\n    createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\nmessagingAccessPoint.startup();\nSystem.out.printf(\"MessagingAccessPoint startup OK%n\");\n\nRuntime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n    @Override\n    public void run() {\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}));\n\nconsumer.attachQueue(\"OMS_HELLO_TOPIC\", new MessageListener() {\n    @Override\n    public void onMessage(final Message message, final ReceivedMessageContext context) {\n        System.out.printf(\"Received one message: %s%n\", message.headers().getString(MessageHeader.MESSAGE_ID));\n        context.ack();\n    }\n});\n```\n\n## 2. RocketMQ事务消息\n\nRocketMQ 事务消息设计则主要是为了解决 Producer 端的消息发送与本地事务执行的原子性问题，RocketMQ 的设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ 本身提供的存储机制，则为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计，则为事务消息在系统在发生异常时，依然能够保证事务的最终一致性达成。\n\n### 2.1 发送事务性消息\n\n事务性消息有三种状态：\n\n（1）TransactionStatus.CommitTransaction：提交事务，这意味着允许消费者使用此消息。\n\n（2）TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除而不允许使用。\n\n（3）TransactionStatus.Unknown：中间状态，表示需要MQ检查以确定状态。\n\n使用TransactionMQProducer类创建生成器客户端，并指定唯一的producerGroup，并且可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果回复MQ，最终结果状态。\n\n```java\nTransactionListener transactionListener = new TransactionListenerImpl();\nTransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\");\nExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {\n    @Override\n    public Thread newThread(Runnable r) {\n        Thread thread = new Thread(r);\n        thread.setName(\"client-transaction-msg-check-thread\");\n        return thread;\n    }\n});\n\nproducer.setExecutorService(executorService);\nproducer.setTransactionListener(transactionListener);\nproducer.start();\n\nString[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\nfor (int i = 0; i < 10; i++) {\n    try {\n        Message msg =new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i,(\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n        SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n        System.out.printf(\"%s%n\", sendResult);\n\n        Thread.sleep(10);\n    } catch (MQClientException | UnsupportedEncodingException e) {\n        e.printStackTrace();\n    }\n}\n\nfor (int i = 0; i < 100000; i++) {\n    Thread.sleep(1000);\n}\nproducer.shutdown();\n```\n\n实现TransactionListener接口\n\n**executeLocalTransaction**：方法用于在发送Half消息成功时执行的本地事务。它返回三种事务状态之一。\n\n**checkLocalTransaction**：方法用于检查本地事务状态并响应MQ检查请求。它返回三种事务状态之一。\n\n```java\npublic class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n\n   private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();\n\n   @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n\n   @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }\n}\n```\n\n### 2.2 RocketMQ事务消息设计\n\n事务消息作为一种异步确保型事务，  将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示：\n\n![交互流程](/images/rocketmq/交互流程.png)\n\n1.事务发起方首先发送 prepare 消息到 MQ。\n\n2.再发送 prepare 消息成功后执行本地事务。\n\n3.根据本地事务执行结果返回 commit 或者是 rollback。\n\n4.如果消息是 rollback，MQ 将删除该 prepare 消息不进行下发，如果是 commit 消息，MQ 将会把这个消息发送给 consumer 端。\n\n<font color=red>5.如果执行本地事务过程中，执行端挂掉，或者超时，MQ 将会不停的询问其同组的其他 producer 来获取状态</font>。 \n\n6.consumer 端的消费成功机制有 MQ 保证。\n\n### 2.3 RocketMQ事务消息实现\n\nRocketMQ 事务消息在实现上充分利用了 RocketMQ 本身机制，在实现零依赖的基础上，同样实现了高性能、可扩展、全异步等一系列特性。\n\n在具体实现上，RocketMQ 通过使用 Half Topic 以及 Operation Topic 两个内部队列来存储事务消息推进状态，如下图所示：\n\n![事务消息实现](/images/rocketmq/事务消息实现.png)\n\n其中，Half Topic 对应队列中存放着 prepare 消息，Operation Topic 对应的队列则存放了 prepare message 对应的 commit/rollback 消息，消息体中则是 prepare message 对应的 offset，服务端通过比对两个队列的差值来找到尚未提交的超时事务，进行回查。\n\n在具体实现上，事务消息作为普通消息的一个应用场景，在实现过程中进行了分层抽象，从而避免了对 RocketMQ 原有存储机制的修改，如下图所示：\n\n![存储机制](/images/rocketmq/存储机制.png)\n\n从用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态即可；而在 service 层，则对事务消息的两阶段提交进行了抽象，同时针对超时事务实现了回查逻辑，通过不断扫描当前事务推进状态，来不断反向请求 Producer 端获取超时事务的执行状态，在避免事务挂起的同时，也避免了 Producer 端的单点故障。而在存储层，RocketMQ 通过 Bridge 封装了与底层队列存储的相关操作，用以操作两个对应的内部队列，用户也可以依赖其他存储介质实现自己的 service，RocketMQ 会通过 ServiceProvider 加载进来。\n\n从上述事务消息设计中可以看到，RocketMQ 事务消息较好的解决了事务的最终一致性问题，事务发起方仅需要关注本地事务执行以及实现回查接口给出事务状态判定等实现，而且在上游事务峰值高时，可以通过消息队列，避免对下游服务产生过大压力。\n\n## 3.参考资料\n\nRocketMQ官方文档： http://rocketmq.apache.org/docs/quick-start/\n\nRocketMQ 4.3正式发布，支持分布式事务： \nhttps://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&source=41#wechat_redirect","slug":"2018-12-05-RocketMQ中间件指南","published":1,"updated":"2018-12-05T13:24:28.737Z","comments":1,"photos":[],"link":"","_id":"cjskffogd006t4glmp6iaok8w","content":"<h2 id=\"1-RocketMQ概述\"><a href=\"#1-RocketMQ概述\" class=\"headerlink\" title=\"1. RocketMQ概述\"></a>1. RocketMQ概述</h2><p>“根据我们的研究，随着使用的队列和虚拟主题的增加，ActiveMQ IO模块成为瓶颈。我们尽力通过节流，断路器或降级解决这个问题，但效果不佳。因此，我们开始关注当时流行的消息传递解决方案Kafka。不幸的是，Kafka无法满足我们的要求，特别是在低延迟和高可靠性方面，详见 <a href=\"http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/</a> ”<br><a id=\"more\"></a></p>\n<p><img src=\"/images/rocketmq/rmq-basic-arc.png\" alt=\"arc\"></p>\n<p>RocketMQ有三种方式发送消息：可靠的同步(reliable synchronous),可靠的异步(reliable asynchronous)和单向传输(one-way transmission)。</p>\n<h3 id=\"1-1-同步发送producer-send\"><a href=\"#1-1-同步发送producer-send\" class=\"headerlink\" title=\"1.1 同步发送producer.send\"></a>1.1 同步发送producer.send</h3><p>可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。</p>\n<p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,(<span class=\"string\">\"Hello RocketMQ \"</span> +i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//Call send message to deliver message to one of brokers.</span></span><br><span class=\"line\">    SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">consumer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"*\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"%s Receive New Messages: %s %n\"</span>, Thread.currentThread().getName(), msgs);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-异步发送producer-send-msg-new-SendCallback\"><a href=\"#1-2-异步发送producer-send-msg-new-SendCallback\" class=\"headerlink\" title=\"1.2 异步发送producer.send(msg, new SendCallback())\"></a>1.2 异步发送producer.send(msg, new SendCallback())</h3><p>异步传输通常用于响应时间敏感的业务场景。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\">producer.setRetryTimesWhenSendAsyncFailed(<span class=\"number\">0</span>);</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> index = i;</span><br><span class=\"line\">        <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">        Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,<span class=\"string\">\"OrderID188\"</span>,<span class=\"string\">\"Hello world\"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"></span><br><span class=\"line\">        producer.send(msg, <span class=\"keyword\">new</span> SendCallback() &#123;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onSuccess</span><span class=\"params\">(SendResult sendResult)</span> </span>&#123;</span><br><span class=\"line\">                System.out.printf(<span class=\"string\">\"%-10d OK %s %n\"</span>, index,</span><br><span class=\"line\">                    sendResult.getMsgId());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onException</span><span class=\"params\">(Throwable e)</span> </span>&#123;</span><br><span class=\"line\">                System.out.printf(<span class=\"string\">\"%-10d Exception %s %n\"</span>, index, e);</span><br><span class=\"line\">                e.printStackTrace();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-单向发送producer-sendOneway\"><a href=\"#1-3-单向发送producer-sendOneway\" class=\"headerlink\" title=\"1.3 单向发送producer.sendOneway\"></a>1.3 单向发送producer.sendOneway</h3><p>单向传输用于需要中等可靠性的情况，例如日志收集。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,(<span class=\"string\">\"Hello RocketMQ \"</span> +i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//Call send message to deliver message to one of brokers.</span></span><br><span class=\"line\">    producer.sendOneway(msg);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-分区发送producer-send-msg-new-MessageQueueSelector\"><a href=\"#1-4-分区发送producer-send-msg-new-MessageQueueSelector\" class=\"headerlink\" title=\"1.4 分区发送producer.send(msg, new MessageQueueSelector())\"></a>1.4 分区发送producer.send(msg, new MessageQueueSelector())</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\">String[] tags = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"TagB\"</span>, <span class=\"string\">\"TagC\"</span>, <span class=\"string\">\"TagD\"</span>, <span class=\"string\">\"TagE\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> orderId = i % <span class=\"number\">10</span>;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTestjjj\"</span>, tags[i % tags.length], <span class=\"string\">\"KEY\"</span> + i,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"></span><br><span class=\"line\">    SendResult sendResult = producer.send(msg, <span class=\"keyword\">new</span> MessageQueueSelector() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> MessageQueue <span class=\"title\">select</span><span class=\"params\">(List&lt;MessageQueue&gt; mqs, Message msg, Object arg)</span> </span>&#123;</span><br><span class=\"line\">        Integer id = (Integer) arg;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> index = id % mqs.size();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mqs.get(index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;, orderId);</span><br><span class=\"line\"></span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"TagA || TagC || TagD\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerOrderly() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    AtomicLong consumeTimes = <span class=\"keyword\">new</span> AtomicLong(<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeOrderlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,ConsumeOrderlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        context.setAutoCommit(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">        System.out.printf(Thread.currentThread().getName() + <span class=\"string\">\" Receive New Messages: \"</span> + msgs + <span class=\"string\">\"%n\"</span>);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">this</span>.consumeTimes.incrementAndGet();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">2</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUCCESS;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">3</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.ROLLBACK;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">4</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.COMMIT;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">5</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            context.setSuspendCurrentQueueTimeMillis(<span class=\"number\">3000</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Consumer Started.%n\"</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-5-广播消费consumer-setMessageModel\"><a href=\"#1-5-广播消费consumer-setMessageModel\" class=\"headerlink\" title=\"1.5 广播消费consumer.setMessageModel\"></a>1.5 广播消费consumer.setMessageModel</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"ProducerGroupName\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++)&#123;</span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,<span class=\"string\">\"OrderID188\"</span>,<span class=\"string\">\"Hello world\"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//set to broadcast mode</span></span><br><span class=\"line\">consumer.setMessageModel(MessageModel.BROADCASTING);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"TagA || TagC || TagD\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(Thread.currentThread().getName() + <span class=\"string\">\" Receive New Messages: \"</span> + msgs + <span class=\"string\">\"%n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Broadcast Consumer Started.%n\"</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-6-延迟发送message-setDelayTimeLevel\"><a href=\"#1-6-延迟发送message-setDelayTimeLevel\" class=\"headerlink\" title=\"1.6 延迟发送message.setDelayTimeLevel\"></a>1.6 延迟发送message.setDelayTimeLevel</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"ExampleProducerGroup\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> totalMessagesToSend = <span class=\"number\">100</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; totalMessagesToSend; i++) &#123;</span><br><span class=\"line\"> Message message = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TestTopic\"</span>, (<span class=\"string\">\"Hello scheduled message \"</span> + i).getBytes());</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"comment\">// This message will be delivered to consumer 10 seconds later.</span></span><br><span class=\"line\"> message.setDelayTimeLevel(<span class=\"number\">3</span>);</span><br><span class=\"line\"> producer.send(message);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"ExampleConsumer\"</span>);</span><br><span class=\"line\"><span class=\"comment\">// Subscribe topics</span></span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TestTopic\"</span>, <span class=\"string\">\"*\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Register message listener</span></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"> <span class=\"meta\">@Override</span></span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"keyword\">for</span> (MessageExt message : messages) &#123;</span><br><span class=\"line\">         <span class=\"comment\">// Print approximate delay time period</span></span><br><span class=\"line\">         System.out.println(<span class=\"string\">\"Receive message[msgId=\"</span> + message.getMsgId() + <span class=\"string\">\"] \"</span></span><br><span class=\"line\">                 + (System.currentTimeMillis() - message.getStoreTimestamp()) + <span class=\"string\">\"ms later\"</span>);</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">     <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-7-批量发送producer-send-new-ArrayList-lt-gt\"><a href=\"#1-7-批量发送producer-send-new-ArrayList-lt-gt\" class=\"headerlink\" title=\"1.7 批量发送producer.send(new ArrayList&lt;&gt;())\"></a>1.7 批量发送producer.send(new ArrayList&lt;&gt;())</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String topic = <span class=\"string\">\"BatchTest\"</span>;</span><br><span class=\"line\">List&lt;Message&gt; messages = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID001\"</span>, <span class=\"string\">\"Hello world 0\"</span>.getBytes()));</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID002\"</span>, <span class=\"string\">\"Hello world 1\"</span>.getBytes()));</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID003\"</span>, <span class=\"string\">\"Hello world 2\"</span>.getBytes()));</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    producer.send(messages);</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">    <span class=\"comment\">//handle the error</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>只有在发送大批量时，复杂性才会增加，您可能不确定它是否超出了大小限制（1MiB）。</p>\n<h3 id=\"1-8-消费过滤MessageSelector-bySql\"><a href=\"#1-8-消费过滤MessageSelector-bySql\" class=\"headerlink\" title=\"1.8 消费过滤MessageSelector.bySql\"></a>1.8 消费过滤MessageSelector.bySql</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\">Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,tag,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"><span class=\"comment\">// Set some properties.</span></span><br><span class=\"line\">msg.putUserProperty(<span class=\"string\">\"a\"</span>, String.valueOf(i));</span><br><span class=\"line\"></span><br><span class=\"line\">SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">   </span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"please_rename_unique_group_name_4\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// only subsribe messages have property a, also a &gt;=0 and a &lt;= 3</span></span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, MessageSelector.bySql(<span class=\"string\">\"a between 0 and 3\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-基于OpenMessaging收发消息\"><a href=\"#2-基于OpenMessaging收发消息\" class=\"headerlink\" title=\"2. 基于OpenMessaging收发消息\"></a>2. 基于OpenMessaging收发消息</h2><h3 id=\"2-1-同步发送producer-send\"><a href=\"#2-1-同步发送producer-send\" class=\"headerlink\" title=\"2.1 同步发送producer.send\"></a>2.1 同步发送producer.send</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    Message message = producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">    SendResult sendResult = producer.send(message);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Send sync message OK, msgId: %s%n\"</span>, sendResult.messageId());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-异步发送producer-sendAsync\"><a href=\"#2-2-异步发送producer-sendAsync\" class=\"headerlink\" title=\"2.2 异步发送producer.sendAsync\"></a>2.2 异步发送producer.sendAsync</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> Promise&lt;SendResult&gt; result = producer.sendAsync(producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>))));</span><br><span class=\"line\">    result.addListener(<span class=\"keyword\">new</span> PromiseListener&lt;SendResult&gt;() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">operationCompleted</span><span class=\"params\">(Promise&lt;SendResult&gt; promise)</span> </span>&#123;</span><br><span class=\"line\">            System.out.printf(<span class=\"string\">\"Send async message OK, msgId: %s%n\"</span>, promise.get().messageId());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">operationFailed</span><span class=\"params\">(Promise&lt;SendResult&gt; promise)</span> </span>&#123;</span><br><span class=\"line\">            System.out.printf(<span class=\"string\">\"Send async message Failed, error: %s%n\"</span>, promise.getThrowable().getMessage());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-3-单向发送producer-sendOneway\"><a href=\"#2-3-单向发送producer-sendOneway\" class=\"headerlink\" title=\"2.3 单向发送producer.sendOneway\"></a>2.3 单向发送producer.sendOneway</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    producer.sendOneway(producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>))));</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Send oneway message OK%n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">producer.shutdown();</span><br><span class=\"line\">messagingAccessPoint.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-消费消息consumer-poll\"><a href=\"#2-4-消费消息consumer-poll\" class=\"headerlink\" title=\"2.4 消费消息consumer.poll\"></a>2.4 消费消息consumer.poll</h3><p>OMSPullConsumer:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> PullConsumer consumer = messagingAccessPoint.createPullConsumer(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>,</span><br><span class=\"line\">    OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, <span class=\"string\">\"OMS_CONSUMER\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Consumer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Message message = consumer.poll();</span><br><span class=\"line\"><span class=\"keyword\">if</span> (message != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">    String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Received one message: %s%n\"</span>, msgId);</span><br><span class=\"line\">    consumer.ack(msgId);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.shutdown();</span><br><span class=\"line\">messagingAccessPoint.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-5-消费消息consumer-attachQueue\"><a href=\"#2-5-消费消息consumer-attachQueue\" class=\"headerlink\" title=\"2.5 消费消息consumer.attachQueue\"></a>2.5 消费消息consumer.attachQueue</h3><p>OMSPushConsumer:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> PushConsumer consumer = messagingAccessPoint.</span><br><span class=\"line\">    createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, <span class=\"string\">\"OMS_CONSUMER\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Runtime.getRuntime().addShutdownHook(<span class=\"keyword\">new</span> Thread(<span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        consumer.shutdown();</span><br><span class=\"line\">        messagingAccessPoint.shutdown();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;));</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.attachQueue(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"keyword\">new</span> MessageListener() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onMessage</span><span class=\"params\">(<span class=\"keyword\">final</span> Message message, <span class=\"keyword\">final</span> ReceivedMessageContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"Received one message: %s%n\"</span>, message.headers().getString(MessageHeader.MESSAGE_ID));</span><br><span class=\"line\">        context.ack();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-RocketMQ事务消息\"><a href=\"#2-RocketMQ事务消息\" class=\"headerlink\" title=\"2. RocketMQ事务消息\"></a>2. RocketMQ事务消息</h2><p>RocketMQ 事务消息设计则主要是为了解决 Producer 端的消息发送与本地事务执行的原子性问题，RocketMQ 的设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ 本身提供的存储机制，则为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计，则为事务消息在系统在发生异常时，依然能够保证事务的最终一致性达成。</p>\n<h3 id=\"2-1-发送事务性消息\"><a href=\"#2-1-发送事务性消息\" class=\"headerlink\" title=\"2.1 发送事务性消息\"></a>2.1 发送事务性消息</h3><p>事务性消息有三种状态：</p>\n<p>（1）TransactionStatus.CommitTransaction：提交事务，这意味着允许消费者使用此消息。</p>\n<p>（2）TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除而不允许使用。</p>\n<p>（3）TransactionStatus.Unknown：中间状态，表示需要MQ检查以确定状态。</p>\n<p>使用TransactionMQProducer类创建生成器客户端，并指定唯一的producerGroup，并且可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果回复MQ，最终结果状态。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TransactionListener transactionListener = <span class=\"keyword\">new</span> TransactionListenerImpl();</span><br><span class=\"line\">TransactionMQProducer producer = <span class=\"keyword\">new</span> TransactionMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">ExecutorService executorService = <span class=\"keyword\">new</span> ThreadPoolExecutor(<span class=\"number\">2</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>, TimeUnit.SECONDS, <span class=\"keyword\">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class=\"number\">2000</span>), <span class=\"keyword\">new</span> ThreadFactory() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Thread <span class=\"title\">newThread</span><span class=\"params\">(Runnable r)</span> </span>&#123;</span><br><span class=\"line\">        Thread thread = <span class=\"keyword\">new</span> Thread(r);</span><br><span class=\"line\">        thread.setName(<span class=\"string\">\"client-transaction-msg-check-thread\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> thread;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.setExecutorService(executorService);</span><br><span class=\"line\">producer.setTransactionListener(transactionListener);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\">String[] tags = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"TagB\"</span>, <span class=\"string\">\"TagC\"</span>, <span class=\"string\">\"TagD\"</span>, <span class=\"string\">\"TagE\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Message msg =<span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest1234\"</span>, tags[i % tags.length], <span class=\"string\">\"KEY\"</span> + i,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">        SendResult sendResult = producer.sendMessageInTransaction(msg, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\"></span><br><span class=\"line\">        Thread.sleep(<span class=\"number\">10</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (MQClientException | UnsupportedEncodingException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100000</span>; i++) &#123;</span><br><span class=\"line\">    Thread.sleep(<span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>实现TransactionListener接口</p>\n<p><strong>executeLocalTransaction</strong>：方法用于在发送Half消息成功时执行的本地事务。它返回三种事务状态之一。</p>\n<p><strong>checkLocalTransaction</strong>：方法用于检查本地事务状态并响应MQ检查请求。它返回三种事务状态之一。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TransactionListenerImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">TransactionListener</span> </span>&#123;</span><br><span class=\"line\">   <span class=\"keyword\">private</span> AtomicInteger transactionIndex = <span class=\"keyword\">new</span> AtomicInteger(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">private</span> ConcurrentHashMap&lt;String, Integer&gt; localTrans = <span class=\"keyword\">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"meta\">@Override</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> LocalTransactionState <span class=\"title\">executeLocalTransaction</span><span class=\"params\">(Message msg, Object arg)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> value = transactionIndex.getAndIncrement();</span><br><span class=\"line\">       <span class=\"keyword\">int</span> status = value % <span class=\"number\">3</span>;</span><br><span class=\"line\">       localTrans.put(msg.getTransactionId(), status);</span><br><span class=\"line\">       <span class=\"keyword\">return</span> LocalTransactionState.UNKNOW;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"meta\">@Override</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> LocalTransactionState <span class=\"title\">checkLocalTransaction</span><span class=\"params\">(MessageExt msg)</span> </span>&#123;</span><br><span class=\"line\">       Integer status = localTrans.get(msg.getTransactionId());</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (<span class=\"keyword\">null</span> != status) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">switch</span> (status) &#123;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">0</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.UNKNOW;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">1</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">2</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-RocketMQ事务消息设计\"><a href=\"#2-2-RocketMQ事务消息设计\" class=\"headerlink\" title=\"2.2 RocketMQ事务消息设计\"></a>2.2 RocketMQ事务消息设计</h3><p>事务消息作为一种异步确保型事务，  将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示：</p>\n<p><img src=\"/images/rocketmq/交互流程.png\" alt=\"交互流程\"></p>\n<p>1.事务发起方首先发送 prepare 消息到 MQ。</p>\n<p>2.再发送 prepare 消息成功后执行本地事务。</p>\n<p>3.根据本地事务执行结果返回 commit 或者是 rollback。</p>\n<p>4.如果消息是 rollback，MQ 将删除该 prepare 消息不进行下发，如果是 commit 消息，MQ 将会把这个消息发送给 consumer 端。</p>\n<p><font color=\"red\">5.如果执行本地事务过程中，执行端挂掉，或者超时，MQ 将会不停的询问其同组的其他 producer 来获取状态</font>。 </p>\n<p>6.consumer 端的消费成功机制有 MQ 保证。</p>\n<h3 id=\"2-3-RocketMQ事务消息实现\"><a href=\"#2-3-RocketMQ事务消息实现\" class=\"headerlink\" title=\"2.3 RocketMQ事务消息实现\"></a>2.3 RocketMQ事务消息实现</h3><p>RocketMQ 事务消息在实现上充分利用了 RocketMQ 本身机制，在实现零依赖的基础上，同样实现了高性能、可扩展、全异步等一系列特性。</p>\n<p>在具体实现上，RocketMQ 通过使用 Half Topic 以及 Operation Topic 两个内部队列来存储事务消息推进状态，如下图所示：</p>\n<p><img src=\"/images/rocketmq/事务消息实现.png\" alt=\"事务消息实现\"></p>\n<p>其中，Half Topic 对应队列中存放着 prepare 消息，Operation Topic 对应的队列则存放了 prepare message 对应的 commit/rollback 消息，消息体中则是 prepare message 对应的 offset，服务端通过比对两个队列的差值来找到尚未提交的超时事务，进行回查。</p>\n<p>在具体实现上，事务消息作为普通消息的一个应用场景，在实现过程中进行了分层抽象，从而避免了对 RocketMQ 原有存储机制的修改，如下图所示：</p>\n<p><img src=\"/images/rocketmq/存储机制.png\" alt=\"存储机制\"></p>\n<p>从用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态即可；而在 service 层，则对事务消息的两阶段提交进行了抽象，同时针对超时事务实现了回查逻辑，通过不断扫描当前事务推进状态，来不断反向请求 Producer 端获取超时事务的执行状态，在避免事务挂起的同时，也避免了 Producer 端的单点故障。而在存储层，RocketMQ 通过 Bridge 封装了与底层队列存储的相关操作，用以操作两个对应的内部队列，用户也可以依赖其他存储介质实现自己的 service，RocketMQ 会通过 ServiceProvider 加载进来。</p>\n<p>从上述事务消息设计中可以看到，RocketMQ 事务消息较好的解决了事务的最终一致性问题，事务发起方仅需要关注本地事务执行以及实现回查接口给出事务状态判定等实现，而且在上游事务峰值高时，可以通过消息队列，避免对下游服务产生过大压力。</p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><p>RocketMQ官方文档： <a href=\"http://rocketmq.apache.org/docs/quick-start/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/docs/quick-start/</a></p>\n<p>RocketMQ 4.3正式发布，支持分布式事务：<br><a href=\"https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&amp;mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&amp;source=41#wechat_redirect\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&amp;mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&amp;source=41#wechat_redirect</a></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"1-RocketMQ概述\"><a href=\"#1-RocketMQ概述\" class=\"headerlink\" title=\"1. RocketMQ概述\"></a>1. RocketMQ概述</h2><p>“根据我们的研究，随着使用的队列和虚拟主题的增加，ActiveMQ IO模块成为瓶颈。我们尽力通过节流，断路器或降级解决这个问题，但效果不佳。因此，我们开始关注当时流行的消息传递解决方案Kafka。不幸的是，Kafka无法满足我们的要求，特别是在低延迟和高可靠性方面，详见 <a href=\"http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/rocketmq/how-to-support-more-queues-in-rocketmq/</a> ”<br>","more":"</p>\n<p><img src=\"/images/rocketmq/rmq-basic-arc.png\" alt=\"arc\"></p>\n<p>RocketMQ有三种方式发送消息：可靠的同步(reliable synchronous),可靠的异步(reliable asynchronous)和单向传输(one-way transmission)。</p>\n<h3 id=\"1-1-同步发送producer-send\"><a href=\"#1-1-同步发送producer-send\" class=\"headerlink\" title=\"1.1 同步发送producer.send\"></a>1.1 同步发送producer.send</h3><p>可靠的同步传输用于广泛的场景，如重要的通知消息，短信通知，短信营销系统等。</p>\n<p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,(<span class=\"string\">\"Hello RocketMQ \"</span> +i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//Call send message to deliver message to one of brokers.</span></span><br><span class=\"line\">    SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">consumer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"*\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"%s Receive New Messages: %s %n\"</span>, Thread.currentThread().getName(), msgs);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-2-异步发送producer-send-msg-new-SendCallback\"><a href=\"#1-2-异步发送producer-send-msg-new-SendCallback\" class=\"headerlink\" title=\"1.2 异步发送producer.send(msg, new SendCallback())\"></a>1.2 异步发送producer.send(msg, new SendCallback())</h3><p>异步传输通常用于响应时间敏感的业务场景。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\">producer.setRetryTimesWhenSendAsyncFailed(<span class=\"number\">0</span>);</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">        <span class=\"keyword\">final</span> <span class=\"keyword\">int</span> index = i;</span><br><span class=\"line\">        <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">        Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,<span class=\"string\">\"OrderID188\"</span>,<span class=\"string\">\"Hello world\"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"></span><br><span class=\"line\">        producer.send(msg, <span class=\"keyword\">new</span> SendCallback() &#123;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onSuccess</span><span class=\"params\">(SendResult sendResult)</span> </span>&#123;</span><br><span class=\"line\">                System.out.printf(<span class=\"string\">\"%-10d OK %s %n\"</span>, index,</span><br><span class=\"line\">                    sendResult.getMsgId());</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"meta\">@Override</span></span><br><span class=\"line\">            <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onException</span><span class=\"params\">(Throwable e)</span> </span>&#123;</span><br><span class=\"line\">                System.out.printf(<span class=\"string\">\"%-10d Exception %s %n\"</span>, index, e);</span><br><span class=\"line\">                e.printStackTrace();</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-3-单向发送producer-sendOneway\"><a href=\"#1-3-单向发送producer-sendOneway\" class=\"headerlink\" title=\"1.3 单向发送producer.sendOneway\"></a>1.3 单向发送producer.sendOneway</h3><p>单向传输用于需要中等可靠性的情况，例如日志收集。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.setNamesrvAddr(<span class=\"string\">\"localhost:9876\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,(<span class=\"string\">\"Hello RocketMQ \"</span> +i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//Call send message to deliver message to one of brokers.</span></span><br><span class=\"line\">    producer.sendOneway(msg);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-分区发送producer-send-msg-new-MessageQueueSelector\"><a href=\"#1-4-分区发送producer-send-msg-new-MessageQueueSelector\" class=\"headerlink\" title=\"1.4 分区发送producer.send(msg, new MessageQueueSelector())\"></a>1.4 分区发送producer.send(msg, new MessageQueueSelector())</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\">String[] tags = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"TagB\"</span>, <span class=\"string\">\"TagC\"</span>, <span class=\"string\">\"TagD\"</span>, <span class=\"string\">\"TagE\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> orderId = i % <span class=\"number\">10</span>;</span><br><span class=\"line\">    <span class=\"comment\">//Create a message instance, specifying topic, tag and message body.</span></span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTestjjj\"</span>, tags[i % tags.length], <span class=\"string\">\"KEY\"</span> + i,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"></span><br><span class=\"line\">    SendResult sendResult = producer.send(msg, <span class=\"keyword\">new</span> MessageQueueSelector() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> MessageQueue <span class=\"title\">select</span><span class=\"params\">(List&lt;MessageQueue&gt; mqs, Message msg, Object arg)</span> </span>&#123;</span><br><span class=\"line\">        Integer id = (Integer) arg;</span><br><span class=\"line\">        <span class=\"keyword\">int</span> index = id % mqs.size();</span><br><span class=\"line\">        <span class=\"keyword\">return</span> mqs.get(index);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    &#125;, orderId);</span><br><span class=\"line\"></span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"TagA || TagC || TagD\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerOrderly() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    AtomicLong consumeTimes = <span class=\"keyword\">new</span> AtomicLong(<span class=\"number\">0</span>);</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeOrderlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,ConsumeOrderlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        context.setAutoCommit(<span class=\"keyword\">false</span>);</span><br><span class=\"line\">        System.out.printf(Thread.currentThread().getName() + <span class=\"string\">\" Receive New Messages: \"</span> + msgs + <span class=\"string\">\"%n\"</span>);</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">this</span>.consumeTimes.incrementAndGet();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">2</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUCCESS;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">3</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.ROLLBACK;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">4</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.COMMIT;</span><br><span class=\"line\">        &#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> ((<span class=\"keyword\">this</span>.consumeTimes.get() % <span class=\"number\">5</span>) == <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">            context.setSuspendCurrentQueueTimeMillis(<span class=\"number\">3000</span>);</span><br><span class=\"line\">            <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeOrderlyStatus.SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Consumer Started.%n\"</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-5-广播消费consumer-setMessageModel\"><a href=\"#1-5-广播消费consumer-setMessageModel\" class=\"headerlink\" title=\"1.5 广播消费consumer.setMessageModel\"></a>1.5 广播消费consumer.setMessageModel</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"ProducerGroupName\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100</span>; i++)&#123;</span><br><span class=\"line\">    Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,<span class=\"string\">\"TagA\"</span>,<span class=\"string\">\"OrderID188\"</span>,<span class=\"string\">\"Hello world\"</span>.getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">    SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"example_group_name\"</span>);</span><br><span class=\"line\">consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//set to broadcast mode</span></span><br><span class=\"line\">consumer.setMessageModel(MessageModel.BROADCASTING);</span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, <span class=\"string\">\"TagA || TagC || TagD\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(Thread.currentThread().getName() + <span class=\"string\">\" Receive New Messages: \"</span> + msgs + <span class=\"string\">\"%n\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Broadcast Consumer Started.%n\"</span>);</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-6-延迟发送message-setDelayTimeLevel\"><a href=\"#1-6-延迟发送message-setDelayTimeLevel\" class=\"headerlink\" title=\"1.6 延迟发送message.setDelayTimeLevel\"></a>1.6 延迟发送message.setDelayTimeLevel</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"ExampleProducerGroup\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">int</span> totalMessagesToSend = <span class=\"number\">100</span>;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; totalMessagesToSend; i++) &#123;</span><br><span class=\"line\"> Message message = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TestTopic\"</span>, (<span class=\"string\">\"Hello scheduled message \"</span> + i).getBytes());</span><br><span class=\"line\"></span><br><span class=\"line\"> <span class=\"comment\">// This message will be delivered to consumer 10 seconds later.</span></span><br><span class=\"line\"> message.setDelayTimeLevel(<span class=\"number\">3</span>);</span><br><span class=\"line\"> producer.send(message);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"ExampleConsumer\"</span>);</span><br><span class=\"line\"><span class=\"comment\">// Subscribe topics</span></span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TestTopic\"</span>, <span class=\"string\">\"*\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// Register message listener</span></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\"> <span class=\"meta\">@Override</span></span><br><span class=\"line\"> <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">     <span class=\"keyword\">for</span> (MessageExt message : messages) &#123;</span><br><span class=\"line\">         <span class=\"comment\">// Print approximate delay time period</span></span><br><span class=\"line\">         System.out.println(<span class=\"string\">\"Receive message[msgId=\"</span> + message.getMsgId() + <span class=\"string\">\"] \"</span></span><br><span class=\"line\">                 + (System.currentTimeMillis() - message.getStoreTimestamp()) + <span class=\"string\">\"ms later\"</span>);</span><br><span class=\"line\">     &#125;</span><br><span class=\"line\">     <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\"> &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-7-批量发送producer-send-new-ArrayList-lt-gt\"><a href=\"#1-7-批量发送producer-send-new-ArrayList-lt-gt\" class=\"headerlink\" title=\"1.7 批量发送producer.send(new ArrayList&lt;&gt;())\"></a>1.7 批量发送producer.send(new ArrayList&lt;&gt;())</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">String topic = <span class=\"string\">\"BatchTest\"</span>;</span><br><span class=\"line\">List&lt;Message&gt; messages = <span class=\"keyword\">new</span> ArrayList&lt;&gt;();</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID001\"</span>, <span class=\"string\">\"Hello world 0\"</span>.getBytes()));</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID002\"</span>, <span class=\"string\">\"Hello world 1\"</span>.getBytes()));</span><br><span class=\"line\">messages.add(<span class=\"keyword\">new</span> Message(topic, <span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"OrderID003\"</span>, <span class=\"string\">\"Hello world 2\"</span>.getBytes()));</span><br><span class=\"line\"><span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">    producer.send(messages);</span><br><span class=\"line\">&#125; <span class=\"keyword\">catch</span> (Exception e) &#123;</span><br><span class=\"line\">    e.printStackTrace();</span><br><span class=\"line\">    <span class=\"comment\">//handle the error</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>只有在发送大批量时，复杂性才会增加，您可能不确定它是否超出了大小限制（1MiB）。</p>\n<h3 id=\"1-8-消费过滤MessageSelector-bySql\"><a href=\"#1-8-消费过滤MessageSelector-bySql\" class=\"headerlink\" title=\"1.8 消费过滤MessageSelector.bySql\"></a>1.8 消费过滤MessageSelector.bySql</h3><p>发送消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQProducer producer = <span class=\"keyword\">new</span> DefaultMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\">Message msg = <span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest\"</span>,tag,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\"><span class=\"comment\">// Set some properties.</span></span><br><span class=\"line\">msg.putUserProperty(<span class=\"string\">\"a\"</span>, String.valueOf(i));</span><br><span class=\"line\"></span><br><span class=\"line\">SendResult sendResult = producer.send(msg);</span><br><span class=\"line\">   </span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>接收消息:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">DefaultMQPushConsumer consumer = <span class=\"keyword\">new</span> DefaultMQPushConsumer(<span class=\"string\">\"please_rename_unique_group_name_4\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// only subsribe messages have property a, also a &gt;=0 and a &lt;= 3</span></span><br><span class=\"line\">consumer.subscribe(<span class=\"string\">\"TopicTest\"</span>, MessageSelector.bySql(<span class=\"string\">\"a between 0 and 3\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.registerMessageListener(<span class=\"keyword\">new</span> MessageListenerConcurrently() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> ConsumeConcurrentlyStatus <span class=\"title\">consumeMessage</span><span class=\"params\">(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context)</span> </span>&#123;</span><br><span class=\"line\">        <span class=\"keyword\">return</span> ConsumeConcurrentlyStatus.CONSUME_SUCCESS;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\">consumer.start();</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-基于OpenMessaging收发消息\"><a href=\"#2-基于OpenMessaging收发消息\" class=\"headerlink\" title=\"2. 基于OpenMessaging收发消息\"></a>2. 基于OpenMessaging收发消息</h2><h3 id=\"2-1-同步发送producer-send\"><a href=\"#2-1-同步发送producer-send\" class=\"headerlink\" title=\"2.1 同步发送producer.send\"></a>2.1 同步发送producer.send</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    Message message = producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>)));</span><br><span class=\"line\">    SendResult sendResult = producer.send(message);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Send sync message OK, msgId: %s%n\"</span>, sendResult.messageId());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-异步发送producer-sendAsync\"><a href=\"#2-2-异步发送producer-sendAsync\" class=\"headerlink\" title=\"2.2 异步发送producer.sendAsync\"></a>2.2 异步发送producer.sendAsync</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    <span class=\"keyword\">final</span> Promise&lt;SendResult&gt; result = producer.sendAsync(producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>))));</span><br><span class=\"line\">    result.addListener(<span class=\"keyword\">new</span> PromiseListener&lt;SendResult&gt;() &#123;</span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">operationCompleted</span><span class=\"params\">(Promise&lt;SendResult&gt; promise)</span> </span>&#123;</span><br><span class=\"line\">            System.out.printf(<span class=\"string\">\"Send async message OK, msgId: %s%n\"</span>, promise.get().messageId());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"meta\">@Override</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">operationFailed</span><span class=\"params\">(Promise&lt;SendResult&gt; promise)</span> </span>&#123;</span><br><span class=\"line\">            System.out.printf(<span class=\"string\">\"Send async message Failed, error: %s%n\"</span>, promise.getThrowable().getMessage());</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-3-单向发送producer-sendOneway\"><a href=\"#2-3-单向发送producer-sendOneway\" class=\"headerlink\" title=\"2.3 单向发送producer.sendOneway\"></a>2.3 单向发送producer.sendOneway</h3><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> Producer producer = messagingAccessPoint.createProducer();</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Producer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    producer.sendOneway(producer.createBytesMessageToTopic(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"string\">\"OMS_HELLO_BODY\"</span>.getBytes(Charset.forName(<span class=\"string\">\"UTF-8\"</span>))));</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Send oneway message OK%n\"</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">producer.shutdown();</span><br><span class=\"line\">messagingAccessPoint.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-4-消费消息consumer-poll\"><a href=\"#2-4-消费消息consumer-poll\" class=\"headerlink\" title=\"2.4 消费消息consumer.poll\"></a>2.4 消费消息consumer.poll</h3><p>OMSPullConsumer:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> PullConsumer consumer = messagingAccessPoint.createPullConsumer(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>,</span><br><span class=\"line\">    OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, <span class=\"string\">\"OMS_CONSUMER\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"Consumer startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Message message = consumer.poll();</span><br><span class=\"line\"><span class=\"keyword\">if</span> (message != <span class=\"keyword\">null</span>) &#123;</span><br><span class=\"line\">    String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);</span><br><span class=\"line\">    System.out.printf(<span class=\"string\">\"Received one message: %s%n\"</span>, msgId);</span><br><span class=\"line\">    consumer.ack(msgId);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.shutdown();</span><br><span class=\"line\">messagingAccessPoint.shutdown();</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-5-消费消息consumer-attachQueue\"><a href=\"#2-5-消费消息consumer-attachQueue\" class=\"headerlink\" title=\"2.5 消费消息consumer.attachQueue\"></a>2.5 消费消息consumer.attachQueue</h3><p>OMSPushConsumer:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">final</span> MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory.getMessagingAccessPoint(<span class=\"string\">\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">final</span> PushConsumer consumer = messagingAccessPoint.</span><br><span class=\"line\">    createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, <span class=\"string\">\"OMS_CONSUMER\"</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">messagingAccessPoint.startup();</span><br><span class=\"line\">System.out.printf(<span class=\"string\">\"MessagingAccessPoint startup OK%n\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">Runtime.getRuntime().addShutdownHook(<span class=\"keyword\">new</span> Thread(<span class=\"keyword\">new</span> Runnable() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">run</span><span class=\"params\">()</span> </span>&#123;</span><br><span class=\"line\">        consumer.shutdown();</span><br><span class=\"line\">        messagingAccessPoint.shutdown();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;));</span><br><span class=\"line\"></span><br><span class=\"line\">consumer.attachQueue(<span class=\"string\">\"OMS_HELLO_TOPIC\"</span>, <span class=\"keyword\">new</span> MessageListener() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title\">onMessage</span><span class=\"params\">(<span class=\"keyword\">final</span> Message message, <span class=\"keyword\">final</span> ReceivedMessageContext context)</span> </span>&#123;</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"Received one message: %s%n\"</span>, message.headers().getString(MessageHeader.MESSAGE_ID));</span><br><span class=\"line\">        context.ack();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-RocketMQ事务消息\"><a href=\"#2-RocketMQ事务消息\" class=\"headerlink\" title=\"2. RocketMQ事务消息\"></a>2. RocketMQ事务消息</h2><p>RocketMQ 事务消息设计则主要是为了解决 Producer 端的消息发送与本地事务执行的原子性问题，RocketMQ 的设计中 broker 与 producer 端的双向通信能力，使得 broker 天生可以作为一个事务协调者存在；而 RocketMQ 本身提供的存储机制，则为事务消息提供了持久化能力；RocketMQ 的高可用机制以及可靠消息设计，则为事务消息在系统在发生异常时，依然能够保证事务的最终一致性达成。</p>\n<h3 id=\"2-1-发送事务性消息\"><a href=\"#2-1-发送事务性消息\" class=\"headerlink\" title=\"2.1 发送事务性消息\"></a>2.1 发送事务性消息</h3><p>事务性消息有三种状态：</p>\n<p>（1）TransactionStatus.CommitTransaction：提交事务，这意味着允许消费者使用此消息。</p>\n<p>（2）TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除而不允许使用。</p>\n<p>（3）TransactionStatus.Unknown：中间状态，表示需要MQ检查以确定状态。</p>\n<p>使用TransactionMQProducer类创建生成器客户端，并指定唯一的producerGroup，并且可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果回复MQ，最终结果状态。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TransactionListener transactionListener = <span class=\"keyword\">new</span> TransactionListenerImpl();</span><br><span class=\"line\">TransactionMQProducer producer = <span class=\"keyword\">new</span> TransactionMQProducer(<span class=\"string\">\"please_rename_unique_group_name\"</span>);</span><br><span class=\"line\">ExecutorService executorService = <span class=\"keyword\">new</span> ThreadPoolExecutor(<span class=\"number\">2</span>, <span class=\"number\">5</span>, <span class=\"number\">100</span>, TimeUnit.SECONDS, <span class=\"keyword\">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class=\"number\">2000</span>), <span class=\"keyword\">new</span> ThreadFactory() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">public</span> Thread <span class=\"title\">newThread</span><span class=\"params\">(Runnable r)</span> </span>&#123;</span><br><span class=\"line\">        Thread thread = <span class=\"keyword\">new</span> Thread(r);</span><br><span class=\"line\">        thread.setName(<span class=\"string\">\"client-transaction-msg-check-thread\"</span>);</span><br><span class=\"line\">        <span class=\"keyword\">return</span> thread;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br><span class=\"line\"></span><br><span class=\"line\">producer.setExecutorService(executorService);</span><br><span class=\"line\">producer.setTransactionListener(transactionListener);</span><br><span class=\"line\">producer.start();</span><br><span class=\"line\"></span><br><span class=\"line\">String[] tags = <span class=\"keyword\">new</span> String[] &#123;<span class=\"string\">\"TagA\"</span>, <span class=\"string\">\"TagB\"</span>, <span class=\"string\">\"TagC\"</span>, <span class=\"string\">\"TagD\"</span>, <span class=\"string\">\"TagE\"</span>&#125;;</span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">10</span>; i++) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">try</span> &#123;</span><br><span class=\"line\">        Message msg =<span class=\"keyword\">new</span> Message(<span class=\"string\">\"TopicTest1234\"</span>, tags[i % tags.length], <span class=\"string\">\"KEY\"</span> + i,(<span class=\"string\">\"Hello RocketMQ \"</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class=\"line\">        SendResult sendResult = producer.sendMessageInTransaction(msg, <span class=\"keyword\">null</span>);</span><br><span class=\"line\">        System.out.printf(<span class=\"string\">\"%s%n\"</span>, sendResult);</span><br><span class=\"line\"></span><br><span class=\"line\">        Thread.sleep(<span class=\"number\">10</span>);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">catch</span> (MQClientException | UnsupportedEncodingException e) &#123;</span><br><span class=\"line\">        e.printStackTrace();</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; <span class=\"number\">100000</span>; i++) &#123;</span><br><span class=\"line\">    Thread.sleep(<span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">producer.shutdown();</span><br></pre></td></tr></table></figure>\n<p>实现TransactionListener接口</p>\n<p><strong>executeLocalTransaction</strong>：方法用于在发送Half消息成功时执行的本地事务。它返回三种事务状态之一。</p>\n<p><strong>checkLocalTransaction</strong>：方法用于检查本地事务状态并响应MQ检查请求。它返回三种事务状态之一。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">TransactionListenerImpl</span> <span class=\"keyword\">implements</span> <span class=\"title\">TransactionListener</span> </span>&#123;</span><br><span class=\"line\">   <span class=\"keyword\">private</span> AtomicInteger transactionIndex = <span class=\"keyword\">new</span> AtomicInteger(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">private</span> ConcurrentHashMap&lt;String, Integer&gt; localTrans = <span class=\"keyword\">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"meta\">@Override</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> LocalTransactionState <span class=\"title\">executeLocalTransaction</span><span class=\"params\">(Message msg, Object arg)</span> </span>&#123;</span><br><span class=\"line\">       <span class=\"keyword\">int</span> value = transactionIndex.getAndIncrement();</span><br><span class=\"line\">       <span class=\"keyword\">int</span> status = value % <span class=\"number\">3</span>;</span><br><span class=\"line\">       localTrans.put(msg.getTransactionId(), status);</span><br><span class=\"line\">       <span class=\"keyword\">return</span> LocalTransactionState.UNKNOW;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"meta\">@Override</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">public</span> LocalTransactionState <span class=\"title\">checkLocalTransaction</span><span class=\"params\">(MessageExt msg)</span> </span>&#123;</span><br><span class=\"line\">       Integer status = localTrans.get(msg.getTransactionId());</span><br><span class=\"line\">       <span class=\"keyword\">if</span> (<span class=\"keyword\">null</span> != status) &#123;</span><br><span class=\"line\">           <span class=\"keyword\">switch</span> (status) &#123;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">0</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.UNKNOW;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">1</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class=\"line\">               <span class=\"keyword\">case</span> <span class=\"number\">2</span>:</span><br><span class=\"line\">                   <span class=\"keyword\">return</span> LocalTransactionState.ROLLBACK_MESSAGE;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">       <span class=\"keyword\">return</span> LocalTransactionState.COMMIT_MESSAGE;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-RocketMQ事务消息设计\"><a href=\"#2-2-RocketMQ事务消息设计\" class=\"headerlink\" title=\"2.2 RocketMQ事务消息设计\"></a>2.2 RocketMQ事务消息设计</h3><p>事务消息作为一种异步确保型事务，  将两个事务分支通过 MQ 进行异步解耦，RocketMQ 事务消息的设计流程同样借鉴了两阶段提交理论，整体交互流程如下图所示：</p>\n<p><img src=\"/images/rocketmq/交互流程.png\" alt=\"交互流程\"></p>\n<p>1.事务发起方首先发送 prepare 消息到 MQ。</p>\n<p>2.再发送 prepare 消息成功后执行本地事务。</p>\n<p>3.根据本地事务执行结果返回 commit 或者是 rollback。</p>\n<p>4.如果消息是 rollback，MQ 将删除该 prepare 消息不进行下发，如果是 commit 消息，MQ 将会把这个消息发送给 consumer 端。</p>\n<p><font color=\"red\">5.如果执行本地事务过程中，执行端挂掉，或者超时，MQ 将会不停的询问其同组的其他 producer 来获取状态</font>。 </p>\n<p>6.consumer 端的消费成功机制有 MQ 保证。</p>\n<h3 id=\"2-3-RocketMQ事务消息实现\"><a href=\"#2-3-RocketMQ事务消息实现\" class=\"headerlink\" title=\"2.3 RocketMQ事务消息实现\"></a>2.3 RocketMQ事务消息实现</h3><p>RocketMQ 事务消息在实现上充分利用了 RocketMQ 本身机制，在实现零依赖的基础上，同样实现了高性能、可扩展、全异步等一系列特性。</p>\n<p>在具体实现上，RocketMQ 通过使用 Half Topic 以及 Operation Topic 两个内部队列来存储事务消息推进状态，如下图所示：</p>\n<p><img src=\"/images/rocketmq/事务消息实现.png\" alt=\"事务消息实现\"></p>\n<p>其中，Half Topic 对应队列中存放着 prepare 消息，Operation Topic 对应的队列则存放了 prepare message 对应的 commit/rollback 消息，消息体中则是 prepare message 对应的 offset，服务端通过比对两个队列的差值来找到尚未提交的超时事务，进行回查。</p>\n<p>在具体实现上，事务消息作为普通消息的一个应用场景，在实现过程中进行了分层抽象，从而避免了对 RocketMQ 原有存储机制的修改，如下图所示：</p>\n<p><img src=\"/images/rocketmq/存储机制.png\" alt=\"存储机制\"></p>\n<p>从用户侧来说，用户需要分别实现本地事务执行以及本地事务回查方法，因此只需关注本地事务的执行状态即可；而在 service 层，则对事务消息的两阶段提交进行了抽象，同时针对超时事务实现了回查逻辑，通过不断扫描当前事务推进状态，来不断反向请求 Producer 端获取超时事务的执行状态，在避免事务挂起的同时，也避免了 Producer 端的单点故障。而在存储层，RocketMQ 通过 Bridge 封装了与底层队列存储的相关操作，用以操作两个对应的内部队列，用户也可以依赖其他存储介质实现自己的 service，RocketMQ 会通过 ServiceProvider 加载进来。</p>\n<p>从上述事务消息设计中可以看到，RocketMQ 事务消息较好的解决了事务的最终一致性问题，事务发起方仅需要关注本地事务执行以及实现回查接口给出事务状态判定等实现，而且在上游事务峰值高时，可以通过消息队列，避免对下游服务产生过大压力。</p>\n<h2 id=\"3-参考资料\"><a href=\"#3-参考资料\" class=\"headerlink\" title=\"3.参考资料\"></a>3.参考资料</h2><p>RocketMQ官方文档： <a href=\"http://rocketmq.apache.org/docs/quick-start/\" target=\"_blank\" rel=\"noopener\">http://rocketmq.apache.org/docs/quick-start/</a></p>\n<p>RocketMQ 4.3正式发布，支持分布式事务：<br><a href=\"https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&amp;mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&amp;source=41#wechat_redirect\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&amp;mid=2247488985&amp;idx=1&amp;sn=cafd8ce4b47bf098c7e87846318eff4d&amp;source=41#wechat_redirect</a></p>"},{"layout":"lay_post","title":"双高配置之Nginx+Keepalived整理","date":"2016-03-13T12:59:00.000Z","author":"lvyafei","_content":"\n## 0.概述\n\n前几天发的一篇\"系统架构总结之高可用高负载\"文章里面讲到的双高策略，里面包含的详细配置，在这里整理出来以做备忘。\n\n<!-- more -->\n\n## 1.Nginx安装\n\n版本:1.9.11\n\n依赖pcre-8.38.tar.gz\n\n<font color=\"blue\">安装:</font>\n\n\t./configure --with-pcre=/aclome/pcre-8.38 --prefix=/aclome/nginx\n\n\tMake\n\n\tMake install\n\n<font color=\"blue\">配置负载策略:</font>\n\n\thttp{\n\t......\n\tupstream myServer{\n\t server 199.31.165.61:8080;\n\t server 199.31.165.62:8080;\n\t}\n\tserver{\n\t  listen   8001;\n\t  location / {\n        root  html;\n        index index.html index.htm;\n        proxy_pass http://myServer;\n\t  }\n\t}\n\t......\n\t}\n\n\n<font color=\"blue\">启动</font>\n\n\t/sbin/nginx\n\n<font color=\"blue\">停止</font>\n\n\tps -ef |grep nginx\n\n\tkill -9 <pid>\n\n<font color=\"blue\">访问</font>\n\nhttp://199.31.165.61:8001  可以在61:8080和62:8080之间跳转\n\n**nginx的upstream目前支持的5种方式的分配**\n\n1、轮询（默认）\n\n每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\n\nupstream backserver {\n\nserver 192.168.0.14;\n\nserver 192.168.0.15;\n\n}\n\n2、weight\n\n指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n\nupstream backserver {\n\nserver 192.168.0.14 weight=10;\n\nserver 192.168.0.15 weight=10;\n\n}\n\n3、ip_hash\n\n每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。\n\nupstream backserver {\n\nip_hash;\n\nserver 192.168.0.14:88;\n\nserver 192.168.0.15:80;\n\n}\n\n4、fair（第三方）\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n\nupstream backserver {\n\nserver server1;\n\nserver server2;\n\nfair;\n\n}\n\n5、url_hash（第三方）\n\n按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。\n\nupstream backserver {\n\nserver squid1:3128;\n\nserver squid2:3128;\n\nhash $request_uri;\n\nhash_method crc32;\n\n}\n\n在需要使用负载均衡的server中增加\n\nproxy_pass http://backserver/ ;\n\nupstream backserver{\n\nip_hash;\n\nserver 127.0.0.1:9090 down; (down 表示单前的server暂时不参与负载)\n\nserver 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大)\n\nserver 127.0.0.1:6060;\n\nserver 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)\n\n}\n\nmax_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\n\n## 2.Keepalived安装\n\n版本:1.2.19\n\n<font color=\"blue\">安装</font>\n\n\t./configure --disable-fwmark --prefix=/aclome/keepalived\n\n\t//使用root安装指定如下:\n\t\n\t./configure --prefix=/usr --sysconf=/etc\n\n\tmake \n\n\tmake install\n\n<font color=\"blue\">配置</font>\n\n**主:**\n\n\tvi /etc/keepalived/keepalived.conf\n\n\tglobal_defs{\n\t  smtp_server 127.0.0.1\n\t}\n\tvrrp_instance_VI_1{\n\t  state MASTER \n\t  interface eth1\n\t  priority 100\n\t  ......\n\t  virtual_ipaddress{\n\t    199.31.165.65\n\t  }\n\t}\n\n**备:**\n\n\tvi /etc/keepalived/keepalived.conf\n\n\tglobal_defs{\n\t  smtp_server 127.0.0.1\n\t}\n\tvrrp_instance_VI_1{\n\t  state BACKUP\n\t  interface eth1\n\t  priority 50\n\t  ......\n\t  virtual_ipaddress{\n\t    199.31.165.65\n\t  }\n\t}\n\n<font color=\"blue\">启动</font>\n\n\tsudo service keepalived start\n\n\tsudo service keepalived status\n\n\tsudo service keepalived stop \n\n<font color=\"blue\">验证</font>\n\n![验证](/images/架构/配置/keepalived验证.png)\n\n## 3.Redis安装\n\n版本:3.0.7\n\n**安装:**\n\n\tMake PREFIX=/aclome/redis install\n\n**配置:** \n\n\tcp /aclome/redis-3.0.7/utils/redis_init_script /aclome/redis/\n\n\tvi redis_init_script\n\n\tEXEC=/aclome/redis/bin/redis-server\n\tCLIEXEC=/aclome/redis/bin/redis-cli\n\n\tcp /aclome/redis-0.0.7/redis.conf /aclome/redis/\n\n\tVi redis.conf\n\n\tdir ./data\n\n\tmkdir data\n\n\tmkdir data/sentinel\n\n**启动：**\n\n\tnohup bin/redis-server conf/redis.conf &\n\n**停止:**\n\n\tbin/redis-cli -p 6379 shutdown\n\n\n**验证状态:**\n\n\tps -ef |grep redis\n\n![验证](/images/架构/配置/redis验证.png)\n\n\n**客户端:**\n\n\t/aclome/redis/bin/redis-cli -p 6379\n\n连接到远程的redis服务器: bin/redis-cli -h 199.31.165.62 -p 6379 get myname\n\n存储KEY/VALUE命令：set myname “lvyafei”\n\n读取Value命令: get myname\n\n删除缓存命令: del myname\n\n批量删除缓存: ./redis-cli -p 6379 KEYS “*” | xargs ./redis-cli -p 6379 DEL\n\n获取所有Key命令: keys *\n\n**Redis-HA方案-Sentinel配置:**\n\n<font color=\"red\">Redis-server端口:6379  Redis-sentinel端口:7031</font>\n\n>1.master-slave配置\n\n只需要在slave上配置redis.conf即可,master不用配置\n\n\tslaveof 199.31.165.61 6379\n\n\tslave-read-only yes\n\n在master,slave上分别启动nohup bin/redis-server conf/redis.conf &\n\n停止master/slave命令:bin/redis-cli -p 6379 shutdown\n\n>2.Sentinel配置\n\n在master/slave上配置sentinel.conf（master/slave相同配置）\n\n\t#######redis-sentinel######################\n\tport 7031\n\n\tdir ./data/sentinel\n\n\tsentinel monitor mymaster 199.31.165.61 6379 1\n\tsentinel down-after-milliseconds mymaster 5000\n\tsentinel parallel-syncs mymaster 1\n\tsentinel failover-timeout mymaster 15000\n\n**启动sentinel：**\n\n分别在master/slave上执行命令：nohup bin/redis-sentinel conf/sentinel.conf &\n\n**3.验证：**\n\n\tBin/redis-cli -p 7031 sentinel masters\n\n停止master:\n\n在master上执行bin/redis-cli -p 6379 shutdown.观察sentinel输出.\n\n停止sentinel:bin/redis-cli -p 7031 shutdown \n\n## 4.Tomcat Session共享配置\n\n拷贝 jar包到tomcat 的libs目录下:\n\n1.x版本：不支持Redis集群\n\n![配置](/images/架构/配置/tomcat-session1.png)\n\n2.x版本：支持Redis集群\n\n![配置](/images/架构/配置/tomcat-session2.png)\n\n配置:vi /tomcat/config/content.xml\n\n<font color=\"red\">注意：1.x版本的包名和2.x版本的包名不一样，且2.x中多的参数1.x版本中不支持。</font>\n\n1.x版本配置:\n\n![配置](/images/架构/配置/tomcat-session3.png)\n\n2.x版本配置：\n\n![配置](/images/架构/配置/tomcat-session4.png)\n\n启动即可，在redis客户端验证存储的KEY/VALUE\n\n## 5.CAS ticket共享 \n\n复制redis-ticket-registry.jar包到 cas/WEB-INF/libs和cas/libs目录下。\n\n编辑cas/WEB-INF/spring-configuration/ticketRegistry.xml文件\n\n![配置](/images/架构/配置/cas-ticket.png)\n","source":"_posts/2016-03-13-双高配置之Nginx+Keepalived整理.md","raw":"---\nlayout: lay_post\ntitle: \"双高配置之Nginx+Keepalived整理\"\ndate: 2016-03-13 20:59:00\ncategories: 架构\ntags: 双高架构\nauthor: lvyafei\n---\n\n## 0.概述\n\n前几天发的一篇\"系统架构总结之高可用高负载\"文章里面讲到的双高策略，里面包含的详细配置，在这里整理出来以做备忘。\n\n<!-- more -->\n\n## 1.Nginx安装\n\n版本:1.9.11\n\n依赖pcre-8.38.tar.gz\n\n<font color=\"blue\">安装:</font>\n\n\t./configure --with-pcre=/aclome/pcre-8.38 --prefix=/aclome/nginx\n\n\tMake\n\n\tMake install\n\n<font color=\"blue\">配置负载策略:</font>\n\n\thttp{\n\t......\n\tupstream myServer{\n\t server 199.31.165.61:8080;\n\t server 199.31.165.62:8080;\n\t}\n\tserver{\n\t  listen   8001;\n\t  location / {\n        root  html;\n        index index.html index.htm;\n        proxy_pass http://myServer;\n\t  }\n\t}\n\t......\n\t}\n\n\n<font color=\"blue\">启动</font>\n\n\t/sbin/nginx\n\n<font color=\"blue\">停止</font>\n\n\tps -ef |grep nginx\n\n\tkill -9 <pid>\n\n<font color=\"blue\">访问</font>\n\nhttp://199.31.165.61:8001  可以在61:8080和62:8080之间跳转\n\n**nginx的upstream目前支持的5种方式的分配**\n\n1、轮询（默认）\n\n每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\n\nupstream backserver {\n\nserver 192.168.0.14;\n\nserver 192.168.0.15;\n\n}\n\n2、weight\n\n指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。\n\nupstream backserver {\n\nserver 192.168.0.14 weight=10;\n\nserver 192.168.0.15 weight=10;\n\n}\n\n3、ip_hash\n\n每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。\n\nupstream backserver {\n\nip_hash;\n\nserver 192.168.0.14:88;\n\nserver 192.168.0.15:80;\n\n}\n\n4、fair（第三方）\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n\nupstream backserver {\n\nserver server1;\n\nserver server2;\n\nfair;\n\n}\n\n5、url_hash（第三方）\n\n按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。\n\nupstream backserver {\n\nserver squid1:3128;\n\nserver squid2:3128;\n\nhash $request_uri;\n\nhash_method crc32;\n\n}\n\n在需要使用负载均衡的server中增加\n\nproxy_pass http://backserver/ ;\n\nupstream backserver{\n\nip_hash;\n\nserver 127.0.0.1:9090 down; (down 表示单前的server暂时不参与负载)\n\nserver 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大)\n\nserver 127.0.0.1:6060;\n\nserver 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)\n\n}\n\nmax_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误。\n\n## 2.Keepalived安装\n\n版本:1.2.19\n\n<font color=\"blue\">安装</font>\n\n\t./configure --disable-fwmark --prefix=/aclome/keepalived\n\n\t//使用root安装指定如下:\n\t\n\t./configure --prefix=/usr --sysconf=/etc\n\n\tmake \n\n\tmake install\n\n<font color=\"blue\">配置</font>\n\n**主:**\n\n\tvi /etc/keepalived/keepalived.conf\n\n\tglobal_defs{\n\t  smtp_server 127.0.0.1\n\t}\n\tvrrp_instance_VI_1{\n\t  state MASTER \n\t  interface eth1\n\t  priority 100\n\t  ......\n\t  virtual_ipaddress{\n\t    199.31.165.65\n\t  }\n\t}\n\n**备:**\n\n\tvi /etc/keepalived/keepalived.conf\n\n\tglobal_defs{\n\t  smtp_server 127.0.0.1\n\t}\n\tvrrp_instance_VI_1{\n\t  state BACKUP\n\t  interface eth1\n\t  priority 50\n\t  ......\n\t  virtual_ipaddress{\n\t    199.31.165.65\n\t  }\n\t}\n\n<font color=\"blue\">启动</font>\n\n\tsudo service keepalived start\n\n\tsudo service keepalived status\n\n\tsudo service keepalived stop \n\n<font color=\"blue\">验证</font>\n\n![验证](/images/架构/配置/keepalived验证.png)\n\n## 3.Redis安装\n\n版本:3.0.7\n\n**安装:**\n\n\tMake PREFIX=/aclome/redis install\n\n**配置:** \n\n\tcp /aclome/redis-3.0.7/utils/redis_init_script /aclome/redis/\n\n\tvi redis_init_script\n\n\tEXEC=/aclome/redis/bin/redis-server\n\tCLIEXEC=/aclome/redis/bin/redis-cli\n\n\tcp /aclome/redis-0.0.7/redis.conf /aclome/redis/\n\n\tVi redis.conf\n\n\tdir ./data\n\n\tmkdir data\n\n\tmkdir data/sentinel\n\n**启动：**\n\n\tnohup bin/redis-server conf/redis.conf &\n\n**停止:**\n\n\tbin/redis-cli -p 6379 shutdown\n\n\n**验证状态:**\n\n\tps -ef |grep redis\n\n![验证](/images/架构/配置/redis验证.png)\n\n\n**客户端:**\n\n\t/aclome/redis/bin/redis-cli -p 6379\n\n连接到远程的redis服务器: bin/redis-cli -h 199.31.165.62 -p 6379 get myname\n\n存储KEY/VALUE命令：set myname “lvyafei”\n\n读取Value命令: get myname\n\n删除缓存命令: del myname\n\n批量删除缓存: ./redis-cli -p 6379 KEYS “*” | xargs ./redis-cli -p 6379 DEL\n\n获取所有Key命令: keys *\n\n**Redis-HA方案-Sentinel配置:**\n\n<font color=\"red\">Redis-server端口:6379  Redis-sentinel端口:7031</font>\n\n>1.master-slave配置\n\n只需要在slave上配置redis.conf即可,master不用配置\n\n\tslaveof 199.31.165.61 6379\n\n\tslave-read-only yes\n\n在master,slave上分别启动nohup bin/redis-server conf/redis.conf &\n\n停止master/slave命令:bin/redis-cli -p 6379 shutdown\n\n>2.Sentinel配置\n\n在master/slave上配置sentinel.conf（master/slave相同配置）\n\n\t#######redis-sentinel######################\n\tport 7031\n\n\tdir ./data/sentinel\n\n\tsentinel monitor mymaster 199.31.165.61 6379 1\n\tsentinel down-after-milliseconds mymaster 5000\n\tsentinel parallel-syncs mymaster 1\n\tsentinel failover-timeout mymaster 15000\n\n**启动sentinel：**\n\n分别在master/slave上执行命令：nohup bin/redis-sentinel conf/sentinel.conf &\n\n**3.验证：**\n\n\tBin/redis-cli -p 7031 sentinel masters\n\n停止master:\n\n在master上执行bin/redis-cli -p 6379 shutdown.观察sentinel输出.\n\n停止sentinel:bin/redis-cli -p 7031 shutdown \n\n## 4.Tomcat Session共享配置\n\n拷贝 jar包到tomcat 的libs目录下:\n\n1.x版本：不支持Redis集群\n\n![配置](/images/架构/配置/tomcat-session1.png)\n\n2.x版本：支持Redis集群\n\n![配置](/images/架构/配置/tomcat-session2.png)\n\n配置:vi /tomcat/config/content.xml\n\n<font color=\"red\">注意：1.x版本的包名和2.x版本的包名不一样，且2.x中多的参数1.x版本中不支持。</font>\n\n1.x版本配置:\n\n![配置](/images/架构/配置/tomcat-session3.png)\n\n2.x版本配置：\n\n![配置](/images/架构/配置/tomcat-session4.png)\n\n启动即可，在redis客户端验证存储的KEY/VALUE\n\n## 5.CAS ticket共享 \n\n复制redis-ticket-registry.jar包到 cas/WEB-INF/libs和cas/libs目录下。\n\n编辑cas/WEB-INF/spring-configuration/ticketRegistry.xml文件\n\n![配置](/images/架构/配置/cas-ticket.png)\n","slug":"2016-03-13-双高配置之Nginx+Keepalived整理","published":1,"updated":"2018-11-29T12:51:24.633Z","comments":1,"photos":[],"link":"","_id":"cjskffogt006w4glm1n56zuw1","content":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>前几天发的一篇”系统架构总结之高可用高负载”文章里面讲到的双高策略，里面包含的详细配置，在这里整理出来以做备忘。</p>\n<a id=\"more\"></a>\n<h2 id=\"1-Nginx安装\"><a href=\"#1-Nginx安装\" class=\"headerlink\" title=\"1.Nginx安装\"></a>1.Nginx安装</h2><p>版本:1.9.11</p>\n<p>依赖pcre-8.38.tar.gz</p>\n<font color=\"blue\">安装:</font>\n\n<pre><code>./configure --with-pcre=/aclome/pcre-8.38 --prefix=/aclome/nginx\n\nMake\n\nMake install\n</code></pre><font color=\"blue\">配置负载策略:</font>\n\n<pre><code>http{\n......\nupstream myServer{\n server 199.31.165.61:8080;\n server 199.31.165.62:8080;\n}\nserver{\n  listen   8001;\n  location / {\n    root  html;\n    index index.html index.htm;\n    proxy_pass http://myServer;\n  }\n}\n......\n}\n</code></pre><font color=\"blue\">启动</font>\n\n<pre><code>/sbin/nginx\n</code></pre><font color=\"blue\">停止</font>\n\n<pre><code>ps -ef |grep nginx\n\nkill -9 &lt;pid&gt;\n</code></pre><font color=\"blue\">访问</font>\n\n<p><a href=\"http://199.31.165.61:8001\" target=\"_blank\" rel=\"noopener\">http://199.31.165.61:8001</a>  可以在61:8080和62:8080之间跳转</p>\n<p><strong>nginx的upstream目前支持的5种方式的分配</strong></p>\n<p>1、轮询（默认）</p>\n<p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p>\n<p>upstream backserver {</p>\n<p>server 192.168.0.14;</p>\n<p>server 192.168.0.15;</p>\n<p>}</p>\n<p>2、weight</p>\n<p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p>\n<p>upstream backserver {</p>\n<p>server 192.168.0.14 weight=10;</p>\n<p>server 192.168.0.15 weight=10;</p>\n<p>}</p>\n<p>3、ip_hash</p>\n<p>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>\n<p>upstream backserver {</p>\n<p>ip_hash;</p>\n<p>server 192.168.0.14:88;</p>\n<p>server 192.168.0.15:80;</p>\n<p>}</p>\n<p>4、fair（第三方）</p>\n<p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p>\n<p>upstream backserver {</p>\n<p>server server1;</p>\n<p>server server2;</p>\n<p>fair;</p>\n<p>}</p>\n<p>5、url_hash（第三方）</p>\n<p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</p>\n<p>upstream backserver {</p>\n<p>server squid1:3128;</p>\n<p>server squid2:3128;</p>\n<p>hash $request_uri;</p>\n<p>hash_method crc32;</p>\n<p>}</p>\n<p>在需要使用负载均衡的server中增加</p>\n<p>proxy_pass <a href=\"http://backserver/\" target=\"_blank\" rel=\"noopener\">http://backserver/</a> ;</p>\n<p>upstream backserver{</p>\n<p>ip_hash;</p>\n<p>server 127.0.0.1:9090 down; (down 表示单前的server暂时不参与负载)</p>\n<p>server 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大)</p>\n<p>server 127.0.0.1:6060;</p>\n<p>server 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)</p>\n<p>}</p>\n<p>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误。</p>\n<h2 id=\"2-Keepalived安装\"><a href=\"#2-Keepalived安装\" class=\"headerlink\" title=\"2.Keepalived安装\"></a>2.Keepalived安装</h2><p>版本:1.2.19</p>\n<font color=\"blue\">安装</font>\n\n<pre><code>./configure --disable-fwmark --prefix=/aclome/keepalived\n\n//使用root安装指定如下:\n\n./configure --prefix=/usr --sysconf=/etc\n\nmake \n\nmake install\n</code></pre><font color=\"blue\">配置</font>\n\n<p><strong>主:</strong></p>\n<pre><code>vi /etc/keepalived/keepalived.conf\n\nglobal_defs{\n  smtp_server 127.0.0.1\n}\nvrrp_instance_VI_1{\n  state MASTER \n  interface eth1\n  priority 100\n  ......\n  virtual_ipaddress{\n    199.31.165.65\n  }\n}\n</code></pre><p><strong>备:</strong></p>\n<pre><code>vi /etc/keepalived/keepalived.conf\n\nglobal_defs{\n  smtp_server 127.0.0.1\n}\nvrrp_instance_VI_1{\n  state BACKUP\n  interface eth1\n  priority 50\n  ......\n  virtual_ipaddress{\n    199.31.165.65\n  }\n}\n</code></pre><font color=\"blue\">启动</font>\n\n<pre><code>sudo service keepalived start\n\nsudo service keepalived status\n\nsudo service keepalived stop \n</code></pre><font color=\"blue\">验证</font>\n\n<p><img src=\"/images/架构/配置/keepalived验证.png\" alt=\"验证\"></p>\n<h2 id=\"3-Redis安装\"><a href=\"#3-Redis安装\" class=\"headerlink\" title=\"3.Redis安装\"></a>3.Redis安装</h2><p>版本:3.0.7</p>\n<p><strong>安装:</strong></p>\n<pre><code>Make PREFIX=/aclome/redis install\n</code></pre><p><strong>配置:</strong> </p>\n<pre><code>cp /aclome/redis-3.0.7/utils/redis_init_script /aclome/redis/\n\nvi redis_init_script\n\nEXEC=/aclome/redis/bin/redis-server\nCLIEXEC=/aclome/redis/bin/redis-cli\n\ncp /aclome/redis-0.0.7/redis.conf /aclome/redis/\n\nVi redis.conf\n\ndir ./data\n\nmkdir data\n\nmkdir data/sentinel\n</code></pre><p><strong>启动：</strong></p>\n<pre><code>nohup bin/redis-server conf/redis.conf &amp;\n</code></pre><p><strong>停止:</strong></p>\n<pre><code>bin/redis-cli -p 6379 shutdown\n</code></pre><p><strong>验证状态:</strong></p>\n<pre><code>ps -ef |grep redis\n</code></pre><p><img src=\"/images/架构/配置/redis验证.png\" alt=\"验证\"></p>\n<p><strong>客户端:</strong></p>\n<pre><code>/aclome/redis/bin/redis-cli -p 6379\n</code></pre><p>连接到远程的redis服务器: bin/redis-cli -h 199.31.165.62 -p 6379 get myname</p>\n<p>存储KEY/VALUE命令：set myname “lvyafei”</p>\n<p>读取Value命令: get myname</p>\n<p>删除缓存命令: del myname</p>\n<p>批量删除缓存: ./redis-cli -p 6379 KEYS “*” | xargs ./redis-cli -p 6379 DEL</p>\n<p>获取所有Key命令: keys *</p>\n<p><strong>Redis-HA方案-Sentinel配置:</strong></p>\n<font color=\"red\">Redis-server端口:6379  Redis-sentinel端口:7031</font>\n\n<blockquote>\n<p>1.master-slave配置</p>\n</blockquote>\n<p>只需要在slave上配置redis.conf即可,master不用配置</p>\n<pre><code>slaveof 199.31.165.61 6379\n\nslave-read-only yes\n</code></pre><p>在master,slave上分别启动nohup bin/redis-server conf/redis.conf &amp;</p>\n<p>停止master/slave命令:bin/redis-cli -p 6379 shutdown</p>\n<blockquote>\n<p>2.Sentinel配置</p>\n</blockquote>\n<p>在master/slave上配置sentinel.conf（master/slave相同配置）</p>\n<pre><code>#######redis-sentinel######################\nport 7031\n\ndir ./data/sentinel\n\nsentinel monitor mymaster 199.31.165.61 6379 1\nsentinel down-after-milliseconds mymaster 5000\nsentinel parallel-syncs mymaster 1\nsentinel failover-timeout mymaster 15000\n</code></pre><p><strong>启动sentinel：</strong></p>\n<p>分别在master/slave上执行命令：nohup bin/redis-sentinel conf/sentinel.conf &amp;</p>\n<p><strong>3.验证：</strong></p>\n<pre><code>Bin/redis-cli -p 7031 sentinel masters\n</code></pre><p>停止master:</p>\n<p>在master上执行bin/redis-cli -p 6379 shutdown.观察sentinel输出.</p>\n<p>停止sentinel:bin/redis-cli -p 7031 shutdown </p>\n<h2 id=\"4-Tomcat-Session共享配置\"><a href=\"#4-Tomcat-Session共享配置\" class=\"headerlink\" title=\"4.Tomcat Session共享配置\"></a>4.Tomcat Session共享配置</h2><p>拷贝 jar包到tomcat 的libs目录下:</p>\n<p>1.x版本：不支持Redis集群</p>\n<p><img src=\"/images/架构/配置/tomcat-session1.png\" alt=\"配置\"></p>\n<p>2.x版本：支持Redis集群</p>\n<p><img src=\"/images/架构/配置/tomcat-session2.png\" alt=\"配置\"></p>\n<p>配置:vi /tomcat/config/content.xml</p>\n<font color=\"red\">注意：1.x版本的包名和2.x版本的包名不一样，且2.x中多的参数1.x版本中不支持。</font>\n\n<p>1.x版本配置:</p>\n<p><img src=\"/images/架构/配置/tomcat-session3.png\" alt=\"配置\"></p>\n<p>2.x版本配置：</p>\n<p><img src=\"/images/架构/配置/tomcat-session4.png\" alt=\"配置\"></p>\n<p>启动即可，在redis客户端验证存储的KEY/VALUE</p>\n<h2 id=\"5-CAS-ticket共享\"><a href=\"#5-CAS-ticket共享\" class=\"headerlink\" title=\"5.CAS ticket共享\"></a>5.CAS ticket共享</h2><p>复制redis-ticket-registry.jar包到 cas/WEB-INF/libs和cas/libs目录下。</p>\n<p>编辑cas/WEB-INF/spring-configuration/ticketRegistry.xml文件</p>\n<p><img src=\"/images/架构/配置/cas-ticket.png\" alt=\"配置\"></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"0-概述\"><a href=\"#0-概述\" class=\"headerlink\" title=\"0.概述\"></a>0.概述</h2><p>前几天发的一篇”系统架构总结之高可用高负载”文章里面讲到的双高策略，里面包含的详细配置，在这里整理出来以做备忘。</p>","more":"<h2 id=\"1-Nginx安装\"><a href=\"#1-Nginx安装\" class=\"headerlink\" title=\"1.Nginx安装\"></a>1.Nginx安装</h2><p>版本:1.9.11</p>\n<p>依赖pcre-8.38.tar.gz</p>\n<font color=\"blue\">安装:</font>\n\n<pre><code>./configure --with-pcre=/aclome/pcre-8.38 --prefix=/aclome/nginx\n\nMake\n\nMake install\n</code></pre><font color=\"blue\">配置负载策略:</font>\n\n<pre><code>http{\n......\nupstream myServer{\n server 199.31.165.61:8080;\n server 199.31.165.62:8080;\n}\nserver{\n  listen   8001;\n  location / {\n    root  html;\n    index index.html index.htm;\n    proxy_pass http://myServer;\n  }\n}\n......\n}\n</code></pre><font color=\"blue\">启动</font>\n\n<pre><code>/sbin/nginx\n</code></pre><font color=\"blue\">停止</font>\n\n<pre><code>ps -ef |grep nginx\n\nkill -9 &lt;pid&gt;\n</code></pre><font color=\"blue\">访问</font>\n\n<p><a href=\"http://199.31.165.61:8001\" target=\"_blank\" rel=\"noopener\">http://199.31.165.61:8001</a>  可以在61:8080和62:8080之间跳转</p>\n<p><strong>nginx的upstream目前支持的5种方式的分配</strong></p>\n<p>1、轮询（默认）</p>\n<p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p>\n<p>upstream backserver {</p>\n<p>server 192.168.0.14;</p>\n<p>server 192.168.0.15;</p>\n<p>}</p>\n<p>2、weight</p>\n<p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p>\n<p>upstream backserver {</p>\n<p>server 192.168.0.14 weight=10;</p>\n<p>server 192.168.0.15 weight=10;</p>\n<p>}</p>\n<p>3、ip_hash</p>\n<p>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>\n<p>upstream backserver {</p>\n<p>ip_hash;</p>\n<p>server 192.168.0.14:88;</p>\n<p>server 192.168.0.15:80;</p>\n<p>}</p>\n<p>4、fair（第三方）</p>\n<p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p>\n<p>upstream backserver {</p>\n<p>server server1;</p>\n<p>server server2;</p>\n<p>fair;</p>\n<p>}</p>\n<p>5、url_hash（第三方）</p>\n<p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</p>\n<p>upstream backserver {</p>\n<p>server squid1:3128;</p>\n<p>server squid2:3128;</p>\n<p>hash $request_uri;</p>\n<p>hash_method crc32;</p>\n<p>}</p>\n<p>在需要使用负载均衡的server中增加</p>\n<p>proxy_pass <a href=\"http://backserver/\" target=\"_blank\" rel=\"noopener\">http://backserver/</a> ;</p>\n<p>upstream backserver{</p>\n<p>ip_hash;</p>\n<p>server 127.0.0.1:9090 down; (down 表示单前的server暂时不参与负载)</p>\n<p>server 127.0.0.1:8080 weight=2; (weight 默认为1.weight越大，负载的权重就越大)</p>\n<p>server 127.0.0.1:6060;</p>\n<p>server 127.0.0.1:7070 backup; (其它所有的非backup机器down或者忙的时候，请求backup机器)</p>\n<p>}</p>\n<p>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误。</p>\n<h2 id=\"2-Keepalived安装\"><a href=\"#2-Keepalived安装\" class=\"headerlink\" title=\"2.Keepalived安装\"></a>2.Keepalived安装</h2><p>版本:1.2.19</p>\n<font color=\"blue\">安装</font>\n\n<pre><code>./configure --disable-fwmark --prefix=/aclome/keepalived\n\n//使用root安装指定如下:\n\n./configure --prefix=/usr --sysconf=/etc\n\nmake \n\nmake install\n</code></pre><font color=\"blue\">配置</font>\n\n<p><strong>主:</strong></p>\n<pre><code>vi /etc/keepalived/keepalived.conf\n\nglobal_defs{\n  smtp_server 127.0.0.1\n}\nvrrp_instance_VI_1{\n  state MASTER \n  interface eth1\n  priority 100\n  ......\n  virtual_ipaddress{\n    199.31.165.65\n  }\n}\n</code></pre><p><strong>备:</strong></p>\n<pre><code>vi /etc/keepalived/keepalived.conf\n\nglobal_defs{\n  smtp_server 127.0.0.1\n}\nvrrp_instance_VI_1{\n  state BACKUP\n  interface eth1\n  priority 50\n  ......\n  virtual_ipaddress{\n    199.31.165.65\n  }\n}\n</code></pre><font color=\"blue\">启动</font>\n\n<pre><code>sudo service keepalived start\n\nsudo service keepalived status\n\nsudo service keepalived stop \n</code></pre><font color=\"blue\">验证</font>\n\n<p><img src=\"/images/架构/配置/keepalived验证.png\" alt=\"验证\"></p>\n<h2 id=\"3-Redis安装\"><a href=\"#3-Redis安装\" class=\"headerlink\" title=\"3.Redis安装\"></a>3.Redis安装</h2><p>版本:3.0.7</p>\n<p><strong>安装:</strong></p>\n<pre><code>Make PREFIX=/aclome/redis install\n</code></pre><p><strong>配置:</strong> </p>\n<pre><code>cp /aclome/redis-3.0.7/utils/redis_init_script /aclome/redis/\n\nvi redis_init_script\n\nEXEC=/aclome/redis/bin/redis-server\nCLIEXEC=/aclome/redis/bin/redis-cli\n\ncp /aclome/redis-0.0.7/redis.conf /aclome/redis/\n\nVi redis.conf\n\ndir ./data\n\nmkdir data\n\nmkdir data/sentinel\n</code></pre><p><strong>启动：</strong></p>\n<pre><code>nohup bin/redis-server conf/redis.conf &amp;\n</code></pre><p><strong>停止:</strong></p>\n<pre><code>bin/redis-cli -p 6379 shutdown\n</code></pre><p><strong>验证状态:</strong></p>\n<pre><code>ps -ef |grep redis\n</code></pre><p><img src=\"/images/架构/配置/redis验证.png\" alt=\"验证\"></p>\n<p><strong>客户端:</strong></p>\n<pre><code>/aclome/redis/bin/redis-cli -p 6379\n</code></pre><p>连接到远程的redis服务器: bin/redis-cli -h 199.31.165.62 -p 6379 get myname</p>\n<p>存储KEY/VALUE命令：set myname “lvyafei”</p>\n<p>读取Value命令: get myname</p>\n<p>删除缓存命令: del myname</p>\n<p>批量删除缓存: ./redis-cli -p 6379 KEYS “*” | xargs ./redis-cli -p 6379 DEL</p>\n<p>获取所有Key命令: keys *</p>\n<p><strong>Redis-HA方案-Sentinel配置:</strong></p>\n<font color=\"red\">Redis-server端口:6379  Redis-sentinel端口:7031</font>\n\n<blockquote>\n<p>1.master-slave配置</p>\n</blockquote>\n<p>只需要在slave上配置redis.conf即可,master不用配置</p>\n<pre><code>slaveof 199.31.165.61 6379\n\nslave-read-only yes\n</code></pre><p>在master,slave上分别启动nohup bin/redis-server conf/redis.conf &amp;</p>\n<p>停止master/slave命令:bin/redis-cli -p 6379 shutdown</p>\n<blockquote>\n<p>2.Sentinel配置</p>\n</blockquote>\n<p>在master/slave上配置sentinel.conf（master/slave相同配置）</p>\n<pre><code>#######redis-sentinel######################\nport 7031\n\ndir ./data/sentinel\n\nsentinel monitor mymaster 199.31.165.61 6379 1\nsentinel down-after-milliseconds mymaster 5000\nsentinel parallel-syncs mymaster 1\nsentinel failover-timeout mymaster 15000\n</code></pre><p><strong>启动sentinel：</strong></p>\n<p>分别在master/slave上执行命令：nohup bin/redis-sentinel conf/sentinel.conf &amp;</p>\n<p><strong>3.验证：</strong></p>\n<pre><code>Bin/redis-cli -p 7031 sentinel masters\n</code></pre><p>停止master:</p>\n<p>在master上执行bin/redis-cli -p 6379 shutdown.观察sentinel输出.</p>\n<p>停止sentinel:bin/redis-cli -p 7031 shutdown </p>\n<h2 id=\"4-Tomcat-Session共享配置\"><a href=\"#4-Tomcat-Session共享配置\" class=\"headerlink\" title=\"4.Tomcat Session共享配置\"></a>4.Tomcat Session共享配置</h2><p>拷贝 jar包到tomcat 的libs目录下:</p>\n<p>1.x版本：不支持Redis集群</p>\n<p><img src=\"/images/架构/配置/tomcat-session1.png\" alt=\"配置\"></p>\n<p>2.x版本：支持Redis集群</p>\n<p><img src=\"/images/架构/配置/tomcat-session2.png\" alt=\"配置\"></p>\n<p>配置:vi /tomcat/config/content.xml</p>\n<font color=\"red\">注意：1.x版本的包名和2.x版本的包名不一样，且2.x中多的参数1.x版本中不支持。</font>\n\n<p>1.x版本配置:</p>\n<p><img src=\"/images/架构/配置/tomcat-session3.png\" alt=\"配置\"></p>\n<p>2.x版本配置：</p>\n<p><img src=\"/images/架构/配置/tomcat-session4.png\" alt=\"配置\"></p>\n<p>启动即可，在redis客户端验证存储的KEY/VALUE</p>\n<h2 id=\"5-CAS-ticket共享\"><a href=\"#5-CAS-ticket共享\" class=\"headerlink\" title=\"5.CAS ticket共享\"></a>5.CAS ticket共享</h2><p>复制redis-ticket-registry.jar包到 cas/WEB-INF/libs和cas/libs目录下。</p>\n<p>编辑cas/WEB-INF/spring-configuration/ticketRegistry.xml文件</p>\n<p><img src=\"/images/架构/配置/cas-ticket.png\" alt=\"配置\"></p>"},{"layout":"lay_post","title":"大数据处理工具汇总","date":"2015-07-29T03:24:00.000Z","author":"36dsj","published":1,"summary":["http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg","http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg","http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg"],"_content":"\n* 目录\n{:toc #meuid}\n\n## 查询引擎\n\n### 一、Phoenix\n\n贡献者：：Salesforce\n\n简介：这是一个Java中间层，可以让开发者在Apache HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于GitHub上，并且提供了一个客户端可嵌入的JDBC驱动。\n<!-- more -->\n\nPhoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。\n\nPhoenix最值得关注的一些特性有：\n\n❶嵌入式的JDBC驱动，实现了大部分的java.sql接口，包括元数据API\n\n❷可以通过多部行键或是键/值单元对列进行建模\n\n❸完善的查询支持，可以使用多个谓词以及优化的扫描键\n\n❹DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除列\n\n❺版本化的模式仓库：当写入数据时，快照查询会使用恰当的模式\n\n❻DML支持：用于逐行插入的UPSERT VALUES、用于相同或不同表之间大量数据传输的UPSERT \n\n❼SELECT、用于删除行的DELETE\n\n❽通过客户端的批处理实现的有限的事务支持\n\n❾单表——还没有连接，同时二级索引也在开发当中\n\n➓紧跟ANSI SQL标准\n\n[Phoenix官方网站>>>](http://phoenix.apache.org/)\n\n### 二、Stinger\n贡献者：：Hortonworks\n\n简介：原叫Tez，下一代Hive,Hortonworks主导开发，运行在YARN上的DAG计算框架。\n\n某些测试下，Stinger能提升10倍左右的性能，同时会让Hive支持更多的SQL，其主要优点包括：\n\n❶让用户在Hadoop获得更多的查询匹配。其中包括类似OVER的字句分析功能，支持WHERE查询，让Hive的样式系统更符合SQL模型。\n\n❷优化了Hive请求执行计划，优化后请求时间减少90%。改动了Hive执行引擎，增加单Hive任务的被秒处理记录数。\n\n❸在Hive社区中引入了新的列式文件格式（如ORC文件），提供一种更现代、高效和高性能的方式来储存Hive数据。\n\n❹引入了新的运行时框架——Tez，旨在消除Hive的延时和吞吐量限制。Tez通过消除不必要的task、障碍同步和对HDFS的读写作业来优化Hive job。这将优化Hadoop内部的执行链，彻底加速Hive负载处理。\n\n[Stinger官方网站>>>](http://hortonworks.com/labs/stinger/)\n\n### 三、Presto\n贡献者：：Facebook\n\n简介：Facebook开源的数据查询引擎Presto ，可对250PB以上的数据进行快速地交互式分析。该项目始于 2012 年秋季开始开发，目前该项目已经在超过 1000 名 Facebook 雇员中使用，运行超过 30000 个查询，每日数据在 1PB 级别。Facebook 称 Presto 的性能比诸如 Hive 和 Map*Reduce 要好上 10 倍有多。\n\nPresto 当前支持 ANSI SQL 的大多数特效，包括联合查询、左右联接、子查询以及一些聚合和计算函数；支持近似截然不同的计数(DISTINCT COUNT)等。\n\n[github源代码下载>>>](https://github.com/facebook/presto)\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1105.jpg)\n\n### 四、Shark\n简介：Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的特点就是快，完全兼容Hive，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。\n\n❶Shark速度快的原因除了Spark平台提供的基于内存迭代计算外，在设计上还存在对Spark上进行了一定的改造，主要有\n\n❷partial DAG execution：对join优化，调节并行粒度，因为Spark本身的宽依赖和窄依赖会影响并行计算和速度\n\n基于列的压缩和存储：把HQL表数据按列存，每列是一个array，存在JVM上，避免了JVM GC低效，而压缩和解压相关的技术是Yahoo!提供的。\n\n结来说，Shark是一个插件式的东西，在我现有的Spark和Hive及hadoop-client之间，在这两套都可用的情况下，Shark只要获取Hive的配置（还有metastore和exec等关键包），Spark的路径，Shark就能利用Hive和Spark，把HQL解析成RDD的转换，把数据取到Spark上运算和分析。在SQL on Hadoop这块，Shark有别于Impala，Stringer，而这些系统各有自己的设计思路，相对于对MR进行优化和改进的思路，Shark的思路更加简单明了些\n\n[Shark官方网站>>>](http://shark.cs.berkeley.edu/)\n\n### 五、Pig\n\n简介：Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。\n\nPig最大的作用就是对mapreduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组(group by)、关联(Joining)，Pig也可以由用户自定义一些函数对数据集进行操作，也就是传说中的UDF(user-defined functions)。\n\n[Pig官方网站>>>](http://pig.apache.org/)\n\n### 六、Cloudera Impala\n\n贡献者：:Cloudera\n\n简介：Cloudera Impala 可以直接为存储在HDFS或HBase中的Hadoop数据提供快速，交互式的SQL查询。除了使用相同的存储平台外， Impala和Apache Hive一样也使用了相同的元数据，SQL语法（Hive SQL），ODBC驱动和用户接口（Hue Beeswax），这就很方便的为用户提供了一个相似并且统一的平台来进行批量或实时查询。\n\nCloudera Impala 是用来进行大数据查询的补充工具。 Impala 并没有取代像Hive这样基于MapReduce的分布式处理框架。Hive和其它基于MapReduce的计算框架非常适合长时间运行的批处理作业，例如那些涉及到批量 Extract、Transform、Load ，即需要进行ETL作业。\n\nImpala 提供了：\n\n❶数据科学家或数据分析师已经熟知的SQL接口\n\n❷能够在Apache Hadoop 的大数据中进行交互式数据查询\n\n❸ Single system for big data processing and analytics so customers can avoid costly modeling and ETL just for analytics\n\n[Cloudera Impala官方网站>>>](http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html)\n\n### 七、Apache Drill\n\n贡献者：：MapR\n\n简介：Apache Drill是是一个能够对大数据进行交互分析、开源的分布式系统，且基于Google Dremel实现，它能够运行在上千个节点的服务器集群上，且能在几秒内处理PB级或者万亿条的数据记录。Drill能够帮助企业用户快速、高效地进行Hadoop数据查询和企业级大数据分析。Drill于2012年8月份由Apache推出。\n\n从Drill官方对其架构的介绍中得知，其具有适于实时的分析和快速的应用开发、适于半结构化/嵌套数据的分析、兼容现有的SQL环境和Apache Hive等特征。另外，Drill的核心模块是Drillbit服务，该服务模块包括远程访问子模块、SQL解析器、查询优化器、任务计划执行引擎、存储插件接口（DFS、HBase、Hive等的接口）、分布式缓存模块等几部分，如下图所示：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg)\n\n[Apache Drill官方网站>>>](http://incubator.apache.org/drill/)\n\n### 八、Apache Tajo\n\n简介：Apache Tajo项目的目的是在HDFS之上构建一个先进的数据仓库系统。Tajo将自己标榜为一个“大数据仓库”，但是它好像和之前介绍的那些低延迟查询引擎类似。虽然它支持外部表和Hive数据集（通过HCatalog），但是它的重点是数据管理，提供低延迟的数据访问，以及为更传统的ETL提供工具。它也需要在数据节点上部署Tajo特定的工作进程。\n\nTajo的功能包括：\n\n❶ANSI SQL兼容\n❷JDBC 驱动\n❸集成Hive metastore能够访问Hive数据集\n❹一个命令行客户端\n❺一个自定义函数API\n\n[Apache Tajo官方网站>>>](http://tajo.incubator.apache.org/)\n\n### 九、Hive\n\n简介：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。\n\n[Hive官方网站>>>](http://hive.apache.org/)\n\n## 流式计算\n\n### 一、Facebook Puma\n\n贡献者：Facebook\n\n简介：实时数据流分析\n\n### 二、Twitter Rainbird\n\n贡献者：Twitter\n\n简介：Rainbird一款基于Zookeeper, Cassandra, Scribe, Thrift的分布式实时统计系统，这些基础组件的基本功能如下：\n\n❶ Zookeeper，Hadoop子项目中的一款分布式协调系统，用于控制分布式系统中各个组件中的一致性。\n\n❷Cassandra，NoSQL中一款非常出色的产品，集合了Dynamo和Bigtable特性的分布式存储系统，用于存储需要进行统计的数据，统计数据，并且提供客户端进行统计数据的查询。（需要使用分布式Counter补丁CASSANDRA-1072）\n\n❸ Scribe，Facebook开源的一款分布式日志收集系统，用于在系统中将各个需要统计的数据源收集到Cassandra中。\n\n❹ Thrift，Facebook开源的一款跨语言C/S网络通信框架，开发人员基于这个框架可以轻易地开发C/S应用。\n\n用处\n\nRainbird可以用于实时数据的统计：\n\n❶统计网站中每一个页面，域名的点击次数\n\n❷内部系统的运行监控（统计被监控服务器的运行状态）\n\n❸记录最大值和最小值\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/280.jpg)\n\n### 三、Yahoo S4\n\n贡献者：Yahoo\n\n简介：S4（Simple Scalable Streaming System）最初是Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。目前该项目刚启动不久，所以也可以理解为是他们提出的一个分布式流计算（Distributed Stream Computing）的模型。\n\nS4的设计目标是：\n\n·提供一种简单的编程接口来处理数据流\n\n·设计一个可以在普通硬件之上可扩展的高可用集群。\n\n·通过在每个处理节点使用本地内存，避免磁盘I/O瓶颈达到最小化延迟\n\n·使用一个去中心的，对等架构；所有节点提供相同的功能和职责。没有担负特殊责任的中心节点。这大大简化了部署和维护。\n\n·使用可插拔的架构，使设计尽可能的即通用又可定制化。\n\n·友好的设计理念，易于编程，具有灵活的弹性\n\n[Yahoo S4官方网站>>>](http://incubator.apache.org/s4/)\n\n### 四、Twitter Storm\n\n贡献者：Twitter\n\n简介：Storm是Twitter开源的一个类似于Hadoop的实时数据处理框架，它原来是由BackType开发，后BackType被Twitter收购，将Storm作为Twitter的实时数据分析系统。\n\n实时数据处理的应用场景很广泛，例如商品推荐，广告投放，它能根据当前情景上下文（用户偏好，地理位置，已发生的查询和点击等）来估计用户点击的可能性并实时做出调整。\n\nstorm的三大作用领域：\n\n1.信息流处理（Stream Processing）\n\nStorm可以用来实时处理新数据和更新数据库，兼具容错性和可扩展性,它 可以用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。\n\n2.连续计算（Continuous Computation）\n\nStorm可以进行连续查询并把结果即时反馈给客户，比如将Twitter上的热门话题发送到客户端。\n\n3.分布式远程过程调用（Distributed RPC）\n\n除此之外，Storm也被广泛用于以下方面：\n\n精确的广告推送\n实时日志的处理\n\n[Twitter Storm官方网站>>>](http://storm.incubator.apache.org/)\n\n##迭代计算\n\n### 一、Apache Hama\n\n简介：Apache Hama是一个纯BSP（Bulk Synchronous Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。\n\n❶建立在Hadoop上的分布式并行计算模型。\n\n❷基于 Map/Reduce 和 Bulk Synchronous 的实现框架。\n\n❸运行环境需要关联 Zookeeper、HBase、HDFS 组件。\n\nHama中有2个主要的模型:\n\n– 矩阵计算(Matrix package)\n\n– 面向图计算(Graph package)\n\n[Apache Hama官方网站>>>](https://hama.apache.org/)\n\n### 二、Apache Giraph\n\n代码托管地址： [GitHub](https://github.com/apache/giraph)\n\n简介：Apache Giraph是一个可伸缩的分布式迭代图处理系统，灵感来自BSP（bulk synchronous parallel）和Google的Pregel，与它们 区别于则是是开源、基于 Hadoop 的架构等。\n\nGiraph处理平台适用于运行大规模的逻辑计算，比如页面排行、共享链接、基于个性化排行等。Giraph专注于社交图计算，被Facebook作为其Open Graph工具的核心，几分钟内处理数万亿次用户及其行为之间的连接。\n\n### 三、HaLoop\n\n简介：迭代的MapReduce，HaLoop——适用于迭代计算的Hadoop 。\n\n ![](http://www.36dsj.com/wp-content/uploads/2015/03/425.jpg)\n \n                                Hadoop与HaLoop的不同\n\n与Hadoop比较的四点改变：\n\n1.提供了一套新的编程接口，更加适用于迭代计算；\n\nHaLoop给迭代计算一个抽象的递归公式：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/403.jpg)\n\n2.HaLoop的master进行job内的循环控制，直到迭代计算结束；\n\n3.Task Scheduler也进行了修改，使得任务能够尽量满足data locality\n\n4.slave nodes对数据进行cache并index索引，索引也以文件的形式保存在本地磁盘。\n\n[HaLoop官网>>>](https://code.google.com/p/haloop/)\n\n### 四、Twister\n\n简介：Twister， 迭代式MapReduce框架，Twister是由一个印度人开发的，其架构如下：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/524.jpg)\n\n在Twister中，大文件不会自动被切割成一个一个block，因而用户需提前把文件分成一个一个小文件，以供每个task处理。在map阶段，经过map（）处理完的结果被放在分布式内存中，然后通过一个broker network（NaradaBroking系统）将数据push给各个reduce task（Twister假设内存足够大，中间数据可以全部放在内存中）；在reduce阶段，所有reduce task产生的结果通过一个combine操作进行归并，此时，用户可以进行条件判定， 确定迭代是否结束。combine后的数据直接被送给map task，开始新一轮的迭代。为了提高容错性，Twister每隔一段时间会将map task和reduce task产生的结果写到磁盘上，这样，一旦某个task失败，它可以从最近的备份中获取输入，重新计算。\n\n为了避免每次迭代重新创建task，Twister维护了一个task pool，每次需要task时直接从pool中取。在Twister中，所有消息和数据都是通过broker network传递的，该broker network是一个独立的模块，目前支持NaradaBroking和ActiveMQ。\n\n## 离线计算\n\n### 一、Hadoop MapReduce\n\n简介：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）”，和它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。\n\n[Hadoop MapReduce官方网站>>>](http://hadoop.apache.org/)\n\n### 二、Berkeley Spark\n\n简介：Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。\n\n### 三、DataTorrent\n\n简介：DataTorrent基于Hadoop 2.x构建，是一个实时的、有容错能力的数据流式处理和分析平台，它使用本地Hadoop应用程序，而这些应用程序可以与执行其它任务，如批处理，的应用程序共存。该平台的架构如下图所示：\n![](http://www.36dsj.com/wp-content/uploads/2015/03/621.jpg)\n\n相关文章：[DataTorrent 1.0每秒处理超过10亿个实时事件](http://www.36dsj.com/archives/20163)\n\n[DataTorrent 将数据分析速度从“实时”提升至“现在时”](http://www.36dsj.com/archives/1596)\n\n## 键值存储\n\n### 一、LevelDB\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/723.jpg)\n\n贡献者：Google\n\n简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。\n\nLevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。\n\n此处随机读是完全命中内存的速度，如果是不命中 速度大大下降。\n\n[LevelDB官方网站>>>](https://code.google.com/p/leveldb/)\n\n### 二、RocksDB\n\n贡献者：facebook\n\n简介：RocksDB虽然在代码层面上是在LevelDB原有的代码上进行开发的，但却借鉴了Apache HBase的一些好的idea。在云计算横行的年代，开口不离Hadoop，RocksDB也开始支持HDFS，允许从HDFS读取数据。RocksDB支持一次获取多个K-V，还支持Key范围查找。LevelDB只能获取单个Key。\n\nRocksDB除了简单的Put、Delete操作，还提供了一个Merge操作，说是为了对多个Put操作进行合并。\n\nRocksDB提供一些方便的工具，这些工具包含解析sst文件中的K-V记录、解析MANIFEST文件的内容等。RocksDB支持多线程合并，而LevelDB是单线程合并的。\n\n[RocksDB官方网站>>>](http://rocksdb.org/)\n\n### 三、HyperDex\n\n贡献者：Facebook\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/821.jpg)\n\nHyperDex是一个分布式、可搜索的键值存储系统，特性如下：\n\n分布式KV存储，系统性能能够随节点数目线性扩展\n吞吐和延时都能秒杀现在风头正劲的MonogDB，吞吐甚至强于Redis\n使用了hyperspace hashing技术，使得对存储的K-V的任意属性进行查询成为可能\n\n官网：[http://hyperdex.org/](http://hyperdex.org/)\n\n### 四、TokyoCabinet\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/104.png)\n\n日本人Mikio Hirabayashi（平林干雄）开发的一款DBM数据库。Tokyo Cabinet 是一个DBM的实现。这里的数据库由一系列key-value对的记录构成。key和value都可以是任意长度的字节序列,既可以是二进制也可以是字符串。这里没有数据类型和数据表的概念。\n当 做为Hash表数据库使用时，每个key必须是不同的,因此无法存储两个key相同的值。提供了以下访问方法:提供key,value参数来存储，按 key删除记录，按key来读取记录，另外，遍历key也被支持，虽然顺序是任意的不能被保证。这些方法跟Unix标准的DBM,例如GDBM,NDBM 等等是相同的，但是比它们的性能要好得多（因此可以替代它们) 。下一代KV存储系统，支持strings、integers、floats、lists、maps和sets等丰富的数据类型。\n\n[TokyoCabinet官方网站>>>](http://fallabs.com/tokyocabinet/)\n\n### 五、Voldemort\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg)\n\nVoldemort是一个分布式键值存储系统，是Amazon’s Dynamo的一个开源克隆。特性如下：\n支持自动复制数据到多个服务器上。\n支持数据自动分割所以每个服务器只包含总数据的一个子集。\n提供服务器故障透明处理功能。\n支持可拨插的序化支持，以实现复杂的键-值存储，它能够很好的5.集成常用的序化框架如：Protocol Buffers、Thrift、Avro和Java Serialization。\n数据项都被标识版本能够在发生故障时尽量保持数据的完整性而不会影响系统的可用性。\n每个节点相互独立，互不影响。\n支持可插拔的数据放置策略\n官网：[http://project-voldemort.com/](http://project-voldemort.com/)\n\n### 六、Amazon Dynamo\n贡献者：亚马逊\n\n简介：Amazon Dynamo 是一个经典的分布式Key-Value 存储系统，具备去中心化，高可用性，高扩展性的特点，但是为了达到这个目标在很多场景中牺牲了一致性。Dynamo在Amazon中得到了成功的应用，能够跨数据中心部署于上万个结点上提供服务，它的设计思想也被后续的许多分布式系统借鉴。如近来火热的Cassandra，实际上就是基本照搬了Dynamo的P2P架构，同时融合了BigTable的数据模型及存储算法。\n\n[Amazon Dynamo官方网站>>>](https://github.com/dynamo/dynamo)\n\n### 七、Tair\n贡献者：淘宝\n\n简介：tair 是淘宝自己开发的一个分布式 key/value 存储引擎. tair 分为持久化和非持久化两种使用方式. 非持久化的 tair 可以看成是一个分布式缓存. 持久化的 tair 将数据存放于磁盘中. 为了解决磁盘损坏导致数据丢失, tair 可以配置数据的备份数目, tair 自动将一份数据的不同备份放到不同的主机上, 当有主机发生异常, 无法正常提供服务的时候, 其于的备份会继续提供服务.tair 的总体结构\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1220.jpg)\n\nTairtair 作为一个分布式系统, 是由一个中心控制节点和一系列的服务节点组成. 我们称中心控制节点为config server. 服务节点是data server. config server 负责管理所有的data server, 维护data server的状态信息. data server 对外提供各种数据服务, 并以心跳的形式将自身状况汇报给config server. config server是控制点, 而且是单点, 目前采用一主一备的形式来保证其可靠性. 所有的 data server 地位都是等价的.\n\n### 八、Apache Accumulo\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/8c2532b6-0c16-3879-9600-2a263d923934.png)\n\nApache Accumulo 是一个可靠的、可伸缩的、高性能的排序分布式的 Key-Value 存储解决方案，基于单元访问控制以及可定制的服务器端处理。Accumulo使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。\n \n官网：[http://accumulo.apache.org/](http://accumulo.apache.org/)\n\n### 九、Redis\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1320.jpg)\n\nRedis是一个高性能的key-value存储系统，和Memcached类似，它支持存储的value类型相对更多，包括string（字符串）、list（链表）、set（集合）和zset（有序集合）。与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了主从同步。\n\nRedis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Python、Ruby、Erlang、PHP客户端，使用很方便。\n\n官网：[http://redis.io/](http://redis.io/)\n\n## 表格存储\n\n### 一、OceanBase\n\n贡献者：阿里巴巴\n\n相关文章：[26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase](http://www.36dsj.com/archives/20317)\n\n简介：OceanBase是一个支持海量数据的高性能分布式数据库系统，实现了数千亿条记录、数百TB数据上的跨行跨表事务，由淘宝核心系统研发部、运维、DBA、广告、应用研发等部门共同完成。在设计和实现OceanBase的时候暂时摒弃了不紧急的DBMS的功能，例如临时表，视图(view)，研发团队把有限的资源集中到关键点上，当前 OceanBase主要解决数据更新一致性、高性能的跨表读事务、范围查询、join、数据全量及增量dump、批量数据导入。\n\n目前OceanBase已经应用于淘宝收藏夹，用于存储淘宝用户收藏条目和具体的商品、店铺信息，每天支持4～5千万的更新操作。等待上线的应用还包括CTU、SNS等，每天更新超过20亿，更新数据量超过2.5TB，并会逐步在淘宝内部推广。\n\nOceanBase 0.3.1在Github开源，开源版本为Revision:12336。\n\n官网：[http://alibaba.github.io/oceanbase/](http://alibaba.github.io/oceanbase/)\n\n### 二、Amazon SimpleDB\n\n贡献者：亚马逊\n\nAmazon SimpleDB是一个分散式数据库，以Erlang撰写。同与Amazon EC2和亚马逊的S3一样作为一项Web 服务，属于亚马逊网络服务的一部分。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1106.jpg)\n\n正如EC2和S3，SimpleDB的按照存储量，在互联网上的传输量和吞吐量收取费用。 在2008年12月1日，亚马逊推出了新的定价策略，提供了免费1 GB的数据和25机器小时的自由层(Free Tire)。 将其中的数据转移到其他亚马逊网络服务是免费的。\n\n它是一个可大规模伸缩、用 Erlang 编写的高可用数据存储。\n\n官网：[http://aws.amazon.com/cn/simpledb/](http://aws.amazon.com/cn/simpledb/)\n\n### 三、Vertica\n\n贡献者：惠普\n\n简介：惠普2011年2月份起始3月21号完成收购Vertica。Vertica基于列存储。基于列存储的设计相比传统面向行存储的数据库具有巨大的优势。同时Vertica支持MPP（massively parallel processing）等技术，查询数据时Vertica只需取得需要的列，而不是被选择行的所有数据，其平均性能可提高50x-1000x倍。（查询性能高速度快）\n\nVertica的设计者多次表示他们的产品围绕着高性能和高可用性设计。由于对MPP技术的支持，可提供对粒度，可伸缩性和可用性的优势。每个节点完全独立运作，完全无共享架构，降低对共享资源的系统竞争。\n\nVertica的数据库使用标准的SQL查询，同时Vertica的架构非常适合云计算，包括虚拟化，分布式多节点运行等，并且可以和Hadoop/MapReduce进行集成。\n\nVertica官网：[http://www.vertica.com/](http://www.vertica.com/)\n\n### 四、Cassandra\n\n贡献者：facebook\n\n相关文章：[开源分布式NoSQL数据库系统——Cassandra](http://www.36dsj.com/archives/20079)   [Cassandra与HBase的大数据对决 谁是胜者？](http://www.36dsj.com/archives/7179)\n\n简介：Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩放性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/290.jpg)\n\nCassandra是一个混合型的非关系的数据库，类似于Google的BigTable。其主要功能比Dynamo （分布式的Key-Value存储系统）更丰富，但支持度却不如文档存储MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的。支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型）。Cassandra最初由Facebook开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族（Column Family）的数据模型。P2P去中心化的存储。很多方面都可以称之为Dynamo 2.0。\n\nCassandra官网：[http://cassandra.apache.org/](http://cassandra.apache.org/)\n\n### 五、HyperTable\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/347.jpg)\n\n简介：Hypertable是一个开源、高性能、可伸缩的数据库，它采用与Google的Bigtable相似的模型。在过去数年中，Google为在PC集群 上运行的可伸缩计算基础设施设计建造了三个关键部分。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/426.jpg)\n\n第一个关键的基础设施是Google File System（GFS），这是一个高可用的文件系统，提供了一个全局的命名空间。它通过跨机器（和跨机架）的文件数据复制来达到高可用性，并因此免受传统 文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等失败。第二个基础设施是名为Map-Reduce的计算框架，它与GFS紧密协作，帮 助处理收集到的海量数据。第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让你可以通过一些主键来组织海量数据，并实现高效的 查询。Hypertable是Bigtable的一个开源实现，并且根据我们的想法进行了一些改进。\n\nHyperTable官网：[http://hypertable.org/](http://hypertable.org/)\n\n### 六、FoundationDB\n\n简介：支持ACID事务处理的NoSQL数据库，提供非常好的性能、数据一致性和操作弹性。\n\n2015年1月2日，FoundationDB已经发布了其key-value数据库的3.0版本，主要专注于可伸缩性和性能上的改善。FoundationDB的CEO David Rosenthal在一篇博客上宣布了新的版本，其中展示了FoundationDB 3.0在可伸缩性方面的数据，它可以在一个32位的c3.8xlarge EC2实例上每秒写入1440万次；这在性能上是之前版本的36倍。\n\n除了性能和可伸缩性的改善之外，FoundationDB 3.0还包含了对监控支持的改善。这种监控机制不仅仅是简单的机器检查，它添加了对多种潜在的硬件瓶颈的诊断，并且把那些高层级的信息整合到现有监控基础架构中。\n\n官网：[https://foundationdb.com/](https://foundationdb.com/)\n\n### 七：HBase\n\n贡献者： Fay Chang 所撰写的“Bigtable\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/526.jpg)\n\n简介：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。\n\n官网：[http://hbase.apache.org/](http://hbase.apache.org/)\n\n## 文件存储\n\n### 一、CouchDB\n\n简介：CouchDB是用Erlang开发的面向文档的数据库系统，最近刚刚发布了1.0版本（2010年7月14日）。CouchDB不是一个传统的关系数据库，而是面向文档的数据库，其数据存储方式有点类似lucene的index文件格式，CouchDB最大的意义在于它是一个面向web应用的新一代存储系统，事实上，CouchDB的口号就是：下一代的Web应用存储系统。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/623.jpg)\n\n特点：\n\n一、CouchDB是分布式的数据库，他可以把存储系统分布到n台物理的节点上面，并且很好的协调和同步节点之间的数据读写一致性。这当然也得靠Erlang无与伦比的并发特性才能做到。对于基于web的大规模应用文档应用，分布式可以让它不必像传统的关系数据库那样分库拆表，在应用代码层进行大量的改动。\n\n二、CouchDB是面向文档的数据库，存储半结构化的数据，比较类似lucene的index结构，特别适合存储文档，因此很适合CMS，电话本，地址本等应用，在这些应用场合，文档数据库要比关系数据库更加方便，性能更好。\n\n三、CouchDB支持REST API，可以让用户使用JavaScript来操作CouchDB数据库，也可以用JavaScript编写查询语句，我们可以想像一下，用AJAX技术结合CouchDB开发出来的CMS系统会是多么的简单和方便。\n\n其实CouchDB只是Erlang应用的冰山一角，在最近几年，基于Erlang的应用也得到的蓬勃的发展，特别是在基于web的大规模，分布式应用领域，几乎都是Erlang的优势项目。\n\n官网：[http://couchdb.apache.org/](http://couchdb.apache.org/)\n\n### 二、MongoDB\n\n简介：MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。\n\nMongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。\n\n相关文章：[MongoDB的基本特性与内部构造](http://www.36dsj.com/archives/22965)  [大数据吃香 创业公司MongoDB估值达16亿美元](http://www.36dsj.com/archives/21104)\n\n![](http://www.36dsj.com/wp-content/uploads/2015/01/2710.jpg)\n\n特点\n\n它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：\n\n*面向集合存储，易存储对象类型的数据。\n\nmongodb集群参考\n\nmongodb集群参考\n\n*模式自由。\n\n*支持动态查询。\n\n*支持完全索引，包含内部对象。\n\n*支持查询。\n\n*支持复制和故障恢复。\n\n*使用高效的二进制数据存储，包括大型对象（如视频等）。\n\n*自动处理碎片，以支持云计算层次的扩展性。\n\n*支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。\n\n*文件存储格式为BSON（一种JSON的扩展）。\n\n*可通过网络访问。\n\n官网：[https://www.mongodb.org/](https://www.mongodb.org/)\n\n### 三、Tachyon\n\n贡献者：Haoyuan Li（李浩源）\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/725-220x150.jpg)\n\n简介：Tachyon是一个分布式内存文件系统，可以在集群里以访问内存的速度来访问存在tachyon里的文件。把Tachyon是架构在最底层的分布式文件存储和上层的各种计算框架之间的一种中间件。主要职责是将那些不需要落地到DFS里的文件，落地到分布式内存文件系统中，来达到共享内存，从而提高效率。同时可以减少内存冗余，GC时间等。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/823.jpg)\n\n**Tachyon架构**\n\nTachyon的架构是传统的Master—slave架构，这里和Hadoop类似，TachyonMaster里WorkflowManager是 Master进程，因为是为了防止单点问题，通过Zookeeper做了HA，可以部署多台Standby Master。Slave是由Worker Daemon和Ramdisk构成。这里个人理解只有Worker Daemon是基于JVM的，Ramdisk是一个off heap memory。Master和Worker直接的通讯协议是Thrift。\n\n下图来自Tachyon的作者Haoyuan Li：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/920.jpg)\n\n下载地址：[https://github.com/amplab/tachyon](https://github.com/amplab/tachyon)\n\n### 四、KFS\n\n简介：GFS的C++开源版本，Kosmos distributed file system (KFS)是一个专门为数据密集型应用（搜索引擎，数据挖掘等）而设计的存储系统，类似于Google的GFS和Hadoop的HDFS分布式文件系统。 KFS使用C++实现，支持的客户端包括C++，Java和Python。KFS系统由三部分组成，分别是metaserver、chunkserver和client library。\n\n官网：[http://code.google.com/p/kosmosfs/](http://code.google.com/p/kosmosfs/)\n\n### 五、HDFS\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1022.jpg)\n\n简介：Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。\n\n官网：[http://hadoop.apache.org/](http://hadoop.apache.org/)\n\n## 资源管理\n\n### 一、Twitter Mesos\n\n开发者：Twitter研发人员John Oskasson\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1129.jpg)\n\n简介：Apache Mesos是由加州大学伯克利分校的AMPLab首先开发的一款开源群集管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等架构，由于其开源性质越来越受到一些大型云计算公司的青睐，例如Twitter、Facebook等。\n\n参考文章：[Mesos渐入主流,Twitter模式有望 “无限复制”-CSDN.NET](http://www.csdn.net/article/2014-02-24/2818520-Cloud-Mesosphere-Mesos-Hadoop-Spark)\n\n官网：[http://mesos.apache.org/](http://mesos.apache.org/)\n\n### 二、Hadoop Yarn\n\nHadoop 新 MapReduce 框架 Yarn。为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1222.jpg)\n\nYarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：\n\n1、这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。\n\n2、在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。\n\n3、对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。\n\n4、老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的行状况，如果出问题，会将其在其他机器上重启。\n\n5、Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。\n\n官网：[http://hadoop.apache.org/](http://hadoop.apache.org/)\n\n## 日志收集系统\n\n### 一、Facebook Scribe\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1107.jpg)\n\n贡献者：Facebook\n\n简介：Scribe是Facebook开源的日志收集系统，在Facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央存储系统。其通常与Hadoop结合使用，scribe用于向HDFS中push日志，而Hadoop通过MapReduce作业进行定期处理。\n\nScribe的系统架构\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/298-600x234.jpg)\n\n代码托管：[https://github.com/facebook/scribe](https://github.com/facebook/scribe)\n\n### 二、Cloudera Flume\n![](http://www.36dsj.com/wp-content/uploads/2015/03/348.jpg)\n\n贡献者：[Cloudera](http://www.36dsj.com/archives/tag/cloudera)\n\n简介：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。\n\nFlume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。\n\n当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。\n\n**Cloudera Flume构架：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/427-414x429.jpg)\n\n官网：[http://flume.apache.org/](http://flume.apache.org/)\n\n### 三、logstash\n\n简介：logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/527-600x265.jpg)\n\n官网：[http://www.logstash.net/](http://www.logstash.net/)\n\n### 四、kibana\n\n简介：Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面。\n\n主页： [http://kibana.org/](http://kibana.org/)\n\n代码托管： [https://github.com/rashidkpc/Kibana/downloads](https://github.com/rashidkpc/Kibana/downloads)\n\n## 消息系统\n\n### 一、StormMQ\n\n简介：MQMessageQueue消息队列产品 StormMQ，是一种服务程序。\n\n官网：[http://stormmq.com/](http://stormmq.com/)\n\n### 二、ZeroMQ\n\n简介：这是个类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。\n\n引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”\n\n官网：[http://zeromq.org/](http://zeromq.org/)\n\n### 三、RabbitMQ\n\n简介：RabbitMQ是一个受欢迎的消息代理，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。本文简单介绍了如何使用 RabbitMQ，假定你已经配置好了rabbitmq服务器。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/624.jpg)\n\nRabbitMQ是用Erlang，对于主要的编程语言都有驱动或者客户端。我们这里要用的是Java，所以先要获得Java客户端。\n\n像RabbitMQ这样的消息代理可用来模拟不同的场景，例如点对点的消息分发或者订阅/推送。我们的程序足够简单，有两个基本的组件，一个生产者用于产生消息，还有一个消费者用来使用产生的消息。\n\n官网：[https://www.rabbitmq.com/](https://www.rabbitmq.com/)\n\n### 四、Apache ActiveMQ\n\n简介：ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/726.jpg)\n\n特性：\n\n⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP\n\n⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)\n\n⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性\n\n⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上\n\n⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA\n\n⒍ 支持通过JDBC和journal提供高速的消息持久化\n\n⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点\n\n⒏ 支持Ajax\n\n⒐ 支持与Axis的整合\n\n⒑ 可以很容易得调用内嵌JMS provider，进行测试\n\n官网：[http://activemq.apache.org/](http://activemq.apache.org/)\n\n### 五、Jafka\n\n贡献者：LinkedIn\n\n简介：Jafka 是一个开源的、高性能的、跨语言分布式消息系统，使用GitHub托管。Jafka 最早是由Apache孵化的Kafka（由LinkedIn捐助给Apache）克隆而来。由于是一个开放式的数据传输协议，因此除了Java开发语言受到支持，Python、Ruby、C、C++等其他语言也能够很好的得到支持。\n\n特性：\n\n1、消息持久化非常快，服务端存储消息的开销为O(1)，并且基于文件系统，能够持久化TB级的消息而不损失性能。\n\n2、吞吐量取决于网络带宽。\n\n3、完全的分布式系统，broker、producer、consumer都原生自动支持分布式。自动实现复杂均衡。\n\n4、内核非常小，整个系统（包括服务端和客户端）只有一个272KB的jar包，内部机制也不复杂，适合进行内嵌或者二次开发 。整个服务端加上依赖组件共3.5MB。\n\n5、消息格式以及通信机制非常简单，适合进行跨语言开发。目前自带的Python3.x的客户端支持发送消息和接收消息。\n\n官网：[http://kafka.apache.org/](http://kafka.apache.org/)\n\n### 六、Apache Kafka\n\n贡献者：LinkedIn\n\n简介：Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。\n\nKafka是一个分布式的、分区的、多复本的日志提交服务。它通过一种独一无二的设计提供了一个消息系统的功能。\n\nKafka集群可以在一个指定的时间内保持所有发布上来的消息，不管这些消息有没有被消费。打个比方，如果这个时间设置为两天，那么在消息发布的两天以内，这条消息都是可以被消费的，但是在两天后，这条消息就会被系统丢弃以释放空间。Kafka的性能不会受数据量的大小影响，因此保持大量的数据不是一个问题。\n\n官网：[http://kafka.apache.org/](http://kafka.apache.org/)\n\n## 分布式服务\n\n### 一、ZooKeeper\n\n贡献者：Google\n\n简介：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。\n\nZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。\n\n架构：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/824-600x244.jpg)\n\n官网：[http://zookeeper.apache.org/](http://zookeeper.apache.org/)\n\n## RPC\n\n（Remote Procedure Call Protocol）——远程过程调用协议\n\n### 一、Apache Avro\n\n简介：Apache Avro是Hadoop下的一个子项目。它本身既是一个序列化框架，同时也实现了RPC的功能。Avro官网描述Avro的特性和功能如下：\n\n丰富的数据结构类型；\n快速可压缩的二进制数据形式；\n存储持久数据的文件容器；\n提供远程过程调用RPC；\n简单的动态语言结合功能。\n相比于Apache Thrift 和Google的Protocol Buffers，Apache Avro具有以下特点：\n\n支持动态模式。Avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。\n数据无须加标签。读取数据前，Avro能够获取模式定义，这使得Avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。\n官网：[http://avro.apache.org/](http://avro.apache.org/)\n\n### 二、Facebook Thrift\n\n贡献者：Facebook\n\n简介：Thrift源于大名鼎鼎的facebook之手，在2007年facebook提交Apache基金会将Thrift作为一个开源项目，对于当时的facebook来说创造thrift是为了解决facebook系统中各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性。\n\nthrift可以支持多种程序语言，例如: C++, C#, Cocoa, Erlang, Haskell, Java, Ocami, Perl, PHP, Python, Ruby, Smalltalk. 在多种不同的语言之间通信thrift可以作为二进制的高性能的通讯中间件，支持数据(对象)序列化和多种类型的RPC服务。\n\nThrift适用于程序对程 序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程，跟其他IDL工具相比较可以视为是Thrift的弱项，Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输相对于JSON和xml无论在性能、传输大小上有明显的优势。\n\nThrift 主要由5个部分组成：\n\n· 类型系统以及 IDL 编译器：负责由用户给定的 IDL 文件生成相应语言的接口代码\n\n· TProtocol：实现 RPC 的协议层，可以选择多种不同的对象串行化方式，如 JSON, Binary。\n\n· TTransport：实现 RPC 的传输层，同样可以选择不同的传输层实现，如socket, 非阻塞的 socket, MemoryBuffer 等。\n\n· TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口。\n\n· TServer：聚合 TProtocol, TTransport 和 TProcessor 几个对象。\n\n上述的这5个部件都是在 Thrift 的源代码中通过为不同语言提供库来实现的，这些库的代码在 Thrift 源码目录的 lib 目录下面，在使用 Thrift 之前需要先熟悉与自己的语言对应的库提供的接口。\n\nFacebook Thrift构架：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/921.jpg)\n\n官网：[http://thrift.apache.org/](http://thrift.apache.org/)\n\n## 集群管理\n\n### 一、Nagios\n\n简介：Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。\n\nNagios可运行在Linux/Unix平台之上，同时提供一个可选的基于浏览器的WEB界面以方便系统管理人员查看网络状态，各种系统问题，以及日志等等。\n\n官网：[http://www.nagios.org/](http://www.nagios.org/)\n\n### 二、Ganglia\n\n简介：Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1130-600x417.jpg)\n\n官网：[http://ganglia.sourceforge.net/](http://ganglia.sourceforge.net/)\n\n### 三、Apache Ambari\n\n简介：Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。\n\nApache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1223.jpg)\n\n**Ambari主要取得了以下成绩：**\n\n通过一步一步的安装向导简化了集群供应。\n预先配置好关键的运维指标（metrics），可以直接查看Hadoop Core（HDFS和MapReduce）及相关项目（如HBase、Hive和HCatalog）是否健康。\n支持作业与任务执行的可视化与分析，能够更好地查看依赖和性能。\n通过一个完整的RESTful API把监控信息暴露出来，集成了现有的运维工具。\n用户界面非常直观，用户可以轻松有效地查看信息并控制集群。\nAmbari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时（比如，节点停机或磁盘剩余空间不足等问题），系统将向其发送邮件。\n\n此外，Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。\n\n官网：[http://ambari.apache.org/](http://ambari.apache.org/)\n\n## 基础设施\n\n### 一、LevelDB\n\n贡献者：Jeff Dean和Sanjay Ghemawat\n\n简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。\n\nLeveldb框架：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1322-468x429.jpg)\n\n官网：[http://code.google.com/p/leveldb/](http://code.google.com/p/leveldb/)\n\n### 二、SSTable\n\n简介：如果说Protocol Buffer是谷歌独立数据记录的通用语言 ，那么有序字符串表（SSTable，Sorted String Table）则是用于存储，处理和数据集交换的最流行​​的数据输出格式。正如它的名字本身，SSTable是有效存储大量键-值对的简单抽象，对高吞吐量顺序读/写进行了优化。\n\nSSTable是Bigtable中至关重要的一块，对于LevelDB来说也是如此。\n\n### 三、RecordIO\n\n贡献者：Google\n\n简介：我们大家都在用文件来存储数据。文件是存储在磁盘上的。如果在一些不稳定的介质上，文件很容损坏。即时文件某个位置出现一点小小的问题，整个文件就废了。\n\n下面我来介绍Google的一个做法，可以比较好的解决这个问题。那就是recordio文件格式。recoidio的存储单元是一个一个record。这个record可以根据业务的需要自行定义。但Google有一种建议的处理方式就是使用protobuf。\n\nreocordio底层的格式其实很简单。一个record由四部分组成：\n\nMagicNumber (32 bits)\nUncompressed data payload size (64 bits)\nCompressed data payload size (64 bits), or 0 if the data is not compressed\nPayload, possibly compressed.\n**详细格式如下图所示：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/recordio_thumb-600x76.png)\n\n到这里，大家可能已经知道，recordio之所以能对付坏数据，其实就是在这个MagicNumber（校验值）。\n\n### 四、Flat Buffers\n\n贡献者：Google\n\n简介：谷歌开源高效、跨平台的序列化库FlatBuffers。\n\n该库的构建是专门为游戏开发人员的性能需求提供支持，它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而不需要任何解析开销。\n\nFlatBuffers有如下一些关键特性——\n\n访问序列化数据不需要打包/拆包\n节省内存而且访问速度快——缓存只占用访问数据所需要的内存；不需要任何额外的内存。\n灵活性——通过可选字段向前向后兼容\n代码规模小\n强类型——错误在编译时捕获，而不是在运行时\n便利性——生成的C++头文件代码简洁。如果需要，有一项可选功能可以用来在运行时高效解析Schema和JSON-like格式的文本。\n跨平台——使用C++编写，不依赖STL之外的库，因此可以用于任何有C++编辑器的平台。当前，该项目包含构建方法和在Android、Linux、Windows和OSX等操作系统上使用该库的示例。\n与Protocol Buffers或JSON Parsing这样的可选方案相比，FlatBuffers的优势在于开销更小，这主要是由于它没有解析过程。\n\n代码托管：[https://github.com/google/flatbuffers](https://github.com/google/flatbuffers)\n\n### 五、Protocol Buffers\n\n贡献者：Google\n\n简介：Protocol Buffers是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。现阶段官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。\n\n通过它，你可以定义你的数据的结构，并生成基于各种语言的代码。这些你定义的数据流可以轻松地在传递并不破坏你已有的程序。并且你也可以更新这些数据而现有的程序也不会受到任何的影响。\n\nProtocol Buffers经常被简称为protobuf。\n\n官网：[http://code.google.com/p/protobuf/](http://code.google.com/p/protobuf/)\n\n### 六、Consistent Hashing（哈希算法）\n\n简介：一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1420.jpg)\n\n一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：\n\n1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。\n\n2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。\n\n3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。\n\n4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。\n\n在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。\n\n### 七、Netty\n\n贡献者：JBOSS\n\n简介：Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1518.jpg)\n\n也就是说，Netty 是一个基于NIO的客户，服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。\n\n“快速”和“简单”并不意味着会让你的最终应用产生维护性或性能上的问题。Netty 是一个吸收了多种协议的实现经验，这些协议包括FTP,SMTP,HTTP，各种二进制，文本协议，并经过相当精心设计的项目，最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。\n\n官网：[http://netty.io/](http://netty.io/)\n\n### 八、BloomFilter\n\n简介：Bloom filter 是由 Howard Bloom 在 1970 年提出的二进制向量数据结构，它具有很好的空间和时间效率，被用来检测一个元素是不是集合中的一个成员。如果检测结果为是，该元素不一定在集合中；但如果检测结果为否，该元素一定不在集合中。因此Bloom filter具有100%的召回率。这样每个检测请求返回有“在集合内（可能错误）”和“不在集合内（绝对不在集合内）”两种情况，可见 Bloom filter 是牺牲了正确率和时间以节省空间。\n\nBloom filter 优点就是它的插入和查询时间都是常数，另外它查询元素却不保存元素本身，具有良好的安全性。\n\n## 搜索引擎\n\n### 一、Nutch\n\n简介：Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。\n\n尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg)\n\nNutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.\n\nNutch目前最新的版本为version v2.2.1。\n\n官网：[https://nutch.apache.org/](https://nutch.apache.org/)\n\n### 二、Lucene\n\n开发者：Doug Cutting（Hadoop之父，你懂的）\n\n简介：Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1717-556x429.jpg)\n\n官网：[http://lucene.apache.org/](http://lucene.apache.org/)\n\n### 三、SolrCloud\n\n简介：SolrCloud是Solr4.0版本以后基于Solr和Zookeeper的分布式搜索方案。SolrCloud是Solr的基于Zookeeper一种部署方式。Solr可以以多种方式部署，例如单机方式，多机Master-Slaver方式。\n\n**原理图：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1813-583x429.jpg)\n\n**SolrCloud有几个特色功能：**\n\n集中式的配置信息使用ZK进行集中配置。启动时可以指定把Solr的相关配置文件上传\n\nZookeeper，多机器共用。这些ZK中的配置不会再拿到本地缓存，Solr直接读取ZK中的配置信息。配置文件的变动，所有机器都可以感知到。另外，Solr的一些任务也是通过ZK作为媒介发布的。目的是为了容错。接收到任务，但在执行任务时崩溃的机器，在重启后，或者集群选出候选者时，可以再次执行这个未完成的任务。\n\n自动容错SolrCloud对索引分片，并对每个分片创建多个Replication。每个Replication都可以对外提供服务。一个Replication挂掉不会影响索引服务。更强大的是，它还能自动的在其它机器上帮你把失败机器上的索引Replication重建并投入使用。\n\n近实时搜索立即推送式的replication（也支持慢推送）。可以在秒内检索到新加入索引。\n\n查询时自动负载均衡SolrCloud索引的多个Replication可以分布在多台机器上，均衡查询压力。如果查询压力大，可以通过扩展机器，增加Replication来减缓。\n\n自动分发的索引和索引分片发送文档到任何节点，它都会转发到正确节点。\n\n事务日志事务日志确保更新无丢失，即使文档没有索引到磁盘。\n\n### 四、Solr\n\n简介：Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1913-593x429.jpg)\n\nSolr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。\n\n官网：[https://lucene.apache.org/solr/](https://lucene.apache.org/solr/)\n\n### 五、ElasticSearch\n\n简介：ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二最流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。\n\n官网：[http://www.elasticsearch.org/](http://www.elasticsearch.org/)\n\n### 六、Sphinx\n\n简介：Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。\n\nSphinx单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。\n\n官网：[http://sphinxsearch.com](http://sphinxsearch.com)\n\n### 七、SenseiDB\n\n贡献者：linkedin\n\n简介：SenseiDB是一个NoSQL数据库，它专注于高更新率以及复杂半结构化搜索查询。熟悉Lucene和Solor的用户会发现，SenseiDB背后有许多似曾相识的概念。SenseiDB部署在多节点集群中，其中每个节点可以包括N块数据片。Apache Zookeeper用于管理节点，它能够保持现有配置，并可以将任意改动（如拓扑修改）传输到整个节点群中。SenseiDB集群还需要一种模式用于定义将要使用的数据模型。\n\n从SenseiDB集群中获取数据的唯一方法是通过Gateways（它 没有“INSERT”方法）。每个集群都连接到一个单一gateway。你需要了解很重要的一点是，由于SenseiDB本身没法处理原子性 （Atomicity）和隔离性（Isolation），因此只能通过外部在gateway层进行限制。另外，gateway必须确保数据流按照预期的方 式运作。内置的gateway有以下几种形式：\n\n来自文件\n来自JMS队列\n通过JDBC\n来自Apache Kafka\n官网：[http://senseidb.com](http://senseidb.com)\n\n## 数据挖掘\n\n### 一、Mahout\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg)\n\n简介：Apache Mahout 是 Apache Software Foundation (ASF) 开发的一个全新的开源项目，其主要目标是创建一些可伸缩的机器学习算法，供开发人员在 Apache 在许可下免费使用。该项目已经发展到了它的最二个年头，目前只有一个公共发行版。Mahout 包含许多实现，包括集群、分类、CP 和进化程序。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。\n\n虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：\n\nTaste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。\n一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。\nDistributed Naive Bayes 和 Complementary Naive Bayes 分类实现。\n针对进化编程的分布式适用性功能。\nMatrix 和矢量库。\n上述算法的示例。\n官网：[http://mahout.apache.org/](http://mahout.apache.org/)\n\n## Iaas\nIaaS（Infrastructure as a Service），即基础设施即服务。\n\n### 一、OpenStack\n\n简介：OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。\n\nOpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。\n\n![](http://www.36dsj.com/wp-content/uploads/2014/12/1148-599x429.jpg)\n\n6个核心项目：Nova（计算，Compute），Swift（对象存储，Object），Glance（镜像，Image），Keystone（身份，Identity），Horizon（自助门户，Dashboard），Quantum & Melange（网络&地址管理），另外还有若干社区项目，如Rackspace（负载均衡）、Rackspace（关系型数据库）。\n\n相关阅读：\n\n[什么是OpenStack？](http://www.36dsj.com/archives/19596)\n\n[成功部署OpenStack的十大要点](http://www.36dsj.com/archives/22179)\n\n 官网：[https://www.openstack.org/](https://www.openstack.org/)\n\n### 二、Docker\n\n贡献者：dotCloud\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2215.jpg)\n\n简介：Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包括系统。\n\n官网：[http://www.docker.io/](http://www.docker.io/)\n\n### 三、Kubernetes\n\n贡献者：Google\n\n简介：Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。\n\nKubernetes从另一个角度对资源进行抽象，它让开发人员和管理人员共同着眼于服务的行为和性能的提升，而不是仅仅关注对单一的组件或者是基础资源。\n\n那么Kubernetes集群到底提供了哪些单一容器所没有功能?它主要关注的是对服务级别的控制而并非仅仅是对容器级别的控制，Kubernetes提供了一种“机智”的管理方式，它将服务看成一个整体。在Kubernete的解决方案中，一个服务甚至可以自我扩展，自我诊断，并且容易升级。例如，在Google中，我们使用机器学习技术来保证每个运行的服务的当前状态都是最高效的。\n\n代码托管：[https://github.com/GoogleCloudPlatform/kubernetes/](https://github.com/GoogleCloudPlatform/kubernetes/)\n\n### 四、Imctfy\n\n贡献者：Google\n\n简介：Google开源了自己所用Linux容器系统的开源版本lmctfy，读音为lem-kut-fee。包括一个C++库（使用了C++11，文档可以参考头文件）和命令行界面。目前的版本是0.1，只提供了CPU与内存隔离。项目还在密集开发中。\n\nmctfy本身是针对某些特定使用场景设计和实现的，目前拥有一台机器上所有容器时运行情况最好，不推荐与LXC和其他容器系统一起使用（虽然也可行）。已在Ubuntu 12.04+和Ubuntu 3.3与3.8内核上测试。\n\n代码托管：[https://github.com/google/Imctfy/](https://github.com/google/Imctfy/)\n\n## 监控管理\n\n### 一、Dapper\n\n贡献者：Google\n\n简介：Dapper是一个轻量的ORM(对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）。并不单纯的是一个DBHelper.因为在Dapper中数据其实就是一个对象。Dapper扩展与IDbConnection上，所以事实上它的倾入性很低。我用了StructureMap。如果不喜欢可以自己更换，或者自己实现下。\n\n代码就一个SqlMapper.cs文件,主要是IDbConnection的扩展方法，编译后就40K的一个很小的dll。\n\n特性：\n\nDapper很快。Dapper的速度接近与IDataReader。\nDapper支持主流数据库 Mysql,SqlLite,Mssql2000,Mssql2005,Oracle等一系列的数据库\n支持多表并联的对象。支持一对多 多对多的关系，并且没侵入性。\n原理通过Emit反射IDataReader的序列队列，来快速的得到和产生对象\nDapper语法十分简单。并且无须迁就数据库的设计\n官方站点 [http://code.google.com/p/dapper-dot-net/](http://code.google.com/p/dapper-dot-net/)\n\n代码托管：[http://bigbully.github.io/Dapper-translation/](http://bigbully.github.io/Dapper-translation/)\n\n### 二、Zipkin\n\n贡献者：Twitter\n\n简介：Zipkin （分布式跟踪系统）是 Twitter 的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口。该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2313-535x429.jpg)\n\n官方网站：[http://twitter.github.io/zipkin/](http://twitter.github.io/zipkin/)\n\n代码托管：[https://github.com/twitter/zipkin/](https://github.com/twitter/zipkin/)\n\n**-------------------------------------End.-------------------------------------------**\n\n感谢:\n36大数据([http://www.36dsj.com/](http://www.36dsj.com/))\n\n转载来源:[http://www.36dsj.com/archives/24852](http://www.36dsj.com/archives/24852)\n[http://www.36dsj.com/archives/25042](http://www.36dsj.com/archives/25042)\n","source":"_posts/2015-07-29-大数据处理工具汇总.md","raw":"---\nlayout: lay_post\ntitle: \"大数据处理工具汇总\"\ndate: 2015-07-29 11:24:00\ncategories: 大数据\ntags: 工具\nauthor: 36dsj\npublished: true\nsummary: [\"http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg\",\"http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg\",\"http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg\"]\n---\n\n* 目录\n{:toc #meuid}\n\n## 查询引擎\n\n### 一、Phoenix\n\n贡献者：：Salesforce\n\n简介：这是一个Java中间层，可以让开发者在Apache HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于GitHub上，并且提供了一个客户端可嵌入的JDBC驱动。\n<!-- more -->\n\nPhoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。\n\nPhoenix最值得关注的一些特性有：\n\n❶嵌入式的JDBC驱动，实现了大部分的java.sql接口，包括元数据API\n\n❷可以通过多部行键或是键/值单元对列进行建模\n\n❸完善的查询支持，可以使用多个谓词以及优化的扫描键\n\n❹DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除列\n\n❺版本化的模式仓库：当写入数据时，快照查询会使用恰当的模式\n\n❻DML支持：用于逐行插入的UPSERT VALUES、用于相同或不同表之间大量数据传输的UPSERT \n\n❼SELECT、用于删除行的DELETE\n\n❽通过客户端的批处理实现的有限的事务支持\n\n❾单表——还没有连接，同时二级索引也在开发当中\n\n➓紧跟ANSI SQL标准\n\n[Phoenix官方网站>>>](http://phoenix.apache.org/)\n\n### 二、Stinger\n贡献者：：Hortonworks\n\n简介：原叫Tez，下一代Hive,Hortonworks主导开发，运行在YARN上的DAG计算框架。\n\n某些测试下，Stinger能提升10倍左右的性能，同时会让Hive支持更多的SQL，其主要优点包括：\n\n❶让用户在Hadoop获得更多的查询匹配。其中包括类似OVER的字句分析功能，支持WHERE查询，让Hive的样式系统更符合SQL模型。\n\n❷优化了Hive请求执行计划，优化后请求时间减少90%。改动了Hive执行引擎，增加单Hive任务的被秒处理记录数。\n\n❸在Hive社区中引入了新的列式文件格式（如ORC文件），提供一种更现代、高效和高性能的方式来储存Hive数据。\n\n❹引入了新的运行时框架——Tez，旨在消除Hive的延时和吞吐量限制。Tez通过消除不必要的task、障碍同步和对HDFS的读写作业来优化Hive job。这将优化Hadoop内部的执行链，彻底加速Hive负载处理。\n\n[Stinger官方网站>>>](http://hortonworks.com/labs/stinger/)\n\n### 三、Presto\n贡献者：：Facebook\n\n简介：Facebook开源的数据查询引擎Presto ，可对250PB以上的数据进行快速地交互式分析。该项目始于 2012 年秋季开始开发，目前该项目已经在超过 1000 名 Facebook 雇员中使用，运行超过 30000 个查询，每日数据在 1PB 级别。Facebook 称 Presto 的性能比诸如 Hive 和 Map*Reduce 要好上 10 倍有多。\n\nPresto 当前支持 ANSI SQL 的大多数特效，包括联合查询、左右联接、子查询以及一些聚合和计算函数；支持近似截然不同的计数(DISTINCT COUNT)等。\n\n[github源代码下载>>>](https://github.com/facebook/presto)\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1105.jpg)\n\n### 四、Shark\n简介：Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的特点就是快，完全兼容Hive，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。\n\n❶Shark速度快的原因除了Spark平台提供的基于内存迭代计算外，在设计上还存在对Spark上进行了一定的改造，主要有\n\n❷partial DAG execution：对join优化，调节并行粒度，因为Spark本身的宽依赖和窄依赖会影响并行计算和速度\n\n基于列的压缩和存储：把HQL表数据按列存，每列是一个array，存在JVM上，避免了JVM GC低效，而压缩和解压相关的技术是Yahoo!提供的。\n\n结来说，Shark是一个插件式的东西，在我现有的Spark和Hive及hadoop-client之间，在这两套都可用的情况下，Shark只要获取Hive的配置（还有metastore和exec等关键包），Spark的路径，Shark就能利用Hive和Spark，把HQL解析成RDD的转换，把数据取到Spark上运算和分析。在SQL on Hadoop这块，Shark有别于Impala，Stringer，而这些系统各有自己的设计思路，相对于对MR进行优化和改进的思路，Shark的思路更加简单明了些\n\n[Shark官方网站>>>](http://shark.cs.berkeley.edu/)\n\n### 五、Pig\n\n简介：Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。\n\nPig最大的作用就是对mapreduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组(group by)、关联(Joining)，Pig也可以由用户自定义一些函数对数据集进行操作，也就是传说中的UDF(user-defined functions)。\n\n[Pig官方网站>>>](http://pig.apache.org/)\n\n### 六、Cloudera Impala\n\n贡献者：:Cloudera\n\n简介：Cloudera Impala 可以直接为存储在HDFS或HBase中的Hadoop数据提供快速，交互式的SQL查询。除了使用相同的存储平台外， Impala和Apache Hive一样也使用了相同的元数据，SQL语法（Hive SQL），ODBC驱动和用户接口（Hue Beeswax），这就很方便的为用户提供了一个相似并且统一的平台来进行批量或实时查询。\n\nCloudera Impala 是用来进行大数据查询的补充工具。 Impala 并没有取代像Hive这样基于MapReduce的分布式处理框架。Hive和其它基于MapReduce的计算框架非常适合长时间运行的批处理作业，例如那些涉及到批量 Extract、Transform、Load ，即需要进行ETL作业。\n\nImpala 提供了：\n\n❶数据科学家或数据分析师已经熟知的SQL接口\n\n❷能够在Apache Hadoop 的大数据中进行交互式数据查询\n\n❸ Single system for big data processing and analytics so customers can avoid costly modeling and ETL just for analytics\n\n[Cloudera Impala官方网站>>>](http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html)\n\n### 七、Apache Drill\n\n贡献者：：MapR\n\n简介：Apache Drill是是一个能够对大数据进行交互分析、开源的分布式系统，且基于Google Dremel实现，它能够运行在上千个节点的服务器集群上，且能在几秒内处理PB级或者万亿条的数据记录。Drill能够帮助企业用户快速、高效地进行Hadoop数据查询和企业级大数据分析。Drill于2012年8月份由Apache推出。\n\n从Drill官方对其架构的介绍中得知，其具有适于实时的分析和快速的应用开发、适于半结构化/嵌套数据的分析、兼容现有的SQL环境和Apache Hive等特征。另外，Drill的核心模块是Drillbit服务，该服务模块包括远程访问子模块、SQL解析器、查询优化器、任务计划执行引擎、存储插件接口（DFS、HBase、Hive等的接口）、分布式缓存模块等几部分，如下图所示：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg)\n\n[Apache Drill官方网站>>>](http://incubator.apache.org/drill/)\n\n### 八、Apache Tajo\n\n简介：Apache Tajo项目的目的是在HDFS之上构建一个先进的数据仓库系统。Tajo将自己标榜为一个“大数据仓库”，但是它好像和之前介绍的那些低延迟查询引擎类似。虽然它支持外部表和Hive数据集（通过HCatalog），但是它的重点是数据管理，提供低延迟的数据访问，以及为更传统的ETL提供工具。它也需要在数据节点上部署Tajo特定的工作进程。\n\nTajo的功能包括：\n\n❶ANSI SQL兼容\n❷JDBC 驱动\n❸集成Hive metastore能够访问Hive数据集\n❹一个命令行客户端\n❺一个自定义函数API\n\n[Apache Tajo官方网站>>>](http://tajo.incubator.apache.org/)\n\n### 九、Hive\n\n简介：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。\n\n[Hive官方网站>>>](http://hive.apache.org/)\n\n## 流式计算\n\n### 一、Facebook Puma\n\n贡献者：Facebook\n\n简介：实时数据流分析\n\n### 二、Twitter Rainbird\n\n贡献者：Twitter\n\n简介：Rainbird一款基于Zookeeper, Cassandra, Scribe, Thrift的分布式实时统计系统，这些基础组件的基本功能如下：\n\n❶ Zookeeper，Hadoop子项目中的一款分布式协调系统，用于控制分布式系统中各个组件中的一致性。\n\n❷Cassandra，NoSQL中一款非常出色的产品，集合了Dynamo和Bigtable特性的分布式存储系统，用于存储需要进行统计的数据，统计数据，并且提供客户端进行统计数据的查询。（需要使用分布式Counter补丁CASSANDRA-1072）\n\n❸ Scribe，Facebook开源的一款分布式日志收集系统，用于在系统中将各个需要统计的数据源收集到Cassandra中。\n\n❹ Thrift，Facebook开源的一款跨语言C/S网络通信框架，开发人员基于这个框架可以轻易地开发C/S应用。\n\n用处\n\nRainbird可以用于实时数据的统计：\n\n❶统计网站中每一个页面，域名的点击次数\n\n❷内部系统的运行监控（统计被监控服务器的运行状态）\n\n❸记录最大值和最小值\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/280.jpg)\n\n### 三、Yahoo S4\n\n贡献者：Yahoo\n\n简介：S4（Simple Scalable Streaming System）最初是Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。目前该项目刚启动不久，所以也可以理解为是他们提出的一个分布式流计算（Distributed Stream Computing）的模型。\n\nS4的设计目标是：\n\n·提供一种简单的编程接口来处理数据流\n\n·设计一个可以在普通硬件之上可扩展的高可用集群。\n\n·通过在每个处理节点使用本地内存，避免磁盘I/O瓶颈达到最小化延迟\n\n·使用一个去中心的，对等架构；所有节点提供相同的功能和职责。没有担负特殊责任的中心节点。这大大简化了部署和维护。\n\n·使用可插拔的架构，使设计尽可能的即通用又可定制化。\n\n·友好的设计理念，易于编程，具有灵活的弹性\n\n[Yahoo S4官方网站>>>](http://incubator.apache.org/s4/)\n\n### 四、Twitter Storm\n\n贡献者：Twitter\n\n简介：Storm是Twitter开源的一个类似于Hadoop的实时数据处理框架，它原来是由BackType开发，后BackType被Twitter收购，将Storm作为Twitter的实时数据分析系统。\n\n实时数据处理的应用场景很广泛，例如商品推荐，广告投放，它能根据当前情景上下文（用户偏好，地理位置，已发生的查询和点击等）来估计用户点击的可能性并实时做出调整。\n\nstorm的三大作用领域：\n\n1.信息流处理（Stream Processing）\n\nStorm可以用来实时处理新数据和更新数据库，兼具容错性和可扩展性,它 可以用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。\n\n2.连续计算（Continuous Computation）\n\nStorm可以进行连续查询并把结果即时反馈给客户，比如将Twitter上的热门话题发送到客户端。\n\n3.分布式远程过程调用（Distributed RPC）\n\n除此之外，Storm也被广泛用于以下方面：\n\n精确的广告推送\n实时日志的处理\n\n[Twitter Storm官方网站>>>](http://storm.incubator.apache.org/)\n\n##迭代计算\n\n### 一、Apache Hama\n\n简介：Apache Hama是一个纯BSP（Bulk Synchronous Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。\n\n❶建立在Hadoop上的分布式并行计算模型。\n\n❷基于 Map/Reduce 和 Bulk Synchronous 的实现框架。\n\n❸运行环境需要关联 Zookeeper、HBase、HDFS 组件。\n\nHama中有2个主要的模型:\n\n– 矩阵计算(Matrix package)\n\n– 面向图计算(Graph package)\n\n[Apache Hama官方网站>>>](https://hama.apache.org/)\n\n### 二、Apache Giraph\n\n代码托管地址： [GitHub](https://github.com/apache/giraph)\n\n简介：Apache Giraph是一个可伸缩的分布式迭代图处理系统，灵感来自BSP（bulk synchronous parallel）和Google的Pregel，与它们 区别于则是是开源、基于 Hadoop 的架构等。\n\nGiraph处理平台适用于运行大规模的逻辑计算，比如页面排行、共享链接、基于个性化排行等。Giraph专注于社交图计算，被Facebook作为其Open Graph工具的核心，几分钟内处理数万亿次用户及其行为之间的连接。\n\n### 三、HaLoop\n\n简介：迭代的MapReduce，HaLoop——适用于迭代计算的Hadoop 。\n\n ![](http://www.36dsj.com/wp-content/uploads/2015/03/425.jpg)\n \n                                Hadoop与HaLoop的不同\n\n与Hadoop比较的四点改变：\n\n1.提供了一套新的编程接口，更加适用于迭代计算；\n\nHaLoop给迭代计算一个抽象的递归公式：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/403.jpg)\n\n2.HaLoop的master进行job内的循环控制，直到迭代计算结束；\n\n3.Task Scheduler也进行了修改，使得任务能够尽量满足data locality\n\n4.slave nodes对数据进行cache并index索引，索引也以文件的形式保存在本地磁盘。\n\n[HaLoop官网>>>](https://code.google.com/p/haloop/)\n\n### 四、Twister\n\n简介：Twister， 迭代式MapReduce框架，Twister是由一个印度人开发的，其架构如下：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/524.jpg)\n\n在Twister中，大文件不会自动被切割成一个一个block，因而用户需提前把文件分成一个一个小文件，以供每个task处理。在map阶段，经过map（）处理完的结果被放在分布式内存中，然后通过一个broker network（NaradaBroking系统）将数据push给各个reduce task（Twister假设内存足够大，中间数据可以全部放在内存中）；在reduce阶段，所有reduce task产生的结果通过一个combine操作进行归并，此时，用户可以进行条件判定， 确定迭代是否结束。combine后的数据直接被送给map task，开始新一轮的迭代。为了提高容错性，Twister每隔一段时间会将map task和reduce task产生的结果写到磁盘上，这样，一旦某个task失败，它可以从最近的备份中获取输入，重新计算。\n\n为了避免每次迭代重新创建task，Twister维护了一个task pool，每次需要task时直接从pool中取。在Twister中，所有消息和数据都是通过broker network传递的，该broker network是一个独立的模块，目前支持NaradaBroking和ActiveMQ。\n\n## 离线计算\n\n### 一、Hadoop MapReduce\n\n简介：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）”，和它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。\n\n[Hadoop MapReduce官方网站>>>](http://hadoop.apache.org/)\n\n### 二、Berkeley Spark\n\n简介：Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。\n\n### 三、DataTorrent\n\n简介：DataTorrent基于Hadoop 2.x构建，是一个实时的、有容错能力的数据流式处理和分析平台，它使用本地Hadoop应用程序，而这些应用程序可以与执行其它任务，如批处理，的应用程序共存。该平台的架构如下图所示：\n![](http://www.36dsj.com/wp-content/uploads/2015/03/621.jpg)\n\n相关文章：[DataTorrent 1.0每秒处理超过10亿个实时事件](http://www.36dsj.com/archives/20163)\n\n[DataTorrent 将数据分析速度从“实时”提升至“现在时”](http://www.36dsj.com/archives/1596)\n\n## 键值存储\n\n### 一、LevelDB\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/723.jpg)\n\n贡献者：Google\n\n简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。\n\nLevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。\n\n此处随机读是完全命中内存的速度，如果是不命中 速度大大下降。\n\n[LevelDB官方网站>>>](https://code.google.com/p/leveldb/)\n\n### 二、RocksDB\n\n贡献者：facebook\n\n简介：RocksDB虽然在代码层面上是在LevelDB原有的代码上进行开发的，但却借鉴了Apache HBase的一些好的idea。在云计算横行的年代，开口不离Hadoop，RocksDB也开始支持HDFS，允许从HDFS读取数据。RocksDB支持一次获取多个K-V，还支持Key范围查找。LevelDB只能获取单个Key。\n\nRocksDB除了简单的Put、Delete操作，还提供了一个Merge操作，说是为了对多个Put操作进行合并。\n\nRocksDB提供一些方便的工具，这些工具包含解析sst文件中的K-V记录、解析MANIFEST文件的内容等。RocksDB支持多线程合并，而LevelDB是单线程合并的。\n\n[RocksDB官方网站>>>](http://rocksdb.org/)\n\n### 三、HyperDex\n\n贡献者：Facebook\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/821.jpg)\n\nHyperDex是一个分布式、可搜索的键值存储系统，特性如下：\n\n分布式KV存储，系统性能能够随节点数目线性扩展\n吞吐和延时都能秒杀现在风头正劲的MonogDB，吞吐甚至强于Redis\n使用了hyperspace hashing技术，使得对存储的K-V的任意属性进行查询成为可能\n\n官网：[http://hyperdex.org/](http://hyperdex.org/)\n\n### 四、TokyoCabinet\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/104.png)\n\n日本人Mikio Hirabayashi（平林干雄）开发的一款DBM数据库。Tokyo Cabinet 是一个DBM的实现。这里的数据库由一系列key-value对的记录构成。key和value都可以是任意长度的字节序列,既可以是二进制也可以是字符串。这里没有数据类型和数据表的概念。\n当 做为Hash表数据库使用时，每个key必须是不同的,因此无法存储两个key相同的值。提供了以下访问方法:提供key,value参数来存储，按 key删除记录，按key来读取记录，另外，遍历key也被支持，虽然顺序是任意的不能被保证。这些方法跟Unix标准的DBM,例如GDBM,NDBM 等等是相同的，但是比它们的性能要好得多（因此可以替代它们) 。下一代KV存储系统，支持strings、integers、floats、lists、maps和sets等丰富的数据类型。\n\n[TokyoCabinet官方网站>>>](http://fallabs.com/tokyocabinet/)\n\n### 五、Voldemort\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg)\n\nVoldemort是一个分布式键值存储系统，是Amazon’s Dynamo的一个开源克隆。特性如下：\n支持自动复制数据到多个服务器上。\n支持数据自动分割所以每个服务器只包含总数据的一个子集。\n提供服务器故障透明处理功能。\n支持可拨插的序化支持，以实现复杂的键-值存储，它能够很好的5.集成常用的序化框架如：Protocol Buffers、Thrift、Avro和Java Serialization。\n数据项都被标识版本能够在发生故障时尽量保持数据的完整性而不会影响系统的可用性。\n每个节点相互独立，互不影响。\n支持可插拔的数据放置策略\n官网：[http://project-voldemort.com/](http://project-voldemort.com/)\n\n### 六、Amazon Dynamo\n贡献者：亚马逊\n\n简介：Amazon Dynamo 是一个经典的分布式Key-Value 存储系统，具备去中心化，高可用性，高扩展性的特点，但是为了达到这个目标在很多场景中牺牲了一致性。Dynamo在Amazon中得到了成功的应用，能够跨数据中心部署于上万个结点上提供服务，它的设计思想也被后续的许多分布式系统借鉴。如近来火热的Cassandra，实际上就是基本照搬了Dynamo的P2P架构，同时融合了BigTable的数据模型及存储算法。\n\n[Amazon Dynamo官方网站>>>](https://github.com/dynamo/dynamo)\n\n### 七、Tair\n贡献者：淘宝\n\n简介：tair 是淘宝自己开发的一个分布式 key/value 存储引擎. tair 分为持久化和非持久化两种使用方式. 非持久化的 tair 可以看成是一个分布式缓存. 持久化的 tair 将数据存放于磁盘中. 为了解决磁盘损坏导致数据丢失, tair 可以配置数据的备份数目, tair 自动将一份数据的不同备份放到不同的主机上, 当有主机发生异常, 无法正常提供服务的时候, 其于的备份会继续提供服务.tair 的总体结构\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1220.jpg)\n\nTairtair 作为一个分布式系统, 是由一个中心控制节点和一系列的服务节点组成. 我们称中心控制节点为config server. 服务节点是data server. config server 负责管理所有的data server, 维护data server的状态信息. data server 对外提供各种数据服务, 并以心跳的形式将自身状况汇报给config server. config server是控制点, 而且是单点, 目前采用一主一备的形式来保证其可靠性. 所有的 data server 地位都是等价的.\n\n### 八、Apache Accumulo\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/8c2532b6-0c16-3879-9600-2a263d923934.png)\n\nApache Accumulo 是一个可靠的、可伸缩的、高性能的排序分布式的 Key-Value 存储解决方案，基于单元访问控制以及可定制的服务器端处理。Accumulo使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。\n \n官网：[http://accumulo.apache.org/](http://accumulo.apache.org/)\n\n### 九、Redis\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1320.jpg)\n\nRedis是一个高性能的key-value存储系统，和Memcached类似，它支持存储的value类型相对更多，包括string（字符串）、list（链表）、set（集合）和zset（有序集合）。与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了主从同步。\n\nRedis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Python、Ruby、Erlang、PHP客户端，使用很方便。\n\n官网：[http://redis.io/](http://redis.io/)\n\n## 表格存储\n\n### 一、OceanBase\n\n贡献者：阿里巴巴\n\n相关文章：[26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase](http://www.36dsj.com/archives/20317)\n\n简介：OceanBase是一个支持海量数据的高性能分布式数据库系统，实现了数千亿条记录、数百TB数据上的跨行跨表事务，由淘宝核心系统研发部、运维、DBA、广告、应用研发等部门共同完成。在设计和实现OceanBase的时候暂时摒弃了不紧急的DBMS的功能，例如临时表，视图(view)，研发团队把有限的资源集中到关键点上，当前 OceanBase主要解决数据更新一致性、高性能的跨表读事务、范围查询、join、数据全量及增量dump、批量数据导入。\n\n目前OceanBase已经应用于淘宝收藏夹，用于存储淘宝用户收藏条目和具体的商品、店铺信息，每天支持4～5千万的更新操作。等待上线的应用还包括CTU、SNS等，每天更新超过20亿，更新数据量超过2.5TB，并会逐步在淘宝内部推广。\n\nOceanBase 0.3.1在Github开源，开源版本为Revision:12336。\n\n官网：[http://alibaba.github.io/oceanbase/](http://alibaba.github.io/oceanbase/)\n\n### 二、Amazon SimpleDB\n\n贡献者：亚马逊\n\nAmazon SimpleDB是一个分散式数据库，以Erlang撰写。同与Amazon EC2和亚马逊的S3一样作为一项Web 服务，属于亚马逊网络服务的一部分。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1106.jpg)\n\n正如EC2和S3，SimpleDB的按照存储量，在互联网上的传输量和吞吐量收取费用。 在2008年12月1日，亚马逊推出了新的定价策略，提供了免费1 GB的数据和25机器小时的自由层(Free Tire)。 将其中的数据转移到其他亚马逊网络服务是免费的。\n\n它是一个可大规模伸缩、用 Erlang 编写的高可用数据存储。\n\n官网：[http://aws.amazon.com/cn/simpledb/](http://aws.amazon.com/cn/simpledb/)\n\n### 三、Vertica\n\n贡献者：惠普\n\n简介：惠普2011年2月份起始3月21号完成收购Vertica。Vertica基于列存储。基于列存储的设计相比传统面向行存储的数据库具有巨大的优势。同时Vertica支持MPP（massively parallel processing）等技术，查询数据时Vertica只需取得需要的列，而不是被选择行的所有数据，其平均性能可提高50x-1000x倍。（查询性能高速度快）\n\nVertica的设计者多次表示他们的产品围绕着高性能和高可用性设计。由于对MPP技术的支持，可提供对粒度，可伸缩性和可用性的优势。每个节点完全独立运作，完全无共享架构，降低对共享资源的系统竞争。\n\nVertica的数据库使用标准的SQL查询，同时Vertica的架构非常适合云计算，包括虚拟化，分布式多节点运行等，并且可以和Hadoop/MapReduce进行集成。\n\nVertica官网：[http://www.vertica.com/](http://www.vertica.com/)\n\n### 四、Cassandra\n\n贡献者：facebook\n\n相关文章：[开源分布式NoSQL数据库系统——Cassandra](http://www.36dsj.com/archives/20079)   [Cassandra与HBase的大数据对决 谁是胜者？](http://www.36dsj.com/archives/7179)\n\n简介：Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩放性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/290.jpg)\n\nCassandra是一个混合型的非关系的数据库，类似于Google的BigTable。其主要功能比Dynamo （分布式的Key-Value存储系统）更丰富，但支持度却不如文档存储MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的。支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型）。Cassandra最初由Facebook开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族（Column Family）的数据模型。P2P去中心化的存储。很多方面都可以称之为Dynamo 2.0。\n\nCassandra官网：[http://cassandra.apache.org/](http://cassandra.apache.org/)\n\n### 五、HyperTable\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/347.jpg)\n\n简介：Hypertable是一个开源、高性能、可伸缩的数据库，它采用与Google的Bigtable相似的模型。在过去数年中，Google为在PC集群 上运行的可伸缩计算基础设施设计建造了三个关键部分。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/426.jpg)\n\n第一个关键的基础设施是Google File System（GFS），这是一个高可用的文件系统，提供了一个全局的命名空间。它通过跨机器（和跨机架）的文件数据复制来达到高可用性，并因此免受传统 文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等失败。第二个基础设施是名为Map-Reduce的计算框架，它与GFS紧密协作，帮 助处理收集到的海量数据。第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让你可以通过一些主键来组织海量数据，并实现高效的 查询。Hypertable是Bigtable的一个开源实现，并且根据我们的想法进行了一些改进。\n\nHyperTable官网：[http://hypertable.org/](http://hypertable.org/)\n\n### 六、FoundationDB\n\n简介：支持ACID事务处理的NoSQL数据库，提供非常好的性能、数据一致性和操作弹性。\n\n2015年1月2日，FoundationDB已经发布了其key-value数据库的3.0版本，主要专注于可伸缩性和性能上的改善。FoundationDB的CEO David Rosenthal在一篇博客上宣布了新的版本，其中展示了FoundationDB 3.0在可伸缩性方面的数据，它可以在一个32位的c3.8xlarge EC2实例上每秒写入1440万次；这在性能上是之前版本的36倍。\n\n除了性能和可伸缩性的改善之外，FoundationDB 3.0还包含了对监控支持的改善。这种监控机制不仅仅是简单的机器检查，它添加了对多种潜在的硬件瓶颈的诊断，并且把那些高层级的信息整合到现有监控基础架构中。\n\n官网：[https://foundationdb.com/](https://foundationdb.com/)\n\n### 七：HBase\n\n贡献者： Fay Chang 所撰写的“Bigtable\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/526.jpg)\n\n简介：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。\n\n官网：[http://hbase.apache.org/](http://hbase.apache.org/)\n\n## 文件存储\n\n### 一、CouchDB\n\n简介：CouchDB是用Erlang开发的面向文档的数据库系统，最近刚刚发布了1.0版本（2010年7月14日）。CouchDB不是一个传统的关系数据库，而是面向文档的数据库，其数据存储方式有点类似lucene的index文件格式，CouchDB最大的意义在于它是一个面向web应用的新一代存储系统，事实上，CouchDB的口号就是：下一代的Web应用存储系统。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/623.jpg)\n\n特点：\n\n一、CouchDB是分布式的数据库，他可以把存储系统分布到n台物理的节点上面，并且很好的协调和同步节点之间的数据读写一致性。这当然也得靠Erlang无与伦比的并发特性才能做到。对于基于web的大规模应用文档应用，分布式可以让它不必像传统的关系数据库那样分库拆表，在应用代码层进行大量的改动。\n\n二、CouchDB是面向文档的数据库，存储半结构化的数据，比较类似lucene的index结构，特别适合存储文档，因此很适合CMS，电话本，地址本等应用，在这些应用场合，文档数据库要比关系数据库更加方便，性能更好。\n\n三、CouchDB支持REST API，可以让用户使用JavaScript来操作CouchDB数据库，也可以用JavaScript编写查询语句，我们可以想像一下，用AJAX技术结合CouchDB开发出来的CMS系统会是多么的简单和方便。\n\n其实CouchDB只是Erlang应用的冰山一角，在最近几年，基于Erlang的应用也得到的蓬勃的发展，特别是在基于web的大规模，分布式应用领域，几乎都是Erlang的优势项目。\n\n官网：[http://couchdb.apache.org/](http://couchdb.apache.org/)\n\n### 二、MongoDB\n\n简介：MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。\n\nMongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。\n\n相关文章：[MongoDB的基本特性与内部构造](http://www.36dsj.com/archives/22965)  [大数据吃香 创业公司MongoDB估值达16亿美元](http://www.36dsj.com/archives/21104)\n\n![](http://www.36dsj.com/wp-content/uploads/2015/01/2710.jpg)\n\n特点\n\n它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：\n\n*面向集合存储，易存储对象类型的数据。\n\nmongodb集群参考\n\nmongodb集群参考\n\n*模式自由。\n\n*支持动态查询。\n\n*支持完全索引，包含内部对象。\n\n*支持查询。\n\n*支持复制和故障恢复。\n\n*使用高效的二进制数据存储，包括大型对象（如视频等）。\n\n*自动处理碎片，以支持云计算层次的扩展性。\n\n*支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。\n\n*文件存储格式为BSON（一种JSON的扩展）。\n\n*可通过网络访问。\n\n官网：[https://www.mongodb.org/](https://www.mongodb.org/)\n\n### 三、Tachyon\n\n贡献者：Haoyuan Li（李浩源）\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/725-220x150.jpg)\n\n简介：Tachyon是一个分布式内存文件系统，可以在集群里以访问内存的速度来访问存在tachyon里的文件。把Tachyon是架构在最底层的分布式文件存储和上层的各种计算框架之间的一种中间件。主要职责是将那些不需要落地到DFS里的文件，落地到分布式内存文件系统中，来达到共享内存，从而提高效率。同时可以减少内存冗余，GC时间等。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/823.jpg)\n\n**Tachyon架构**\n\nTachyon的架构是传统的Master—slave架构，这里和Hadoop类似，TachyonMaster里WorkflowManager是 Master进程，因为是为了防止单点问题，通过Zookeeper做了HA，可以部署多台Standby Master。Slave是由Worker Daemon和Ramdisk构成。这里个人理解只有Worker Daemon是基于JVM的，Ramdisk是一个off heap memory。Master和Worker直接的通讯协议是Thrift。\n\n下图来自Tachyon的作者Haoyuan Li：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/920.jpg)\n\n下载地址：[https://github.com/amplab/tachyon](https://github.com/amplab/tachyon)\n\n### 四、KFS\n\n简介：GFS的C++开源版本，Kosmos distributed file system (KFS)是一个专门为数据密集型应用（搜索引擎，数据挖掘等）而设计的存储系统，类似于Google的GFS和Hadoop的HDFS分布式文件系统。 KFS使用C++实现，支持的客户端包括C++，Java和Python。KFS系统由三部分组成，分别是metaserver、chunkserver和client library。\n\n官网：[http://code.google.com/p/kosmosfs/](http://code.google.com/p/kosmosfs/)\n\n### 五、HDFS\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1022.jpg)\n\n简介：Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。\n\n官网：[http://hadoop.apache.org/](http://hadoop.apache.org/)\n\n## 资源管理\n\n### 一、Twitter Mesos\n\n开发者：Twitter研发人员John Oskasson\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1129.jpg)\n\n简介：Apache Mesos是由加州大学伯克利分校的AMPLab首先开发的一款开源群集管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等架构，由于其开源性质越来越受到一些大型云计算公司的青睐，例如Twitter、Facebook等。\n\n参考文章：[Mesos渐入主流,Twitter模式有望 “无限复制”-CSDN.NET](http://www.csdn.net/article/2014-02-24/2818520-Cloud-Mesosphere-Mesos-Hadoop-Spark)\n\n官网：[http://mesos.apache.org/](http://mesos.apache.org/)\n\n### 二、Hadoop Yarn\n\nHadoop 新 MapReduce 框架 Yarn。为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1222.jpg)\n\nYarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：\n\n1、这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。\n\n2、在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。\n\n3、对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。\n\n4、老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的行状况，如果出问题，会将其在其他机器上重启。\n\n5、Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。\n\n官网：[http://hadoop.apache.org/](http://hadoop.apache.org/)\n\n## 日志收集系统\n\n### 一、Facebook Scribe\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1107.jpg)\n\n贡献者：Facebook\n\n简介：Scribe是Facebook开源的日志收集系统，在Facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央存储系统。其通常与Hadoop结合使用，scribe用于向HDFS中push日志，而Hadoop通过MapReduce作业进行定期处理。\n\nScribe的系统架构\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/298-600x234.jpg)\n\n代码托管：[https://github.com/facebook/scribe](https://github.com/facebook/scribe)\n\n### 二、Cloudera Flume\n![](http://www.36dsj.com/wp-content/uploads/2015/03/348.jpg)\n\n贡献者：[Cloudera](http://www.36dsj.com/archives/tag/cloudera)\n\n简介：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。\n\nFlume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。\n\n当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。\n\n**Cloudera Flume构架：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/427-414x429.jpg)\n\n官网：[http://flume.apache.org/](http://flume.apache.org/)\n\n### 三、logstash\n\n简介：logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/527-600x265.jpg)\n\n官网：[http://www.logstash.net/](http://www.logstash.net/)\n\n### 四、kibana\n\n简介：Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面。\n\n主页： [http://kibana.org/](http://kibana.org/)\n\n代码托管： [https://github.com/rashidkpc/Kibana/downloads](https://github.com/rashidkpc/Kibana/downloads)\n\n## 消息系统\n\n### 一、StormMQ\n\n简介：MQMessageQueue消息队列产品 StormMQ，是一种服务程序。\n\n官网：[http://stormmq.com/](http://stormmq.com/)\n\n### 二、ZeroMQ\n\n简介：这是个类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。\n\n引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”\n\n官网：[http://zeromq.org/](http://zeromq.org/)\n\n### 三、RabbitMQ\n\n简介：RabbitMQ是一个受欢迎的消息代理，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。本文简单介绍了如何使用 RabbitMQ，假定你已经配置好了rabbitmq服务器。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/624.jpg)\n\nRabbitMQ是用Erlang，对于主要的编程语言都有驱动或者客户端。我们这里要用的是Java，所以先要获得Java客户端。\n\n像RabbitMQ这样的消息代理可用来模拟不同的场景，例如点对点的消息分发或者订阅/推送。我们的程序足够简单，有两个基本的组件，一个生产者用于产生消息，还有一个消费者用来使用产生的消息。\n\n官网：[https://www.rabbitmq.com/](https://www.rabbitmq.com/)\n\n### 四、Apache ActiveMQ\n\n简介：ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/726.jpg)\n\n特性：\n\n⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP\n\n⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)\n\n⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性\n\n⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上\n\n⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA\n\n⒍ 支持通过JDBC和journal提供高速的消息持久化\n\n⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点\n\n⒏ 支持Ajax\n\n⒐ 支持与Axis的整合\n\n⒑ 可以很容易得调用内嵌JMS provider，进行测试\n\n官网：[http://activemq.apache.org/](http://activemq.apache.org/)\n\n### 五、Jafka\n\n贡献者：LinkedIn\n\n简介：Jafka 是一个开源的、高性能的、跨语言分布式消息系统，使用GitHub托管。Jafka 最早是由Apache孵化的Kafka（由LinkedIn捐助给Apache）克隆而来。由于是一个开放式的数据传输协议，因此除了Java开发语言受到支持，Python、Ruby、C、C++等其他语言也能够很好的得到支持。\n\n特性：\n\n1、消息持久化非常快，服务端存储消息的开销为O(1)，并且基于文件系统，能够持久化TB级的消息而不损失性能。\n\n2、吞吐量取决于网络带宽。\n\n3、完全的分布式系统，broker、producer、consumer都原生自动支持分布式。自动实现复杂均衡。\n\n4、内核非常小，整个系统（包括服务端和客户端）只有一个272KB的jar包，内部机制也不复杂，适合进行内嵌或者二次开发 。整个服务端加上依赖组件共3.5MB。\n\n5、消息格式以及通信机制非常简单，适合进行跨语言开发。目前自带的Python3.x的客户端支持发送消息和接收消息。\n\n官网：[http://kafka.apache.org/](http://kafka.apache.org/)\n\n### 六、Apache Kafka\n\n贡献者：LinkedIn\n\n简介：Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。\n\nKafka是一个分布式的、分区的、多复本的日志提交服务。它通过一种独一无二的设计提供了一个消息系统的功能。\n\nKafka集群可以在一个指定的时间内保持所有发布上来的消息，不管这些消息有没有被消费。打个比方，如果这个时间设置为两天，那么在消息发布的两天以内，这条消息都是可以被消费的，但是在两天后，这条消息就会被系统丢弃以释放空间。Kafka的性能不会受数据量的大小影响，因此保持大量的数据不是一个问题。\n\n官网：[http://kafka.apache.org/](http://kafka.apache.org/)\n\n## 分布式服务\n\n### 一、ZooKeeper\n\n贡献者：Google\n\n简介：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。\n\nZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。\n\n架构：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/824-600x244.jpg)\n\n官网：[http://zookeeper.apache.org/](http://zookeeper.apache.org/)\n\n## RPC\n\n（Remote Procedure Call Protocol）——远程过程调用协议\n\n### 一、Apache Avro\n\n简介：Apache Avro是Hadoop下的一个子项目。它本身既是一个序列化框架，同时也实现了RPC的功能。Avro官网描述Avro的特性和功能如下：\n\n丰富的数据结构类型；\n快速可压缩的二进制数据形式；\n存储持久数据的文件容器；\n提供远程过程调用RPC；\n简单的动态语言结合功能。\n相比于Apache Thrift 和Google的Protocol Buffers，Apache Avro具有以下特点：\n\n支持动态模式。Avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。\n数据无须加标签。读取数据前，Avro能够获取模式定义，这使得Avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。\n官网：[http://avro.apache.org/](http://avro.apache.org/)\n\n### 二、Facebook Thrift\n\n贡献者：Facebook\n\n简介：Thrift源于大名鼎鼎的facebook之手，在2007年facebook提交Apache基金会将Thrift作为一个开源项目，对于当时的facebook来说创造thrift是为了解决facebook系统中各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性。\n\nthrift可以支持多种程序语言，例如: C++, C#, Cocoa, Erlang, Haskell, Java, Ocami, Perl, PHP, Python, Ruby, Smalltalk. 在多种不同的语言之间通信thrift可以作为二进制的高性能的通讯中间件，支持数据(对象)序列化和多种类型的RPC服务。\n\nThrift适用于程序对程 序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程，跟其他IDL工具相比较可以视为是Thrift的弱项，Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输相对于JSON和xml无论在性能、传输大小上有明显的优势。\n\nThrift 主要由5个部分组成：\n\n· 类型系统以及 IDL 编译器：负责由用户给定的 IDL 文件生成相应语言的接口代码\n\n· TProtocol：实现 RPC 的协议层，可以选择多种不同的对象串行化方式，如 JSON, Binary。\n\n· TTransport：实现 RPC 的传输层，同样可以选择不同的传输层实现，如socket, 非阻塞的 socket, MemoryBuffer 等。\n\n· TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口。\n\n· TServer：聚合 TProtocol, TTransport 和 TProcessor 几个对象。\n\n上述的这5个部件都是在 Thrift 的源代码中通过为不同语言提供库来实现的，这些库的代码在 Thrift 源码目录的 lib 目录下面，在使用 Thrift 之前需要先熟悉与自己的语言对应的库提供的接口。\n\nFacebook Thrift构架：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/921.jpg)\n\n官网：[http://thrift.apache.org/](http://thrift.apache.org/)\n\n## 集群管理\n\n### 一、Nagios\n\n简介：Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。\n\nNagios可运行在Linux/Unix平台之上，同时提供一个可选的基于浏览器的WEB界面以方便系统管理人员查看网络状态，各种系统问题，以及日志等等。\n\n官网：[http://www.nagios.org/](http://www.nagios.org/)\n\n### 二、Ganglia\n\n简介：Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1130-600x417.jpg)\n\n官网：[http://ganglia.sourceforge.net/](http://ganglia.sourceforge.net/)\n\n### 三、Apache Ambari\n\n简介：Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。\n\nApache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1223.jpg)\n\n**Ambari主要取得了以下成绩：**\n\n通过一步一步的安装向导简化了集群供应。\n预先配置好关键的运维指标（metrics），可以直接查看Hadoop Core（HDFS和MapReduce）及相关项目（如HBase、Hive和HCatalog）是否健康。\n支持作业与任务执行的可视化与分析，能够更好地查看依赖和性能。\n通过一个完整的RESTful API把监控信息暴露出来，集成了现有的运维工具。\n用户界面非常直观，用户可以轻松有效地查看信息并控制集群。\nAmbari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时（比如，节点停机或磁盘剩余空间不足等问题），系统将向其发送邮件。\n\n此外，Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。\n\n官网：[http://ambari.apache.org/](http://ambari.apache.org/)\n\n## 基础设施\n\n### 一、LevelDB\n\n贡献者：Jeff Dean和Sanjay Ghemawat\n\n简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。\n\nLeveldb框架：\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1322-468x429.jpg)\n\n官网：[http://code.google.com/p/leveldb/](http://code.google.com/p/leveldb/)\n\n### 二、SSTable\n\n简介：如果说Protocol Buffer是谷歌独立数据记录的通用语言 ，那么有序字符串表（SSTable，Sorted String Table）则是用于存储，处理和数据集交换的最流行​​的数据输出格式。正如它的名字本身，SSTable是有效存储大量键-值对的简单抽象，对高吞吐量顺序读/写进行了优化。\n\nSSTable是Bigtable中至关重要的一块，对于LevelDB来说也是如此。\n\n### 三、RecordIO\n\n贡献者：Google\n\n简介：我们大家都在用文件来存储数据。文件是存储在磁盘上的。如果在一些不稳定的介质上，文件很容损坏。即时文件某个位置出现一点小小的问题，整个文件就废了。\n\n下面我来介绍Google的一个做法，可以比较好的解决这个问题。那就是recordio文件格式。recoidio的存储单元是一个一个record。这个record可以根据业务的需要自行定义。但Google有一种建议的处理方式就是使用protobuf。\n\nreocordio底层的格式其实很简单。一个record由四部分组成：\n\nMagicNumber (32 bits)\nUncompressed data payload size (64 bits)\nCompressed data payload size (64 bits), or 0 if the data is not compressed\nPayload, possibly compressed.\n**详细格式如下图所示：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/recordio_thumb-600x76.png)\n\n到这里，大家可能已经知道，recordio之所以能对付坏数据，其实就是在这个MagicNumber（校验值）。\n\n### 四、Flat Buffers\n\n贡献者：Google\n\n简介：谷歌开源高效、跨平台的序列化库FlatBuffers。\n\n该库的构建是专门为游戏开发人员的性能需求提供支持，它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而不需要任何解析开销。\n\nFlatBuffers有如下一些关键特性——\n\n访问序列化数据不需要打包/拆包\n节省内存而且访问速度快——缓存只占用访问数据所需要的内存；不需要任何额外的内存。\n灵活性——通过可选字段向前向后兼容\n代码规模小\n强类型——错误在编译时捕获，而不是在运行时\n便利性——生成的C++头文件代码简洁。如果需要，有一项可选功能可以用来在运行时高效解析Schema和JSON-like格式的文本。\n跨平台——使用C++编写，不依赖STL之外的库，因此可以用于任何有C++编辑器的平台。当前，该项目包含构建方法和在Android、Linux、Windows和OSX等操作系统上使用该库的示例。\n与Protocol Buffers或JSON Parsing这样的可选方案相比，FlatBuffers的优势在于开销更小，这主要是由于它没有解析过程。\n\n代码托管：[https://github.com/google/flatbuffers](https://github.com/google/flatbuffers)\n\n### 五、Protocol Buffers\n\n贡献者：Google\n\n简介：Protocol Buffers是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。现阶段官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。\n\n通过它，你可以定义你的数据的结构，并生成基于各种语言的代码。这些你定义的数据流可以轻松地在传递并不破坏你已有的程序。并且你也可以更新这些数据而现有的程序也不会受到任何的影响。\n\nProtocol Buffers经常被简称为protobuf。\n\n官网：[http://code.google.com/p/protobuf/](http://code.google.com/p/protobuf/)\n\n### 六、Consistent Hashing（哈希算法）\n\n简介：一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1420.jpg)\n\n一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：\n\n1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。\n\n2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。\n\n3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。\n\n4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。\n\n在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。\n\n### 七、Netty\n\n贡献者：JBOSS\n\n简介：Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1518.jpg)\n\n也就是说，Netty 是一个基于NIO的客户，服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。\n\n“快速”和“简单”并不意味着会让你的最终应用产生维护性或性能上的问题。Netty 是一个吸收了多种协议的实现经验，这些协议包括FTP,SMTP,HTTP，各种二进制，文本协议，并经过相当精心设计的项目，最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。\n\n官网：[http://netty.io/](http://netty.io/)\n\n### 八、BloomFilter\n\n简介：Bloom filter 是由 Howard Bloom 在 1970 年提出的二进制向量数据结构，它具有很好的空间和时间效率，被用来检测一个元素是不是集合中的一个成员。如果检测结果为是，该元素不一定在集合中；但如果检测结果为否，该元素一定不在集合中。因此Bloom filter具有100%的召回率。这样每个检测请求返回有“在集合内（可能错误）”和“不在集合内（绝对不在集合内）”两种情况，可见 Bloom filter 是牺牲了正确率和时间以节省空间。\n\nBloom filter 优点就是它的插入和查询时间都是常数，另外它查询元素却不保存元素本身，具有良好的安全性。\n\n## 搜索引擎\n\n### 一、Nutch\n\n简介：Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。\n\n尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg)\n\nNutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.\n\nNutch目前最新的版本为version v2.2.1。\n\n官网：[https://nutch.apache.org/](https://nutch.apache.org/)\n\n### 二、Lucene\n\n开发者：Doug Cutting（Hadoop之父，你懂的）\n\n简介：Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1717-556x429.jpg)\n\n官网：[http://lucene.apache.org/](http://lucene.apache.org/)\n\n### 三、SolrCloud\n\n简介：SolrCloud是Solr4.0版本以后基于Solr和Zookeeper的分布式搜索方案。SolrCloud是Solr的基于Zookeeper一种部署方式。Solr可以以多种方式部署，例如单机方式，多机Master-Slaver方式。\n\n**原理图：**\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1813-583x429.jpg)\n\n**SolrCloud有几个特色功能：**\n\n集中式的配置信息使用ZK进行集中配置。启动时可以指定把Solr的相关配置文件上传\n\nZookeeper，多机器共用。这些ZK中的配置不会再拿到本地缓存，Solr直接读取ZK中的配置信息。配置文件的变动，所有机器都可以感知到。另外，Solr的一些任务也是通过ZK作为媒介发布的。目的是为了容错。接收到任务，但在执行任务时崩溃的机器，在重启后，或者集群选出候选者时，可以再次执行这个未完成的任务。\n\n自动容错SolrCloud对索引分片，并对每个分片创建多个Replication。每个Replication都可以对外提供服务。一个Replication挂掉不会影响索引服务。更强大的是，它还能自动的在其它机器上帮你把失败机器上的索引Replication重建并投入使用。\n\n近实时搜索立即推送式的replication（也支持慢推送）。可以在秒内检索到新加入索引。\n\n查询时自动负载均衡SolrCloud索引的多个Replication可以分布在多台机器上，均衡查询压力。如果查询压力大，可以通过扩展机器，增加Replication来减缓。\n\n自动分发的索引和索引分片发送文档到任何节点，它都会转发到正确节点。\n\n事务日志事务日志确保更新无丢失，即使文档没有索引到磁盘。\n\n### 四、Solr\n\n简介：Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/1913-593x429.jpg)\n\nSolr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。\n\n官网：[https://lucene.apache.org/solr/](https://lucene.apache.org/solr/)\n\n### 五、ElasticSearch\n\n简介：ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二最流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。\n\n官网：[http://www.elasticsearch.org/](http://www.elasticsearch.org/)\n\n### 六、Sphinx\n\n简介：Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。\n\nSphinx单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。\n\n官网：[http://sphinxsearch.com](http://sphinxsearch.com)\n\n### 七、SenseiDB\n\n贡献者：linkedin\n\n简介：SenseiDB是一个NoSQL数据库，它专注于高更新率以及复杂半结构化搜索查询。熟悉Lucene和Solor的用户会发现，SenseiDB背后有许多似曾相识的概念。SenseiDB部署在多节点集群中，其中每个节点可以包括N块数据片。Apache Zookeeper用于管理节点，它能够保持现有配置，并可以将任意改动（如拓扑修改）传输到整个节点群中。SenseiDB集群还需要一种模式用于定义将要使用的数据模型。\n\n从SenseiDB集群中获取数据的唯一方法是通过Gateways（它 没有“INSERT”方法）。每个集群都连接到一个单一gateway。你需要了解很重要的一点是，由于SenseiDB本身没法处理原子性 （Atomicity）和隔离性（Isolation），因此只能通过外部在gateway层进行限制。另外，gateway必须确保数据流按照预期的方 式运作。内置的gateway有以下几种形式：\n\n来自文件\n来自JMS队列\n通过JDBC\n来自Apache Kafka\n官网：[http://senseidb.com](http://senseidb.com)\n\n## 数据挖掘\n\n### 一、Mahout\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg)\n\n简介：Apache Mahout 是 Apache Software Foundation (ASF) 开发的一个全新的开源项目，其主要目标是创建一些可伸缩的机器学习算法，供开发人员在 Apache 在许可下免费使用。该项目已经发展到了它的最二个年头，目前只有一个公共发行版。Mahout 包含许多实现，包括集群、分类、CP 和进化程序。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。\n\n虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：\n\nTaste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。\n一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。\nDistributed Naive Bayes 和 Complementary Naive Bayes 分类实现。\n针对进化编程的分布式适用性功能。\nMatrix 和矢量库。\n上述算法的示例。\n官网：[http://mahout.apache.org/](http://mahout.apache.org/)\n\n## Iaas\nIaaS（Infrastructure as a Service），即基础设施即服务。\n\n### 一、OpenStack\n\n简介：OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。\n\nOpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。\n\n![](http://www.36dsj.com/wp-content/uploads/2014/12/1148-599x429.jpg)\n\n6个核心项目：Nova（计算，Compute），Swift（对象存储，Object），Glance（镜像，Image），Keystone（身份，Identity），Horizon（自助门户，Dashboard），Quantum & Melange（网络&地址管理），另外还有若干社区项目，如Rackspace（负载均衡）、Rackspace（关系型数据库）。\n\n相关阅读：\n\n[什么是OpenStack？](http://www.36dsj.com/archives/19596)\n\n[成功部署OpenStack的十大要点](http://www.36dsj.com/archives/22179)\n\n 官网：[https://www.openstack.org/](https://www.openstack.org/)\n\n### 二、Docker\n\n贡献者：dotCloud\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2215.jpg)\n\n简介：Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包括系统。\n\n官网：[http://www.docker.io/](http://www.docker.io/)\n\n### 三、Kubernetes\n\n贡献者：Google\n\n简介：Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。\n\nKubernetes从另一个角度对资源进行抽象，它让开发人员和管理人员共同着眼于服务的行为和性能的提升，而不是仅仅关注对单一的组件或者是基础资源。\n\n那么Kubernetes集群到底提供了哪些单一容器所没有功能?它主要关注的是对服务级别的控制而并非仅仅是对容器级别的控制，Kubernetes提供了一种“机智”的管理方式，它将服务看成一个整体。在Kubernete的解决方案中，一个服务甚至可以自我扩展，自我诊断，并且容易升级。例如，在Google中，我们使用机器学习技术来保证每个运行的服务的当前状态都是最高效的。\n\n代码托管：[https://github.com/GoogleCloudPlatform/kubernetes/](https://github.com/GoogleCloudPlatform/kubernetes/)\n\n### 四、Imctfy\n\n贡献者：Google\n\n简介：Google开源了自己所用Linux容器系统的开源版本lmctfy，读音为lem-kut-fee。包括一个C++库（使用了C++11，文档可以参考头文件）和命令行界面。目前的版本是0.1，只提供了CPU与内存隔离。项目还在密集开发中。\n\nmctfy本身是针对某些特定使用场景设计和实现的，目前拥有一台机器上所有容器时运行情况最好，不推荐与LXC和其他容器系统一起使用（虽然也可行）。已在Ubuntu 12.04+和Ubuntu 3.3与3.8内核上测试。\n\n代码托管：[https://github.com/google/Imctfy/](https://github.com/google/Imctfy/)\n\n## 监控管理\n\n### 一、Dapper\n\n贡献者：Google\n\n简介：Dapper是一个轻量的ORM(对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）。并不单纯的是一个DBHelper.因为在Dapper中数据其实就是一个对象。Dapper扩展与IDbConnection上，所以事实上它的倾入性很低。我用了StructureMap。如果不喜欢可以自己更换，或者自己实现下。\n\n代码就一个SqlMapper.cs文件,主要是IDbConnection的扩展方法，编译后就40K的一个很小的dll。\n\n特性：\n\nDapper很快。Dapper的速度接近与IDataReader。\nDapper支持主流数据库 Mysql,SqlLite,Mssql2000,Mssql2005,Oracle等一系列的数据库\n支持多表并联的对象。支持一对多 多对多的关系，并且没侵入性。\n原理通过Emit反射IDataReader的序列队列，来快速的得到和产生对象\nDapper语法十分简单。并且无须迁就数据库的设计\n官方站点 [http://code.google.com/p/dapper-dot-net/](http://code.google.com/p/dapper-dot-net/)\n\n代码托管：[http://bigbully.github.io/Dapper-translation/](http://bigbully.github.io/Dapper-translation/)\n\n### 二、Zipkin\n\n贡献者：Twitter\n\n简介：Zipkin （分布式跟踪系统）是 Twitter 的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口。该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。\n\n![](http://www.36dsj.com/wp-content/uploads/2015/03/2313-535x429.jpg)\n\n官方网站：[http://twitter.github.io/zipkin/](http://twitter.github.io/zipkin/)\n\n代码托管：[https://github.com/twitter/zipkin/](https://github.com/twitter/zipkin/)\n\n**-------------------------------------End.-------------------------------------------**\n\n感谢:\n36大数据([http://www.36dsj.com/](http://www.36dsj.com/))\n\n转载来源:[http://www.36dsj.com/archives/24852](http://www.36dsj.com/archives/24852)\n[http://www.36dsj.com/archives/25042](http://www.36dsj.com/archives/25042)\n","slug":"2015-07-29-大数据处理工具汇总","updated":"2018-11-29T12:51:24.462Z","comments":1,"photos":[],"link":"","_id":"cjskffp4n008q4glm1ufb6xjy","content":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"查询引擎\"><a href=\"#查询引擎\" class=\"headerlink\" title=\"查询引擎\"></a>查询引擎</h2><h3 id=\"一、Phoenix\"><a href=\"#一、Phoenix\" class=\"headerlink\" title=\"一、Phoenix\"></a>一、Phoenix</h3><p>贡献者：：Salesforce</p>\n<p>简介：这是一个Java中间层，可以让开发者在Apache HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于GitHub上，并且提供了一个客户端可嵌入的JDBC驱动。<br><a id=\"more\"></a></p>\n<p>Phoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。</p>\n<p>Phoenix最值得关注的一些特性有：</p>\n<p>❶嵌入式的JDBC驱动，实现了大部分的java.sql接口，包括元数据API</p>\n<p>❷可以通过多部行键或是键/值单元对列进行建模</p>\n<p>❸完善的查询支持，可以使用多个谓词以及优化的扫描键</p>\n<p>❹DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除列</p>\n<p>❺版本化的模式仓库：当写入数据时，快照查询会使用恰当的模式</p>\n<p>❻DML支持：用于逐行插入的UPSERT VALUES、用于相同或不同表之间大量数据传输的UPSERT </p>\n<p>❼SELECT、用于删除行的DELETE</p>\n<p>❽通过客户端的批处理实现的有限的事务支持</p>\n<p>❾单表——还没有连接，同时二级索引也在开发当中</p>\n<p>➓紧跟ANSI SQL标准</p>\n<p><a href=\"http://phoenix.apache.org/\" target=\"_blank\" rel=\"noopener\">Phoenix官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Stinger\"><a href=\"#二、Stinger\" class=\"headerlink\" title=\"二、Stinger\"></a>二、Stinger</h3><p>贡献者：：Hortonworks</p>\n<p>简介：原叫Tez，下一代Hive,Hortonworks主导开发，运行在YARN上的DAG计算框架。</p>\n<p>某些测试下，Stinger能提升10倍左右的性能，同时会让Hive支持更多的SQL，其主要优点包括：</p>\n<p>❶让用户在Hadoop获得更多的查询匹配。其中包括类似OVER的字句分析功能，支持WHERE查询，让Hive的样式系统更符合SQL模型。</p>\n<p>❷优化了Hive请求执行计划，优化后请求时间减少90%。改动了Hive执行引擎，增加单Hive任务的被秒处理记录数。</p>\n<p>❸在Hive社区中引入了新的列式文件格式（如ORC文件），提供一种更现代、高效和高性能的方式来储存Hive数据。</p>\n<p>❹引入了新的运行时框架——Tez，旨在消除Hive的延时和吞吐量限制。Tez通过消除不必要的task、障碍同步和对HDFS的读写作业来优化Hive job。这将优化Hadoop内部的执行链，彻底加速Hive负载处理。</p>\n<p><a href=\"http://hortonworks.com/labs/stinger/\" target=\"_blank\" rel=\"noopener\">Stinger官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"三、Presto\"><a href=\"#三、Presto\" class=\"headerlink\" title=\"三、Presto\"></a>三、Presto</h3><p>贡献者：：Facebook</p>\n<p>简介：Facebook开源的数据查询引擎Presto ，可对250PB以上的数据进行快速地交互式分析。该项目始于 2012 年秋季开始开发，目前该项目已经在超过 1000 名 Facebook 雇员中使用，运行超过 30000 个查询，每日数据在 1PB 级别。Facebook 称 Presto 的性能比诸如 Hive 和 Map*Reduce 要好上 10 倍有多。</p>\n<p>Presto 当前支持 ANSI SQL 的大多数特效，包括联合查询、左右联接、子查询以及一些聚合和计算函数；支持近似截然不同的计数(DISTINCT COUNT)等。</p>\n<p><a href=\"https://github.com/facebook/presto\" target=\"_blank\" rel=\"noopener\">github源代码下载&gt;&gt;&gt;</a></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1105.jpg\" alt=\"\"></p>\n<h3 id=\"四、Shark\"><a href=\"#四、Shark\" class=\"headerlink\" title=\"四、Shark\"></a>四、Shark</h3><p>简介：Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的特点就是快，完全兼容Hive，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。</p>\n<p>❶Shark速度快的原因除了Spark平台提供的基于内存迭代计算外，在设计上还存在对Spark上进行了一定的改造，主要有</p>\n<p>❷partial DAG execution：对join优化，调节并行粒度，因为Spark本身的宽依赖和窄依赖会影响并行计算和速度</p>\n<p>基于列的压缩和存储：把HQL表数据按列存，每列是一个array，存在JVM上，避免了JVM GC低效，而压缩和解压相关的技术是Yahoo!提供的。</p>\n<p>结来说，Shark是一个插件式的东西，在我现有的Spark和Hive及hadoop-client之间，在这两套都可用的情况下，Shark只要获取Hive的配置（还有metastore和exec等关键包），Spark的路径，Shark就能利用Hive和Spark，把HQL解析成RDD的转换，把数据取到Spark上运算和分析。在SQL on Hadoop这块，Shark有别于Impala，Stringer，而这些系统各有自己的设计思路，相对于对MR进行优化和改进的思路，Shark的思路更加简单明了些</p>\n<p><a href=\"http://shark.cs.berkeley.edu/\" target=\"_blank\" rel=\"noopener\">Shark官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"五、Pig\"><a href=\"#五、Pig\" class=\"headerlink\" title=\"五、Pig\"></a>五、Pig</h3><p>简介：Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。</p>\n<p>Pig最大的作用就是对mapreduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组(group by)、关联(Joining)，Pig也可以由用户自定义一些函数对数据集进行操作，也就是传说中的UDF(user-defined functions)。</p>\n<p><a href=\"http://pig.apache.org/\" target=\"_blank\" rel=\"noopener\">Pig官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"六、Cloudera-Impala\"><a href=\"#六、Cloudera-Impala\" class=\"headerlink\" title=\"六、Cloudera Impala\"></a>六、Cloudera Impala</h3><p>贡献者：:Cloudera</p>\n<p>简介：Cloudera Impala 可以直接为存储在HDFS或HBase中的Hadoop数据提供快速，交互式的SQL查询。除了使用相同的存储平台外， Impala和Apache Hive一样也使用了相同的元数据，SQL语法（Hive SQL），ODBC驱动和用户接口（Hue Beeswax），这就很方便的为用户提供了一个相似并且统一的平台来进行批量或实时查询。</p>\n<p>Cloudera Impala 是用来进行大数据查询的补充工具。 Impala 并没有取代像Hive这样基于MapReduce的分布式处理框架。Hive和其它基于MapReduce的计算框架非常适合长时间运行的批处理作业，例如那些涉及到批量 Extract、Transform、Load ，即需要进行ETL作业。</p>\n<p>Impala 提供了：</p>\n<p>❶数据科学家或数据分析师已经熟知的SQL接口</p>\n<p>❷能够在Apache Hadoop 的大数据中进行交互式数据查询</p>\n<p>❸ Single system for big data processing and analytics so customers can avoid costly modeling and ETL just for analytics</p>\n<p><a href=\"http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html\" target=\"_blank\" rel=\"noopener\">Cloudera Impala官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"七、Apache-Drill\"><a href=\"#七、Apache-Drill\" class=\"headerlink\" title=\"七、Apache Drill\"></a>七、Apache Drill</h3><p>贡献者：：MapR</p>\n<p>简介：Apache Drill是是一个能够对大数据进行交互分析、开源的分布式系统，且基于Google Dremel实现，它能够运行在上千个节点的服务器集群上，且能在几秒内处理PB级或者万亿条的数据记录。Drill能够帮助企业用户快速、高效地进行Hadoop数据查询和企业级大数据分析。Drill于2012年8月份由Apache推出。</p>\n<p>从Drill官方对其架构的介绍中得知，其具有适于实时的分析和快速的应用开发、适于半结构化/嵌套数据的分析、兼容现有的SQL环境和Apache Hive等特征。另外，Drill的核心模块是Drillbit服务，该服务模块包括远程访问子模块、SQL解析器、查询优化器、任务计划执行引擎、存储插件接口（DFS、HBase、Hive等的接口）、分布式缓存模块等几部分，如下图所示：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg\" alt=\"\"></p>\n<p><a href=\"http://incubator.apache.org/drill/\" target=\"_blank\" rel=\"noopener\">Apache Drill官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"八、Apache-Tajo\"><a href=\"#八、Apache-Tajo\" class=\"headerlink\" title=\"八、Apache Tajo\"></a>八、Apache Tajo</h3><p>简介：Apache Tajo项目的目的是在HDFS之上构建一个先进的数据仓库系统。Tajo将自己标榜为一个“大数据仓库”，但是它好像和之前介绍的那些低延迟查询引擎类似。虽然它支持外部表和Hive数据集（通过HCatalog），但是它的重点是数据管理，提供低延迟的数据访问，以及为更传统的ETL提供工具。它也需要在数据节点上部署Tajo特定的工作进程。</p>\n<p>Tajo的功能包括：</p>\n<p>❶ANSI SQL兼容<br>❷JDBC 驱动<br>❸集成Hive metastore能够访问Hive数据集<br>❹一个命令行客户端<br>❺一个自定义函数API</p>\n<p><a href=\"http://tajo.incubator.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Tajo官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"九、Hive\"><a href=\"#九、Hive\" class=\"headerlink\" title=\"九、Hive\"></a>九、Hive</h3><p>简介：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>\n<p><a href=\"http://hive.apache.org/\" target=\"_blank\" rel=\"noopener\">Hive官方网站&gt;&gt;&gt;</a></p>\n<h2 id=\"流式计算\"><a href=\"#流式计算\" class=\"headerlink\" title=\"流式计算\"></a>流式计算</h2><h3 id=\"一、Facebook-Puma\"><a href=\"#一、Facebook-Puma\" class=\"headerlink\" title=\"一、Facebook Puma\"></a>一、Facebook Puma</h3><p>贡献者：Facebook</p>\n<p>简介：实时数据流分析</p>\n<h3 id=\"二、Twitter-Rainbird\"><a href=\"#二、Twitter-Rainbird\" class=\"headerlink\" title=\"二、Twitter Rainbird\"></a>二、Twitter Rainbird</h3><p>贡献者：Twitter</p>\n<p>简介：Rainbird一款基于Zookeeper, Cassandra, Scribe, Thrift的分布式实时统计系统，这些基础组件的基本功能如下：</p>\n<p>❶ Zookeeper，Hadoop子项目中的一款分布式协调系统，用于控制分布式系统中各个组件中的一致性。</p>\n<p>❷Cassandra，NoSQL中一款非常出色的产品，集合了Dynamo和Bigtable特性的分布式存储系统，用于存储需要进行统计的数据，统计数据，并且提供客户端进行统计数据的查询。（需要使用分布式Counter补丁CASSANDRA-1072）</p>\n<p>❸ Scribe，Facebook开源的一款分布式日志收集系统，用于在系统中将各个需要统计的数据源收集到Cassandra中。</p>\n<p>❹ Thrift，Facebook开源的一款跨语言C/S网络通信框架，开发人员基于这个框架可以轻易地开发C/S应用。</p>\n<p>用处</p>\n<p>Rainbird可以用于实时数据的统计：</p>\n<p>❶统计网站中每一个页面，域名的点击次数</p>\n<p>❷内部系统的运行监控（统计被监控服务器的运行状态）</p>\n<p>❸记录最大值和最小值</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/280.jpg\" alt=\"\"></p>\n<h3 id=\"三、Yahoo-S4\"><a href=\"#三、Yahoo-S4\" class=\"headerlink\" title=\"三、Yahoo S4\"></a>三、Yahoo S4</h3><p>贡献者：Yahoo</p>\n<p>简介：S4（Simple Scalable Streaming System）最初是Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。目前该项目刚启动不久，所以也可以理解为是他们提出的一个分布式流计算（Distributed Stream Computing）的模型。</p>\n<p>S4的设计目标是：</p>\n<p>·提供一种简单的编程接口来处理数据流</p>\n<p>·设计一个可以在普通硬件之上可扩展的高可用集群。</p>\n<p>·通过在每个处理节点使用本地内存，避免磁盘I/O瓶颈达到最小化延迟</p>\n<p>·使用一个去中心的，对等架构；所有节点提供相同的功能和职责。没有担负特殊责任的中心节点。这大大简化了部署和维护。</p>\n<p>·使用可插拔的架构，使设计尽可能的即通用又可定制化。</p>\n<p>·友好的设计理念，易于编程，具有灵活的弹性</p>\n<p><a href=\"http://incubator.apache.org/s4/\" target=\"_blank\" rel=\"noopener\">Yahoo S4官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"四、Twitter-Storm\"><a href=\"#四、Twitter-Storm\" class=\"headerlink\" title=\"四、Twitter Storm\"></a>四、Twitter Storm</h3><p>贡献者：Twitter</p>\n<p>简介：Storm是Twitter开源的一个类似于Hadoop的实时数据处理框架，它原来是由BackType开发，后BackType被Twitter收购，将Storm作为Twitter的实时数据分析系统。</p>\n<p>实时数据处理的应用场景很广泛，例如商品推荐，广告投放，它能根据当前情景上下文（用户偏好，地理位置，已发生的查询和点击等）来估计用户点击的可能性并实时做出调整。</p>\n<p>storm的三大作用领域：</p>\n<p>1.信息流处理（Stream Processing）</p>\n<p>Storm可以用来实时处理新数据和更新数据库，兼具容错性和可扩展性,它 可以用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。</p>\n<p>2.连续计算（Continuous Computation）</p>\n<p>Storm可以进行连续查询并把结果即时反馈给客户，比如将Twitter上的热门话题发送到客户端。</p>\n<p>3.分布式远程过程调用（Distributed RPC）</p>\n<p>除此之外，Storm也被广泛用于以下方面：</p>\n<p>精确的广告推送<br>实时日志的处理</p>\n<p><a href=\"http://storm.incubator.apache.org/\" target=\"_blank\" rel=\"noopener\">Twitter Storm官方网站&gt;&gt;&gt;</a></p>\n<p>##迭代计算</p>\n<h3 id=\"一、Apache-Hama\"><a href=\"#一、Apache-Hama\" class=\"headerlink\" title=\"一、Apache Hama\"></a>一、Apache Hama</h3><p>简介：Apache Hama是一个纯BSP（Bulk Synchronous Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。</p>\n<p>❶建立在Hadoop上的分布式并行计算模型。</p>\n<p>❷基于 Map/Reduce 和 Bulk Synchronous 的实现框架。</p>\n<p>❸运行环境需要关联 Zookeeper、HBase、HDFS 组件。</p>\n<p>Hama中有2个主要的模型:</p>\n<p>– 矩阵计算(Matrix package)</p>\n<p>– 面向图计算(Graph package)</p>\n<p><a href=\"https://hama.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Hama官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Apache-Giraph\"><a href=\"#二、Apache-Giraph\" class=\"headerlink\" title=\"二、Apache Giraph\"></a>二、Apache Giraph</h3><p>代码托管地址： <a href=\"https://github.com/apache/giraph\" target=\"_blank\" rel=\"noopener\">GitHub</a></p>\n<p>简介：Apache Giraph是一个可伸缩的分布式迭代图处理系统，灵感来自BSP（bulk synchronous parallel）和Google的Pregel，与它们 区别于则是是开源、基于 Hadoop 的架构等。</p>\n<p>Giraph处理平台适用于运行大规模的逻辑计算，比如页面排行、共享链接、基于个性化排行等。Giraph专注于社交图计算，被Facebook作为其Open Graph工具的核心，几分钟内处理数万亿次用户及其行为之间的连接。</p>\n<h3 id=\"三、HaLoop\"><a href=\"#三、HaLoop\" class=\"headerlink\" title=\"三、HaLoop\"></a>三、HaLoop</h3><p>简介：迭代的MapReduce，HaLoop——适用于迭代计算的Hadoop 。</p>\n<p> <img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/425.jpg\" alt=\"\"></p>\n<pre><code>Hadoop与HaLoop的不同\n</code></pre><p>与Hadoop比较的四点改变：</p>\n<p>1.提供了一套新的编程接口，更加适用于迭代计算；</p>\n<p>HaLoop给迭代计算一个抽象的递归公式：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/403.jpg\" alt=\"\"></p>\n<p>2.HaLoop的master进行job内的循环控制，直到迭代计算结束；</p>\n<p>3.Task Scheduler也进行了修改，使得任务能够尽量满足data locality</p>\n<p>4.slave nodes对数据进行cache并index索引，索引也以文件的形式保存在本地磁盘。</p>\n<p><a href=\"https://code.google.com/p/haloop/\" target=\"_blank\" rel=\"noopener\">HaLoop官网&gt;&gt;&gt;</a></p>\n<h3 id=\"四、Twister\"><a href=\"#四、Twister\" class=\"headerlink\" title=\"四、Twister\"></a>四、Twister</h3><p>简介：Twister， 迭代式MapReduce框架，Twister是由一个印度人开发的，其架构如下：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/524.jpg\" alt=\"\"></p>\n<p>在Twister中，大文件不会自动被切割成一个一个block，因而用户需提前把文件分成一个一个小文件，以供每个task处理。在map阶段，经过map（）处理完的结果被放在分布式内存中，然后通过一个broker network（NaradaBroking系统）将数据push给各个reduce task（Twister假设内存足够大，中间数据可以全部放在内存中）；在reduce阶段，所有reduce task产生的结果通过一个combine操作进行归并，此时，用户可以进行条件判定， 确定迭代是否结束。combine后的数据直接被送给map task，开始新一轮的迭代。为了提高容错性，Twister每隔一段时间会将map task和reduce task产生的结果写到磁盘上，这样，一旦某个task失败，它可以从最近的备份中获取输入，重新计算。</p>\n<p>为了避免每次迭代重新创建task，Twister维护了一个task pool，每次需要task时直接从pool中取。在Twister中，所有消息和数据都是通过broker network传递的，该broker network是一个独立的模块，目前支持NaradaBroking和ActiveMQ。</p>\n<h2 id=\"离线计算\"><a href=\"#离线计算\" class=\"headerlink\" title=\"离线计算\"></a>离线计算</h2><h3 id=\"一、Hadoop-MapReduce\"><a href=\"#一、Hadoop-MapReduce\" class=\"headerlink\" title=\"一、Hadoop MapReduce\"></a>一、Hadoop MapReduce</h3><p>简介：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）”，和它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>\n<p><a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">Hadoop MapReduce官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Berkeley-Spark\"><a href=\"#二、Berkeley-Spark\" class=\"headerlink\" title=\"二、Berkeley Spark\"></a>二、Berkeley Spark</h3><p>简介：Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。</p>\n<h3 id=\"三、DataTorrent\"><a href=\"#三、DataTorrent\" class=\"headerlink\" title=\"三、DataTorrent\"></a>三、DataTorrent</h3><p>简介：DataTorrent基于Hadoop 2.x构建，是一个实时的、有容错能力的数据流式处理和分析平台，它使用本地Hadoop应用程序，而这些应用程序可以与执行其它任务，如批处理，的应用程序共存。该平台的架构如下图所示：<br><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/621.jpg\" alt=\"\"></p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20163\" target=\"_blank\" rel=\"noopener\">DataTorrent 1.0每秒处理超过10亿个实时事件</a></p>\n<p><a href=\"http://www.36dsj.com/archives/1596\" target=\"_blank\" rel=\"noopener\">DataTorrent 将数据分析速度从“实时”提升至“现在时”</a></p>\n<h2 id=\"键值存储\"><a href=\"#键值存储\" class=\"headerlink\" title=\"键值存储\"></a>键值存储</h2><h3 id=\"一、LevelDB\"><a href=\"#一、LevelDB\" class=\"headerlink\" title=\"一、LevelDB\"></a>一、LevelDB</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/723.jpg\" alt=\"\"></p>\n<p>贡献者：Google</p>\n<p>简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。</p>\n<p>LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>\n<p>此处随机读是完全命中内存的速度，如果是不命中 速度大大下降。</p>\n<p><a href=\"https://code.google.com/p/leveldb/\" target=\"_blank\" rel=\"noopener\">LevelDB官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、RocksDB\"><a href=\"#二、RocksDB\" class=\"headerlink\" title=\"二、RocksDB\"></a>二、RocksDB</h3><p>贡献者：facebook</p>\n<p>简介：RocksDB虽然在代码层面上是在LevelDB原有的代码上进行开发的，但却借鉴了Apache HBase的一些好的idea。在云计算横行的年代，开口不离Hadoop，RocksDB也开始支持HDFS，允许从HDFS读取数据。RocksDB支持一次获取多个K-V，还支持Key范围查找。LevelDB只能获取单个Key。</p>\n<p>RocksDB除了简单的Put、Delete操作，还提供了一个Merge操作，说是为了对多个Put操作进行合并。</p>\n<p>RocksDB提供一些方便的工具，这些工具包含解析sst文件中的K-V记录、解析MANIFEST文件的内容等。RocksDB支持多线程合并，而LevelDB是单线程合并的。</p>\n<p><a href=\"http://rocksdb.org/\" target=\"_blank\" rel=\"noopener\">RocksDB官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"三、HyperDex\"><a href=\"#三、HyperDex\" class=\"headerlink\" title=\"三、HyperDex\"></a>三、HyperDex</h3><p>贡献者：Facebook</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/821.jpg\" alt=\"\"></p>\n<p>HyperDex是一个分布式、可搜索的键值存储系统，特性如下：</p>\n<p>分布式KV存储，系统性能能够随节点数目线性扩展<br>吞吐和延时都能秒杀现在风头正劲的MonogDB，吞吐甚至强于Redis<br>使用了hyperspace hashing技术，使得对存储的K-V的任意属性进行查询成为可能</p>\n<p>官网：<a href=\"http://hyperdex.org/\" target=\"_blank\" rel=\"noopener\">http://hyperdex.org/</a></p>\n<h3 id=\"四、TokyoCabinet\"><a href=\"#四、TokyoCabinet\" class=\"headerlink\" title=\"四、TokyoCabinet\"></a>四、TokyoCabinet</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/104.png\" alt=\"\"></p>\n<p>日本人Mikio Hirabayashi（平林干雄）开发的一款DBM数据库。Tokyo Cabinet 是一个DBM的实现。这里的数据库由一系列key-value对的记录构成。key和value都可以是任意长度的字节序列,既可以是二进制也可以是字符串。这里没有数据类型和数据表的概念。<br>当 做为Hash表数据库使用时，每个key必须是不同的,因此无法存储两个key相同的值。提供了以下访问方法:提供key,value参数来存储，按 key删除记录，按key来读取记录，另外，遍历key也被支持，虽然顺序是任意的不能被保证。这些方法跟Unix标准的DBM,例如GDBM,NDBM 等等是相同的，但是比它们的性能要好得多（因此可以替代它们) 。下一代KV存储系统，支持strings、integers、floats、lists、maps和sets等丰富的数据类型。</p>\n<p><a href=\"http://fallabs.com/tokyocabinet/\" target=\"_blank\" rel=\"noopener\">TokyoCabinet官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"五、Voldemort\"><a href=\"#五、Voldemort\" class=\"headerlink\" title=\"五、Voldemort\"></a>五、Voldemort</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg\" alt=\"\"></p>\n<p>Voldemort是一个分布式键值存储系统，是Amazon’s Dynamo的一个开源克隆。特性如下：<br>支持自动复制数据到多个服务器上。<br>支持数据自动分割所以每个服务器只包含总数据的一个子集。<br>提供服务器故障透明处理功能。<br>支持可拨插的序化支持，以实现复杂的键-值存储，它能够很好的5.集成常用的序化框架如：Protocol Buffers、Thrift、Avro和Java Serialization。<br>数据项都被标识版本能够在发生故障时尽量保持数据的完整性而不会影响系统的可用性。<br>每个节点相互独立，互不影响。<br>支持可插拔的数据放置策略<br>官网：<a href=\"http://project-voldemort.com/\" target=\"_blank\" rel=\"noopener\">http://project-voldemort.com/</a></p>\n<h3 id=\"六、Amazon-Dynamo\"><a href=\"#六、Amazon-Dynamo\" class=\"headerlink\" title=\"六、Amazon Dynamo\"></a>六、Amazon Dynamo</h3><p>贡献者：亚马逊</p>\n<p>简介：Amazon Dynamo 是一个经典的分布式Key-Value 存储系统，具备去中心化，高可用性，高扩展性的特点，但是为了达到这个目标在很多场景中牺牲了一致性。Dynamo在Amazon中得到了成功的应用，能够跨数据中心部署于上万个结点上提供服务，它的设计思想也被后续的许多分布式系统借鉴。如近来火热的Cassandra，实际上就是基本照搬了Dynamo的P2P架构，同时融合了BigTable的数据模型及存储算法。</p>\n<p><a href=\"https://github.com/dynamo/dynamo\" target=\"_blank\" rel=\"noopener\">Amazon Dynamo官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"七、Tair\"><a href=\"#七、Tair\" class=\"headerlink\" title=\"七、Tair\"></a>七、Tair</h3><p>贡献者：淘宝</p>\n<p>简介：tair 是淘宝自己开发的一个分布式 key/value 存储引擎. tair 分为持久化和非持久化两种使用方式. 非持久化的 tair 可以看成是一个分布式缓存. 持久化的 tair 将数据存放于磁盘中. 为了解决磁盘损坏导致数据丢失, tair 可以配置数据的备份数目, tair 自动将一份数据的不同备份放到不同的主机上, 当有主机发生异常, 无法正常提供服务的时候, 其于的备份会继续提供服务.tair 的总体结构</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1220.jpg\" alt=\"\"></p>\n<p>Tairtair 作为一个分布式系统, 是由一个中心控制节点和一系列的服务节点组成. 我们称中心控制节点为config server. 服务节点是data server. config server 负责管理所有的data server, 维护data server的状态信息. data server 对外提供各种数据服务, 并以心跳的形式将自身状况汇报给config server. config server是控制点, 而且是单点, 目前采用一主一备的形式来保证其可靠性. 所有的 data server 地位都是等价的.</p>\n<h3 id=\"八、Apache-Accumulo\"><a href=\"#八、Apache-Accumulo\" class=\"headerlink\" title=\"八、Apache Accumulo\"></a>八、Apache Accumulo</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/8c2532b6-0c16-3879-9600-2a263d923934.png\" alt=\"\"></p>\n<p>Apache Accumulo 是一个可靠的、可伸缩的、高性能的排序分布式的 Key-Value 存储解决方案，基于单元访问控制以及可定制的服务器端处理。Accumulo使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。</p>\n<p>官网：<a href=\"http://accumulo.apache.org/\" target=\"_blank\" rel=\"noopener\">http://accumulo.apache.org/</a></p>\n<h3 id=\"九、Redis\"><a href=\"#九、Redis\" class=\"headerlink\" title=\"九、Redis\"></a>九、Redis</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1320.jpg\" alt=\"\"></p>\n<p>Redis是一个高性能的key-value存储系统，和Memcached类似，它支持存储的value类型相对更多，包括string（字符串）、list（链表）、set（集合）和zset（有序集合）。与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了主从同步。</p>\n<p>Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Python、Ruby、Erlang、PHP客户端，使用很方便。</p>\n<p>官网：<a href=\"http://redis.io/\" target=\"_blank\" rel=\"noopener\">http://redis.io/</a></p>\n<h2 id=\"表格存储\"><a href=\"#表格存储\" class=\"headerlink\" title=\"表格存储\"></a>表格存储</h2><h3 id=\"一、OceanBase\"><a href=\"#一、OceanBase\" class=\"headerlink\" title=\"一、OceanBase\"></a>一、OceanBase</h3><p>贡献者：阿里巴巴</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20317\" target=\"_blank\" rel=\"noopener\">26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase</a></p>\n<p>简介：OceanBase是一个支持海量数据的高性能分布式数据库系统，实现了数千亿条记录、数百TB数据上的跨行跨表事务，由淘宝核心系统研发部、运维、DBA、广告、应用研发等部门共同完成。在设计和实现OceanBase的时候暂时摒弃了不紧急的DBMS的功能，例如临时表，视图(view)，研发团队把有限的资源集中到关键点上，当前 OceanBase主要解决数据更新一致性、高性能的跨表读事务、范围查询、join、数据全量及增量dump、批量数据导入。</p>\n<p>目前OceanBase已经应用于淘宝收藏夹，用于存储淘宝用户收藏条目和具体的商品、店铺信息，每天支持4～5千万的更新操作。等待上线的应用还包括CTU、SNS等，每天更新超过20亿，更新数据量超过2.5TB，并会逐步在淘宝内部推广。</p>\n<p>OceanBase 0.3.1在Github开源，开源版本为Revision:12336。</p>\n<p>官网：<a href=\"http://alibaba.github.io/oceanbase/\" target=\"_blank\" rel=\"noopener\">http://alibaba.github.io/oceanbase/</a></p>\n<h3 id=\"二、Amazon-SimpleDB\"><a href=\"#二、Amazon-SimpleDB\" class=\"headerlink\" title=\"二、Amazon SimpleDB\"></a>二、Amazon SimpleDB</h3><p>贡献者：亚马逊</p>\n<p>Amazon SimpleDB是一个分散式数据库，以Erlang撰写。同与Amazon EC2和亚马逊的S3一样作为一项Web 服务，属于亚马逊网络服务的一部分。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1106.jpg\" alt=\"\"></p>\n<p>正如EC2和S3，SimpleDB的按照存储量，在互联网上的传输量和吞吐量收取费用。 在2008年12月1日，亚马逊推出了新的定价策略，提供了免费1 GB的数据和25机器小时的自由层(Free Tire)。 将其中的数据转移到其他亚马逊网络服务是免费的。</p>\n<p>它是一个可大规模伸缩、用 Erlang 编写的高可用数据存储。</p>\n<p>官网：<a href=\"http://aws.amazon.com/cn/simpledb/\" target=\"_blank\" rel=\"noopener\">http://aws.amazon.com/cn/simpledb/</a></p>\n<h3 id=\"三、Vertica\"><a href=\"#三、Vertica\" class=\"headerlink\" title=\"三、Vertica\"></a>三、Vertica</h3><p>贡献者：惠普</p>\n<p>简介：惠普2011年2月份起始3月21号完成收购Vertica。Vertica基于列存储。基于列存储的设计相比传统面向行存储的数据库具有巨大的优势。同时Vertica支持MPP（massively parallel processing）等技术，查询数据时Vertica只需取得需要的列，而不是被选择行的所有数据，其平均性能可提高50x-1000x倍。（查询性能高速度快）</p>\n<p>Vertica的设计者多次表示他们的产品围绕着高性能和高可用性设计。由于对MPP技术的支持，可提供对粒度，可伸缩性和可用性的优势。每个节点完全独立运作，完全无共享架构，降低对共享资源的系统竞争。</p>\n<p>Vertica的数据库使用标准的SQL查询，同时Vertica的架构非常适合云计算，包括虚拟化，分布式多节点运行等，并且可以和Hadoop/MapReduce进行集成。</p>\n<p>Vertica官网：<a href=\"http://www.vertica.com/\" target=\"_blank\" rel=\"noopener\">http://www.vertica.com/</a></p>\n<h3 id=\"四、Cassandra\"><a href=\"#四、Cassandra\" class=\"headerlink\" title=\"四、Cassandra\"></a>四、Cassandra</h3><p>贡献者：facebook</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20079\" target=\"_blank\" rel=\"noopener\">开源分布式NoSQL数据库系统——Cassandra</a>   <a href=\"http://www.36dsj.com/archives/7179\" target=\"_blank\" rel=\"noopener\">Cassandra与HBase的大数据对决 谁是胜者？</a></p>\n<p>简介：Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩放性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/290.jpg\" alt=\"\"></p>\n<p>Cassandra是一个混合型的非关系的数据库，类似于Google的BigTable。其主要功能比Dynamo （分布式的Key-Value存储系统）更丰富，但支持度却不如文档存储MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的。支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型）。Cassandra最初由Facebook开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族（Column Family）的数据模型。P2P去中心化的存储。很多方面都可以称之为Dynamo 2.0。</p>\n<p>Cassandra官网：<a href=\"http://cassandra.apache.org/\" target=\"_blank\" rel=\"noopener\">http://cassandra.apache.org/</a></p>\n<h3 id=\"五、HyperTable\"><a href=\"#五、HyperTable\" class=\"headerlink\" title=\"五、HyperTable\"></a>五、HyperTable</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/347.jpg\" alt=\"\"></p>\n<p>简介：Hypertable是一个开源、高性能、可伸缩的数据库，它采用与Google的Bigtable相似的模型。在过去数年中，Google为在PC集群 上运行的可伸缩计算基础设施设计建造了三个关键部分。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/426.jpg\" alt=\"\"></p>\n<p>第一个关键的基础设施是Google File System（GFS），这是一个高可用的文件系统，提供了一个全局的命名空间。它通过跨机器（和跨机架）的文件数据复制来达到高可用性，并因此免受传统 文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等失败。第二个基础设施是名为Map-Reduce的计算框架，它与GFS紧密协作，帮 助处理收集到的海量数据。第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让你可以通过一些主键来组织海量数据，并实现高效的 查询。Hypertable是Bigtable的一个开源实现，并且根据我们的想法进行了一些改进。</p>\n<p>HyperTable官网：<a href=\"http://hypertable.org/\" target=\"_blank\" rel=\"noopener\">http://hypertable.org/</a></p>\n<h3 id=\"六、FoundationDB\"><a href=\"#六、FoundationDB\" class=\"headerlink\" title=\"六、FoundationDB\"></a>六、FoundationDB</h3><p>简介：支持ACID事务处理的NoSQL数据库，提供非常好的性能、数据一致性和操作弹性。</p>\n<p>2015年1月2日，FoundationDB已经发布了其key-value数据库的3.0版本，主要专注于可伸缩性和性能上的改善。FoundationDB的CEO David Rosenthal在一篇博客上宣布了新的版本，其中展示了FoundationDB 3.0在可伸缩性方面的数据，它可以在一个32位的c3.8xlarge EC2实例上每秒写入1440万次；这在性能上是之前版本的36倍。</p>\n<p>除了性能和可伸缩性的改善之外，FoundationDB 3.0还包含了对监控支持的改善。这种监控机制不仅仅是简单的机器检查，它添加了对多种潜在的硬件瓶颈的诊断，并且把那些高层级的信息整合到现有监控基础架构中。</p>\n<p>官网：<a href=\"https://foundationdb.com/\" target=\"_blank\" rel=\"noopener\">https://foundationdb.com/</a></p>\n<h3 id=\"七：HBase\"><a href=\"#七：HBase\" class=\"headerlink\" title=\"七：HBase\"></a>七：HBase</h3><p>贡献者： Fay Chang 所撰写的“Bigtable</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/526.jpg\" alt=\"\"></p>\n<p>简介：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p>\n<p>官网：<a href=\"http://hbase.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hbase.apache.org/</a></p>\n<h2 id=\"文件存储\"><a href=\"#文件存储\" class=\"headerlink\" title=\"文件存储\"></a>文件存储</h2><h3 id=\"一、CouchDB\"><a href=\"#一、CouchDB\" class=\"headerlink\" title=\"一、CouchDB\"></a>一、CouchDB</h3><p>简介：CouchDB是用Erlang开发的面向文档的数据库系统，最近刚刚发布了1.0版本（2010年7月14日）。CouchDB不是一个传统的关系数据库，而是面向文档的数据库，其数据存储方式有点类似lucene的index文件格式，CouchDB最大的意义在于它是一个面向web应用的新一代存储系统，事实上，CouchDB的口号就是：下一代的Web应用存储系统。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/623.jpg\" alt=\"\"></p>\n<p>特点：</p>\n<p>一、CouchDB是分布式的数据库，他可以把存储系统分布到n台物理的节点上面，并且很好的协调和同步节点之间的数据读写一致性。这当然也得靠Erlang无与伦比的并发特性才能做到。对于基于web的大规模应用文档应用，分布式可以让它不必像传统的关系数据库那样分库拆表，在应用代码层进行大量的改动。</p>\n<p>二、CouchDB是面向文档的数据库，存储半结构化的数据，比较类似lucene的index结构，特别适合存储文档，因此很适合CMS，电话本，地址本等应用，在这些应用场合，文档数据库要比关系数据库更加方便，性能更好。</p>\n<p>三、CouchDB支持REST API，可以让用户使用JavaScript来操作CouchDB数据库，也可以用JavaScript编写查询语句，我们可以想像一下，用AJAX技术结合CouchDB开发出来的CMS系统会是多么的简单和方便。</p>\n<p>其实CouchDB只是Erlang应用的冰山一角，在最近几年，基于Erlang的应用也得到的蓬勃的发展，特别是在基于web的大规模，分布式应用领域，几乎都是Erlang的优势项目。</p>\n<p>官网：<a href=\"http://couchdb.apache.org/\" target=\"_blank\" rel=\"noopener\">http://couchdb.apache.org/</a></p>\n<h3 id=\"二、MongoDB\"><a href=\"#二、MongoDB\" class=\"headerlink\" title=\"二、MongoDB\"></a>二、MongoDB</h3><p>简介：MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p>\n<p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/22965\" target=\"_blank\" rel=\"noopener\">MongoDB的基本特性与内部构造</a>  <a href=\"http://www.36dsj.com/archives/21104\" target=\"_blank\" rel=\"noopener\">大数据吃香 创业公司MongoDB估值达16亿美元</a></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/01/2710.jpg\" alt=\"\"></p>\n<p>特点</p>\n<p>它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：</p>\n<p>*面向集合存储，易存储对象类型的数据。</p>\n<p>mongodb集群参考</p>\n<p>mongodb集群参考</p>\n<p>*模式自由。</p>\n<p>*支持动态查询。</p>\n<p>*支持完全索引，包含内部对象。</p>\n<p>*支持查询。</p>\n<p>*支持复制和故障恢复。</p>\n<p>*使用高效的二进制数据存储，包括大型对象（如视频等）。</p>\n<p>*自动处理碎片，以支持云计算层次的扩展性。</p>\n<p>*支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。</p>\n<p>*文件存储格式为BSON（一种JSON的扩展）。</p>\n<p>*可通过网络访问。</p>\n<p>官网：<a href=\"https://www.mongodb.org/\" target=\"_blank\" rel=\"noopener\">https://www.mongodb.org/</a></p>\n<h3 id=\"三、Tachyon\"><a href=\"#三、Tachyon\" class=\"headerlink\" title=\"三、Tachyon\"></a>三、Tachyon</h3><p>贡献者：Haoyuan Li（李浩源）</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/725-220x150.jpg\" alt=\"\"></p>\n<p>简介：Tachyon是一个分布式内存文件系统，可以在集群里以访问内存的速度来访问存在tachyon里的文件。把Tachyon是架构在最底层的分布式文件存储和上层的各种计算框架之间的一种中间件。主要职责是将那些不需要落地到DFS里的文件，落地到分布式内存文件系统中，来达到共享内存，从而提高效率。同时可以减少内存冗余，GC时间等。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/823.jpg\" alt=\"\"></p>\n<p><strong>Tachyon架构</strong></p>\n<p>Tachyon的架构是传统的Master—slave架构，这里和Hadoop类似，TachyonMaster里WorkflowManager是 Master进程，因为是为了防止单点问题，通过Zookeeper做了HA，可以部署多台Standby Master。Slave是由Worker Daemon和Ramdisk构成。这里个人理解只有Worker Daemon是基于JVM的，Ramdisk是一个off heap memory。Master和Worker直接的通讯协议是Thrift。</p>\n<p>下图来自Tachyon的作者Haoyuan Li：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/920.jpg\" alt=\"\"></p>\n<p>下载地址：<a href=\"https://github.com/amplab/tachyon\" target=\"_blank\" rel=\"noopener\">https://github.com/amplab/tachyon</a></p>\n<h3 id=\"四、KFS\"><a href=\"#四、KFS\" class=\"headerlink\" title=\"四、KFS\"></a>四、KFS</h3><p>简介：GFS的C++开源版本，Kosmos distributed file system (KFS)是一个专门为数据密集型应用（搜索引擎，数据挖掘等）而设计的存储系统，类似于Google的GFS和Hadoop的HDFS分布式文件系统。 KFS使用C++实现，支持的客户端包括C++，Java和Python。KFS系统由三部分组成，分别是metaserver、chunkserver和client library。</p>\n<p>官网：<a href=\"http://code.google.com/p/kosmosfs/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/kosmosfs/</a></p>\n<h3 id=\"五、HDFS\"><a href=\"#五、HDFS\" class=\"headerlink\" title=\"五、HDFS\"></a>五、HDFS</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1022.jpg\" alt=\"\"></p>\n<p>简介：Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。</p>\n<p>官网：<a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hadoop.apache.org/</a></p>\n<h2 id=\"资源管理\"><a href=\"#资源管理\" class=\"headerlink\" title=\"资源管理\"></a>资源管理</h2><h3 id=\"一、Twitter-Mesos\"><a href=\"#一、Twitter-Mesos\" class=\"headerlink\" title=\"一、Twitter Mesos\"></a>一、Twitter Mesos</h3><p>开发者：Twitter研发人员John Oskasson</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1129.jpg\" alt=\"\"></p>\n<p>简介：Apache Mesos是由加州大学伯克利分校的AMPLab首先开发的一款开源群集管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等架构，由于其开源性质越来越受到一些大型云计算公司的青睐，例如Twitter、Facebook等。</p>\n<p>参考文章：<a href=\"http://www.csdn.net/article/2014-02-24/2818520-Cloud-Mesosphere-Mesos-Hadoop-Spark\" target=\"_blank\" rel=\"noopener\">Mesos渐入主流,Twitter模式有望 “无限复制”-CSDN.NET</a></p>\n<p>官网：<a href=\"http://mesos.apache.org/\" target=\"_blank\" rel=\"noopener\">http://mesos.apache.org/</a></p>\n<h3 id=\"二、Hadoop-Yarn\"><a href=\"#二、Hadoop-Yarn\" class=\"headerlink\" title=\"二、Hadoop Yarn\"></a>二、Hadoop Yarn</h3><p>Hadoop 新 MapReduce 框架 Yarn。为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1222.jpg\" alt=\"\"></p>\n<p>Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：</p>\n<p>1、这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。</p>\n<p>2、在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。</p>\n<p>3、对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。</p>\n<p>4、老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的行状况，如果出问题，会将其在其他机器上重启。</p>\n<p>5、Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>\n<p>官网：<a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hadoop.apache.org/</a></p>\n<h2 id=\"日志收集系统\"><a href=\"#日志收集系统\" class=\"headerlink\" title=\"日志收集系统\"></a>日志收集系统</h2><h3 id=\"一、Facebook-Scribe\"><a href=\"#一、Facebook-Scribe\" class=\"headerlink\" title=\"一、Facebook Scribe\"></a>一、Facebook Scribe</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1107.jpg\" alt=\"\"></p>\n<p>贡献者：Facebook</p>\n<p>简介：Scribe是Facebook开源的日志收集系统，在Facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央存储系统。其通常与Hadoop结合使用，scribe用于向HDFS中push日志，而Hadoop通过MapReduce作业进行定期处理。</p>\n<p>Scribe的系统架构</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/298-600x234.jpg\" alt=\"\"></p>\n<p>代码托管：<a href=\"https://github.com/facebook/scribe\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/scribe</a></p>\n<h3 id=\"二、Cloudera-Flume\"><a href=\"#二、Cloudera-Flume\" class=\"headerlink\" title=\"二、Cloudera Flume\"></a>二、Cloudera Flume</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/348.jpg\" alt=\"\"></p>\n<p>贡献者：<a href=\"http://www.36dsj.com/archives/tag/cloudera\" target=\"_blank\" rel=\"noopener\">Cloudera</a></p>\n<p>简介：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>\n<p>Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。</p>\n<p>当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。</p>\n<p><strong>Cloudera Flume构架：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/427-414x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://flume.apache.org/\" target=\"_blank\" rel=\"noopener\">http://flume.apache.org/</a></p>\n<h3 id=\"三、logstash\"><a href=\"#三、logstash\" class=\"headerlink\" title=\"三、logstash\"></a>三、logstash</h3><p>简介：logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/527-600x265.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://www.logstash.net/\" target=\"_blank\" rel=\"noopener\">http://www.logstash.net/</a></p>\n<h3 id=\"四、kibana\"><a href=\"#四、kibana\" class=\"headerlink\" title=\"四、kibana\"></a>四、kibana</h3><p>简介：Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面。</p>\n<p>主页： <a href=\"http://kibana.org/\" target=\"_blank\" rel=\"noopener\">http://kibana.org/</a></p>\n<p>代码托管： <a href=\"https://github.com/rashidkpc/Kibana/downloads\" target=\"_blank\" rel=\"noopener\">https://github.com/rashidkpc/Kibana/downloads</a></p>\n<h2 id=\"消息系统\"><a href=\"#消息系统\" class=\"headerlink\" title=\"消息系统\"></a>消息系统</h2><h3 id=\"一、StormMQ\"><a href=\"#一、StormMQ\" class=\"headerlink\" title=\"一、StormMQ\"></a>一、StormMQ</h3><p>简介：MQMessageQueue消息队列产品 StormMQ，是一种服务程序。</p>\n<p>官网：<a href=\"http://stormmq.com/\" target=\"_blank\" rel=\"noopener\">http://stormmq.com/</a></p>\n<h3 id=\"二、ZeroMQ\"><a href=\"#二、ZeroMQ\" class=\"headerlink\" title=\"二、ZeroMQ\"></a>二、ZeroMQ</h3><p>简介：这是个类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。</p>\n<p>引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”</p>\n<p>官网：<a href=\"http://zeromq.org/\" target=\"_blank\" rel=\"noopener\">http://zeromq.org/</a></p>\n<h3 id=\"三、RabbitMQ\"><a href=\"#三、RabbitMQ\" class=\"headerlink\" title=\"三、RabbitMQ\"></a>三、RabbitMQ</h3><p>简介：RabbitMQ是一个受欢迎的消息代理，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。本文简单介绍了如何使用 RabbitMQ，假定你已经配置好了rabbitmq服务器。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/624.jpg\" alt=\"\"></p>\n<p>RabbitMQ是用Erlang，对于主要的编程语言都有驱动或者客户端。我们这里要用的是Java，所以先要获得Java客户端。</p>\n<p>像RabbitMQ这样的消息代理可用来模拟不同的场景，例如点对点的消息分发或者订阅/推送。我们的程序足够简单，有两个基本的组件，一个生产者用于产生消息，还有一个消费者用来使用产生的消息。</p>\n<p>官网：<a href=\"https://www.rabbitmq.com/\" target=\"_blank\" rel=\"noopener\">https://www.rabbitmq.com/</a></p>\n<h3 id=\"四、Apache-ActiveMQ\"><a href=\"#四、Apache-ActiveMQ\" class=\"headerlink\" title=\"四、Apache ActiveMQ\"></a>四、Apache ActiveMQ</h3><p>简介：ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/726.jpg\" alt=\"\"></p>\n<p>特性：</p>\n<p>⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP</p>\n<p>⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)</p>\n<p>⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性</p>\n<p>⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上</p>\n<p>⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA</p>\n<p>⒍ 支持通过JDBC和journal提供高速的消息持久化</p>\n<p>⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点</p>\n<p>⒏ 支持Ajax</p>\n<p>⒐ 支持与Axis的整合</p>\n<p>⒑ 可以很容易得调用内嵌JMS provider，进行测试</p>\n<p>官网：<a href=\"http://activemq.apache.org/\" target=\"_blank\" rel=\"noopener\">http://activemq.apache.org/</a></p>\n<h3 id=\"五、Jafka\"><a href=\"#五、Jafka\" class=\"headerlink\" title=\"五、Jafka\"></a>五、Jafka</h3><p>贡献者：LinkedIn</p>\n<p>简介：Jafka 是一个开源的、高性能的、跨语言分布式消息系统，使用GitHub托管。Jafka 最早是由Apache孵化的Kafka（由LinkedIn捐助给Apache）克隆而来。由于是一个开放式的数据传输协议，因此除了Java开发语言受到支持，Python、Ruby、C、C++等其他语言也能够很好的得到支持。</p>\n<p>特性：</p>\n<p>1、消息持久化非常快，服务端存储消息的开销为O(1)，并且基于文件系统，能够持久化TB级的消息而不损失性能。</p>\n<p>2、吞吐量取决于网络带宽。</p>\n<p>3、完全的分布式系统，broker、producer、consumer都原生自动支持分布式。自动实现复杂均衡。</p>\n<p>4、内核非常小，整个系统（包括服务端和客户端）只有一个272KB的jar包，内部机制也不复杂，适合进行内嵌或者二次开发 。整个服务端加上依赖组件共3.5MB。</p>\n<p>5、消息格式以及通信机制非常简单，适合进行跨语言开发。目前自带的Python3.x的客户端支持发送消息和接收消息。</p>\n<p>官网：<a href=\"http://kafka.apache.org/\" target=\"_blank\" rel=\"noopener\">http://kafka.apache.org/</a></p>\n<h3 id=\"六、Apache-Kafka\"><a href=\"#六、Apache-Kafka\" class=\"headerlink\" title=\"六、Apache Kafka\"></a>六、Apache Kafka</h3><p>贡献者：LinkedIn</p>\n<p>简介：Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。</p>\n<p>Kafka是一个分布式的、分区的、多复本的日志提交服务。它通过一种独一无二的设计提供了一个消息系统的功能。</p>\n<p>Kafka集群可以在一个指定的时间内保持所有发布上来的消息，不管这些消息有没有被消费。打个比方，如果这个时间设置为两天，那么在消息发布的两天以内，这条消息都是可以被消费的，但是在两天后，这条消息就会被系统丢弃以释放空间。Kafka的性能不会受数据量的大小影响，因此保持大量的数据不是一个问题。</p>\n<p>官网：<a href=\"http://kafka.apache.org/\" target=\"_blank\" rel=\"noopener\">http://kafka.apache.org/</a></p>\n<h2 id=\"分布式服务\"><a href=\"#分布式服务\" class=\"headerlink\" title=\"分布式服务\"></a>分布式服务</h2><h3 id=\"一、ZooKeeper\"><a href=\"#一、ZooKeeper\" class=\"headerlink\" title=\"一、ZooKeeper\"></a>一、ZooKeeper</h3><p>贡献者：Google</p>\n<p>简介：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p>\n<p>ZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。</p>\n<p>架构：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/824-600x244.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://zookeeper.apache.org/\" target=\"_blank\" rel=\"noopener\">http://zookeeper.apache.org/</a></p>\n<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p>（Remote Procedure Call Protocol）——远程过程调用协议</p>\n<h3 id=\"一、Apache-Avro\"><a href=\"#一、Apache-Avro\" class=\"headerlink\" title=\"一、Apache Avro\"></a>一、Apache Avro</h3><p>简介：Apache Avro是Hadoop下的一个子项目。它本身既是一个序列化框架，同时也实现了RPC的功能。Avro官网描述Avro的特性和功能如下：</p>\n<p>丰富的数据结构类型；<br>快速可压缩的二进制数据形式；<br>存储持久数据的文件容器；<br>提供远程过程调用RPC；<br>简单的动态语言结合功能。<br>相比于Apache Thrift 和Google的Protocol Buffers，Apache Avro具有以下特点：</p>\n<p>支持动态模式。Avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。<br>数据无须加标签。读取数据前，Avro能够获取模式定义，这使得Avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。<br>官网：<a href=\"http://avro.apache.org/\" target=\"_blank\" rel=\"noopener\">http://avro.apache.org/</a></p>\n<h3 id=\"二、Facebook-Thrift\"><a href=\"#二、Facebook-Thrift\" class=\"headerlink\" title=\"二、Facebook Thrift\"></a>二、Facebook Thrift</h3><p>贡献者：Facebook</p>\n<p>简介：Thrift源于大名鼎鼎的facebook之手，在2007年facebook提交Apache基金会将Thrift作为一个开源项目，对于当时的facebook来说创造thrift是为了解决facebook系统中各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性。</p>\n<p>thrift可以支持多种程序语言，例如: C++, C#, Cocoa, Erlang, Haskell, Java, Ocami, Perl, PHP, Python, Ruby, Smalltalk. 在多种不同的语言之间通信thrift可以作为二进制的高性能的通讯中间件，支持数据(对象)序列化和多种类型的RPC服务。</p>\n<p>Thrift适用于程序对程 序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程，跟其他IDL工具相比较可以视为是Thrift的弱项，Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输相对于JSON和xml无论在性能、传输大小上有明显的优势。</p>\n<p>Thrift 主要由5个部分组成：</p>\n<p>· 类型系统以及 IDL 编译器：负责由用户给定的 IDL 文件生成相应语言的接口代码</p>\n<p>· TProtocol：实现 RPC 的协议层，可以选择多种不同的对象串行化方式，如 JSON, Binary。</p>\n<p>· TTransport：实现 RPC 的传输层，同样可以选择不同的传输层实现，如socket, 非阻塞的 socket, MemoryBuffer 等。</p>\n<p>· TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口。</p>\n<p>· TServer：聚合 TProtocol, TTransport 和 TProcessor 几个对象。</p>\n<p>上述的这5个部件都是在 Thrift 的源代码中通过为不同语言提供库来实现的，这些库的代码在 Thrift 源码目录的 lib 目录下面，在使用 Thrift 之前需要先熟悉与自己的语言对应的库提供的接口。</p>\n<p>Facebook Thrift构架：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/921.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://thrift.apache.org/\" target=\"_blank\" rel=\"noopener\">http://thrift.apache.org/</a></p>\n<h2 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h2><h3 id=\"一、Nagios\"><a href=\"#一、Nagios\" class=\"headerlink\" title=\"一、Nagios\"></a>一、Nagios</h3><p>简介：Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。</p>\n<p>Nagios可运行在Linux/Unix平台之上，同时提供一个可选的基于浏览器的WEB界面以方便系统管理人员查看网络状态，各种系统问题，以及日志等等。</p>\n<p>官网：<a href=\"http://www.nagios.org/\" target=\"_blank\" rel=\"noopener\">http://www.nagios.org/</a></p>\n<h3 id=\"二、Ganglia\"><a href=\"#二、Ganglia\" class=\"headerlink\" title=\"二、Ganglia\"></a>二、Ganglia</h3><p>简介：Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1130-600x417.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://ganglia.sourceforge.net/\" target=\"_blank\" rel=\"noopener\">http://ganglia.sourceforge.net/</a></p>\n<h3 id=\"三、Apache-Ambari\"><a href=\"#三、Apache-Ambari\" class=\"headerlink\" title=\"三、Apache Ambari\"></a>三、Apache Ambari</h3><p>简介：Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。</p>\n<p>Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1223.jpg\" alt=\"\"></p>\n<p><strong>Ambari主要取得了以下成绩：</strong></p>\n<p>通过一步一步的安装向导简化了集群供应。<br>预先配置好关键的运维指标（metrics），可以直接查看Hadoop Core（HDFS和MapReduce）及相关项目（如HBase、Hive和HCatalog）是否健康。<br>支持作业与任务执行的可视化与分析，能够更好地查看依赖和性能。<br>通过一个完整的RESTful API把监控信息暴露出来，集成了现有的运维工具。<br>用户界面非常直观，用户可以轻松有效地查看信息并控制集群。<br>Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时（比如，节点停机或磁盘剩余空间不足等问题），系统将向其发送邮件。</p>\n<p>此外，Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。</p>\n<p>官网：<a href=\"http://ambari.apache.org/\" target=\"_blank\" rel=\"noopener\">http://ambari.apache.org/</a></p>\n<h2 id=\"基础设施\"><a href=\"#基础设施\" class=\"headerlink\" title=\"基础设施\"></a>基础设施</h2><h3 id=\"一、LevelDB-1\"><a href=\"#一、LevelDB-1\" class=\"headerlink\" title=\"一、LevelDB\"></a>一、LevelDB</h3><p>贡献者：Jeff Dean和Sanjay Ghemawat</p>\n<p>简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>\n<p>Leveldb框架：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1322-468x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://code.google.com/p/leveldb/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/leveldb/</a></p>\n<h3 id=\"二、SSTable\"><a href=\"#二、SSTable\" class=\"headerlink\" title=\"二、SSTable\"></a>二、SSTable</h3><p>简介：如果说Protocol Buffer是谷歌独立数据记录的通用语言 ，那么有序字符串表（SSTable，Sorted String Table）则是用于存储，处理和数据集交换的最流行​​的数据输出格式。正如它的名字本身，SSTable是有效存储大量键-值对的简单抽象，对高吞吐量顺序读/写进行了优化。</p>\n<p>SSTable是Bigtable中至关重要的一块，对于LevelDB来说也是如此。</p>\n<h3 id=\"三、RecordIO\"><a href=\"#三、RecordIO\" class=\"headerlink\" title=\"三、RecordIO\"></a>三、RecordIO</h3><p>贡献者：Google</p>\n<p>简介：我们大家都在用文件来存储数据。文件是存储在磁盘上的。如果在一些不稳定的介质上，文件很容损坏。即时文件某个位置出现一点小小的问题，整个文件就废了。</p>\n<p>下面我来介绍Google的一个做法，可以比较好的解决这个问题。那就是recordio文件格式。recoidio的存储单元是一个一个record。这个record可以根据业务的需要自行定义。但Google有一种建议的处理方式就是使用protobuf。</p>\n<p>reocordio底层的格式其实很简单。一个record由四部分组成：</p>\n<p>MagicNumber (32 bits)<br>Uncompressed data payload size (64 bits)<br>Compressed data payload size (64 bits), or 0 if the data is not compressed<br>Payload, possibly compressed.<br><strong>详细格式如下图所示：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/recordio_thumb-600x76.png\" alt=\"\"></p>\n<p>到这里，大家可能已经知道，recordio之所以能对付坏数据，其实就是在这个MagicNumber（校验值）。</p>\n<h3 id=\"四、Flat-Buffers\"><a href=\"#四、Flat-Buffers\" class=\"headerlink\" title=\"四、Flat Buffers\"></a>四、Flat Buffers</h3><p>贡献者：Google</p>\n<p>简介：谷歌开源高效、跨平台的序列化库FlatBuffers。</p>\n<p>该库的构建是专门为游戏开发人员的性能需求提供支持，它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而不需要任何解析开销。</p>\n<p>FlatBuffers有如下一些关键特性——</p>\n<p>访问序列化数据不需要打包/拆包<br>节省内存而且访问速度快——缓存只占用访问数据所需要的内存；不需要任何额外的内存。<br>灵活性——通过可选字段向前向后兼容<br>代码规模小<br>强类型——错误在编译时捕获，而不是在运行时<br>便利性——生成的C++头文件代码简洁。如果需要，有一项可选功能可以用来在运行时高效解析Schema和JSON-like格式的文本。<br>跨平台——使用C++编写，不依赖STL之外的库，因此可以用于任何有C++编辑器的平台。当前，该项目包含构建方法和在Android、Linux、Windows和OSX等操作系统上使用该库的示例。<br>与Protocol Buffers或JSON Parsing这样的可选方案相比，FlatBuffers的优势在于开销更小，这主要是由于它没有解析过程。</p>\n<p>代码托管：<a href=\"https://github.com/google/flatbuffers\" target=\"_blank\" rel=\"noopener\">https://github.com/google/flatbuffers</a></p>\n<h3 id=\"五、Protocol-Buffers\"><a href=\"#五、Protocol-Buffers\" class=\"headerlink\" title=\"五、Protocol Buffers\"></a>五、Protocol Buffers</h3><p>贡献者：Google</p>\n<p>简介：Protocol Buffers是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。现阶段官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。</p>\n<p>通过它，你可以定义你的数据的结构，并生成基于各种语言的代码。这些你定义的数据流可以轻松地在传递并不破坏你已有的程序。并且你也可以更新这些数据而现有的程序也不会受到任何的影响。</p>\n<p>Protocol Buffers经常被简称为protobuf。</p>\n<p>官网：<a href=\"http://code.google.com/p/protobuf/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/protobuf/</a></p>\n<h3 id=\"六、Consistent-Hashing（哈希算法）\"><a href=\"#六、Consistent-Hashing（哈希算法）\" class=\"headerlink\" title=\"六、Consistent Hashing（哈希算法）\"></a>六、Consistent Hashing（哈希算法）</h3><p>简介：一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1420.jpg\" alt=\"\"></p>\n<p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p>\n<p>1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p>\n<p>2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</p>\n<p>3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p>\n<p>4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p>\n<p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。</p>\n<h3 id=\"七、Netty\"><a href=\"#七、Netty\" class=\"headerlink\" title=\"七、Netty\"></a>七、Netty</h3><p>贡献者：JBOSS</p>\n<p>简介：Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1518.jpg\" alt=\"\"></p>\n<p>也就是说，Netty 是一个基于NIO的客户，服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。</p>\n<p>“快速”和“简单”并不意味着会让你的最终应用产生维护性或性能上的问题。Netty 是一个吸收了多种协议的实现经验，这些协议包括FTP,SMTP,HTTP，各种二进制，文本协议，并经过相当精心设计的项目，最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。</p>\n<p>官网：<a href=\"http://netty.io/\" target=\"_blank\" rel=\"noopener\">http://netty.io/</a></p>\n<h3 id=\"八、BloomFilter\"><a href=\"#八、BloomFilter\" class=\"headerlink\" title=\"八、BloomFilter\"></a>八、BloomFilter</h3><p>简介：Bloom filter 是由 Howard Bloom 在 1970 年提出的二进制向量数据结构，它具有很好的空间和时间效率，被用来检测一个元素是不是集合中的一个成员。如果检测结果为是，该元素不一定在集合中；但如果检测结果为否，该元素一定不在集合中。因此Bloom filter具有100%的召回率。这样每个检测请求返回有“在集合内（可能错误）”和“不在集合内（绝对不在集合内）”两种情况，可见 Bloom filter 是牺牲了正确率和时间以节省空间。</p>\n<p>Bloom filter 优点就是它的插入和查询时间都是常数，另外它查询元素却不保存元素本身，具有良好的安全性。</p>\n<h2 id=\"搜索引擎\"><a href=\"#搜索引擎\" class=\"headerlink\" title=\"搜索引擎\"></a>搜索引擎</h2><h3 id=\"一、Nutch\"><a href=\"#一、Nutch\" class=\"headerlink\" title=\"一、Nutch\"></a>一、Nutch</h3><p>简介：Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。</p>\n<p>尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg\" alt=\"\"></p>\n<p>Nutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.</p>\n<p>Nutch目前最新的版本为version v2.2.1。</p>\n<p>官网：<a href=\"https://nutch.apache.org/\" target=\"_blank\" rel=\"noopener\">https://nutch.apache.org/</a></p>\n<h3 id=\"二、Lucene\"><a href=\"#二、Lucene\" class=\"headerlink\" title=\"二、Lucene\"></a>二、Lucene</h3><p>开发者：Doug Cutting（Hadoop之父，你懂的）</p>\n<p>简介：Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1717-556x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://lucene.apache.org/\" target=\"_blank\" rel=\"noopener\">http://lucene.apache.org/</a></p>\n<h3 id=\"三、SolrCloud\"><a href=\"#三、SolrCloud\" class=\"headerlink\" title=\"三、SolrCloud\"></a>三、SolrCloud</h3><p>简介：SolrCloud是Solr4.0版本以后基于Solr和Zookeeper的分布式搜索方案。SolrCloud是Solr的基于Zookeeper一种部署方式。Solr可以以多种方式部署，例如单机方式，多机Master-Slaver方式。</p>\n<p><strong>原理图：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1813-583x429.jpg\" alt=\"\"></p>\n<p><strong>SolrCloud有几个特色功能：</strong></p>\n<p>集中式的配置信息使用ZK进行集中配置。启动时可以指定把Solr的相关配置文件上传</p>\n<p>Zookeeper，多机器共用。这些ZK中的配置不会再拿到本地缓存，Solr直接读取ZK中的配置信息。配置文件的变动，所有机器都可以感知到。另外，Solr的一些任务也是通过ZK作为媒介发布的。目的是为了容错。接收到任务，但在执行任务时崩溃的机器，在重启后，或者集群选出候选者时，可以再次执行这个未完成的任务。</p>\n<p>自动容错SolrCloud对索引分片，并对每个分片创建多个Replication。每个Replication都可以对外提供服务。一个Replication挂掉不会影响索引服务。更强大的是，它还能自动的在其它机器上帮你把失败机器上的索引Replication重建并投入使用。</p>\n<p>近实时搜索立即推送式的replication（也支持慢推送）。可以在秒内检索到新加入索引。</p>\n<p>查询时自动负载均衡SolrCloud索引的多个Replication可以分布在多台机器上，均衡查询压力。如果查询压力大，可以通过扩展机器，增加Replication来减缓。</p>\n<p>自动分发的索引和索引分片发送文档到任何节点，它都会转发到正确节点。</p>\n<p>事务日志事务日志确保更新无丢失，即使文档没有索引到磁盘。</p>\n<h3 id=\"四、Solr\"><a href=\"#四、Solr\" class=\"headerlink\" title=\"四、Solr\"></a>四、Solr</h3><p>简介：Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1913-593x429.jpg\" alt=\"\"></p>\n<p>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。</p>\n<p>官网：<a href=\"https://lucene.apache.org/solr/\" target=\"_blank\" rel=\"noopener\">https://lucene.apache.org/solr/</a></p>\n<h3 id=\"五、ElasticSearch\"><a href=\"#五、ElasticSearch\" class=\"headerlink\" title=\"五、ElasticSearch\"></a>五、ElasticSearch</h3><p>简介：ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二最流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。</p>\n<p>官网：<a href=\"http://www.elasticsearch.org/\" target=\"_blank\" rel=\"noopener\">http://www.elasticsearch.org/</a></p>\n<h3 id=\"六、Sphinx\"><a href=\"#六、Sphinx\" class=\"headerlink\" title=\"六、Sphinx\"></a>六、Sphinx</h3><p>简介：Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。</p>\n<p>Sphinx单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。</p>\n<p>官网：<a href=\"http://sphinxsearch.com\" target=\"_blank\" rel=\"noopener\">http://sphinxsearch.com</a></p>\n<h3 id=\"七、SenseiDB\"><a href=\"#七、SenseiDB\" class=\"headerlink\" title=\"七、SenseiDB\"></a>七、SenseiDB</h3><p>贡献者：linkedin</p>\n<p>简介：SenseiDB是一个NoSQL数据库，它专注于高更新率以及复杂半结构化搜索查询。熟悉Lucene和Solor的用户会发现，SenseiDB背后有许多似曾相识的概念。SenseiDB部署在多节点集群中，其中每个节点可以包括N块数据片。Apache Zookeeper用于管理节点，它能够保持现有配置，并可以将任意改动（如拓扑修改）传输到整个节点群中。SenseiDB集群还需要一种模式用于定义将要使用的数据模型。</p>\n<p>从SenseiDB集群中获取数据的唯一方法是通过Gateways（它 没有“INSERT”方法）。每个集群都连接到一个单一gateway。你需要了解很重要的一点是，由于SenseiDB本身没法处理原子性 （Atomicity）和隔离性（Isolation），因此只能通过外部在gateway层进行限制。另外，gateway必须确保数据流按照预期的方 式运作。内置的gateway有以下几种形式：</p>\n<p>来自文件<br>来自JMS队列<br>通过JDBC<br>来自Apache Kafka<br>官网：<a href=\"http://senseidb.com\" target=\"_blank\" rel=\"noopener\">http://senseidb.com</a></p>\n<h2 id=\"数据挖掘\"><a href=\"#数据挖掘\" class=\"headerlink\" title=\"数据挖掘\"></a>数据挖掘</h2><h3 id=\"一、Mahout\"><a href=\"#一、Mahout\" class=\"headerlink\" title=\"一、Mahout\"></a>一、Mahout</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg\" alt=\"\"></p>\n<p>简介：Apache Mahout 是 Apache Software Foundation (ASF) 开发的一个全新的开源项目，其主要目标是创建一些可伸缩的机器学习算法，供开发人员在 Apache 在许可下免费使用。该项目已经发展到了它的最二个年头，目前只有一个公共发行版。Mahout 包含许多实现，包括集群、分类、CP 和进化程序。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。</p>\n<p>虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：</p>\n<p>Taste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。<br>一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。<br>Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现。<br>针对进化编程的分布式适用性功能。<br>Matrix 和矢量库。<br>上述算法的示例。<br>官网：<a href=\"http://mahout.apache.org/\" target=\"_blank\" rel=\"noopener\">http://mahout.apache.org/</a></p>\n<h2 id=\"Iaas\"><a href=\"#Iaas\" class=\"headerlink\" title=\"Iaas\"></a>Iaas</h2><p>IaaS（Infrastructure as a Service），即基础设施即服务。</p>\n<h3 id=\"一、OpenStack\"><a href=\"#一、OpenStack\" class=\"headerlink\" title=\"一、OpenStack\"></a>一、OpenStack</h3><p>简介：OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。</p>\n<p>OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2014/12/1148-599x429.jpg\" alt=\"\"></p>\n<p>6个核心项目：Nova（计算，Compute），Swift（对象存储，Object），Glance（镜像，Image），Keystone（身份，Identity），Horizon（自助门户，Dashboard），Quantum &amp; Melange（网络&amp;地址管理），另外还有若干社区项目，如Rackspace（负载均衡）、Rackspace（关系型数据库）。</p>\n<p>相关阅读：</p>\n<p><a href=\"http://www.36dsj.com/archives/19596\" target=\"_blank\" rel=\"noopener\">什么是OpenStack？</a></p>\n<p><a href=\"http://www.36dsj.com/archives/22179\" target=\"_blank\" rel=\"noopener\">成功部署OpenStack的十大要点</a></p>\n<p> 官网：<a href=\"https://www.openstack.org/\" target=\"_blank\" rel=\"noopener\">https://www.openstack.org/</a></p>\n<h3 id=\"二、Docker\"><a href=\"#二、Docker\" class=\"headerlink\" title=\"二、Docker\"></a>二、Docker</h3><p>贡献者：dotCloud</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2215.jpg\" alt=\"\"></p>\n<p>简介：Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包括系统。</p>\n<p>官网：<a href=\"http://www.docker.io/\" target=\"_blank\" rel=\"noopener\">http://www.docker.io/</a></p>\n<h3 id=\"三、Kubernetes\"><a href=\"#三、Kubernetes\" class=\"headerlink\" title=\"三、Kubernetes\"></a>三、Kubernetes</h3><p>贡献者：Google</p>\n<p>简介：Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。</p>\n<p>Kubernetes从另一个角度对资源进行抽象，它让开发人员和管理人员共同着眼于服务的行为和性能的提升，而不是仅仅关注对单一的组件或者是基础资源。</p>\n<p>那么Kubernetes集群到底提供了哪些单一容器所没有功能?它主要关注的是对服务级别的控制而并非仅仅是对容器级别的控制，Kubernetes提供了一种“机智”的管理方式，它将服务看成一个整体。在Kubernete的解决方案中，一个服务甚至可以自我扩展，自我诊断，并且容易升级。例如，在Google中，我们使用机器学习技术来保证每个运行的服务的当前状态都是最高效的。</p>\n<p>代码托管：<a href=\"https://github.com/GoogleCloudPlatform/kubernetes/\" target=\"_blank\" rel=\"noopener\">https://github.com/GoogleCloudPlatform/kubernetes/</a></p>\n<h3 id=\"四、Imctfy\"><a href=\"#四、Imctfy\" class=\"headerlink\" title=\"四、Imctfy\"></a>四、Imctfy</h3><p>贡献者：Google</p>\n<p>简介：Google开源了自己所用Linux容器系统的开源版本lmctfy，读音为lem-kut-fee。包括一个C++库（使用了C++11，文档可以参考头文件）和命令行界面。目前的版本是0.1，只提供了CPU与内存隔离。项目还在密集开发中。</p>\n<p>mctfy本身是针对某些特定使用场景设计和实现的，目前拥有一台机器上所有容器时运行情况最好，不推荐与LXC和其他容器系统一起使用（虽然也可行）。已在Ubuntu 12.04+和Ubuntu 3.3与3.8内核上测试。</p>\n<p>代码托管：<a href=\"https://github.com/google/Imctfy/\" target=\"_blank\" rel=\"noopener\">https://github.com/google/Imctfy/</a></p>\n<h2 id=\"监控管理\"><a href=\"#监控管理\" class=\"headerlink\" title=\"监控管理\"></a>监控管理</h2><h3 id=\"一、Dapper\"><a href=\"#一、Dapper\" class=\"headerlink\" title=\"一、Dapper\"></a>一、Dapper</h3><p>贡献者：Google</p>\n<p>简介：Dapper是一个轻量的ORM(对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）。并不单纯的是一个DBHelper.因为在Dapper中数据其实就是一个对象。Dapper扩展与IDbConnection上，所以事实上它的倾入性很低。我用了StructureMap。如果不喜欢可以自己更换，或者自己实现下。</p>\n<p>代码就一个SqlMapper.cs文件,主要是IDbConnection的扩展方法，编译后就40K的一个很小的dll。</p>\n<p>特性：</p>\n<p>Dapper很快。Dapper的速度接近与IDataReader。<br>Dapper支持主流数据库 Mysql,SqlLite,Mssql2000,Mssql2005,Oracle等一系列的数据库<br>支持多表并联的对象。支持一对多 多对多的关系，并且没侵入性。<br>原理通过Emit反射IDataReader的序列队列，来快速的得到和产生对象<br>Dapper语法十分简单。并且无须迁就数据库的设计<br>官方站点 <a href=\"http://code.google.com/p/dapper-dot-net/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/dapper-dot-net/</a></p>\n<p>代码托管：<a href=\"http://bigbully.github.io/Dapper-translation/\" target=\"_blank\" rel=\"noopener\">http://bigbully.github.io/Dapper-translation/</a></p>\n<h3 id=\"二、Zipkin\"><a href=\"#二、Zipkin\" class=\"headerlink\" title=\"二、Zipkin\"></a>二、Zipkin</h3><p>贡献者：Twitter</p>\n<p>简介：Zipkin （分布式跟踪系统）是 Twitter 的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口。该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2313-535x429.jpg\" alt=\"\"></p>\n<p>官方网站：<a href=\"http://twitter.github.io/zipkin/\" target=\"_blank\" rel=\"noopener\">http://twitter.github.io/zipkin/</a></p>\n<p>代码托管：<a href=\"https://github.com/twitter/zipkin/\" target=\"_blank\" rel=\"noopener\">https://github.com/twitter/zipkin/</a></p>\n<p><strong>————————————-End.——————————————-</strong></p>\n<p>感谢:<br>36大数据(<a href=\"http://www.36dsj.com/\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/</a>)</p>\n<p>转载来源:<a href=\"http://www.36dsj.com/archives/24852\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/archives/24852</a><br><a href=\"http://www.36dsj.com/archives/25042\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/archives/25042</a></p>\n","site":{"data":{}},"excerpt":"<ul>\n<li>目录<br>{:toc #meuid}</li>\n</ul>\n<h2 id=\"查询引擎\"><a href=\"#查询引擎\" class=\"headerlink\" title=\"查询引擎\"></a>查询引擎</h2><h3 id=\"一、Phoenix\"><a href=\"#一、Phoenix\" class=\"headerlink\" title=\"一、Phoenix\"></a>一、Phoenix</h3><p>贡献者：：Salesforce</p>\n<p>简介：这是一个Java中间层，可以让开发者在Apache HBase上执行SQL查询。Phoenix完全使用Java编写，代码位于GitHub上，并且提供了一个客户端可嵌入的JDBC驱动。<br>","more":"</p>\n<p>Phoenix查询引擎会将SQL查询转换为一个或多个HBase scan，并编排执行以生成标准的JDBC结果集。直接使用HBase API、协同处理器与自定义过滤器，对于简单查询来说，其性能量级是毫秒，对于百万级别的行数来说，其性能量级是秒。</p>\n<p>Phoenix最值得关注的一些特性有：</p>\n<p>❶嵌入式的JDBC驱动，实现了大部分的java.sql接口，包括元数据API</p>\n<p>❷可以通过多部行键或是键/值单元对列进行建模</p>\n<p>❸完善的查询支持，可以使用多个谓词以及优化的扫描键</p>\n<p>❹DDL支持：通过CREATE TABLE、DROP TABLE及ALTER TABLE来添加/删除列</p>\n<p>❺版本化的模式仓库：当写入数据时，快照查询会使用恰当的模式</p>\n<p>❻DML支持：用于逐行插入的UPSERT VALUES、用于相同或不同表之间大量数据传输的UPSERT </p>\n<p>❼SELECT、用于删除行的DELETE</p>\n<p>❽通过客户端的批处理实现的有限的事务支持</p>\n<p>❾单表——还没有连接，同时二级索引也在开发当中</p>\n<p>➓紧跟ANSI SQL标准</p>\n<p><a href=\"http://phoenix.apache.org/\" target=\"_blank\" rel=\"noopener\">Phoenix官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Stinger\"><a href=\"#二、Stinger\" class=\"headerlink\" title=\"二、Stinger\"></a>二、Stinger</h3><p>贡献者：：Hortonworks</p>\n<p>简介：原叫Tez，下一代Hive,Hortonworks主导开发，运行在YARN上的DAG计算框架。</p>\n<p>某些测试下，Stinger能提升10倍左右的性能，同时会让Hive支持更多的SQL，其主要优点包括：</p>\n<p>❶让用户在Hadoop获得更多的查询匹配。其中包括类似OVER的字句分析功能，支持WHERE查询，让Hive的样式系统更符合SQL模型。</p>\n<p>❷优化了Hive请求执行计划，优化后请求时间减少90%。改动了Hive执行引擎，增加单Hive任务的被秒处理记录数。</p>\n<p>❸在Hive社区中引入了新的列式文件格式（如ORC文件），提供一种更现代、高效和高性能的方式来储存Hive数据。</p>\n<p>❹引入了新的运行时框架——Tez，旨在消除Hive的延时和吞吐量限制。Tez通过消除不必要的task、障碍同步和对HDFS的读写作业来优化Hive job。这将优化Hadoop内部的执行链，彻底加速Hive负载处理。</p>\n<p><a href=\"http://hortonworks.com/labs/stinger/\" target=\"_blank\" rel=\"noopener\">Stinger官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"三、Presto\"><a href=\"#三、Presto\" class=\"headerlink\" title=\"三、Presto\"></a>三、Presto</h3><p>贡献者：：Facebook</p>\n<p>简介：Facebook开源的数据查询引擎Presto ，可对250PB以上的数据进行快速地交互式分析。该项目始于 2012 年秋季开始开发，目前该项目已经在超过 1000 名 Facebook 雇员中使用，运行超过 30000 个查询，每日数据在 1PB 级别。Facebook 称 Presto 的性能比诸如 Hive 和 Map*Reduce 要好上 10 倍有多。</p>\n<p>Presto 当前支持 ANSI SQL 的大多数特效，包括联合查询、左右联接、子查询以及一些聚合和计算函数；支持近似截然不同的计数(DISTINCT COUNT)等。</p>\n<p><a href=\"https://github.com/facebook/presto\" target=\"_blank\" rel=\"noopener\">github源代码下载&gt;&gt;&gt;</a></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1105.jpg\" alt=\"\"></p>\n<h3 id=\"四、Shark\"><a href=\"#四、Shark\" class=\"headerlink\" title=\"四、Shark\"></a>四、Shark</h3><p>简介：Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。Shark的特点就是快，完全兼容Hive，且可以在shell模式下使用rdd2sql()这样的API，把HQL得到的结果集，继续在scala环境下运算，支持自己编写简单的机器学习或简单分析处理函数，对HQL结果进一步分析计算。</p>\n<p>❶Shark速度快的原因除了Spark平台提供的基于内存迭代计算外，在设计上还存在对Spark上进行了一定的改造，主要有</p>\n<p>❷partial DAG execution：对join优化，调节并行粒度，因为Spark本身的宽依赖和窄依赖会影响并行计算和速度</p>\n<p>基于列的压缩和存储：把HQL表数据按列存，每列是一个array，存在JVM上，避免了JVM GC低效，而压缩和解压相关的技术是Yahoo!提供的。</p>\n<p>结来说，Shark是一个插件式的东西，在我现有的Spark和Hive及hadoop-client之间，在这两套都可用的情况下，Shark只要获取Hive的配置（还有metastore和exec等关键包），Spark的路径，Shark就能利用Hive和Spark，把HQL解析成RDD的转换，把数据取到Spark上运算和分析。在SQL on Hadoop这块，Shark有别于Impala，Stringer，而这些系统各有自己的设计思路，相对于对MR进行优化和改进的思路，Shark的思路更加简单明了些</p>\n<p><a href=\"http://shark.cs.berkeley.edu/\" target=\"_blank\" rel=\"noopener\">Shark官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"五、Pig\"><a href=\"#五、Pig\" class=\"headerlink\" title=\"五、Pig\"></a>五、Pig</h3><p>简介：Pig是一种编程语言，它简化了Hadoop常见的工作任务。Pig可加载数据、表达转换数据以及存储最终结果。Pig内置的操作使得半结构化数据变得有意义（如日志文件）。同时Pig可扩展使用Java中添加的自定义数据类型并支持数据转换。</p>\n<p>Pig最大的作用就是对mapreduce算法(框架)实现了一套shell脚本 ，类似我们通常熟悉的SQL语句，在Pig中称之为Pig Latin，在这套脚本中我们可以对加载出来的数据进行排序、过滤、求和、分组(group by)、关联(Joining)，Pig也可以由用户自定义一些函数对数据集进行操作，也就是传说中的UDF(user-defined functions)。</p>\n<p><a href=\"http://pig.apache.org/\" target=\"_blank\" rel=\"noopener\">Pig官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"六、Cloudera-Impala\"><a href=\"#六、Cloudera-Impala\" class=\"headerlink\" title=\"六、Cloudera Impala\"></a>六、Cloudera Impala</h3><p>贡献者：:Cloudera</p>\n<p>简介：Cloudera Impala 可以直接为存储在HDFS或HBase中的Hadoop数据提供快速，交互式的SQL查询。除了使用相同的存储平台外， Impala和Apache Hive一样也使用了相同的元数据，SQL语法（Hive SQL），ODBC驱动和用户接口（Hue Beeswax），这就很方便的为用户提供了一个相似并且统一的平台来进行批量或实时查询。</p>\n<p>Cloudera Impala 是用来进行大数据查询的补充工具。 Impala 并没有取代像Hive这样基于MapReduce的分布式处理框架。Hive和其它基于MapReduce的计算框架非常适合长时间运行的批处理作业，例如那些涉及到批量 Extract、Transform、Load ，即需要进行ETL作业。</p>\n<p>Impala 提供了：</p>\n<p>❶数据科学家或数据分析师已经熟知的SQL接口</p>\n<p>❷能够在Apache Hadoop 的大数据中进行交互式数据查询</p>\n<p>❸ Single system for big data processing and analytics so customers can avoid costly modeling and ETL just for analytics</p>\n<p><a href=\"http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html\" target=\"_blank\" rel=\"noopener\">Cloudera Impala官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"七、Apache-Drill\"><a href=\"#七、Apache-Drill\" class=\"headerlink\" title=\"七、Apache Drill\"></a>七、Apache Drill</h3><p>贡献者：：MapR</p>\n<p>简介：Apache Drill是是一个能够对大数据进行交互分析、开源的分布式系统，且基于Google Dremel实现，它能够运行在上千个节点的服务器集群上，且能在几秒内处理PB级或者万亿条的数据记录。Drill能够帮助企业用户快速、高效地进行Hadoop数据查询和企业级大数据分析。Drill于2012年8月份由Apache推出。</p>\n<p>从Drill官方对其架构的介绍中得知，其具有适于实时的分析和快速的应用开发、适于半结构化/嵌套数据的分析、兼容现有的SQL环境和Apache Hive等特征。另外，Drill的核心模块是Drillbit服务，该服务模块包括远程访问子模块、SQL解析器、查询优化器、任务计划执行引擎、存储插件接口（DFS、HBase、Hive等的接口）、分布式缓存模块等几部分，如下图所示：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/346.jpg\" alt=\"\"></p>\n<p><a href=\"http://incubator.apache.org/drill/\" target=\"_blank\" rel=\"noopener\">Apache Drill官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"八、Apache-Tajo\"><a href=\"#八、Apache-Tajo\" class=\"headerlink\" title=\"八、Apache Tajo\"></a>八、Apache Tajo</h3><p>简介：Apache Tajo项目的目的是在HDFS之上构建一个先进的数据仓库系统。Tajo将自己标榜为一个“大数据仓库”，但是它好像和之前介绍的那些低延迟查询引擎类似。虽然它支持外部表和Hive数据集（通过HCatalog），但是它的重点是数据管理，提供低延迟的数据访问，以及为更传统的ETL提供工具。它也需要在数据节点上部署Tajo特定的工作进程。</p>\n<p>Tajo的功能包括：</p>\n<p>❶ANSI SQL兼容<br>❷JDBC 驱动<br>❸集成Hive metastore能够访问Hive数据集<br>❹一个命令行客户端<br>❺一个自定义函数API</p>\n<p><a href=\"http://tajo.incubator.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Tajo官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"九、Hive\"><a href=\"#九、Hive\" class=\"headerlink\" title=\"九、Hive\"></a>九、Hive</h3><p>简介：hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 其优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，不必开发专门的MapReduce应用，十分适合数据仓库的统计分析。</p>\n<p><a href=\"http://hive.apache.org/\" target=\"_blank\" rel=\"noopener\">Hive官方网站&gt;&gt;&gt;</a></p>\n<h2 id=\"流式计算\"><a href=\"#流式计算\" class=\"headerlink\" title=\"流式计算\"></a>流式计算</h2><h3 id=\"一、Facebook-Puma\"><a href=\"#一、Facebook-Puma\" class=\"headerlink\" title=\"一、Facebook Puma\"></a>一、Facebook Puma</h3><p>贡献者：Facebook</p>\n<p>简介：实时数据流分析</p>\n<h3 id=\"二、Twitter-Rainbird\"><a href=\"#二、Twitter-Rainbird\" class=\"headerlink\" title=\"二、Twitter Rainbird\"></a>二、Twitter Rainbird</h3><p>贡献者：Twitter</p>\n<p>简介：Rainbird一款基于Zookeeper, Cassandra, Scribe, Thrift的分布式实时统计系统，这些基础组件的基本功能如下：</p>\n<p>❶ Zookeeper，Hadoop子项目中的一款分布式协调系统，用于控制分布式系统中各个组件中的一致性。</p>\n<p>❷Cassandra，NoSQL中一款非常出色的产品，集合了Dynamo和Bigtable特性的分布式存储系统，用于存储需要进行统计的数据，统计数据，并且提供客户端进行统计数据的查询。（需要使用分布式Counter补丁CASSANDRA-1072）</p>\n<p>❸ Scribe，Facebook开源的一款分布式日志收集系统，用于在系统中将各个需要统计的数据源收集到Cassandra中。</p>\n<p>❹ Thrift，Facebook开源的一款跨语言C/S网络通信框架，开发人员基于这个框架可以轻易地开发C/S应用。</p>\n<p>用处</p>\n<p>Rainbird可以用于实时数据的统计：</p>\n<p>❶统计网站中每一个页面，域名的点击次数</p>\n<p>❷内部系统的运行监控（统计被监控服务器的运行状态）</p>\n<p>❸记录最大值和最小值</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/280.jpg\" alt=\"\"></p>\n<h3 id=\"三、Yahoo-S4\"><a href=\"#三、Yahoo-S4\" class=\"headerlink\" title=\"三、Yahoo S4\"></a>三、Yahoo S4</h3><p>贡献者：Yahoo</p>\n<p>简介：S4（Simple Scalable Streaming System）最初是Yahoo!为提高搜索广告有效点击率的问题而开发的一个平台，通过统计分析用户对广告的点击率，排除相关度低的广告，提升点击率。目前该项目刚启动不久，所以也可以理解为是他们提出的一个分布式流计算（Distributed Stream Computing）的模型。</p>\n<p>S4的设计目标是：</p>\n<p>·提供一种简单的编程接口来处理数据流</p>\n<p>·设计一个可以在普通硬件之上可扩展的高可用集群。</p>\n<p>·通过在每个处理节点使用本地内存，避免磁盘I/O瓶颈达到最小化延迟</p>\n<p>·使用一个去中心的，对等架构；所有节点提供相同的功能和职责。没有担负特殊责任的中心节点。这大大简化了部署和维护。</p>\n<p>·使用可插拔的架构，使设计尽可能的即通用又可定制化。</p>\n<p>·友好的设计理念，易于编程，具有灵活的弹性</p>\n<p><a href=\"http://incubator.apache.org/s4/\" target=\"_blank\" rel=\"noopener\">Yahoo S4官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"四、Twitter-Storm\"><a href=\"#四、Twitter-Storm\" class=\"headerlink\" title=\"四、Twitter Storm\"></a>四、Twitter Storm</h3><p>贡献者：Twitter</p>\n<p>简介：Storm是Twitter开源的一个类似于Hadoop的实时数据处理框架，它原来是由BackType开发，后BackType被Twitter收购，将Storm作为Twitter的实时数据分析系统。</p>\n<p>实时数据处理的应用场景很广泛，例如商品推荐，广告投放，它能根据当前情景上下文（用户偏好，地理位置，已发生的查询和点击等）来估计用户点击的可能性并实时做出调整。</p>\n<p>storm的三大作用领域：</p>\n<p>1.信息流处理（Stream Processing）</p>\n<p>Storm可以用来实时处理新数据和更新数据库，兼具容错性和可扩展性,它 可以用来处理源源不断的消息，并将处理之后的结果保存到持久化介质中。</p>\n<p>2.连续计算（Continuous Computation）</p>\n<p>Storm可以进行连续查询并把结果即时反馈给客户，比如将Twitter上的热门话题发送到客户端。</p>\n<p>3.分布式远程过程调用（Distributed RPC）</p>\n<p>除此之外，Storm也被广泛用于以下方面：</p>\n<p>精确的广告推送<br>实时日志的处理</p>\n<p><a href=\"http://storm.incubator.apache.org/\" target=\"_blank\" rel=\"noopener\">Twitter Storm官方网站&gt;&gt;&gt;</a></p>\n<p>##迭代计算</p>\n<h3 id=\"一、Apache-Hama\"><a href=\"#一、Apache-Hama\" class=\"headerlink\" title=\"一、Apache Hama\"></a>一、Apache Hama</h3><p>简介：Apache Hama是一个纯BSP（Bulk Synchronous Parallel）计算框架，模仿了Google的Pregel。用来处理大规模的科学计算，特别是矩阵和图计算。</p>\n<p>❶建立在Hadoop上的分布式并行计算模型。</p>\n<p>❷基于 Map/Reduce 和 Bulk Synchronous 的实现框架。</p>\n<p>❸运行环境需要关联 Zookeeper、HBase、HDFS 组件。</p>\n<p>Hama中有2个主要的模型:</p>\n<p>– 矩阵计算(Matrix package)</p>\n<p>– 面向图计算(Graph package)</p>\n<p><a href=\"https://hama.apache.org/\" target=\"_blank\" rel=\"noopener\">Apache Hama官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Apache-Giraph\"><a href=\"#二、Apache-Giraph\" class=\"headerlink\" title=\"二、Apache Giraph\"></a>二、Apache Giraph</h3><p>代码托管地址： <a href=\"https://github.com/apache/giraph\" target=\"_blank\" rel=\"noopener\">GitHub</a></p>\n<p>简介：Apache Giraph是一个可伸缩的分布式迭代图处理系统，灵感来自BSP（bulk synchronous parallel）和Google的Pregel，与它们 区别于则是是开源、基于 Hadoop 的架构等。</p>\n<p>Giraph处理平台适用于运行大规模的逻辑计算，比如页面排行、共享链接、基于个性化排行等。Giraph专注于社交图计算，被Facebook作为其Open Graph工具的核心，几分钟内处理数万亿次用户及其行为之间的连接。</p>\n<h3 id=\"三、HaLoop\"><a href=\"#三、HaLoop\" class=\"headerlink\" title=\"三、HaLoop\"></a>三、HaLoop</h3><p>简介：迭代的MapReduce，HaLoop——适用于迭代计算的Hadoop 。</p>\n<p> <img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/425.jpg\" alt=\"\"></p>\n<pre><code>Hadoop与HaLoop的不同\n</code></pre><p>与Hadoop比较的四点改变：</p>\n<p>1.提供了一套新的编程接口，更加适用于迭代计算；</p>\n<p>HaLoop给迭代计算一个抽象的递归公式：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/403.jpg\" alt=\"\"></p>\n<p>2.HaLoop的master进行job内的循环控制，直到迭代计算结束；</p>\n<p>3.Task Scheduler也进行了修改，使得任务能够尽量满足data locality</p>\n<p>4.slave nodes对数据进行cache并index索引，索引也以文件的形式保存在本地磁盘。</p>\n<p><a href=\"https://code.google.com/p/haloop/\" target=\"_blank\" rel=\"noopener\">HaLoop官网&gt;&gt;&gt;</a></p>\n<h3 id=\"四、Twister\"><a href=\"#四、Twister\" class=\"headerlink\" title=\"四、Twister\"></a>四、Twister</h3><p>简介：Twister， 迭代式MapReduce框架，Twister是由一个印度人开发的，其架构如下：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/524.jpg\" alt=\"\"></p>\n<p>在Twister中，大文件不会自动被切割成一个一个block，因而用户需提前把文件分成一个一个小文件，以供每个task处理。在map阶段，经过map（）处理完的结果被放在分布式内存中，然后通过一个broker network（NaradaBroking系统）将数据push给各个reduce task（Twister假设内存足够大，中间数据可以全部放在内存中）；在reduce阶段，所有reduce task产生的结果通过一个combine操作进行归并，此时，用户可以进行条件判定， 确定迭代是否结束。combine后的数据直接被送给map task，开始新一轮的迭代。为了提高容错性，Twister每隔一段时间会将map task和reduce task产生的结果写到磁盘上，这样，一旦某个task失败，它可以从最近的备份中获取输入，重新计算。</p>\n<p>为了避免每次迭代重新创建task，Twister维护了一个task pool，每次需要task时直接从pool中取。在Twister中，所有消息和数据都是通过broker network传递的，该broker network是一个独立的模块，目前支持NaradaBroking和ActiveMQ。</p>\n<h2 id=\"离线计算\"><a href=\"#离线计算\" class=\"headerlink\" title=\"离线计算\"></a>离线计算</h2><h3 id=\"一、Hadoop-MapReduce\"><a href=\"#一、Hadoop-MapReduce\" class=\"headerlink\" title=\"一、Hadoop MapReduce\"></a>一、Hadoop MapReduce</h3><p>简介：MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。概念”Map（映射）”和”Reduce（归约）”，和它们的主要思想，都是从函数式编程语言里借来的，还有从矢量编程语言里借来的特性。它极大地方便了编程人员在不会分布式并行编程的情况下，将自己的程序运行在分布式系统上。 当前的软件实现是指定一个Map（映射）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组。</p>\n<p><a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">Hadoop MapReduce官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、Berkeley-Spark\"><a href=\"#二、Berkeley-Spark\" class=\"headerlink\" title=\"二、Berkeley Spark\"></a>二、Berkeley Spark</h3><p>简介：Spark是UC Berkeley AMP lab所开源的类Hadoop MapReduce的通用的并行，Spark，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的map reduce的算法。</p>\n<h3 id=\"三、DataTorrent\"><a href=\"#三、DataTorrent\" class=\"headerlink\" title=\"三、DataTorrent\"></a>三、DataTorrent</h3><p>简介：DataTorrent基于Hadoop 2.x构建，是一个实时的、有容错能力的数据流式处理和分析平台，它使用本地Hadoop应用程序，而这些应用程序可以与执行其它任务，如批处理，的应用程序共存。该平台的架构如下图所示：<br><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/621.jpg\" alt=\"\"></p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20163\" target=\"_blank\" rel=\"noopener\">DataTorrent 1.0每秒处理超过10亿个实时事件</a></p>\n<p><a href=\"http://www.36dsj.com/archives/1596\" target=\"_blank\" rel=\"noopener\">DataTorrent 将数据分析速度从“实时”提升至“现在时”</a></p>\n<h2 id=\"键值存储\"><a href=\"#键值存储\" class=\"headerlink\" title=\"键值存储\"></a>键值存储</h2><h3 id=\"一、LevelDB\"><a href=\"#一、LevelDB\" class=\"headerlink\" title=\"一、LevelDB\"></a>一、LevelDB</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/723.jpg\" alt=\"\"></p>\n<p>贡献者：Google</p>\n<p>简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。</p>\n<p>LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>\n<p>此处随机读是完全命中内存的速度，如果是不命中 速度大大下降。</p>\n<p><a href=\"https://code.google.com/p/leveldb/\" target=\"_blank\" rel=\"noopener\">LevelDB官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"二、RocksDB\"><a href=\"#二、RocksDB\" class=\"headerlink\" title=\"二、RocksDB\"></a>二、RocksDB</h3><p>贡献者：facebook</p>\n<p>简介：RocksDB虽然在代码层面上是在LevelDB原有的代码上进行开发的，但却借鉴了Apache HBase的一些好的idea。在云计算横行的年代，开口不离Hadoop，RocksDB也开始支持HDFS，允许从HDFS读取数据。RocksDB支持一次获取多个K-V，还支持Key范围查找。LevelDB只能获取单个Key。</p>\n<p>RocksDB除了简单的Put、Delete操作，还提供了一个Merge操作，说是为了对多个Put操作进行合并。</p>\n<p>RocksDB提供一些方便的工具，这些工具包含解析sst文件中的K-V记录、解析MANIFEST文件的内容等。RocksDB支持多线程合并，而LevelDB是单线程合并的。</p>\n<p><a href=\"http://rocksdb.org/\" target=\"_blank\" rel=\"noopener\">RocksDB官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"三、HyperDex\"><a href=\"#三、HyperDex\" class=\"headerlink\" title=\"三、HyperDex\"></a>三、HyperDex</h3><p>贡献者：Facebook</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/821.jpg\" alt=\"\"></p>\n<p>HyperDex是一个分布式、可搜索的键值存储系统，特性如下：</p>\n<p>分布式KV存储，系统性能能够随节点数目线性扩展<br>吞吐和延时都能秒杀现在风头正劲的MonogDB，吞吐甚至强于Redis<br>使用了hyperspace hashing技术，使得对存储的K-V的任意属性进行查询成为可能</p>\n<p>官网：<a href=\"http://hyperdex.org/\" target=\"_blank\" rel=\"noopener\">http://hyperdex.org/</a></p>\n<h3 id=\"四、TokyoCabinet\"><a href=\"#四、TokyoCabinet\" class=\"headerlink\" title=\"四、TokyoCabinet\"></a>四、TokyoCabinet</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/104.png\" alt=\"\"></p>\n<p>日本人Mikio Hirabayashi（平林干雄）开发的一款DBM数据库。Tokyo Cabinet 是一个DBM的实现。这里的数据库由一系列key-value对的记录构成。key和value都可以是任意长度的字节序列,既可以是二进制也可以是字符串。这里没有数据类型和数据表的概念。<br>当 做为Hash表数据库使用时，每个key必须是不同的,因此无法存储两个key相同的值。提供了以下访问方法:提供key,value参数来存储，按 key删除记录，按key来读取记录，另外，遍历key也被支持，虽然顺序是任意的不能被保证。这些方法跟Unix标准的DBM,例如GDBM,NDBM 等等是相同的，但是比它们的性能要好得多（因此可以替代它们) 。下一代KV存储系统，支持strings、integers、floats、lists、maps和sets等丰富的数据类型。</p>\n<p><a href=\"http://fallabs.com/tokyocabinet/\" target=\"_blank\" rel=\"noopener\">TokyoCabinet官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"五、Voldemort\"><a href=\"#五、Voldemort\" class=\"headerlink\" title=\"五、Voldemort\"></a>五、Voldemort</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1127.jpg\" alt=\"\"></p>\n<p>Voldemort是一个分布式键值存储系统，是Amazon’s Dynamo的一个开源克隆。特性如下：<br>支持自动复制数据到多个服务器上。<br>支持数据自动分割所以每个服务器只包含总数据的一个子集。<br>提供服务器故障透明处理功能。<br>支持可拨插的序化支持，以实现复杂的键-值存储，它能够很好的5.集成常用的序化框架如：Protocol Buffers、Thrift、Avro和Java Serialization。<br>数据项都被标识版本能够在发生故障时尽量保持数据的完整性而不会影响系统的可用性。<br>每个节点相互独立，互不影响。<br>支持可插拔的数据放置策略<br>官网：<a href=\"http://project-voldemort.com/\" target=\"_blank\" rel=\"noopener\">http://project-voldemort.com/</a></p>\n<h3 id=\"六、Amazon-Dynamo\"><a href=\"#六、Amazon-Dynamo\" class=\"headerlink\" title=\"六、Amazon Dynamo\"></a>六、Amazon Dynamo</h3><p>贡献者：亚马逊</p>\n<p>简介：Amazon Dynamo 是一个经典的分布式Key-Value 存储系统，具备去中心化，高可用性，高扩展性的特点，但是为了达到这个目标在很多场景中牺牲了一致性。Dynamo在Amazon中得到了成功的应用，能够跨数据中心部署于上万个结点上提供服务，它的设计思想也被后续的许多分布式系统借鉴。如近来火热的Cassandra，实际上就是基本照搬了Dynamo的P2P架构，同时融合了BigTable的数据模型及存储算法。</p>\n<p><a href=\"https://github.com/dynamo/dynamo\" target=\"_blank\" rel=\"noopener\">Amazon Dynamo官方网站&gt;&gt;&gt;</a></p>\n<h3 id=\"七、Tair\"><a href=\"#七、Tair\" class=\"headerlink\" title=\"七、Tair\"></a>七、Tair</h3><p>贡献者：淘宝</p>\n<p>简介：tair 是淘宝自己开发的一个分布式 key/value 存储引擎. tair 分为持久化和非持久化两种使用方式. 非持久化的 tair 可以看成是一个分布式缓存. 持久化的 tair 将数据存放于磁盘中. 为了解决磁盘损坏导致数据丢失, tair 可以配置数据的备份数目, tair 自动将一份数据的不同备份放到不同的主机上, 当有主机发生异常, 无法正常提供服务的时候, 其于的备份会继续提供服务.tair 的总体结构</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1220.jpg\" alt=\"\"></p>\n<p>Tairtair 作为一个分布式系统, 是由一个中心控制节点和一系列的服务节点组成. 我们称中心控制节点为config server. 服务节点是data server. config server 负责管理所有的data server, 维护data server的状态信息. data server 对外提供各种数据服务, 并以心跳的形式将自身状况汇报给config server. config server是控制点, 而且是单点, 目前采用一主一备的形式来保证其可靠性. 所有的 data server 地位都是等价的.</p>\n<h3 id=\"八、Apache-Accumulo\"><a href=\"#八、Apache-Accumulo\" class=\"headerlink\" title=\"八、Apache Accumulo\"></a>八、Apache Accumulo</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/8c2532b6-0c16-3879-9600-2a263d923934.png\" alt=\"\"></p>\n<p>Apache Accumulo 是一个可靠的、可伸缩的、高性能的排序分布式的 Key-Value 存储解决方案，基于单元访问控制以及可定制的服务器端处理。Accumulo使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。</p>\n<p>官网：<a href=\"http://accumulo.apache.org/\" target=\"_blank\" rel=\"noopener\">http://accumulo.apache.org/</a></p>\n<h3 id=\"九、Redis\"><a href=\"#九、Redis\" class=\"headerlink\" title=\"九、Redis\"></a>九、Redis</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1320.jpg\" alt=\"\"></p>\n<p>Redis是一个高性能的key-value存储系统，和Memcached类似，它支持存储的value类型相对更多，包括string（字符串）、list（链表）、set（集合）和zset（有序集合）。与memcached一样，为了保证效率，数据都是缓存在内存中，区别的是Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了主从同步。</p>\n<p>Redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部分场合可以对关系数据库起到很好的补充作用。它提供了Python、Ruby、Erlang、PHP客户端，使用很方便。</p>\n<p>官网：<a href=\"http://redis.io/\" target=\"_blank\" rel=\"noopener\">http://redis.io/</a></p>\n<h2 id=\"表格存储\"><a href=\"#表格存储\" class=\"headerlink\" title=\"表格存储\"></a>表格存储</h2><h3 id=\"一、OceanBase\"><a href=\"#一、OceanBase\" class=\"headerlink\" title=\"一、OceanBase\"></a>一、OceanBase</h3><p>贡献者：阿里巴巴</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20317\" target=\"_blank\" rel=\"noopener\">26页PPT解密支撑支付宝交易的分布式数据库系统——OceanBase</a></p>\n<p>简介：OceanBase是一个支持海量数据的高性能分布式数据库系统，实现了数千亿条记录、数百TB数据上的跨行跨表事务，由淘宝核心系统研发部、运维、DBA、广告、应用研发等部门共同完成。在设计和实现OceanBase的时候暂时摒弃了不紧急的DBMS的功能，例如临时表，视图(view)，研发团队把有限的资源集中到关键点上，当前 OceanBase主要解决数据更新一致性、高性能的跨表读事务、范围查询、join、数据全量及增量dump、批量数据导入。</p>\n<p>目前OceanBase已经应用于淘宝收藏夹，用于存储淘宝用户收藏条目和具体的商品、店铺信息，每天支持4～5千万的更新操作。等待上线的应用还包括CTU、SNS等，每天更新超过20亿，更新数据量超过2.5TB，并会逐步在淘宝内部推广。</p>\n<p>OceanBase 0.3.1在Github开源，开源版本为Revision:12336。</p>\n<p>官网：<a href=\"http://alibaba.github.io/oceanbase/\" target=\"_blank\" rel=\"noopener\">http://alibaba.github.io/oceanbase/</a></p>\n<h3 id=\"二、Amazon-SimpleDB\"><a href=\"#二、Amazon-SimpleDB\" class=\"headerlink\" title=\"二、Amazon SimpleDB\"></a>二、Amazon SimpleDB</h3><p>贡献者：亚马逊</p>\n<p>Amazon SimpleDB是一个分散式数据库，以Erlang撰写。同与Amazon EC2和亚马逊的S3一样作为一项Web 服务，属于亚马逊网络服务的一部分。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1106.jpg\" alt=\"\"></p>\n<p>正如EC2和S3，SimpleDB的按照存储量，在互联网上的传输量和吞吐量收取费用。 在2008年12月1日，亚马逊推出了新的定价策略，提供了免费1 GB的数据和25机器小时的自由层(Free Tire)。 将其中的数据转移到其他亚马逊网络服务是免费的。</p>\n<p>它是一个可大规模伸缩、用 Erlang 编写的高可用数据存储。</p>\n<p>官网：<a href=\"http://aws.amazon.com/cn/simpledb/\" target=\"_blank\" rel=\"noopener\">http://aws.amazon.com/cn/simpledb/</a></p>\n<h3 id=\"三、Vertica\"><a href=\"#三、Vertica\" class=\"headerlink\" title=\"三、Vertica\"></a>三、Vertica</h3><p>贡献者：惠普</p>\n<p>简介：惠普2011年2月份起始3月21号完成收购Vertica。Vertica基于列存储。基于列存储的设计相比传统面向行存储的数据库具有巨大的优势。同时Vertica支持MPP（massively parallel processing）等技术，查询数据时Vertica只需取得需要的列，而不是被选择行的所有数据，其平均性能可提高50x-1000x倍。（查询性能高速度快）</p>\n<p>Vertica的设计者多次表示他们的产品围绕着高性能和高可用性设计。由于对MPP技术的支持，可提供对粒度，可伸缩性和可用性的优势。每个节点完全独立运作，完全无共享架构，降低对共享资源的系统竞争。</p>\n<p>Vertica的数据库使用标准的SQL查询，同时Vertica的架构非常适合云计算，包括虚拟化，分布式多节点运行等，并且可以和Hadoop/MapReduce进行集成。</p>\n<p>Vertica官网：<a href=\"http://www.vertica.com/\" target=\"_blank\" rel=\"noopener\">http://www.vertica.com/</a></p>\n<h3 id=\"四、Cassandra\"><a href=\"#四、Cassandra\" class=\"headerlink\" title=\"四、Cassandra\"></a>四、Cassandra</h3><p>贡献者：facebook</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/20079\" target=\"_blank\" rel=\"noopener\">开源分布式NoSQL数据库系统——Cassandra</a>   <a href=\"http://www.36dsj.com/archives/7179\" target=\"_blank\" rel=\"noopener\">Cassandra与HBase的大数据对决 谁是胜者？</a></p>\n<p>简介：Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩放性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/290.jpg\" alt=\"\"></p>\n<p>Cassandra是一个混合型的非关系的数据库，类似于Google的BigTable。其主要功能比Dynamo （分布式的Key-Value存储系统）更丰富，但支持度却不如文档存储MongoDB（介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的。支持的数据结构非常松散，是类似json的bjson格式，因此可以存储比较复杂的数据类型）。Cassandra最初由Facebook开发，后转变成了开源项目。它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族（Column Family）的数据模型。P2P去中心化的存储。很多方面都可以称之为Dynamo 2.0。</p>\n<p>Cassandra官网：<a href=\"http://cassandra.apache.org/\" target=\"_blank\" rel=\"noopener\">http://cassandra.apache.org/</a></p>\n<h3 id=\"五、HyperTable\"><a href=\"#五、HyperTable\" class=\"headerlink\" title=\"五、HyperTable\"></a>五、HyperTable</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/347.jpg\" alt=\"\"></p>\n<p>简介：Hypertable是一个开源、高性能、可伸缩的数据库，它采用与Google的Bigtable相似的模型。在过去数年中，Google为在PC集群 上运行的可伸缩计算基础设施设计建造了三个关键部分。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/426.jpg\" alt=\"\"></p>\n<p>第一个关键的基础设施是Google File System（GFS），这是一个高可用的文件系统，提供了一个全局的命名空间。它通过跨机器（和跨机架）的文件数据复制来达到高可用性，并因此免受传统 文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等失败。第二个基础设施是名为Map-Reduce的计算框架，它与GFS紧密协作，帮 助处理收集到的海量数据。第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让你可以通过一些主键来组织海量数据，并实现高效的 查询。Hypertable是Bigtable的一个开源实现，并且根据我们的想法进行了一些改进。</p>\n<p>HyperTable官网：<a href=\"http://hypertable.org/\" target=\"_blank\" rel=\"noopener\">http://hypertable.org/</a></p>\n<h3 id=\"六、FoundationDB\"><a href=\"#六、FoundationDB\" class=\"headerlink\" title=\"六、FoundationDB\"></a>六、FoundationDB</h3><p>简介：支持ACID事务处理的NoSQL数据库，提供非常好的性能、数据一致性和操作弹性。</p>\n<p>2015年1月2日，FoundationDB已经发布了其key-value数据库的3.0版本，主要专注于可伸缩性和性能上的改善。FoundationDB的CEO David Rosenthal在一篇博客上宣布了新的版本，其中展示了FoundationDB 3.0在可伸缩性方面的数据，它可以在一个32位的c3.8xlarge EC2实例上每秒写入1440万次；这在性能上是之前版本的36倍。</p>\n<p>除了性能和可伸缩性的改善之外，FoundationDB 3.0还包含了对监控支持的改善。这种监控机制不仅仅是简单的机器检查，它添加了对多种潜在的硬件瓶颈的诊断，并且把那些高层级的信息整合到现有监控基础架构中。</p>\n<p>官网：<a href=\"https://foundationdb.com/\" target=\"_blank\" rel=\"noopener\">https://foundationdb.com/</a></p>\n<h3 id=\"七：HBase\"><a href=\"#七：HBase\" class=\"headerlink\" title=\"七：HBase\"></a>七：HBase</h3><p>贡献者： Fay Chang 所撰写的“Bigtable</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/526.jpg\" alt=\"\"></p>\n<p>简介：HBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。HBase不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。另一个不同的是HBase基于列的而不是基于行的模式。</p>\n<p>官网：<a href=\"http://hbase.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hbase.apache.org/</a></p>\n<h2 id=\"文件存储\"><a href=\"#文件存储\" class=\"headerlink\" title=\"文件存储\"></a>文件存储</h2><h3 id=\"一、CouchDB\"><a href=\"#一、CouchDB\" class=\"headerlink\" title=\"一、CouchDB\"></a>一、CouchDB</h3><p>简介：CouchDB是用Erlang开发的面向文档的数据库系统，最近刚刚发布了1.0版本（2010年7月14日）。CouchDB不是一个传统的关系数据库，而是面向文档的数据库，其数据存储方式有点类似lucene的index文件格式，CouchDB最大的意义在于它是一个面向web应用的新一代存储系统，事实上，CouchDB的口号就是：下一代的Web应用存储系统。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/623.jpg\" alt=\"\"></p>\n<p>特点：</p>\n<p>一、CouchDB是分布式的数据库，他可以把存储系统分布到n台物理的节点上面，并且很好的协调和同步节点之间的数据读写一致性。这当然也得靠Erlang无与伦比的并发特性才能做到。对于基于web的大规模应用文档应用，分布式可以让它不必像传统的关系数据库那样分库拆表，在应用代码层进行大量的改动。</p>\n<p>二、CouchDB是面向文档的数据库，存储半结构化的数据，比较类似lucene的index结构，特别适合存储文档，因此很适合CMS，电话本，地址本等应用，在这些应用场合，文档数据库要比关系数据库更加方便，性能更好。</p>\n<p>三、CouchDB支持REST API，可以让用户使用JavaScript来操作CouchDB数据库，也可以用JavaScript编写查询语句，我们可以想像一下，用AJAX技术结合CouchDB开发出来的CMS系统会是多么的简单和方便。</p>\n<p>其实CouchDB只是Erlang应用的冰山一角，在最近几年，基于Erlang的应用也得到的蓬勃的发展，特别是在基于web的大规模，分布式应用领域，几乎都是Erlang的优势项目。</p>\n<p>官网：<a href=\"http://couchdb.apache.org/\" target=\"_blank\" rel=\"noopener\">http://couchdb.apache.org/</a></p>\n<h3 id=\"二、MongoDB\"><a href=\"#二、MongoDB\" class=\"headerlink\" title=\"二、MongoDB\"></a>二、MongoDB</h3><p>简介：MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。</p>\n<p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>\n<p>相关文章：<a href=\"http://www.36dsj.com/archives/22965\" target=\"_blank\" rel=\"noopener\">MongoDB的基本特性与内部构造</a>  <a href=\"http://www.36dsj.com/archives/21104\" target=\"_blank\" rel=\"noopener\">大数据吃香 创业公司MongoDB估值达16亿美元</a></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/01/2710.jpg\" alt=\"\"></p>\n<p>特点</p>\n<p>它的特点是高性能、易部署、易使用，存储数据非常方便。主要功能特性有：</p>\n<p>*面向集合存储，易存储对象类型的数据。</p>\n<p>mongodb集群参考</p>\n<p>mongodb集群参考</p>\n<p>*模式自由。</p>\n<p>*支持动态查询。</p>\n<p>*支持完全索引，包含内部对象。</p>\n<p>*支持查询。</p>\n<p>*支持复制和故障恢复。</p>\n<p>*使用高效的二进制数据存储，包括大型对象（如视频等）。</p>\n<p>*自动处理碎片，以支持云计算层次的扩展性。</p>\n<p>*支持RUBY，PYTHON，JAVA，C++，PHP，C#等多种语言。</p>\n<p>*文件存储格式为BSON（一种JSON的扩展）。</p>\n<p>*可通过网络访问。</p>\n<p>官网：<a href=\"https://www.mongodb.org/\" target=\"_blank\" rel=\"noopener\">https://www.mongodb.org/</a></p>\n<h3 id=\"三、Tachyon\"><a href=\"#三、Tachyon\" class=\"headerlink\" title=\"三、Tachyon\"></a>三、Tachyon</h3><p>贡献者：Haoyuan Li（李浩源）</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/725-220x150.jpg\" alt=\"\"></p>\n<p>简介：Tachyon是一个分布式内存文件系统，可以在集群里以访问内存的速度来访问存在tachyon里的文件。把Tachyon是架构在最底层的分布式文件存储和上层的各种计算框架之间的一种中间件。主要职责是将那些不需要落地到DFS里的文件，落地到分布式内存文件系统中，来达到共享内存，从而提高效率。同时可以减少内存冗余，GC时间等。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/823.jpg\" alt=\"\"></p>\n<p><strong>Tachyon架构</strong></p>\n<p>Tachyon的架构是传统的Master—slave架构，这里和Hadoop类似，TachyonMaster里WorkflowManager是 Master进程，因为是为了防止单点问题，通过Zookeeper做了HA，可以部署多台Standby Master。Slave是由Worker Daemon和Ramdisk构成。这里个人理解只有Worker Daemon是基于JVM的，Ramdisk是一个off heap memory。Master和Worker直接的通讯协议是Thrift。</p>\n<p>下图来自Tachyon的作者Haoyuan Li：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/920.jpg\" alt=\"\"></p>\n<p>下载地址：<a href=\"https://github.com/amplab/tachyon\" target=\"_blank\" rel=\"noopener\">https://github.com/amplab/tachyon</a></p>\n<h3 id=\"四、KFS\"><a href=\"#四、KFS\" class=\"headerlink\" title=\"四、KFS\"></a>四、KFS</h3><p>简介：GFS的C++开源版本，Kosmos distributed file system (KFS)是一个专门为数据密集型应用（搜索引擎，数据挖掘等）而设计的存储系统，类似于Google的GFS和Hadoop的HDFS分布式文件系统。 KFS使用C++实现，支持的客户端包括C++，Java和Python。KFS系统由三部分组成，分别是metaserver、chunkserver和client library。</p>\n<p>官网：<a href=\"http://code.google.com/p/kosmosfs/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/kosmosfs/</a></p>\n<h3 id=\"五、HDFS\"><a href=\"#五、HDFS\" class=\"headerlink\" title=\"五、HDFS\"></a>五、HDFS</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1022.jpg\" alt=\"\"></p>\n<p>简介：Hadoop分布式文件系统(HDFS)被设计成适合运行在通用硬件(commodity hardware)上的分布式文件系统。它和现有的分布式文件系统有很多共同点。但同时，它和其他的分布式文件系统的区别也是很明显的。HDFS是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，非常适合大规模数据集上的应用。HDFS放宽了一部分POSIX约束，来实现流式读取文件系统数据的目的。HDFS在最开始是作为Apache Nutch搜索引擎项目的基础架构而开发的。HDFS是Apache Hadoop Core项目的一部分。</p>\n<p>官网：<a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hadoop.apache.org/</a></p>\n<h2 id=\"资源管理\"><a href=\"#资源管理\" class=\"headerlink\" title=\"资源管理\"></a>资源管理</h2><h3 id=\"一、Twitter-Mesos\"><a href=\"#一、Twitter-Mesos\" class=\"headerlink\" title=\"一、Twitter Mesos\"></a>一、Twitter Mesos</h3><p>开发者：Twitter研发人员John Oskasson</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1129.jpg\" alt=\"\"></p>\n<p>简介：Apache Mesos是由加州大学伯克利分校的AMPLab首先开发的一款开源群集管理软件，支持Hadoop、ElasticSearch、Spark、Storm 和Kafka等架构，由于其开源性质越来越受到一些大型云计算公司的青睐，例如Twitter、Facebook等。</p>\n<p>参考文章：<a href=\"http://www.csdn.net/article/2014-02-24/2818520-Cloud-Mesosphere-Mesos-Hadoop-Spark\" target=\"_blank\" rel=\"noopener\">Mesos渐入主流,Twitter模式有望 “无限复制”-CSDN.NET</a></p>\n<p>官网：<a href=\"http://mesos.apache.org/\" target=\"_blank\" rel=\"noopener\">http://mesos.apache.org/</a></p>\n<h3 id=\"二、Hadoop-Yarn\"><a href=\"#二、Hadoop-Yarn\" class=\"headerlink\" title=\"二、Hadoop Yarn\"></a>二、Hadoop Yarn</h3><p>Hadoop 新 MapReduce 框架 Yarn。为从根本上解决旧 MapReduce 框架的性能瓶颈，促进 Hadoop 框架的更长远发展，从 0.23.0 版本开始，Hadoop 的 MapReduce 框架完全重构，发生了根本的变化。新的 Hadoop MapReduce 框架命名为 MapReduceV2 或者叫 Yarn，其架构图如下图所示：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1222.jpg\" alt=\"\"></p>\n<p>Yarn 框架相对于老的 MapReduce 框架什么优势呢？我们可以看到：</p>\n<p>1、这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。</p>\n<p>2、在新的 Yarn 中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 AppMst，让更多类型的编程模型能够跑在 Hadoop 集群中，可以参考 hadoop Yarn 官方配置模板中的 mapred-site.xml 配置。</p>\n<p>3、对于资源的表示以内存为单位 ( 在目前版本的 Yarn 中，没有考虑 cpu 的占用 )，比之前以剩余 slot 数目更合理。</p>\n<p>4、老的框架中，JobTracker 一个很大的负担就是监控 job 下的 tasks 的运行状况，现在，这个部分就扔给 ApplicationMaster 做了，而 ResourceManager 中有一个模块叫做 ApplicationsMasters( 注意不是 ApplicationMaster)，它是监测 ApplicationMaster 的行状况，如果出问题，会将其在其他机器上重启。</p>\n<p>5、Container 是 Yarn 为了将来作资源隔离而提出的一个框架。这一点应该借鉴了 Mesos 的工作，目前是一个框架，仅仅提供 java 虚拟机内存的隔离 ,hadoop 团队的设计思路应该后续能支持更多的资源调度和控制 , 既然资源表示成内存量，那就没有了之前的 map slot/reduce slot 分开造成集群资源闲置的尴尬情况。</p>\n<p>官网：<a href=\"http://hadoop.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hadoop.apache.org/</a></p>\n<h2 id=\"日志收集系统\"><a href=\"#日志收集系统\" class=\"headerlink\" title=\"日志收集系统\"></a>日志收集系统</h2><h3 id=\"一、Facebook-Scribe\"><a href=\"#一、Facebook-Scribe\" class=\"headerlink\" title=\"一、Facebook Scribe\"></a>一、Facebook Scribe</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1107.jpg\" alt=\"\"></p>\n<p>贡献者：Facebook</p>\n<p>简介：Scribe是Facebook开源的日志收集系统，在Facebook内部已经得到大量的应用。它能够从各种日志源上收集日志，存储到一个中央存储系统（可以是NFS，分布式文件系统等）上，以便于进行集中统计分析处理。它为日志的“分布式收集，统一处理”提供了一个可扩展的，高容错的方案。当中央存储系统的网络或者机器出现故障时，scribe会将日志转存到本地或者另一个位置，当中央存储系统恢复后，scribe会将转存的日志重新传输给中央存储系统。其通常与Hadoop结合使用，scribe用于向HDFS中push日志，而Hadoop通过MapReduce作业进行定期处理。</p>\n<p>Scribe的系统架构</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/298-600x234.jpg\" alt=\"\"></p>\n<p>代码托管：<a href=\"https://github.com/facebook/scribe\" target=\"_blank\" rel=\"noopener\">https://github.com/facebook/scribe</a></p>\n<h3 id=\"二、Cloudera-Flume\"><a href=\"#二、Cloudera-Flume\" class=\"headerlink\" title=\"二、Cloudera Flume\"></a>二、Cloudera Flume</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/348.jpg\" alt=\"\"></p>\n<p>贡献者：<a href=\"http://www.36dsj.com/archives/tag/cloudera\" target=\"_blank\" rel=\"noopener\">Cloudera</a></p>\n<p>简介：Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据；同时，Flume提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。</p>\n<p>Flume提供了从console（控制台）、RPC（Thrift-RPC）、text（文件）、tail（UNIX tail）、syslog（syslog日志系统，支持TCP和UDP等2种模式），exec（命令执行）等数据源上收集数据的能力。</p>\n<p>当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng。由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。</p>\n<p><strong>Cloudera Flume构架：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/427-414x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://flume.apache.org/\" target=\"_blank\" rel=\"noopener\">http://flume.apache.org/</a></p>\n<h3 id=\"三、logstash\"><a href=\"#三、logstash\" class=\"headerlink\" title=\"三、logstash\"></a>三、logstash</h3><p>简介：logstash 是一个应用程序日志、事件的传输、处理、管理和搜索的平台。你可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/527-600x265.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://www.logstash.net/\" target=\"_blank\" rel=\"noopener\">http://www.logstash.net/</a></p>\n<h3 id=\"四、kibana\"><a href=\"#四、kibana\" class=\"headerlink\" title=\"四、kibana\"></a>四、kibana</h3><p>简介：Kibana 是一个为 Logstash 和 ElasticSearch 提供的日志分析的 Web 接口。可使用它对日志进行高效的搜索、可视化、分析等各种操作。kibana 也是一个开源和免费的工具，他可以帮助您汇总、分析和搜索重要数据日志并提供友好的web界面。他可以为 Logstash 和 ElasticSearch 提供的日志分析的 Web 界面。</p>\n<p>主页： <a href=\"http://kibana.org/\" target=\"_blank\" rel=\"noopener\">http://kibana.org/</a></p>\n<p>代码托管： <a href=\"https://github.com/rashidkpc/Kibana/downloads\" target=\"_blank\" rel=\"noopener\">https://github.com/rashidkpc/Kibana/downloads</a></p>\n<h2 id=\"消息系统\"><a href=\"#消息系统\" class=\"headerlink\" title=\"消息系统\"></a>消息系统</h2><h3 id=\"一、StormMQ\"><a href=\"#一、StormMQ\" class=\"headerlink\" title=\"一、StormMQ\"></a>一、StormMQ</h3><p>简介：MQMessageQueue消息队列产品 StormMQ，是一种服务程序。</p>\n<p>官网：<a href=\"http://stormmq.com/\" target=\"_blank\" rel=\"noopener\">http://stormmq.com/</a></p>\n<h3 id=\"二、ZeroMQ\"><a href=\"#二、ZeroMQ\" class=\"headerlink\" title=\"二、ZeroMQ\"></a>二、ZeroMQ</h3><p>简介：这是个类似于Socket的一系列接口，他跟Socket的区别是：普通的socket是端到端的（1:1的关系），而ZMQ却是可以N：M 的关系，人们对BSD套接字的了解较多的是点对点的连接，点对点连接需要显式地建立连接、销毁连接、选择协议（TCP/UDP）和处理错误等，而ZMQ屏蔽了这些细节，让你的网络编程更为简单。ZMQ用于node与node间的通信，node可以是主机或者是进程。</p>\n<p>引用官方的说法： “ZMQ(以下ZeroMQ简称ZMQ)是一个简单好用的传输层，像框架一样的一个socket library，他使得Socket编程更加简单、简洁和性能更高。是一个消息处理队列库，可在多个线程、内核和主机盒之间弹性伸缩。ZMQ的明确目标是“成为标准网络协议栈的一部分，之后进入Linux内核”。现在还未看到它们的成功。但是，它无疑是极具前景的、并且是人们更加需要的“传统”BSD套接字之上的一 层封装。ZMQ让编写高性能网络应用程序极为简单和有趣。”</p>\n<p>官网：<a href=\"http://zeromq.org/\" target=\"_blank\" rel=\"noopener\">http://zeromq.org/</a></p>\n<h3 id=\"三、RabbitMQ\"><a href=\"#三、RabbitMQ\" class=\"headerlink\" title=\"三、RabbitMQ\"></a>三、RabbitMQ</h3><p>简介：RabbitMQ是一个受欢迎的消息代理，通常用于应用程序之间或者程序的不同组件之间通过消息来进行集成。本文简单介绍了如何使用 RabbitMQ，假定你已经配置好了rabbitmq服务器。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/624.jpg\" alt=\"\"></p>\n<p>RabbitMQ是用Erlang，对于主要的编程语言都有驱动或者客户端。我们这里要用的是Java，所以先要获得Java客户端。</p>\n<p>像RabbitMQ这样的消息代理可用来模拟不同的场景，例如点对点的消息分发或者订阅/推送。我们的程序足够简单，有两个基本的组件，一个生产者用于产生消息，还有一个消费者用来使用产生的消息。</p>\n<p>官网：<a href=\"https://www.rabbitmq.com/\" target=\"_blank\" rel=\"noopener\">https://www.rabbitmq.com/</a></p>\n<h3 id=\"四、Apache-ActiveMQ\"><a href=\"#四、Apache-ActiveMQ\" class=\"headerlink\" title=\"四、Apache ActiveMQ\"></a>四、Apache ActiveMQ</h3><p>简介：ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现，尽管JMS规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/726.jpg\" alt=\"\"></p>\n<p>特性：</p>\n<p>⒈ 多种语言和协议编写客户端。语言: Java,C,C++,C#,Ruby,Perl,Python,PHP。应用协议： OpenWire,Stomp REST,WS Notification,XMPP,AMQP</p>\n<p>⒉ 完全支持JMS1.1和J2EE 1.4规范 （持久化，XA消息，事务)</p>\n<p>⒊ 对Spring的支持，ActiveMQ可以很容易内嵌到使用Spring的系统里面去，而且也支持Spring2.0的特性</p>\n<p>⒋ 通过了常见J2EE服务器（如 Geronimo,JBoss 4,GlassFish,WebLogic)的测试，其中通过JCA 1.5 resource adaptors的配置，可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上</p>\n<p>⒌ 支持多种传送协议：in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA</p>\n<p>⒍ 支持通过JDBC和journal提供高速的消息持久化</p>\n<p>⒎ 从设计上保证了高性能的集群，客户端-服务器，点对点</p>\n<p>⒏ 支持Ajax</p>\n<p>⒐ 支持与Axis的整合</p>\n<p>⒑ 可以很容易得调用内嵌JMS provider，进行测试</p>\n<p>官网：<a href=\"http://activemq.apache.org/\" target=\"_blank\" rel=\"noopener\">http://activemq.apache.org/</a></p>\n<h3 id=\"五、Jafka\"><a href=\"#五、Jafka\" class=\"headerlink\" title=\"五、Jafka\"></a>五、Jafka</h3><p>贡献者：LinkedIn</p>\n<p>简介：Jafka 是一个开源的、高性能的、跨语言分布式消息系统，使用GitHub托管。Jafka 最早是由Apache孵化的Kafka（由LinkedIn捐助给Apache）克隆而来。由于是一个开放式的数据传输协议，因此除了Java开发语言受到支持，Python、Ruby、C、C++等其他语言也能够很好的得到支持。</p>\n<p>特性：</p>\n<p>1、消息持久化非常快，服务端存储消息的开销为O(1)，并且基于文件系统，能够持久化TB级的消息而不损失性能。</p>\n<p>2、吞吐量取决于网络带宽。</p>\n<p>3、完全的分布式系统，broker、producer、consumer都原生自动支持分布式。自动实现复杂均衡。</p>\n<p>4、内核非常小，整个系统（包括服务端和客户端）只有一个272KB的jar包，内部机制也不复杂，适合进行内嵌或者二次开发 。整个服务端加上依赖组件共3.5MB。</p>\n<p>5、消息格式以及通信机制非常简单，适合进行跨语言开发。目前自带的Python3.x的客户端支持发送消息和接收消息。</p>\n<p>官网：<a href=\"http://kafka.apache.org/\" target=\"_blank\" rel=\"noopener\">http://kafka.apache.org/</a></p>\n<h3 id=\"六、Apache-Kafka\"><a href=\"#六、Apache-Kafka\" class=\"headerlink\" title=\"六、Apache Kafka\"></a>六、Apache Kafka</h3><p>贡献者：LinkedIn</p>\n<p>简介：Apache Kafka是由Apache软件基金会开发的一个开源消息系统项目，由Scala写成。Kafka最初是由LinkedIn开发，并于2011年初开源。2012年10月从Apache Incubator毕业。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。</p>\n<p>Kafka是一个分布式的、分区的、多复本的日志提交服务。它通过一种独一无二的设计提供了一个消息系统的功能。</p>\n<p>Kafka集群可以在一个指定的时间内保持所有发布上来的消息，不管这些消息有没有被消费。打个比方，如果这个时间设置为两天，那么在消息发布的两天以内，这条消息都是可以被消费的，但是在两天后，这条消息就会被系统丢弃以释放空间。Kafka的性能不会受数据量的大小影响，因此保持大量的数据不是一个问题。</p>\n<p>官网：<a href=\"http://kafka.apache.org/\" target=\"_blank\" rel=\"noopener\">http://kafka.apache.org/</a></p>\n<h2 id=\"分布式服务\"><a href=\"#分布式服务\" class=\"headerlink\" title=\"分布式服务\"></a>分布式服务</h2><h3 id=\"一、ZooKeeper\"><a href=\"#一、ZooKeeper\" class=\"headerlink\" title=\"一、ZooKeeper\"></a>一、ZooKeeper</h3><p>贡献者：Google</p>\n<p>简介：ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。</p>\n<p>ZooKeeper是以Fast Paxos算法为基础的，paxos算法存在活锁的问题，即当有多个proposer交错提交时，有可能互相排斥导致没有一个proposer能提交成功，而Fast Paxos作了一些优化，通过选举产生一个leader，只有leader才能提交propose，具体算法可见Fast Paxos。因此，要想弄懂ZooKeeper首先得对Fast Paxos有所了解。</p>\n<p>架构：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/824-600x244.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://zookeeper.apache.org/\" target=\"_blank\" rel=\"noopener\">http://zookeeper.apache.org/</a></p>\n<h2 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h2><p>（Remote Procedure Call Protocol）——远程过程调用协议</p>\n<h3 id=\"一、Apache-Avro\"><a href=\"#一、Apache-Avro\" class=\"headerlink\" title=\"一、Apache Avro\"></a>一、Apache Avro</h3><p>简介：Apache Avro是Hadoop下的一个子项目。它本身既是一个序列化框架，同时也实现了RPC的功能。Avro官网描述Avro的特性和功能如下：</p>\n<p>丰富的数据结构类型；<br>快速可压缩的二进制数据形式；<br>存储持久数据的文件容器；<br>提供远程过程调用RPC；<br>简单的动态语言结合功能。<br>相比于Apache Thrift 和Google的Protocol Buffers，Apache Avro具有以下特点：</p>\n<p>支持动态模式。Avro不需要生成代码，这有利于搭建通用的数据处理系统，同时避免了代码入侵。<br>数据无须加标签。读取数据前，Avro能够获取模式定义，这使得Avro在数据编码时只需要保留更少的类型信息，有利于减少序列化后的数据大小。<br>官网：<a href=\"http://avro.apache.org/\" target=\"_blank\" rel=\"noopener\">http://avro.apache.org/</a></p>\n<h3 id=\"二、Facebook-Thrift\"><a href=\"#二、Facebook-Thrift\" class=\"headerlink\" title=\"二、Facebook Thrift\"></a>二、Facebook Thrift</h3><p>贡献者：Facebook</p>\n<p>简介：Thrift源于大名鼎鼎的facebook之手，在2007年facebook提交Apache基金会将Thrift作为一个开源项目，对于当时的facebook来说创造thrift是为了解决facebook系统中各系统间大数据量的传输通信以及系统之间语言环境不同需要跨平台的特性。</p>\n<p>thrift可以支持多种程序语言，例如: C++, C#, Cocoa, Erlang, Haskell, Java, Ocami, Perl, PHP, Python, Ruby, Smalltalk. 在多种不同的语言之间通信thrift可以作为二进制的高性能的通讯中间件，支持数据(对象)序列化和多种类型的RPC服务。</p>\n<p>Thrift适用于程序对程 序静态的数据交换，需要先确定好他的数据结构，他是完全静态化的，当数据结构发生变化时，必须重新编辑IDL文件，代码生成，再编译载入的流程，跟其他IDL工具相比较可以视为是Thrift的弱项，Thrift适用于搭建大型数据交换及存储的通用工具，对于大型系统中的内部数据传输相对于JSON和xml无论在性能、传输大小上有明显的优势。</p>\n<p>Thrift 主要由5个部分组成：</p>\n<p>· 类型系统以及 IDL 编译器：负责由用户给定的 IDL 文件生成相应语言的接口代码</p>\n<p>· TProtocol：实现 RPC 的协议层，可以选择多种不同的对象串行化方式，如 JSON, Binary。</p>\n<p>· TTransport：实现 RPC 的传输层，同样可以选择不同的传输层实现，如socket, 非阻塞的 socket, MemoryBuffer 等。</p>\n<p>· TProcessor：作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口。</p>\n<p>· TServer：聚合 TProtocol, TTransport 和 TProcessor 几个对象。</p>\n<p>上述的这5个部件都是在 Thrift 的源代码中通过为不同语言提供库来实现的，这些库的代码在 Thrift 源码目录的 lib 目录下面，在使用 Thrift 之前需要先熟悉与自己的语言对应的库提供的接口。</p>\n<p>Facebook Thrift构架：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/921.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://thrift.apache.org/\" target=\"_blank\" rel=\"noopener\">http://thrift.apache.org/</a></p>\n<h2 id=\"集群管理\"><a href=\"#集群管理\" class=\"headerlink\" title=\"集群管理\"></a>集群管理</h2><h3 id=\"一、Nagios\"><a href=\"#一、Nagios\" class=\"headerlink\" title=\"一、Nagios\"></a>一、Nagios</h3><p>简介：Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。</p>\n<p>Nagios可运行在Linux/Unix平台之上，同时提供一个可选的基于浏览器的WEB界面以方便系统管理人员查看网络状态，各种系统问题，以及日志等等。</p>\n<p>官网：<a href=\"http://www.nagios.org/\" target=\"_blank\" rel=\"noopener\">http://www.nagios.org/</a></p>\n<h3 id=\"二、Ganglia\"><a href=\"#二、Ganglia\" class=\"headerlink\" title=\"二、Ganglia\"></a>二、Ganglia</h3><p>简介：Ganglia是UC Berkeley发起的一个开源集群监视项目，设计用于测量数以千计的节点。Ganglia的核心包含gmond、gmetad以及一个Web前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1130-600x417.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://ganglia.sourceforge.net/\" target=\"_blank\" rel=\"noopener\">http://ganglia.sourceforge.net/</a></p>\n<h3 id=\"三、Apache-Ambari\"><a href=\"#三、Apache-Ambari\" class=\"headerlink\" title=\"三、Apache Ambari\"></a>三、Apache Ambari</h3><p>简介：Apache Ambari是一种基于Web的工具，支持Apache Hadoop集群的供应、管理和监控。Ambari目前已支持大多数Hadoop组件，包括HDFS、MapReduce、Hive、Pig、 Hbase、Zookeper、Sqoop和Hcatalog等。</p>\n<p>Apache Ambari 支持HDFS、MapReduce、Hive、Pig、Hbase、Zookeper、Sqoop和Hcatalog等的集中管理。也是5个顶级hadoop管理工具之一。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1223.jpg\" alt=\"\"></p>\n<p><strong>Ambari主要取得了以下成绩：</strong></p>\n<p>通过一步一步的安装向导简化了集群供应。<br>预先配置好关键的运维指标（metrics），可以直接查看Hadoop Core（HDFS和MapReduce）及相关项目（如HBase、Hive和HCatalog）是否健康。<br>支持作业与任务执行的可视化与分析，能够更好地查看依赖和性能。<br>通过一个完整的RESTful API把监控信息暴露出来，集成了现有的运维工具。<br>用户界面非常直观，用户可以轻松有效地查看信息并控制集群。<br>Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时（比如，节点停机或磁盘剩余空间不足等问题），系统将向其发送邮件。</p>\n<p>此外，Ambari能够安装安全的（基于Kerberos）Hadoop集群，以此实现了对Hadoop 安全的支持，提供了基于角色的用户认证、授权和审计功能，并为用户管理集成了LDAP和Active Directory。</p>\n<p>官网：<a href=\"http://ambari.apache.org/\" target=\"_blank\" rel=\"noopener\">http://ambari.apache.org/</a></p>\n<h2 id=\"基础设施\"><a href=\"#基础设施\" class=\"headerlink\" title=\"基础设施\"></a>基础设施</h2><h3 id=\"一、LevelDB-1\"><a href=\"#一、LevelDB-1\" class=\"headerlink\" title=\"一、LevelDB\"></a>一、LevelDB</h3><p>贡献者：Jeff Dean和Sanjay Ghemawat</p>\n<p>简介：Leveldb是一个google实现的非常高效的kv数据库，目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能，主要归功于它的良好的设计。特别是LMS算法。LevelDB 是单进程的服务，性能非常之高，在一台4核Q6600的CPU机器上，每秒钟写数据超过40w，而随机读的性能每秒钟超过10w。</p>\n<p>Leveldb框架：</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1322-468x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://code.google.com/p/leveldb/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/leveldb/</a></p>\n<h3 id=\"二、SSTable\"><a href=\"#二、SSTable\" class=\"headerlink\" title=\"二、SSTable\"></a>二、SSTable</h3><p>简介：如果说Protocol Buffer是谷歌独立数据记录的通用语言 ，那么有序字符串表（SSTable，Sorted String Table）则是用于存储，处理和数据集交换的最流行​​的数据输出格式。正如它的名字本身，SSTable是有效存储大量键-值对的简单抽象，对高吞吐量顺序读/写进行了优化。</p>\n<p>SSTable是Bigtable中至关重要的一块，对于LevelDB来说也是如此。</p>\n<h3 id=\"三、RecordIO\"><a href=\"#三、RecordIO\" class=\"headerlink\" title=\"三、RecordIO\"></a>三、RecordIO</h3><p>贡献者：Google</p>\n<p>简介：我们大家都在用文件来存储数据。文件是存储在磁盘上的。如果在一些不稳定的介质上，文件很容损坏。即时文件某个位置出现一点小小的问题，整个文件就废了。</p>\n<p>下面我来介绍Google的一个做法，可以比较好的解决这个问题。那就是recordio文件格式。recoidio的存储单元是一个一个record。这个record可以根据业务的需要自行定义。但Google有一种建议的处理方式就是使用protobuf。</p>\n<p>reocordio底层的格式其实很简单。一个record由四部分组成：</p>\n<p>MagicNumber (32 bits)<br>Uncompressed data payload size (64 bits)<br>Compressed data payload size (64 bits), or 0 if the data is not compressed<br>Payload, possibly compressed.<br><strong>详细格式如下图所示：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/recordio_thumb-600x76.png\" alt=\"\"></p>\n<p>到这里，大家可能已经知道，recordio之所以能对付坏数据，其实就是在这个MagicNumber（校验值）。</p>\n<h3 id=\"四、Flat-Buffers\"><a href=\"#四、Flat-Buffers\" class=\"headerlink\" title=\"四、Flat Buffers\"></a>四、Flat Buffers</h3><p>贡献者：Google</p>\n<p>简介：谷歌开源高效、跨平台的序列化库FlatBuffers。</p>\n<p>该库的构建是专门为游戏开发人员的性能需求提供支持，它将序列化数据存储在缓存中，这些数据既可以存储在文件中，又可以通过网络原样传输，而不需要任何解析开销。</p>\n<p>FlatBuffers有如下一些关键特性——</p>\n<p>访问序列化数据不需要打包/拆包<br>节省内存而且访问速度快——缓存只占用访问数据所需要的内存；不需要任何额外的内存。<br>灵活性——通过可选字段向前向后兼容<br>代码规模小<br>强类型——错误在编译时捕获，而不是在运行时<br>便利性——生成的C++头文件代码简洁。如果需要，有一项可选功能可以用来在运行时高效解析Schema和JSON-like格式的文本。<br>跨平台——使用C++编写，不依赖STL之外的库，因此可以用于任何有C++编辑器的平台。当前，该项目包含构建方法和在Android、Linux、Windows和OSX等操作系统上使用该库的示例。<br>与Protocol Buffers或JSON Parsing这样的可选方案相比，FlatBuffers的优势在于开销更小，这主要是由于它没有解析过程。</p>\n<p>代码托管：<a href=\"https://github.com/google/flatbuffers\" target=\"_blank\" rel=\"noopener\">https://github.com/google/flatbuffers</a></p>\n<h3 id=\"五、Protocol-Buffers\"><a href=\"#五、Protocol-Buffers\" class=\"headerlink\" title=\"五、Protocol Buffers\"></a>五、Protocol Buffers</h3><p>贡献者：Google</p>\n<p>简介：Protocol Buffers是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。它不依赖于语言和平台并且可扩展性极强。现阶段官方支持C++、JAVA、Python等三种编程语言，但可以找到大量的几乎涵盖所有语言的第三方拓展包。</p>\n<p>通过它，你可以定义你的数据的结构，并生成基于各种语言的代码。这些你定义的数据流可以轻松地在传递并不破坏你已有的程序。并且你也可以更新这些数据而现有的程序也不会受到任何的影响。</p>\n<p>Protocol Buffers经常被简称为protobuf。</p>\n<p>官网：<a href=\"http://code.google.com/p/protobuf/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/protobuf/</a></p>\n<h3 id=\"六、Consistent-Hashing（哈希算法）\"><a href=\"#六、Consistent-Hashing（哈希算法）\" class=\"headerlink\" title=\"六、Consistent Hashing（哈希算法）\"></a>六、Consistent Hashing（哈希算法）</h3><p>简介：一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1420.jpg\" alt=\"\"></p>\n<p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p>\n<p>1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p>\n<p>2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</p>\n<p>3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</p>\n<p>4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p>\n<p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。</p>\n<h3 id=\"七、Netty\"><a href=\"#七、Netty\" class=\"headerlink\" title=\"七、Netty\"></a>七、Netty</h3><p>贡献者：JBOSS</p>\n<p>简介：Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1518.jpg\" alt=\"\"></p>\n<p>也就是说，Netty 是一个基于NIO的客户，服务器端编程框架，使用Netty 可以确保你快速和简单的开发出一个网络应用，例如实现了某种协议的客户，服务端应用。Netty相当简化和流线化了网络应用的编程开发过程，例如，TCP和UDP的socket服务开发。</p>\n<p>“快速”和“简单”并不意味着会让你的最终应用产生维护性或性能上的问题。Netty 是一个吸收了多种协议的实现经验，这些协议包括FTP,SMTP,HTTP，各种二进制，文本协议，并经过相当精心设计的项目，最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性。</p>\n<p>官网：<a href=\"http://netty.io/\" target=\"_blank\" rel=\"noopener\">http://netty.io/</a></p>\n<h3 id=\"八、BloomFilter\"><a href=\"#八、BloomFilter\" class=\"headerlink\" title=\"八、BloomFilter\"></a>八、BloomFilter</h3><p>简介：Bloom filter 是由 Howard Bloom 在 1970 年提出的二进制向量数据结构，它具有很好的空间和时间效率，被用来检测一个元素是不是集合中的一个成员。如果检测结果为是，该元素不一定在集合中；但如果检测结果为否，该元素一定不在集合中。因此Bloom filter具有100%的召回率。这样每个检测请求返回有“在集合内（可能错误）”和“不在集合内（绝对不在集合内）”两种情况，可见 Bloom filter 是牺牲了正确率和时间以节省空间。</p>\n<p>Bloom filter 优点就是它的插入和查询时间都是常数，另外它查询元素却不保存元素本身，具有良好的安全性。</p>\n<h2 id=\"搜索引擎\"><a href=\"#搜索引擎\" class=\"headerlink\" title=\"搜索引擎\"></a>搜索引擎</h2><h3 id=\"一、Nutch\"><a href=\"#一、Nutch\" class=\"headerlink\" title=\"一、Nutch\"></a>一、Nutch</h3><p>简介：Nutch 是一个开源Java 实现的搜索引擎。它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。</p>\n<p>尽管Web搜索是漫游Internet的基本要求, 但是现有web搜索引擎的数目却在下降. 并且这很有可能进一步演变成为一个公司垄断了几乎所有的web搜索为其谋取商业利益.这显然 不利于广大Internet用户.</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1615.jpg\" alt=\"\"></p>\n<p>Nutch为我们提供了这样一个不同的选择. 相对于那些商用的搜索引擎, Nutch作为开放源代码 搜索引擎将会更加透明, 从而更值得大家信赖. 现在所有主要的搜索引擎都采用私有的排序算法, 而不会解释为什么一个网页会排在一个特定的位置. 除此之外, 有的搜索引擎依照网站所付的 费用, 而不是根据它们本身的价值进行排序. 与它们不同, Nucth没有什么需要隐瞒, 也没有 动机去扭曲搜索的结果. Nutch将尽自己最大的努力为用户提供最好的搜索结果.</p>\n<p>Nutch目前最新的版本为version v2.2.1。</p>\n<p>官网：<a href=\"https://nutch.apache.org/\" target=\"_blank\" rel=\"noopener\">https://nutch.apache.org/</a></p>\n<h3 id=\"二、Lucene\"><a href=\"#二、Lucene\" class=\"headerlink\" title=\"二、Lucene\"></a>二、Lucene</h3><p>开发者：Doug Cutting（Hadoop之父，你懂的）</p>\n<p>简介：Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，即它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1717-556x429.jpg\" alt=\"\"></p>\n<p>官网：<a href=\"http://lucene.apache.org/\" target=\"_blank\" rel=\"noopener\">http://lucene.apache.org/</a></p>\n<h3 id=\"三、SolrCloud\"><a href=\"#三、SolrCloud\" class=\"headerlink\" title=\"三、SolrCloud\"></a>三、SolrCloud</h3><p>简介：SolrCloud是Solr4.0版本以后基于Solr和Zookeeper的分布式搜索方案。SolrCloud是Solr的基于Zookeeper一种部署方式。Solr可以以多种方式部署，例如单机方式，多机Master-Slaver方式。</p>\n<p><strong>原理图：</strong></p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1813-583x429.jpg\" alt=\"\"></p>\n<p><strong>SolrCloud有几个特色功能：</strong></p>\n<p>集中式的配置信息使用ZK进行集中配置。启动时可以指定把Solr的相关配置文件上传</p>\n<p>Zookeeper，多机器共用。这些ZK中的配置不会再拿到本地缓存，Solr直接读取ZK中的配置信息。配置文件的变动，所有机器都可以感知到。另外，Solr的一些任务也是通过ZK作为媒介发布的。目的是为了容错。接收到任务，但在执行任务时崩溃的机器，在重启后，或者集群选出候选者时，可以再次执行这个未完成的任务。</p>\n<p>自动容错SolrCloud对索引分片，并对每个分片创建多个Replication。每个Replication都可以对外提供服务。一个Replication挂掉不会影响索引服务。更强大的是，它还能自动的在其它机器上帮你把失败机器上的索引Replication重建并投入使用。</p>\n<p>近实时搜索立即推送式的replication（也支持慢推送）。可以在秒内检索到新加入索引。</p>\n<p>查询时自动负载均衡SolrCloud索引的多个Replication可以分布在多台机器上，均衡查询压力。如果查询压力大，可以通过扩展机器，增加Replication来减缓。</p>\n<p>自动分发的索引和索引分片发送文档到任何节点，它都会转发到正确节点。</p>\n<p>事务日志事务日志确保更新无丢失，即使文档没有索引到磁盘。</p>\n<h3 id=\"四、Solr\"><a href=\"#四、Solr\" class=\"headerlink\" title=\"四、Solr\"></a>四、Solr</h3><p>简介：Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/1913-593x429.jpg\" alt=\"\"></p>\n<p>Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。</p>\n<p>官网：<a href=\"https://lucene.apache.org/solr/\" target=\"_blank\" rel=\"noopener\">https://lucene.apache.org/solr/</a></p>\n<h3 id=\"五、ElasticSearch\"><a href=\"#五、ElasticSearch\" class=\"headerlink\" title=\"五、ElasticSearch\"></a>五、ElasticSearch</h3><p>简介：ElasticSearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是第二最流行的企业搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。</p>\n<p>官网：<a href=\"http://www.elasticsearch.org/\" target=\"_blank\" rel=\"noopener\">http://www.elasticsearch.org/</a></p>\n<h3 id=\"六、Sphinx\"><a href=\"#六、Sphinx\" class=\"headerlink\" title=\"六、Sphinx\"></a>六、Sphinx</h3><p>简介：Sphinx是一个基于SQL的全文检索引擎，可以结合MySQL,PostgreSQL做全文搜索，它可以提供比数据库本身更专业的搜索功能，使得应用程序更容易实现专业化的全文检索。Sphinx特别为一些脚本语言设计搜索API接口，如PHP,Python,Perl,Ruby等，同时为MySQL也设计了一个存储引擎插件。</p>\n<p>Sphinx单一索引最大可包含1亿条记录，在1千万条记录情况下的查询速度为0.x秒（毫秒级）。Sphinx创建索引的速度为：创建100万条记录的索引只需 3～4分钟，创建1000万条记录的索引可以在50分钟内完成，而只包含最新10万条记录的增量索引，重建一次只需几十秒。</p>\n<p>官网：<a href=\"http://sphinxsearch.com\" target=\"_blank\" rel=\"noopener\">http://sphinxsearch.com</a></p>\n<h3 id=\"七、SenseiDB\"><a href=\"#七、SenseiDB\" class=\"headerlink\" title=\"七、SenseiDB\"></a>七、SenseiDB</h3><p>贡献者：linkedin</p>\n<p>简介：SenseiDB是一个NoSQL数据库，它专注于高更新率以及复杂半结构化搜索查询。熟悉Lucene和Solor的用户会发现，SenseiDB背后有许多似曾相识的概念。SenseiDB部署在多节点集群中，其中每个节点可以包括N块数据片。Apache Zookeeper用于管理节点，它能够保持现有配置，并可以将任意改动（如拓扑修改）传输到整个节点群中。SenseiDB集群还需要一种模式用于定义将要使用的数据模型。</p>\n<p>从SenseiDB集群中获取数据的唯一方法是通过Gateways（它 没有“INSERT”方法）。每个集群都连接到一个单一gateway。你需要了解很重要的一点是，由于SenseiDB本身没法处理原子性 （Atomicity）和隔离性（Isolation），因此只能通过外部在gateway层进行限制。另外，gateway必须确保数据流按照预期的方 式运作。内置的gateway有以下几种形式：</p>\n<p>来自文件<br>来自JMS队列<br>通过JDBC<br>来自Apache Kafka<br>官网：<a href=\"http://senseidb.com\" target=\"_blank\" rel=\"noopener\">http://senseidb.com</a></p>\n<h2 id=\"数据挖掘\"><a href=\"#数据挖掘\" class=\"headerlink\" title=\"数据挖掘\"></a>数据挖掘</h2><h3 id=\"一、Mahout\"><a href=\"#一、Mahout\" class=\"headerlink\" title=\"一、Mahout\"></a>一、Mahout</h3><p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2012.jpg\" alt=\"\"></p>\n<p>简介：Apache Mahout 是 Apache Software Foundation (ASF) 开发的一个全新的开源项目，其主要目标是创建一些可伸缩的机器学习算法，供开发人员在 Apache 在许可下免费使用。该项目已经发展到了它的最二个年头，目前只有一个公共发行版。Mahout 包含许多实现，包括集群、分类、CP 和进化程序。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。</p>\n<p>虽然在开源领域中相对较为年轻，但 Mahout 已经提供了大量功能，特别是在集群和 CF 方面。Mahout 的主要特性包括：</p>\n<p>Taste CF。Taste 是 Sean Owen 在 SourceForge 上发起的一个针对 CF 的开源项目，并在 2008 年被赠予 Mahout。<br>一些支持 Map-Reduce 的集群实现包括 k-Means、模糊 k-Means、Canopy、Dirichlet 和 Mean-Shift。<br>Distributed Naive Bayes 和 Complementary Naive Bayes 分类实现。<br>针对进化编程的分布式适用性功能。<br>Matrix 和矢量库。<br>上述算法的示例。<br>官网：<a href=\"http://mahout.apache.org/\" target=\"_blank\" rel=\"noopener\">http://mahout.apache.org/</a></p>\n<h2 id=\"Iaas\"><a href=\"#Iaas\" class=\"headerlink\" title=\"Iaas\"></a>Iaas</h2><p>IaaS（Infrastructure as a Service），即基础设施即服务。</p>\n<h3 id=\"一、OpenStack\"><a href=\"#一、OpenStack\" class=\"headerlink\" title=\"一、OpenStack\"></a>一、OpenStack</h3><p>简介：OpenStack是一个由NASA（美国国家航空航天局）和Rackspace合作研发并发起的，以Apache许可证授权的自由软件和开放源代码项目。</p>\n<p>OpenStack是一个开源的云计算管理平台项目，由几个主要的组件组合起来完成具体工作。OpenStack支持几乎所有类型的云环境，项目目标是提供实施简单、可大规模扩展、丰富、标准统一的云计算管理平台。OpenStack通过各种互补的服务提供了基础设施即服务（IaaS）的解决方案，每个服务提供API以进行集成。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2014/12/1148-599x429.jpg\" alt=\"\"></p>\n<p>6个核心项目：Nova（计算，Compute），Swift（对象存储，Object），Glance（镜像，Image），Keystone（身份，Identity），Horizon（自助门户，Dashboard），Quantum &amp; Melange（网络&amp;地址管理），另外还有若干社区项目，如Rackspace（负载均衡）、Rackspace（关系型数据库）。</p>\n<p>相关阅读：</p>\n<p><a href=\"http://www.36dsj.com/archives/19596\" target=\"_blank\" rel=\"noopener\">什么是OpenStack？</a></p>\n<p><a href=\"http://www.36dsj.com/archives/22179\" target=\"_blank\" rel=\"noopener\">成功部署OpenStack的十大要点</a></p>\n<p> 官网：<a href=\"https://www.openstack.org/\" target=\"_blank\" rel=\"noopener\">https://www.openstack.org/</a></p>\n<h3 id=\"二、Docker\"><a href=\"#二、Docker\" class=\"headerlink\" title=\"二、Docker\"></a>二、Docker</h3><p>贡献者：dotCloud</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2215.jpg\" alt=\"\"></p>\n<p>简介：Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）。几乎没有性能开销,可以很容易地在机器和数据中心中运行。最重要的是,他们不依赖于任何语言、框架或包括系统。</p>\n<p>官网：<a href=\"http://www.docker.io/\" target=\"_blank\" rel=\"noopener\">http://www.docker.io/</a></p>\n<h3 id=\"三、Kubernetes\"><a href=\"#三、Kubernetes\" class=\"headerlink\" title=\"三、Kubernetes\"></a>三、Kubernetes</h3><p>贡献者：Google</p>\n<p>简介：Kubernetes是Google开源的容器集群管理系统。它构建Ddocker技术之上，为容器化的应用提供资源调度、部署运行、服务发现、扩容缩容等整一套功能，本质上可看作是基于容器技术的mini-PaaS平台。</p>\n<p>Kubernetes从另一个角度对资源进行抽象，它让开发人员和管理人员共同着眼于服务的行为和性能的提升，而不是仅仅关注对单一的组件或者是基础资源。</p>\n<p>那么Kubernetes集群到底提供了哪些单一容器所没有功能?它主要关注的是对服务级别的控制而并非仅仅是对容器级别的控制，Kubernetes提供了一种“机智”的管理方式，它将服务看成一个整体。在Kubernete的解决方案中，一个服务甚至可以自我扩展，自我诊断，并且容易升级。例如，在Google中，我们使用机器学习技术来保证每个运行的服务的当前状态都是最高效的。</p>\n<p>代码托管：<a href=\"https://github.com/GoogleCloudPlatform/kubernetes/\" target=\"_blank\" rel=\"noopener\">https://github.com/GoogleCloudPlatform/kubernetes/</a></p>\n<h3 id=\"四、Imctfy\"><a href=\"#四、Imctfy\" class=\"headerlink\" title=\"四、Imctfy\"></a>四、Imctfy</h3><p>贡献者：Google</p>\n<p>简介：Google开源了自己所用Linux容器系统的开源版本lmctfy，读音为lem-kut-fee。包括一个C++库（使用了C++11，文档可以参考头文件）和命令行界面。目前的版本是0.1，只提供了CPU与内存隔离。项目还在密集开发中。</p>\n<p>mctfy本身是针对某些特定使用场景设计和实现的，目前拥有一台机器上所有容器时运行情况最好，不推荐与LXC和其他容器系统一起使用（虽然也可行）。已在Ubuntu 12.04+和Ubuntu 3.3与3.8内核上测试。</p>\n<p>代码托管：<a href=\"https://github.com/google/Imctfy/\" target=\"_blank\" rel=\"noopener\">https://github.com/google/Imctfy/</a></p>\n<h2 id=\"监控管理\"><a href=\"#监控管理\" class=\"headerlink\" title=\"监控管理\"></a>监控管理</h2><h3 id=\"一、Dapper\"><a href=\"#一、Dapper\" class=\"headerlink\" title=\"一、Dapper\"></a>一、Dapper</h3><p>贡献者：Google</p>\n<p>简介：Dapper是一个轻量的ORM(对象关系映射（英语：Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）。并不单纯的是一个DBHelper.因为在Dapper中数据其实就是一个对象。Dapper扩展与IDbConnection上，所以事实上它的倾入性很低。我用了StructureMap。如果不喜欢可以自己更换，或者自己实现下。</p>\n<p>代码就一个SqlMapper.cs文件,主要是IDbConnection的扩展方法，编译后就40K的一个很小的dll。</p>\n<p>特性：</p>\n<p>Dapper很快。Dapper的速度接近与IDataReader。<br>Dapper支持主流数据库 Mysql,SqlLite,Mssql2000,Mssql2005,Oracle等一系列的数据库<br>支持多表并联的对象。支持一对多 多对多的关系，并且没侵入性。<br>原理通过Emit反射IDataReader的序列队列，来快速的得到和产生对象<br>Dapper语法十分简单。并且无须迁就数据库的设计<br>官方站点 <a href=\"http://code.google.com/p/dapper-dot-net/\" target=\"_blank\" rel=\"noopener\">http://code.google.com/p/dapper-dot-net/</a></p>\n<p>代码托管：<a href=\"http://bigbully.github.io/Dapper-translation/\" target=\"_blank\" rel=\"noopener\">http://bigbully.github.io/Dapper-translation/</a></p>\n<h3 id=\"二、Zipkin\"><a href=\"#二、Zipkin\" class=\"headerlink\" title=\"二、Zipkin\"></a>二、Zipkin</h3><p>贡献者：Twitter</p>\n<p>简介：Zipkin （分布式跟踪系统）是 Twitter 的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口。该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。</p>\n<p><img src=\"http://www.36dsj.com/wp-content/uploads/2015/03/2313-535x429.jpg\" alt=\"\"></p>\n<p>官方网站：<a href=\"http://twitter.github.io/zipkin/\" target=\"_blank\" rel=\"noopener\">http://twitter.github.io/zipkin/</a></p>\n<p>代码托管：<a href=\"https://github.com/twitter/zipkin/\" target=\"_blank\" rel=\"noopener\">https://github.com/twitter/zipkin/</a></p>\n<p><strong>————————————-End.——————————————-</strong></p>\n<p>感谢:<br>36大数据(<a href=\"http://www.36dsj.com/\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/</a>)</p>\n<p>转载来源:<a href=\"http://www.36dsj.com/archives/24852\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/archives/24852</a><br><a href=\"http://www.36dsj.com/archives/25042\" target=\"_blank\" rel=\"noopener\">http://www.36dsj.com/archives/25042</a></p>"}],"PostAsset":[],"PostCategory":[{"post_id":"cjskffnv500004glmttvc9pny","category_id":"cjskffnw000024glmvspznr50","_id":"cjskffnxb000d4glmhesrj1ri"},{"post_id":"cjskffnvk00014glm8ftkgsqo","category_id":"cjskffnw000024glmvspznr50","_id":"cjskffnxq000j4glmu78t2xby"},{"post_id":"cjskffnw000044glmm803ssdv","category_id":"cjskffnw000024glmvspznr50","_id":"cjskffny6000o4glm86vy82rf"},{"post_id":"cjskffnwg00054glmn3fxxoz8","category_id":"cjskffnxq000i4glmajxydbl2","_id":"cjskffny6000u4glmbe7ezrf2"},{"post_id":"cjskffnwg00064glmupt7y625","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffnym00104glmmgif2xmn"},{"post_id":"cjskffnwv000a4glmg5zomogh","category_id":"cjskffny6000v4glm41hq6ttx","_id":"cjskffnym00144glm9hn7awr9"},{"post_id":"cjskffnym000z4glmods45xgl","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffnz100174glm7s3gj3q5"},{"post_id":"cjskffnwv000b4glm2w66ci9s","category_id":"cjskffnym00114glmi95ebesu","_id":"cjskffnz100194glm8qe4e70n"},{"post_id":"cjskffnxb000f4glmraz90dp7","category_id":"cjskffnym00154glmx7inrh5l","_id":"cjskffnz1001e4glmdquuwe3o"},{"post_id":"cjskffnxb000h4glmy1a3gzk7","category_id":"cjskffnym00154glmx7inrh5l","_id":"cjskffnz1001i4glm84klwdw8"},{"post_id":"cjskffnxq000l4glmg9x6e8e6","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffnz1001m4glme6dakmy5"},{"post_id":"cjskffnxq000n4glmvtpu5wbw","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffnzh001p4glm0wlb8ckk"},{"post_id":"cjskffny6000r4glm53t9dmpy","category_id":"cjskffnz1001l4glmakxlvgyd","_id":"cjskffnzh001u4glmwafroc83"},{"post_id":"cjskffny6000t4glm5v7h7qt5","category_id":"cjskffnz1001l4glmakxlvgyd","_id":"cjskffnzh001x4glmz2kmuwa5"},{"post_id":"cjskffnym000x4glmlrvuwxgh","category_id":"cjskffnz1001l4glmakxlvgyd","_id":"cjskffnzh001z4glmiuw6dvgm"},{"post_id":"cjskffo5z00224glmu92mduiv","category_id":"cjskffo6e00264glmhs5kk6ww","_id":"cjskffo7a002h4glm08mtlcyu"},{"post_id":"cjskffo6u002b4glmqtblogt9","category_id":"cjskffnz1001l4glmakxlvgyd","_id":"cjskffo7p002l4glma3i8fyhv"},{"post_id":"cjskffo5z00244glm06rmvutr","category_id":"cjskffo6u002c4glmos81466d","_id":"cjskffo7p002o4glm4lvq85i2"},{"post_id":"cjskffo7a002g4glmgb2fqhvg","category_id":"cjskffny6000v4glm41hq6ttx","_id":"cjskffo85002t4glm619vfsfw"},{"post_id":"cjskffo6e00284glm46n6iftl","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffo85002w4glmdxvlnqiv"},{"post_id":"cjskffo85002s4glmnlunc0xl","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffo8k00324glmxfw5pek8"},{"post_id":"cjskffo6u002a4glm6pq5101m","category_id":"cjskffo7p002p4glm35x2m0u1","_id":"cjskffo8k00354glmykdqnpla"},{"post_id":"cjskffo8k00314glm17y1ok96","category_id":"cjskffnym00114glmi95ebesu","_id":"cjskffo90003a4glm8utmzz08"},{"post_id":"cjskffo7a002f4glmfkd0o943","category_id":"cjskffo85002y4glm5v2icjnn","_id":"cjskffo90003f4glmf218i9iv"},{"post_id":"cjskffo7p002k4glmrfydiw8h","category_id":"cjskffo8k00364glm9sn226u8","_id":"cjskffo9g003h4glmxlkcacdr"},{"post_id":"cjskffo7p002n4glm9w5k1ka5","category_id":"cjskffo90003c4glmz0vb2t94","_id":"cjskffo9g003n4glmehm48rde"},{"post_id":"cjskffo9g003k4glm4cs8h9zt","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffo9v003t4glmbu4rgowx"},{"post_id":"cjskffo85002v4glmzyies7sx","category_id":"cjskffo9g003j4glmjveuehx3","_id":"cjskffo9v003x4glmf2xunhzt"},{"post_id":"cjskffo9g003m4glm2eyl949r","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffoab00404glmz1cfgwdy"},{"post_id":"cjskffo9g003q4glmztj4zd9j","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffoab00424glmd6inhl5q"},{"post_id":"cjskffo85002z4glm6ok3lgl6","category_id":"cjskffo9g003j4glmjveuehx3","_id":"cjskffoab00474glm9r05iotm"},{"post_id":"cjskffo9v003s4glm6e2fvws0","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffoaq00494glm3gbzc4il"},{"post_id":"cjskffo9v003w4glmc2wcgmjb","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffoaq004e4glm116ow7s8"},{"post_id":"cjskffoab003z4glmrlszcfx7","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffob6004h4glmuqp400zm"},{"post_id":"cjskffo8k00344glm454658n9","category_id":"cjskffo9v003u4glm7lglska5","_id":"cjskffob6004m4glmx0rjuyih"},{"post_id":"cjskffoab00414glm4v1u4afz","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffobm004p4glmksecatkf"},{"post_id":"cjskffoab00464glmnvxmdcz4","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffobm004u4glm3tod5sdz"},{"post_id":"cjskffo8k00384glmw7cfxccz","category_id":"cjskffoab00434glmyvocsg13","_id":"cjskffoc1004x4glmkpiawj14"},{"post_id":"cjskffoaq004d4glm7nev95rh","category_id":"cjskffo7p002p4glm35x2m0u1","_id":"cjskffoch00524glmsvtnwzsl"},{"post_id":"cjskffo9000394glmc7uodlr6","category_id":"cjskffoab00434glmyvocsg13","_id":"cjskffoch00554glmyz9wiepe"},{"post_id":"cjskffo90003e4glmhoby23j3","category_id":"cjskffoab00434glmyvocsg13","_id":"cjskffocw005a4glmncbwlkje"},{"post_id":"cjskffob6004o4glm0zxyws76","category_id":"cjskffoab00434glmyvocsg13","_id":"cjskffocw005d4glm4t9to1lu"},{"post_id":"cjskffobm004t4glmwx1lxu2a","category_id":"cjskffo9v003u4glm7lglska5","_id":"cjskffodc005h4glmrz6a8pw5"},{"post_id":"cjskffo90003g4glmb4eljxl4","category_id":"cjskffobm004q4glmfl48w6rj","_id":"cjskffods005l4glmnj4ynr93"},{"post_id":"cjskffoc1004w4glmaboxrmk3","category_id":"cjskffo9v003u4glm7lglska5","_id":"cjskffoen005p4glm5zykn6pc"},{"post_id":"cjskffoaq00484glmw41oopfp","category_id":"cjskffoc1004y4glmulnmikfi","_id":"cjskffoen005t4glmr23ykscr"},{"post_id":"cjskffocw005c4glm14hwcklm","category_id":"cjskffo7a002i4glm5pa4x5gz","_id":"cjskffoen005w4glmqau2obn3"},{"post_id":"cjskffoaq004g4glmp5e5nl3t","category_id":"cjskffoch00584glmpo1vn9py","_id":"cjskffof200604glmx8adiywf"},{"post_id":"cjskffob6004l4glmqm30j57m","category_id":"cjskffodc005i4glmn3dqjyfx","_id":"cjskffof200634glm4wyh1e7g"},{"post_id":"cjskffoch00514glm4f9jv6s9","category_id":"cjskffoen005q4glmw16nhnpx","_id":"cjskffofi00674glm3p1hj4iv"},{"post_id":"cjskffoch00544glm7d4mdooe","category_id":"cjskffof2005y4glmoed1izr9","_id":"cjskffofi006c4glm28dflxf8"},{"post_id":"cjskffoch00594glm4u1p7r1t","category_id":"cjskffof2005y4glmoed1izr9","_id":"cjskffofy006h4glmby6eefvf"},{"post_id":"cjskffofi006d4glmk62d7svo","category_id":"cjskffo6u002c4glmos81466d","_id":"cjskffogd006n4glm8rj57tsu"},{"post_id":"cjskffodc005g4glma7q6mkam","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffogd006r4glmfkiv32lc"},{"post_id":"cjskffofy006i4glmz2iemp4f","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffogt006u4glmxpebxwbr"},{"post_id":"cjskffofy006m4glm36r80gyd","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffogt006x4glmlyipgjzj"},{"post_id":"cjskffodc005k4glmrtwkxtca","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffogt00704glm8dij0sfz"},{"post_id":"cjskffogd006t4glmp6iaok8w","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffogt00724glm98w0vzu4"},{"post_id":"cjskffoe7005o4glmug81m8lz","category_id":"cjskffogd006q4glmh5svmfke","_id":"cjskffogt00764glmxtyjf5w6"},{"post_id":"cjskffogt006w4glm1n56zuw1","category_id":"cjskffny6000p4glmd8ksw0cr","_id":"cjskffoh800784glm1orumtfa"},{"post_id":"cjskffoen005s4glm4whqaqcz","category_id":"cjskffogt006y4glmxy956yo9","_id":"cjskffoh8007a4glmffrdijr5"},{"post_id":"cjskffoen005v4glmfcdb3ouv","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffoh8007e4glmy9qyqn8a"},{"post_id":"cjskffof2005z4glmmnm381ca","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffoh8007i4glm3e4bnix8"},{"post_id":"cjskffof200624glm6wco1h12","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffoho007m4glmu0brpboc"},{"post_id":"cjskffof200664glmt91nr1sr","category_id":"cjskffofi006b4glmulr9s618","_id":"cjskffoho007o4glmouaxj25g"},{"post_id":"cjskffofi00694glm9d7jvqyd","category_id":"cjskffoho007l4glmuj2kygu5","_id":"cjskffoho007s4glmpa0uwhp3"},{"post_id":"cjskffofy006f4glmoe8diwf4","category_id":"cjskffoho007q4glmtkug9g0c","_id":"cjskffoho007v4glmhh22xulw"},{"post_id":"cjskffogd006p4glmvjahk904","category_id":"cjskffoho007t4glmt4snvjjc","_id":"cjskffoi4007z4glmmw65mffh"},{"post_id":"cjskffp4n008q4glm1ufb6xjy","category_id":"cjskffp4n008r4glm2jwokcuw","_id":"cjskffp52008u4glm0f3mslu2"}],"PostTag":[{"post_id":"cjskffnv500004glmttvc9pny","tag_id":"cjskffnw000034glm1ez3xn7l","_id":"cjskffnwv00094glm503n18ae"},{"post_id":"cjskffnvk00014glm8ftkgsqo","tag_id":"cjskffnwg00084glm53v3escg","_id":"cjskffnxb000g4glm3qoxhtrp"},{"post_id":"cjskffnw000044glmm803ssdv","tag_id":"cjskffnwg00084glm53v3escg","_id":"cjskffnxq000m4glmtv34641d"},{"post_id":"cjskffnwg00054glmn3fxxoz8","tag_id":"cjskffnxq000k4glm9zmfr2ka","_id":"cjskffny6000s4glmwyy9qcer"},{"post_id":"cjskffnwg00064glmupt7y625","tag_id":"cjskffny6000q4glmq30qvg89","_id":"cjskffnym000y4glm0tf0wbyv"},{"post_id":"cjskffnwv000a4glmg5zomogh","tag_id":"cjskffnym000w4glmlu7hp29n","_id":"cjskffnym00134glm74u6v394"},{"post_id":"cjskffnwv000b4glm2w66ci9s","tag_id":"cjskffnym00124glmozpwp52n","_id":"cjskffnz100184glm8vlp5ddo"},{"post_id":"cjskffnxb000f4glmraz90dp7","tag_id":"cjskffnz100164glmh2mbe67o","_id":"cjskffnz1001c4glmrxi1lla1"},{"post_id":"cjskffnxb000h4glmy1a3gzk7","tag_id":"cjskffnz1001b4glmjc59903l","_id":"cjskffnz1001g4glmfr8x0llr"},{"post_id":"cjskffnxq000l4glmg9x6e8e6","tag_id":"cjskffnz1001f4glmsplcemyg","_id":"cjskffnz1001k4glmnn6jnzoa"},{"post_id":"cjskffnxq000n4glmvtpu5wbw","tag_id":"cjskffnz1001j4glmodk0ufu8","_id":"cjskffnzh001o4glmmihtg2cn"},{"post_id":"cjskffny6000r4glm53t9dmpy","tag_id":"cjskffnzh001n4glmb9ok6dw3","_id":"cjskffnzh001s4glmqrpvr9ov"},{"post_id":"cjskffny6000t4glm5v7h7qt5","tag_id":"cjskffnzh001n4glmb9ok6dw3","_id":"cjskffnzh001w4glmsxa4ztnp"},{"post_id":"cjskffnym000x4glmlrvuwxgh","tag_id":"cjskffnzh001v4glmp806aa96","_id":"cjskffnzh00204glmg13g5l60"},{"post_id":"cjskffnym000z4glmods45xgl","tag_id":"cjskffnzh001y4glma03y18r5","_id":"cjskffnzh00214glmljtxphce"},{"post_id":"cjskffo5z00224glmu92mduiv","tag_id":"cjskffo6e00274glmq4yhtxjg","_id":"cjskffo7a002e4glmg8gm16qe"},{"post_id":"cjskffo5z00244glm06rmvutr","tag_id":"cjskffo7a002d4glmrgz5y7bk","_id":"cjskffo7p002m4glmxy4r3p0y"},{"post_id":"cjskffo7p002k4glmrfydiw8h","tag_id":"cjskffo7p002j4glm3z7obvcf","_id":"cjskffo7p002r4glmhyn6vi8q"},{"post_id":"cjskffo6e00284glm46n6iftl","tag_id":"cjskffo7p002j4glm3z7obvcf","_id":"cjskffo85002u4glmml7jjax0"},{"post_id":"cjskffo6u002a4glm6pq5101m","tag_id":"cjskffo7p002j4glm3z7obvcf","_id":"cjskffo8k00304glmxgsxw1a9"},{"post_id":"cjskffo6u002b4glmqtblogt9","tag_id":"cjskffo85002x4glmtslpyhlz","_id":"cjskffo8k00374glmeqt13pm5"},{"post_id":"cjskffo7a002f4glmfkd0o943","tag_id":"cjskffo8k00334glmetfozw8q","_id":"cjskffo90003d4glmw3pbewa9"},{"post_id":"cjskffo7a002g4glmgb2fqhvg","tag_id":"cjskffo90003b4glmcyls6l5y","_id":"cjskffo9g003l4glmxunxykzh"},{"post_id":"cjskffo7p002n4glm9w5k1ka5","tag_id":"cjskffo9g003i4glmm9zhdidc","_id":"cjskffo9v003r4glmy06xvft6"},{"post_id":"cjskffo85002s4glmnlunc0xl","tag_id":"cjskffo9g003o4glmtmgh988b","_id":"cjskffo9v003y4glm3invhu40"},{"post_id":"cjskffo85002v4glmzyies7sx","tag_id":"cjskffo9v003v4glm6czrv0wo","_id":"cjskffoab00454glmcibk35bh"},{"post_id":"cjskffoab00464glmnvxmdcz4","tag_id":"cjskffo9g003o4glmtmgh988b","_id":"cjskffoaq004c4glm9g0boesl"},{"post_id":"cjskffo85002z4glm6ok3lgl6","tag_id":"cjskffoab00444glmka07e4y6","_id":"cjskffoaq004f4glmp5gkbfn1"},{"post_id":"cjskffoaq004d4glm7nev95rh","tag_id":"cjskffo7p002j4glm3z7obvcf","_id":"cjskffob6004k4glm21yg7y2f"},{"post_id":"cjskffo8k00314glm17y1ok96","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffob6004n4glmyvkbjb1o"},{"post_id":"cjskffoaq004g4glmp5e5nl3t","tag_id":"cjskffo7p002j4glm3z7obvcf","_id":"cjskffobm004s4glmyh3etwon"},{"post_id":"cjskffo8k00344glm454658n9","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoc1004v4glm9bu43h84"},{"post_id":"cjskffob6004o4glm0zxyws76","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoc100504glm0gokuh4t"},{"post_id":"cjskffobm004t4glmwx1lxu2a","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoch00534glmeoquau3k"},{"post_id":"cjskffo8k00384glmw7cfxccz","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoch00574glmmvkvzzjm"},{"post_id":"cjskffoc1004w4glmaboxrmk3","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffocw005b4glmn01gqbs5"},{"post_id":"cjskffo9000394glmc7uodlr6","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffodc005f4glmyn9em8k4"},{"post_id":"cjskffo90003e4glmhoby23j3","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffodc005j4glmdiyoccww"},{"post_id":"cjskffocw005c4glm14hwcklm","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoe7005n4glmcjhcwocx"},{"post_id":"cjskffo90003g4glmb4eljxl4","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffoen005r4glmnc9kmqr7"},{"post_id":"cjskffo9g003k4glm4cs8h9zt","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffof2005x4glm189jt1c1"},{"post_id":"cjskffo9g003m4glm2eyl949r","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffof200644glmyxnlcy9r"},{"post_id":"cjskffo9g003q4glmztj4zd9j","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffofi006a4glm51z4zc1u"},{"post_id":"cjskffo9v003s4glm6e2fvws0","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffofy006g4glm4s742uoy"},{"post_id":"cjskffofi006d4glmk62d7svo","tag_id":"cjskffo7a002d4glmrgz5y7bk","_id":"cjskffofy006k4glml40rgudx"},{"post_id":"cjskffo9v003w4glmc2wcgmjb","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffogd006o4glm7o00s4xz"},{"post_id":"cjskffoab003z4glmrlszcfx7","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffogt006v4glm56h2bnbu"},{"post_id":"cjskffoab00414glm4v1u4afz","tag_id":"cjskffoaq004b4glmcxx4e3nh","_id":"cjskffogt00714glmuykykoz7"},{"post_id":"cjskffogt006w4glm1n56zuw1","tag_id":"cjskffnz1001j4glmodk0ufu8","_id":"cjskffogt00734glmiyrj1kzt"},{"post_id":"cjskffoaq00484glmw41oopfp","tag_id":"cjskffogt006z4glmsqdshiad","_id":"cjskffoh800774glmre1xhoar"},{"post_id":"cjskffob6004l4glmqm30j57m","tag_id":"cjskffogt00754glmti4rnb9u","_id":"cjskffoh8007c4glmb7o5p2m5"},{"post_id":"cjskffoch00514glm4f9jv6s9","tag_id":"cjskffoh8007b4glmggfkjdvx","_id":"cjskffoh8007g4glm70jlbl1d"},{"post_id":"cjskffoch00544glm7d4mdooe","tag_id":"cjskffoh8007f4glmlhzqpz12","_id":"cjskffoho007k4glm5wtyodcn"},{"post_id":"cjskffoch00594glm4u1p7r1t","tag_id":"cjskffoh8007j4glm8obhk90m","_id":"cjskffoho007p4glmc7qiqe2g"},{"post_id":"cjskffodc005g4glma7q6mkam","tag_id":"cjskffoho007n4glm6v5djpwt","_id":"cjskffoho007w4glmenc6mxol"},{"post_id":"cjskffodc005g4glma7q6mkam","tag_id":"cjskffoho007r4glm3kboeukl","_id":"cjskffoi4007x4glml8turfir"},{"post_id":"cjskffodc005k4glmrtwkxtca","tag_id":"cjskffoho007u4glm8xzn9loo","_id":"cjskffoi400804glm2gqur2a1"},{"post_id":"cjskffoe7005o4glmug81m8lz","tag_id":"cjskffoh8007b4glmggfkjdvx","_id":"cjskffoi400824glmv8byu562"},{"post_id":"cjskffoen005s4glm4whqaqcz","tag_id":"cjskffoh8007b4glmggfkjdvx","_id":"cjskffoi400844glmwunu5ot0"},{"post_id":"cjskffoen005v4glmfcdb3ouv","tag_id":"cjskffoi400834glmn48dsped","_id":"cjskffoi400864glmopzxvnqi"},{"post_id":"cjskffof2005z4glmmnm381ca","tag_id":"cjskffoho007n4glm6v5djpwt","_id":"cjskffoij00884glmls7tvqao"},{"post_id":"cjskffof200624glm6wco1h12","tag_id":"cjskffoij00874glmk5j8fsfk","_id":"cjskffoij008a4glmb63ontef"},{"post_id":"cjskffof200664glmt91nr1sr","tag_id":"cjskffoho007n4glm6v5djpwt","_id":"cjskffoij008d4glm3obrpe7b"},{"post_id":"cjskffof200664glmt91nr1sr","tag_id":"cjskffoho007r4glm3kboeukl","_id":"cjskffoij008e4glmwkggn4ls"},{"post_id":"cjskffofi00694glm9d7jvqyd","tag_id":"cjskffoij008c4glmbylbeu29","_id":"cjskffoiz008g4glm3su1qrwv"},{"post_id":"cjskffofy006f4glmoe8diwf4","tag_id":"cjskffoij008f4glmu614v3cy","_id":"cjskffoiz008i4glmob4f2kft"},{"post_id":"cjskffofy006i4glmz2iemp4f","tag_id":"cjskffoiz008h4glmvyaif8yf","_id":"cjskffoiz008k4glm3vqbohem"},{"post_id":"cjskffofy006m4glm36r80gyd","tag_id":"cjskffoi400834glmn48dsped","_id":"cjskffoiz008m4glm3um85oq5"},{"post_id":"cjskffogd006p4glmvjahk904","tag_id":"cjskffoiz008l4glmkx19ravz","_id":"cjskffoiz008o4glm39o81f5z"},{"post_id":"cjskffogd006t4glmp6iaok8w","tag_id":"cjskffoho007u4glm8xzn9loo","_id":"cjskffoje008p4glmhc652eeu"},{"post_id":"cjskffp4n008q4glm1ufb6xjy","tag_id":"cjskffp4n008s4glm3dpw2dwp","_id":"cjskffp4n008t4glmuakuq55t"}],"Tag":[{"name":"AngularJS","_id":"cjskffnw000034glm1ez3xn7l"},{"name":"NodeJS","_id":"cjskffnwg00084glm53v3escg"},{"name":"Python","_id":"cjskffnxq000k4glm9zmfr2ka"},{"name":"网站架构","_id":"cjskffny6000q4glmq30qvg89"},{"name":"内存区域","_id":"cjskffnym000w4glmlu7hp29n"},{"name":"Search-algorithm","_id":"cjskffnym00124glmozpwp52n"},{"name":"工作效率","_id":"cjskffnz100164glmh2mbe67o"},{"name":"需求分析","_id":"cjskffnz1001b4glmjc59903l"},{"name":"消息中间件","_id":"cjskffnz1001f4glmsplcemyg"},{"name":"双高架构","_id":"cjskffnz1001j4glmodk0ufu8"},{"name":"IO类","_id":"cjskffnzh001n4glmb9ok6dw3"},{"name":"并发类","_id":"cjskffnzh001v4glmp806aa96"},{"name":"单点登录","_id":"cjskffnzh001y4glma03y18r5"},{"name":"新浪微博","_id":"cjskffo6e00274glmq4yhtxjg"},{"name":"加密解密","_id":"cjskffo7a002d4glmrgz5y7bk"},{"name":"推荐系统","_id":"cjskffo7p002j4glm3z7obvcf"},{"name":"Collection集合类","_id":"cjskffo85002x4glmtslpyhlz"},{"name":"文本挖掘","_id":"cjskffo8k00334glmetfozw8q"},{"name":"内存模型","_id":"cjskffo90003b4glmcyls6l5y"},{"name":"备忘录","_id":"cjskffo9g003i4glmm9zhdidc"},{"name":"Servlet3.0","_id":"cjskffo9g003o4glmtmgh988b"},{"name":"均值算法","_id":"cjskffo9v003v4glm6czrv0wo"},{"name":"ROC曲线","_id":"cjskffoab00444glmka07e4y6"},{"name":"机器学习","_id":"cjskffoaq004b4glmcxx4e3nh"},{"name":"其他","_id":"cjskffogt006z4glmsqdshiad"},{"name":"数据挖掘","_id":"cjskffogt00754glmti4rnb9u"},{"name":"WEB技术","_id":"cjskffoh8007b4glmggfkjdvx"},{"name":"C/C++","_id":"cjskffoh8007f4glmlhzqpz12"},{"name":"爬虫","_id":"cjskffoh8007j4glm8obhk90m"},{"name":"NoSQL","_id":"cjskffoho007n4glm6v5djpwt"},{"name":"mongoDB","_id":"cjskffoho007r4glm3kboeukl"},{"name":"MQ","_id":"cjskffoho007u4glm8xzn9loo"},{"name":"MySQL","_id":"cjskffoi400834glmn48dsped"},{"name":"Mycat","_id":"cjskffoij00874glmk5j8fsfk"},{"name":"编程语言","_id":"cjskffoij008c4glmbylbeu29"},{"name":"JAVA框架","_id":"cjskffoij008f4glmu614v3cy"},{"name":"TiDB","_id":"cjskffoiz008h4glmvyaif8yf"},{"name":"分布式事务","_id":"cjskffoiz008l4glmkx19ravz"},{"name":"工具","_id":"cjskffp4n008s4glm3dpw2dwp"}]}}